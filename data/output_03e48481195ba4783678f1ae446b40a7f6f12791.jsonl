{"id": "a2914e1f917c617fa5c3ab9f8e99015af885622c", "text": "The Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nA Theory,\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nThe Information\n\nA History,\n\nThe Information\n\nThe Information\n\nThe Information\n\nA Flood\n\nThe Information\n\nBy James Gleick\n\nBy James Gleick\n\nBy James Gleick\n\nBy James Gleick\n\nBy James Gleick\n\nBy James Gleick\n\nBy James Gleick\n\nBy James Gleick\n\nBy James Gleick\n\nBy James Gleick\n\nBy James Gleick\n\nBy James Gleick\n\nAuthor of Chaos\n\nAuthor of Chaos\n\nAuthor of Chaos\n\nAuthor of Chaos\n\nAuthor of Chaos\n\nAuthor of Chaos\nTHE INFORMATION\nA HISTORY, A THEORY, A FLOOD\n\n\"AMBITIOUS, ILLUMINATING AND SEXILY THEORETICAL.\"\n\u2014 THE NEW YORK TIMES\nALSO BY JAMES GLEICK\n\nChaos: Making a New Science\nGenius: The Life and Science of Richard Feynman\nFaster: The Acceleration of Just About Everything\nWhat Just Happened: A Chronicle from the Information Frontier\nIsaac Newton\nTHE INFORMATION\nTHE INFORMATION\n\nA History\nA Theory\nA Flood\n\nJAMES GLEICK\n\nPANTHEON BOOKS, NEW YORK\nCopyright \u00a9 2011 by James Gleick\n\nAll rights reserved. Published in the United States by Pantheon Books, a division of Random House, Inc., New York, and in Canada by Random House of Canada Limited, Toronto.\n\nPantheon Books and colophon are registered trademarks of Random House, Inc.\n\nLibrary of Congress Cataloging-in-Publication Data\nGleick, James.\nThe information : a history, a theory, a flood / James Gleick.\np. cm.\nIncludes bibliographical references and index.\neISBN 978-0-307-37957-3\n1. Information science\u2014History. 2. Information society. I. Title.\nZ665.G547 2011 020.9\u2014dc22 2010023221\n\nwww.around.com\n\nwww.pantheonbooks.com\n\nJacket design by Peter Mendelsund\n\nv3.1r3\nFOR CYNTHIA\nThe Information\nAnyway, those tickets, the old ones, they didn\u2019t tell you where you were going, much less where you came from. He couldn\u2019t remember seeing any dates on them, either, and there was certainly no mention of time. It was all different now, of course. All this information. Archie wondered why that was.\n\n\u2014Zadie Smith\n\nWhat we call the past is built on bits.\n\n\u2014John Archibald Wheeler\nThe Information\nContents\n\nPrologue\nChapter 1. Drums That Talk\nChapter 2. The Persistence of the Word\nChapter 3. Two Wordbooks\nChapter 4. To Throw the Powers of Thought into Wheel-Work\nChapter 5. A Nervous System for the Earth\nChapter 6. New Wires, New Logic\nChapter 7. Information Theory\nChapter 8. The Informational Turn\nChapter 9. Entropy and Its Demons\nChapter 10. Life\u2019s Own Code\nChapter 11. Into the Meme Pool\nChapter 12. The Sense of Randomness\nChapter 13. Information Is Physical\nChapter 14. After the Flood\nChapter 15. New News Every Day\nEpilogue\n\nAcknowledgments\nNotes\nBibliography\nIndex\n\nIllustration Credits\nA Note About The Author\nThe Information\nTHE INFORMATION\nJames Gleick\n\nTHE INFORMATION\n\nA History, a Theory, a Flood\nPROLOGUE\n\nThe fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point. Frequently the messages have meaning.\n\n\u2014Claude Shannon (1948)\n\nAFTER 1948, which was the crucial year, people thought they could see the clear purpose that inspired Claude Shannon\u2019s work, but that was hindsight. He saw it differently: My mind wanders around, and I conceive of different things day and night. Like a science-fiction writer, I\u2019m thinking, \u201cWhat if it were like this?\u201d\n\nAs it happened, 1948 was when the Bell Telephone Laboratories announced the invention of a tiny electronic semiconductor, \u201can amazingly simple device\u201d that could do anything a vacuum tube could do and more efficiently. It was a crystalline sliver, so small that a hundred would fit in the palm of a hand. In May, scientists formed a committee to come up with a name, and the committee passed out paper ballots to senior engineers in Murray Hill, New Jersey, listing some choices: semiconductor triode \u2026 iotatron \u2026 transistor (a hybrid of varistor and transconductance). Transistor won out. \u201cIt may have far-reaching significance in electronics and electrical communication,\u201d Bell Labs declared in a press release, and for once the reality surpassed the hype. The transistor sparked the revolution in electronics, setting the technology on its path of miniaturization and ubiquity, and soon won the Nobel Prize for its three chief inventors. For the laboratory it was the jewel in the crown. But it was only the second most significant development of that year. The transistor was only hardware.\n\nAn invention even more profound and more fundamental came in a monograph spread across seventy-nine pages of *The Bell System Technical Journal* in July and October. No one bothered with a press release. It carried a title both simple and grand\u2014\u201cA Mathematical Theory of Communication\u201d\u2014and the message was hard to summarize. But it was a fulcrum around which the world began to turn. Like the transistor, this development also involved a neologism: the word bit, chosen in this case not by committee but by the lone author, a thirty-two-year-old named Claude Shannon. The bit now joined the inch, the pound, the quart, and the minute as a determinate quantity\u2014a fundamental unit of measure.\n\nBut measuring what? \u201cA unit for measuring information,\u201d Shannon wrote, as though there were such a thing, measurable and quantifiable, as information.\n\nShannon supposedly belonged to the Bell Labs mathematical research group, but he mostly kept to himself. When the group left the New York headquarters\nfor shiny new space in the New Jersey suburbs, he stayed behind, haunting a cubbyhole in the old building, a twelve-story sandy brick hulk on West Street, its industrial back to the Hudson River, its front facing the edge of Greenwich Village. He disliked commuting, and he liked the downtown neighborhood, where he could hear jazz clarinetists in late-night clubs. He was flirting shyly with a young woman who worked in Bell Labs\u2019 microwave research group in the two-story former Nabisco factory across the street. People considered him a smart young man. Fresh from MIT he had plunged into the laboratory\u2019s war work, first developing an automatic fire-control director for antiaircraft guns, then focusing on the theoretical underpinnings of secret communication\u2014cryptography\u2014and working out a mathematical proof of the security of the so-called X System, the telephone hotline between Winston Churchill and President Roosevelt. So now his managers were willing to leave him alone, even though they did not understand exactly what he was working on.\n\nAT&T at midcentury did not demand instant gratification from its research division. It allowed detours into mathematics or astrophysics with no apparent commercial purpose. Anyway so much of modern science bore directly or indirectly on the company\u2019s mission, which was vast, monopolistic, and almost all-encompassing. Still, broad as it was, the telephone company\u2019s core subject matter remained just out of focus. By 1948 more than 125 million conversations passed daily through the Bell System\u2019s 138 million miles of cable and 31 million telephone sets. The Bureau of the Census reported these facts under the rubric of \u201cCommunications in the United States,\u201d but they were crude measures of communication. The census also counted several thousand broadcasting stations for radio and a few dozen for television, along with newspapers, books, pamphlets, and the mail. The post office counted its letters and parcels, but what, exactly, did the Bell System carry, counted in what units? Not conversations, surely; nor words, nor certainly characters. Perhaps it was just electricity. The company\u2019s engineers were electrical engineers. Everyone understood that electricity served as a surrogate for sound, the sound of the human voice, waves in the air entering the telephone mouthpiece and converted into electrical waveforms. This conversion was the essence of the telephone\u2019s advance over the telegraph\u2014the predecessor technology, already seeming so quaint. Telegraphy relied on a different sort of conversion: a code of dots and dashes, not based on sounds at all but on the written alphabet, which was, after all, a code in its turn. Indeed, considering the matter closely, one could see a chain of abstraction and conversion: the dots and dashes representing letters of the alphabet; the letters representing sounds, and in combination forming words; the words representing some ultimate substrate of meaning, perhaps best left to philosophers.\n\nThe Bell System had none of those, but the company had hired its first\nmathematician in 1897: George Campbell, a Minnesotan who had studied in G\u00f6ttingen and Vienna. He immediately confronted a crippling problem of early telephone transmission. Signals were distorted as they passed across the circuits; the greater the distance, the worse the distortion. Campbell\u2019s solution was partly mathematics and partly electrical engineering. His employers learned not to worry much about the distinction. Shannon himself, as a student, had never been quite able to decide whether to become an engineer or a mathematician. For Bell Labs he was both, willy-nilly, practical about circuits and relays but happiest in a realm of symbolic abstraction. Most communications engineers focused their expertise on physical problems, amplification and modulation, phase distortion and signal-to-noise degradation. Shannon liked games and puzzles. Secret codes entranced him, beginning when he was a boy reading Edgar Allan Poe. He gathered threads like a magpie. As a first-year research assistant at MIT, he worked on a hundred-ton proto-computer, Vannevar Bush\u2019s Differential Analyzer, which could solve equations with great rotating gears, shafts, and wheels. At twenty-two he wrote a dissertation that applied a nineteenth-century idea, George Boole\u2019s algebra of logic, to the design of electrical circuits. (Logic and electricity\u2014a peculiar combination.) Later he worked with the mathematician and logician Hermann Weyl, who taught him what a theory was: \u201cTheories permit consciousness to \u2018jump over its own shadow,\u2019 to leave behind the given, to represent the transcendent, yet, as is self-evident, only in symbols.\u201d\n\nIn 1943 the English mathematician and code breaker Alan Turing visited Bell Labs on a cryptographic mission and met Shannon sometimes over lunch, where they traded speculation on the future of artificial thinking machines. (\u201cShannon wants to feed not just data to a Brain, but cultural things!\u201d Turing exclaimed. \u201cHe wants to play music to it!\u201d) Shannon also crossed paths with Norbert Wiener, who had taught him at MIT and by 1948 was proposing a new discipline to be called \u201ccybernetics,\u201d the study of communication and control. Meanwhile Shannon began paying special attention to television signals, from a peculiar point of view: wondering whether their content could be somehow compacted or compressed to allow for faster transmission. Logic and circuits crossbred to make a new, hybrid thing; so did codes and genes. In his solitary way, seeking a framework to connect his many threads, Shannon began assembling a theory for information.\n\nThe raw material lay all around, glistening and buzzing in the landscape of the early twentieth century, letters and messages, sounds and images, news and instructions, figures and facts, signals and signs: a hodgepodge of related species. They were on the move, by post or wire or electromagnetic wave. But no one word denoted all that stuff. \u201cOff and on,\u201d Shannon wrote to Vannever Bush at\nMIT in 1939, \u201cI have been working on an analysis of some of the fundamental properties of general systems for the transmission of intelligence.\u201d *Intelligence*: that was a flexible term, very old. \u201cNowe used for an elegant worde,\u201d Sir Thomas Elyot wrote in the sixteenth century, \u201cwhere there is mutuall treaties or appoyntementes, eyther by letters or message.\u201d It had taken on other meanings, though. A few engineers, especially in the telephone labs, began speaking of *information*. They used the word in a way suggesting something technical: quantity of information, or measure of information. Shannon adopted this usage.\n\nFor the purposes of science, *information* had to mean something special. Three centuries earlier, the new discipline of physics could not proceed until Isaac Newton appropriated words that were ancient and vague\u2014*force*, *mass*, *motion*, and even *time*\u2014and gave them new meanings. Newton made these terms into quantities, suitable for use in mathematical formulas. Until then, *motion* (for example) had been just as soft and inclusive a term as *information*. For Aristotelians, motion covered a far-flung family of phenomena: a peach ripening, a stone falling, a child growing, a body decaying. That was too rich. Most varieties of motion had to be tossed out before Newton\u2019s laws could apply and the Scientific Revolution could succeed. In the nineteenth century, *energy* began to undergo a similar transformation: natural philosophers adapted a word meaning vigor or intensity. They mathematicized it, giving energy its fundamental place in the physicists\u2019 view of nature.\n\nIt was the same with information. A rite of purification became necessary.\n\nAnd then, when it was made simple, distilled, counted in bits, information was found to be everywhere. Shannon\u2019s theory made a bridge between information and uncertainty; between information and entropy; and between information and chaos. It led to compact discs and fax machines, computers and cyberspace, Moore\u2019s law and all the world\u2019s Silicon Alleys. Information processing was born, along with information storage and information retrieval. People began to name a successor to the Iron Age and the Steam Age. \u201cMan the food-gatherer reappears incongruously as information-gatherer,\u201d remarked Marshall McLuhan in 1967.* He wrote this an instant too soon, in the first dawn of computation and cyberspace.\n\nWe can see now that information is what our world runs on: the blood and the fuel, the vital principle. It pervades the sciences from top to bottom, transforming every branch of knowledge. Information theory began as a bridge from mathematics to electrical engineering and from there to computing. What English speakers call \u201ccomputer science\u201d Europeans have known as *informatique*, *informatica*, and *Informatik*. Now even biology has become an information science, a subject of messages, instructions, and code. Genes encapsulate information and enable procedures for reading it in and writing it out. Life\nspreads by networking. The body itself is an information processor. Memory resides not just in brains but in every cell. No wonder genetics bloomed along with information theory. DNA is the quintessential information molecule, the most advanced message processor at the cellular level\u2014an alphabet and a code, 6 billion bits to form a human being. \u201cWhat lies at the heart of every living thing is not a fire, not warm breath, not a \u2018spark of life,\u2019 \u201d declares the evolutionary theorist Richard Dawkins. \u201cIt is information, words, instructions\u2026. If you want to understand life, don\u2019t think about vibrant, throbbing gels and oozes, think about information technology.\u201d The cells of an organism are nodes in a richly interwoven communications network, transmitting and receiving, coding and decoding. Evolution itself embodies an ongoing exchange of information between organism and environment.\n\n\u201cThe information circle becomes the unit of life,\u201d says Werner Loewenstein after thirty years spent studying intercellular communication. He reminds us that information means something deeper now: \u201cIt connotes a cosmic principle of organization and order, and it provides an exact measure of that.\u201d The gene has its cultural analog, too: the meme. In cultural evolution, a meme is a replicator and propagator\u2014an idea, a fashion, a chain letter, or a conspiracy theory. On a bad day, a meme is a virus.\n\nEconomics is recognizing itself as an information science, now that money itself is completing a developmental arc from matter to bits, stored in computer memory and magnetic strips, world finance coursing through the global nervous system. Even when money seemed to be material treasure, heavy in pockets and ships\u2019 holds and bank vaults, it always was information. Coins and notes, shekels and cowries were all just short-lived technologies for tokenizing information about who owns what.\n\nAnd atoms? Matter has its own coinage, and the hardest science of all, physics, seemed to have reached maturity. But physics, too, finds itself sideswiped by a new intellectual model. In the years after World War II, the heyday of the physicists, the great news of science appeared to be the splitting of the atom and the control of nuclear energy. Theorists focused their prestige and resources on the search for fundamental particles and the laws governing their interaction, the construction of giant accelerators and the discovery of quarks and gluons. From this exalted enterprise, the business of communications research could not have appeared further removed. At Bell Labs, Claude Shannon was not thinking about physics. Particle physicists did not need bits.\n\nAnd then, all at once, they did. Increasingly, the physicists and the information theorists are one and the same. The bit is a fundamental particle of a different sort: not just tiny but abstract\u2014a binary digit, a flip-flop, a yes-or-no. It is insubstantial, yet as scientists finally come to understand information, they wonder whether it\nmay be primary: more fundamental than matter itself. They suggest that the bit is the irreducible kernel and that information forms the very core of existence. Bridging the physics of the twentieth and twenty-first centuries, John Archibald Wheeler, the last surviving collaborator of both Einstein and Bohr, put this manifesto in oracular monosyllables: \u201cIt from Bit.\u201d Information gives rise to \u201cevery it\u2014every particle, every field of force, even the spacetime continuum itself.\u201d This is another way of fathoming the paradox of the observer: that the outcome of an experiment is affected, or even determined, when it is observed. Not only is the observer observing, she is asking questions and making statements that must ultimately be expressed in discrete bits. \u201cWhat we call reality,\u201d Wheeler wrote coyly, \u201carises in the last analysis from the posing of yes-no questions.\u201d He added: \u201cAll things physical are information-theoretic in origin, and this is a participatory universe.\u201d The whole universe is thus seen as a computer\u2014a cosmic information-processing machine.\n\nA key to the enigma is a type of relationship that had no place in classical physics: the phenomenon known as entanglement. When particles or quantum systems are entangled, their properties remain correlated across vast distances and vast times. Light-years apart, they share something that is physical, yet not only physical. Spooky paradoxes arise, unresolvable until one understands how entanglement encodes information, measured in bits or their drolly named quantum counterpart, qubits. When photons and electrons and other particles interact, what are they really doing? Exchanging bits, transmitting quantum states, processing information. The laws of physics are the algorithms. Every burning star, every silent nebula, every particle leaving its ghostly trace in a cloud chamber is an information processor. The universe computes its own destiny.\n\nHow much does it compute? How fast? How big is its total information capacity, its memory space? What is the link between energy and information; what is the energy cost of flipping a bit? These are hard questions, but they are not as mystical or metaphorical as they sound. Physicists and quantum information theorists, a new breed, struggle with them together. They do the math and produce tentative answers. (\u201cThe bit count of the cosmos, however it is figured, is ten raised to a very large power,\u201d according to Wheeler. According to Seth Lloyd: \u201cNo more than $10^{120}$ ops on $10^{90}$ bits.\u201d) They look anew at the mysteries of thermodynamic entropy and at those notorious information swallowers, black holes. \u201cTomorrow,\u201d Wheeler declares, \u201cwe will have learned to understand and express all of physics in the language of information.\u201d\n\nAs the role of information grows beyond anyone\u2019s reckoning, it grows to be too much. \u201cTMI,\u201d people now say. We have information fatigue, anxiety, and glut. We have met the Devil of Information Overload and his impish underlings, the\ncomputer virus, the busy signal, the dead link, and the PowerPoint presentation. All this, too, is due in its roundabout way to Shannon. Everything changed so quickly. John Robinson Pierce (the Bell Labs engineer who had come up with the word *transistor*) mused afterward: \u201cIt is hard to picture the world before Shannon as it seemed to those who lived in it. It is difficult to recover innocence, ignorance, and lack of understanding.\u201d\n\nYet the past does come back into focus. *In the beginning was the word*, according to John. We are the species that named itself *Homo sapiens*, the one who knows\u2014and then, after reflection, amended that to *Homo sapiens sapiens*. The greatest gift of Prometheus to humanity was not fire after all: \u201cNumbers, too, chiefest of sciences, I invented for them, and the combining of letters, creative mother of the Muses\u2019 arts, with which to hold all things in memory.\u201d The alphabet was a founding technology of information. The telephone, the fax machine, the calculator, and, ultimately, the computer are only the latest innovations devised for saving, manipulating, and communicating knowledge. Our culture has absorbed a working vocabulary for these useful inventions. We speak of compressing data, aware that this is quite different from compressing a gas. We know about streaming information, parsing it, sorting it, matching it, and filtering it. Our furniture includes iPods and plasma displays, our skills include texting and Googling, we are endowed, we are expert, so we see information in the foreground. But it has always been there. It pervaded our ancestors\u2019 world, too, taking forms from solid to ethereal, granite gravestones and the whispers of courtiers. The punched card, the cash register, the nineteenth-century Difference Engine, the wires of telegraphy all played their parts in weaving the spiderweb of information to which we cling. Each new information technology, in its own time, set off blooms in storage and transmission. From the printing press came new species of information organizers: dictionaries, cyclopaedias, almanacs\u2014compendiums of words, classifiers of facts, trees of knowledge. Hardly any information technology goes obsolete. Each new one throws its predecessors into relief. Thus Thomas Hobbes, in the seventeenth century, resisted his era\u2019s new-media hype: \u201cThe invention of printing, though ingenious, compared with the invention of letters is no great matter.\u201d Up to a point, he was right. Every new medium transforms the nature of human thought. In the long run, history is the story of information becoming aware of itself.\n\nSome information technologies were appreciated in their own time, but others were not. One that was sorely misunderstood was the African talking drum.\n\n* And added drily: \u201cIn this role, electronic man is no less a nomad than his Paleolithic ancestors.\u201d\n1 | DRUMS THAT TALK\n\n(When a Code Is Not a Code)\n\nAcross the Dark Continent sound the never-silent drums:\nthe base of all the music, the focus of every dance;\nthe talking drums, the wireless of the unmapped jungle.\n\n\u2014Irma Wassall (1943)\n\nNO ONE SPOKE SIMPLY ON THE DRUMS. Drummers would not say, \u201cCome back home,\u201d but rather,\n\nMake your feet come back the way they went,\nmake your legs come back the way they went,\nplant your feet and your legs below,\nin the village which belongs to us.\n\nThey could not just say \u201ccorpse\u201d but would elaborate: \u201cwhich lies on its back on clods of earth.\u201d Instead of \u201cdon\u2019t be afraid,\u201d they would say, \u201cBring your heart back down out of your mouth, your heart out of your mouth, get it back down from there.\u201d The drums generated fountains of oratory. This seemed inefficient. Was it grandiloquence or bombast? Or something else?\n\nFor a long time Europeans in sub-Saharan Africa had no idea. In fact they had no idea that the drums conveyed information at all. In their own cultures, in special cases a drum could be an instrument of signaling, along with the bugle and the bell, used to transmit a small set of messages: attack; retreat; come to church. But they could not conceive of talking drums. In 1730 Francis Moore sailed eastward up the Gambia River, finding it navigable for six hundred miles, all the way admiring the beauty of the country and such curious wonders as \u201coysters that grew upon trees\u201d (mangroves). He was not much of a naturalist. He was reconnoitering as an agent for English slavers in kingdoms inhabited, as he saw it, by different races of people of black or tawny colors, \u201cas Mundingoes, Jolloiffs, Pholeys, Floops, and Portuguese.\u201d When he came upon men and women carrying drums, carved wood as much as a yard long, tapered from top to bottom, he noted that women danced briskly to their music, and sometimes that the drums were \u201cbeat on the approach of an enemy,\u201d and finally, \u201con some very extraordinary occasions,\u201d that the drums summoned help from neighboring towns. But that was all he noticed.\nA century later, Captain William Allen, on an expedition to the Niger River,* made a further discovery, by virtue of paying attention to his Cameroon pilot, whom he called Glasgow. They were in the cabin of the iron paddle ship when, as Allen recalled:\n\nSuddenly he became totally abstracted, and remained for a while in the attitude of listening. On being taxed with inattention, he said, \u201cYou no hear my son speak?\u201d As we had heard no voice, he was asked how he knew it. He said, \u201cDrum speak me, tell me come up deck.\u201d This seemed to be very singular.\n\nThe captain\u2019s skepticism gave way to amazement, as Glasgow convinced him that every village had this \u201cfacility of musical correspondence.\u201d Hard though it was to believe, the captain finally accepted that detailed messages of many sentences could be conveyed across miles. \u201cWe are often surprised,\u201d he wrote, \u201cto find the sound of the trumpet so well understood in our military evolutions; but how far short that falls of the result arrived at by those untutored savages.\u201d That result was a technology much sought in Europe: long-distance communication faster than any traveler on foot or horseback. Through the still night air over a river, the thump of the drum could carry six or seven miles. Relayed from village to village, messages could rumble a hundred miles or more in a matter of an hour.\n\nA birth announcement in Bolenge, a village of the Belgian Congo, went like this:\n\n*Batoko fala fala, tokema bolo bolo, boseka woliana imaki tonkilingonda, ale nda bobila wa fole fole, asokoka l\u2019isika koke koke.*\n\nThe mats are rolled up, we feel strong, a woman came from the forest, she is in the open village, that is enough for this time.\n\nA missionary, Roger T. Clarke, transcribed this call to a fisherman\u2019s funeral:\n\n*La nkesa laa mpombolo, tofolange benteke biesala, tolanga bonteke bolokolo bole nda elinga l\u2019enjale baenga, basaki l\u2019okala bopele pele. Bojende bosalaki lifeta Bolenge wa kala kala, tekendake tonkilingonda, tekendake beningo la nkaka elinga l\u2019enjale. Tolanga bonteke bolokolo bole nda elinga l\u2019enjale, la nkesa la mpombolo.*\n\nIn the morning at dawn, we do not want gatherings for work, we want a meeting of play on the river. Men who live in Bolenge, do not go to the forest, do not go fishing. We want a meeting of play on the river, in the morning at dawn.\n\nClarke noted several facts. While only some people learned to communicate by drum, almost anyone could understand the messages in the drumbeats. Some people drummed rapidly and some slowly. Set phrases would recur again and again, virtually unchanged, yet different drummers would send the same message with different wording. Clarke decided that the drum language was at once formulaic and fluid. \u201cThe signals represent the tones of the syllables of conventional phrases of a traditional and highly poetic character,\u201d he concluded, and this was correct, but he could not take the last step toward understanding why.\nThese Europeans spoke of \u201cthe native mind\u201d and described Africans as \u201cprimitive\u201d and \u201canimistic\u201d and nonetheless came to see that they had achieved an ancient dream of every human culture. Here was a messaging system that outpaced the best couriers, the fastest horses on good roads with way stations and relays. Earth-bound, foot-based messaging systems always disappointed. Their armies outran them. Julius Caesar, for example, was \u201cvery often arriving before the messengers sent to announce his coming,\u201d as Suetonius reported in the first century. The ancients were not without resources, however. The Greeks used fire beacons at the time of the Trojan War, in the twelfth century BCE, by all accounts\u2014that is, those of Homer, Virgil, and Aeschylus. A bonfire on a mountaintop could be seen from watchtowers twenty miles distant, or in special cases even farther. In the Aeschylus version, Clytemnestra gets the news of the fall of Troy that very night, four hundred miles away in Mycenae. \u201cYet who so swift could speed the message here?\u201d the skeptical Chorus asks.\n\nShe credits Hephaestus, god of fire: \u201cSent forth his sign; and on, and ever on, beacon to beacon sped the courier-flame.\u201d This is no small accomplishment, and the listener needs convincing, so Aeschylus has Clytemnestra continue for several minutes with every detail of the route: the blazing signal rose from Mount Ida, carried across the northern Aegean Sea to the island of Lemnos; from there to Mount Athos in Macedonia; then southward across plains and lakes to Macistus; Messapius, where the watcher \u201csaw the far flame gleam on Euripus\u2019 tide, and from the high-piled heap of withered furze lit the new sign and bade the message on\u201d; Cithaeron; Aegiplanetus; and her own town\u2019s mountain watch, Arachne. \u201cSo sped from stage to stage, fulfilled in turn, flame after flame,\u201d she boasts, \u201calong the course ordained.\u201d A German historian, Richard Hennig, traced and measured the route in 1908 and confirmed the feasibility of this chain of bonfires. The meaning of the message had, of course, to be prearranged, effectively condensed into a single bit. A binary choice, something or nothing: the fire signal meant something, which, just this once, meant \u201cTroy has fallen.\u201d To transmit this one bit required immense planning, labor, watchfulness, and firewood. Many years later, lanterns in Old North Church likewise sent Paul Revere a single precious bit, which he carried onward, one binary choice: by land or by sea.\n\nMore capacity was required, for less extraordinary occasions. People tried flags, horns, intermitting smoke, and flashing mirrors. They conjured spirits and angels for purposes of communication\u2014angels being divine messengers, by definition. The discovery of magnetism held particular promise. In a world already suffused with magic, magnets embodied occult powers. The lodestone attracts iron. This power of attraction extends invisibly through the air. Nor is it interrupted by water or even solid bodies. A lodestone held on one side of a wall can move a piece of iron on the other side. Most intriguing, the magnetic power appears able\nto coordinate objects vast distances apart, across the whole earth: namely, compass needles. What if one needle could control another? This idea spread\u2014a \u201cconceit,\u201d Thomas Browne wrote in the 1640s,\n\nwhispered thorow the world with some attention, credulous and vulgar auditors readily believing it, and more judicious and distinctive heads, not altogether rejecting it. The conceit is excellent, and if the effect would follow, somewhat divine; whereby we might communicate like spirits, and confer on earth with Menippus in the Moon.\n\nThe idea of \u201csympathetic\u201d needles appeared wherever there were natural philosophers and confidence artists. In Italy a man tried to sell Galileo \u201ca secret method of communicating with a person two or three thousand miles away, by means of a certain sympathy of magnetic needles.\u201d\n\nI told him that I would gladly buy, but wanted to see by experiment and that it would be enough for me if he would stand in one room and I in another. He replied that its operation could not be detected at such a short distance. I sent him on his way, with the remark that I was not in the mood at that time to go to Cairo or Moscow for the experiment, but that if he wanted to go I would stay in Venice and take care of the other end.\n\nThe idea was that if a pair of needles were magnetized together\u2014\u201ctouched with the same Loadstone,\u201d as Browne put it\u2014they would remain in sympathy from then on, even when separated by distance. One might call this \u201centanglement.\u201d A sender and a recipient would take the needles and agree on a time to communicate. They would place their needle in disks with the letters of the alphabet spaced around the rim. The sender would spell out a message by turning the needle. \u201cFor then, saith tradition,\u201d Browne explained, \u201cat what distance of place soever, when one needle shall be removed unto any letter, the other by a wonderfull sympathy will move unto the same.\u201d Unlike most people who considered the idea of sympathetic needles, however, Browne actually tried the experiment. It did not work. When he turned one needle, the other stood still.\n\nBrowne did not go so far as to rule out the possibility that this mysterious force could someday be used for communication, but he added one more caveat. Even if magnetic communication at a distance was possible, he suggested, a problem might arise when sender and receiver tried to synchronize their actions. How would they know the time,\n\nit being no ordinary or Almanack business, but a probleme Mathematical, to finde out the difference of hours in different places; nor do the wisest exactly satisfy themselves in all. For the hours of several places anticipate each other, according to their Longitudes; which are not exactly discovered of every place.\n\nThis was a prescient thought, and entirely theoretical, a product of new seventeenth-century knowledge of astronomy and geography. It was the first crack in the hitherto solid assumption of simultaneity. Anyway, as Browne noted, experts differed. Two more centuries would pass before anyone could actually\ntravel fast enough, or communicate fast enough, to experience local time differences. For now, in fact, no one in the world could communicate as much, as fast, as far as unlettered Africans with their drums.\n\n\u2014\n\nBy the time Captain Allen discovered the talking drums in 1841, Samuel F. B. Morse was struggling with his own percussive code, the electromagnetic drumbeat designed to pulse along the telegraph wire. Inventing a code was a complex and delicate problem. He did not even think in terms of a code, at first, but \u201ca system of signs for letters, to be indicated and marked by a quick succession of strokes or shocks of the galvanic current.\u201d The annals of invention offered scarcely any precedent. How to convert information from one form, the everyday language, into another form suitable for transmission by wire taxed his ingenuity more than any mechanical problem of the telegraph. It is fitting that history attached Morse\u2019s name to his code, more than to his device.\n\nHe had at hand a technology that seemed to allow only crude pulses, bursts of current on and off, an electrical circuit closing and opening. How could he convey language through the clicking of an electromagnet? His first idea was to send numbers, a digit at a time, with dots and pauses. The sequence $\\ldots \\cdot \\cdot \\cdot \\cdot \\cdot$ would mean 325. Every English word would be assigned a number, and the telegraphists at each end of the line would look them up in a special dictionary. Morse set about creating this dictionary himself, wasting many hours inscribing it on large folios.* He claimed the idea in his first telegraph patent, in 1840:\n\nThe dictionary or vocabulary consists of words alphabetically arranged and regularly numbered, beginning with the letters of the alphabet, so that each word in the language has its telegraphic number, and is designated at pleasure, through the signs of numerals.\n\nSeeking efficiency, he weighed the costs and possibilities across several intersecting planes. There was the cost of transmission itself: the wires would be expensive and would convey only so many pulses per minute. Numbers would be relatively easy to transmit. But then there was the extra cost in time and difficulty for the telegraphists. The idea of code books\u2014lookup tables\u2014still had possibilities, and it echoed into the future, arising again in other technologies. Eventually it worked for Chinese telegraphy. But Morse realized that it would be hopelessly cumbersome for operators to page through a dictionary for every word.\n\nHis prot\u00e9g\u00e9 Alfred Vail, meanwhile, was developing a simple lever key by which an operator could rapidly close and open the electric circuit. Vail and Morse turned to the idea of a coded alphabet, using signs as surrogates for the letters and thus spelling out every word. Somehow the bare signs would have to stand in for all the words of the spoken or written language. They had to map the\nentire language onto a single dimension of pulses. At first they conceived of a system built on two elements: the clicks (now called dots) and the spaces in between. Then, as they fiddled with the prototype keypad, they came up with a third sign: the line or dash, \u201cwhen the circuit was closed a longer time than was necessary to make a dot.\u201d (The code became known as the dot-and-dash alphabet, but the unmentioned space remained just as important; Morse code was not a binary language.*) That humans could learn this new language was, at first, wondrous. They would have to master the coding system and then perform a continuous act of double translation: language to signs; mind to fingers. One witness was amazed at how the telegraphists internalized these skills:\n\nThe clerks who attend at the recording instrument become so expert in their curious hieroglyphics, that they do not need to look at the printed record to know what the message under reception is; the recording instrument has for them an intelligible articulate language. They understand its speech. They can close their eyes and listen to the strange clicking that is going on close to their ear whilst the printing is in progress, and at once say what it all means.\n\nIn the name of speed, Morse and Vail had realized that they could save strokes by reserving the shorter sequences of dots and dashes for the most common letters. But which letters would be used most often? Little was known about the alphabet\u2019s statistics. In search of data on the letters\u2019 relative frequencies, Vail was inspired to visit the local newspaper office in Morristown, New Jersey, and look over the type cases. He found a stock of twelve thousand E\u2019s, nine thousand T\u2019s, and only two hundred Z\u2019s. He and Morse rearranged the alphabet accordingly. They had originally used dash-dash-dot to represent T, the second most common letter; now they promoted T to a single dash, thus saving telegraph operators uncountable billions of key taps in the world to come. Long afterward, information theorists calculated that they had come within 15 percent of an optimal arrangement for telegraphing English text.\n\nNo such science, no such pragmatism informed the language of the drums. Yet there had been a problem to solve, just as there was in the design of a code for telegraphers: how to map an entire language onto a one-dimensional stream of the barest sounds. This design problem was solved collectively by generations of drummers in a centuries-long process of social evolution. By the early twentieth century the analogy to the telegraph was apparent to Europeans studying Africa. \u201cOnly a few days ago I read in the Times,\u201d Captain Robert Sutherland Rattray reported to the Royal African Society in London, \u201chow a resident in one part of Africa heard of the death\u2014in another and far remote part of the continent\u2014of a European baby, and how this news was carried by means of drums, which were used, it was stated, \u2018on the Morse principle\u2019\u2014it is always \u2018the Morse principle.\u2019\u201d\n\nBut the obvious analogy led people astray. They failed to decipher the code of\nthe drums because, in effect, there was no code. Morse had bootstrapped his system from a middle symbolic layer, the written alphabet, intermediate between speech and his final code. His dots and dashes had no direct connection to sound; they represented letters, which formed written words, which represented the spoken words in turn. The drummers could not build on an intermediate code\u2014they could not abstract through a layer of symbols\u2014because the African languages, like all but a few dozen of the six thousand languages spoken in the modern world, lacked an alphabet. The drums metamorphosed speech.\n\nIt fell to John F. Carrington to explain. An English missionary, born in 1914 in Northamptonshire, Carrington left for Africa at the age of twenty-four and Africa became his lifetime home. The drums caught his attention early, as he traveled from the Baptist Missionary Society station in Yakusu, on the Upper Congo River, through the villages of the Bambole forest. One day he made an impromptu trip to the small town of Yaongama and was surprised to find a teacher, medical assistant, and church members already assembled for his arrival. They had heard the drums, they explained. Eventually he realized that the drums conveyed not just announcements and warnings but prayers, poetry, and even jokes. The drummers were not signaling but talking: they spoke a special, adapted language.\n\nEventually Carrington himself learned to drum. He drummed mainly in Kele, a language of the Bantu family in what is now eastern Zaire. \u201cHe is not really a European, despite the color of his skin,\u201d a Lokele villager said of Carrington. \u201cHe used to be from our village, one of us. After he died, the spirits made a mistake and sent him off far away to a village of whites to enter into the body of a little baby who was born of a white woman instead of one of ours. But because he belongs to us, he could not forget where he came from and so he came back.\u201d The villager added generously, \u201cIf he is a bit awkward on the drums, this is because of the poor education that the whites gave him.\u201d Carrington\u2019s life in Africa spanned four decades. He became an accomplished botanist, anthropologist, and above all linguist, authoritative on the structure of African language families: thousands of dialects and several hundred distinct languages. He noticed how loquacious a good drummer had to be. He finally published his discoveries about drums in 1949, in a slim volume titled *The Talking Drums of Africa*.\n\nIn solving the enigma of the drums, Carrington found the key in a central fact about the relevant African languages. They are tonal languages, in which meaning is determined as much by rising or falling pitch contours as by distinctions between consonants or vowels. This feature is missing from most Indo-European languages, including English, which uses tone only in limited, syntactical ways: for example, to distinguish questions (\u201cyou are happy \u2191\u201d) from declarations (\u201cyou are happy \u2193\u201d). But for other languages, including, most famously, Mandarin and Cantonese, tone has primary significance in\ndistinguishing words. So it does in most African languages. Even when Europeans learned to communicate in these languages, they generally failed to grasp the importance of tonality, because they had no experience with it. When they transliterated the words they heard into the Latin alphabet, they disregarded pitch altogether. In effect, they were color-blind.\n\nThree different Kele words are transliterated by Europeans as *lisaka*. The words are distinguished only by their speech-tones. Thus *lisaka* with three low syllables is a puddle; *lisa*ka, the last syllable rising (not necessarily stressed) is a promise; and *li*saka is a poison. *Li*da means fianc\u00e9e and *li*la, rubbish pit. In transliteration they appear to be homonyms, but they are not. Carrington, after the light dawned, recalled, \u201cI must have been guilty many a time of asking a boy to \u2018paddle for a book\u2019 or to \u2018fish that his friend is coming.\u2019\u201d Europeans just lacked the ear for the distinctions. Carrington saw how comical the confusion could become:\n\n- *alambaka boili* [\u2013 _ \u2013 \u2013 _ _ _] = he watched the riverbank\n- *alambaka boili* [\u2013 \u2013 \u2013 \u2013 _ _ _] = he boiled his mother-in-law\n\nSince the late nineteenth century, linguists have identified the phoneme as the smallest acoustic unit that makes a difference in meaning. The English word *chuck* comprises three phonemes: different meanings can be created by changing *ch* to *d*, or *u* to *e*, or *ck* to *m*. It is a useful concept but an imperfect one: linguists have found it surprisingly difficult to agree on an exact inventory of phonemes for English or any other language (most estimates for English are in the vicinity of forty-five). The problem is that a stream of speech is a continuum; a linguist may abstractly, and arbitrarily, break it into discrete units, but the meaningfulness of these units varies from speaker to speaker and depends on the context. Most speakers\u2019 instincts about phonemes are biased, too, by their knowledge of the written alphabet, which codifies language in its own sometimes arbitrary ways. In any case, tonal languages, with their extra variable, contain many more phonemes than were first apparent to inexperienced linguists.\n\nAs the spoken languages of Africa elevated tonality to a crucial role, the drum language went a difficult step further. It employed tone and only tone. It was a language of a single pair of phonemes, a language composed entirely of pitch contours. The drums varied in materials and craft. Some were slit gongs, tubes of padauk wood, hollow, cut with a long and narrow mouth to make a high-sounding lip and a low-sounding lip; others had skin tops, and these were used in pairs. All that mattered was for the drums to sound two distinct notes, at an interval of about a major third.\n\nSo in mapping the spoken language to the drum language, information was lost. The drum talk was speech with a deficit. For every village and every tribe, the\nThe Information\n\ndrum language began with the spoken word and shed the consonants and vowels. That was a lot to lose. The remaining information stream would be riddled with ambiguity. A double stroke on the high-tone lip of the drum [\u2013 \u2013] matched the tonal pattern of the Kele word for father, sango, but naturally it could just as well be songe, the moon; koko, fowl; fele, a species of fish; or any other word of two high tones. Even the limited dictionary of the missionaries at Yakusu contained 130 such words. Having reduced spoken words, in all their sonic richness, to such a minimal code, how could the drums distinguish them? The answer lay partly in stress and timing, but these could not compensate for the lack of consonants and vowels. Thus, Carrington discovered, a drummer would invariably add \u201ca little phrase\u201d to each short word. Songe, the moon, is rendered as songe li tange la manga\u2014\u201cthe moon looks down at the earth.\u201d Koko, the fowl, is rendered koko olongo la bokiokio\u2014\u201cthe fowl, the little one that says kiokio.\u201d The extra drumbeats, far from being extraneous, provide context. Every ambiguous word begins in a cloud of possible alternative interpretations; then the unwanted possibilities evaporate. This takes place below the level of consciousness. Listeners are hearing only staccato drum tones, low and high, but in effect they \u201chear\u201d the missing consonants and vowels, too. For that matter, they hear whole phrases, not individual words. \u201cAmong peoples who know nothing of writing or grammar, a word per se, cut out of its sound group, seems almost to cease to be an intelligible articulation,\u201d Captain Rattray reported.\n\nThe stereotyped long tails flap along, their redundancy overcoming ambiguity. The drum language is creative, freely generating neologisms for innovations from the north: steamboats, cigarettes, and the Christian god being three that Carrington particularly noted. But drummers begin by learning the traditional fixed formulas. Indeed, the formulas of the African drummers sometimes preserve archaic words that have been forgotten in the everyday language. For the Yaunde, the elephant is always \u201cthe great awkward one.\u201d The resemblance to Homeric formulas\u2014not merely Zeus, but Zeus the cloud-gatherer; not just the sea, but the wine-dark sea\u2014is no accident. In an oral culture, inspiration has to serve clarity and memory first. The Muses are the daughters of Mnemosyne.\n\nNeither Kele nor English yet had words to say, allocate extra bits for disambiguation and error correction. Yet this is what the drum language did. Redundancy\u2014inefficient by definition\u2014serves as the antidote to confusion. It provides second chances. Every natural language has redundancy built in; this is why people can understand text riddled with errors and why they can understand conversation in a noisy room. The natural redundancy of English motivates the famous New York City subway poster of the 1970s (and the poem by James Merrill),\nif u cn rd ths\nu cn gt a gd jb w hi pa!\n\n(\"This counterspell may save your soul,\" Merrill adds.) Most of the time, redundancy in language is just part of the background. For a telegraphist it is an expensive waste. For an African drummer it is essential. Another specialized language provides a perfect analog: the language of aviation radio. Numbers and letters make up much of the information passed between pilots and air traffic controllers: altitudes, vectors, aircraft tail numbers, runway and taxiway identifiers, radio frequencies. This is critical communication over a notoriously noisy channel, so a specialized alphabet is employed to minimize ambiguity. The spoken letters B and V are easy to confuse; bravo and victor are safer. M and N become mike and november. In the case of numbers, five and nine, particularly prone to confusion, are spoken as fife and niner. The extra syllables perform the same function as the extra verbosity of the talking drums.\n\nAfter publishing his book, John Carrington came across a mathematical way to understand this point. A paper by a Bell Labs telephone engineer, Ralph Hartley, even had a relevant-looking formula: $H = n \\log s$, where $H$ is the amount of information, $n$ is the number of symbols in the message, and $s$ is the number of symbols available in the language. Hartley\u2019s younger colleague Claude Shannon later pursued this lead, and one of his touchstone projects became a precise measurement of the redundancy in English. Symbols could be words, phonemes, or dots and dashes. The degree of choice within a symbol set varied\u2014a thousand words or forty-five phonemes or twenty-six letters or three types of interruption in an electrical circuit. The formula quantified a simple enough phenomenon (simple, anyway, once it was noticed): the fewer symbols available, the more of them must be transmitted to get across a given amount of information. For the African drummers, messages need to be about eight times as long as their spoken equivalents.\n\nHartley took some pains to justify his use of the word information. \u201cAs commonly used, information is a very elastic term,\u201d he wrote, \u201cand it will first be necessary to set up for it a more specific meaning.\u201d He proposed to think of information \u201cphysically\u201d\u2014his word\u2014rather than psychologically. He found the complications multiplying. Somewhat paradoxically, the complexity arose from the intermediate layers of symbols: letters of the alphabet, or dots and dashes, which were discrete and therefore easily countable in themselves. Harder to measure were the connections between these stand-ins and the bottom layer: the human voice itself. It was this stream of meaningful sound that still seemed, to a telephone engineer as much as an African drummer, the real stuff of communication, even if the sound, in turn, served as a code for the knowledge or meaning below. In any case Hartley thought an engineer should be able to\nThe Information\n\ngeneralize over all cases of communication: writing and telegraph codes as well as the physical transmission of sound by means of electromagnetic waves along telephone wires or through the ether.\n\nHe knew nothing of the drums, of course. And no sooner did John Carrington come to understand them than they began to fade from the African scene. He saw Lokele youth practicing the drums less and less, schoolboys who did not even learn their own drum names. He regretted it. He had made the talking drums a part of his own life. In 1954 a visitor from the United States found him running a mission school in the Congolese outpost of Yalemba. Carrington still walked daily in the jungle, and when it was time for lunch his wife would summon him with a fast tattoo. She drummed: \u201cWhite man spirit in forest come come to house of shingles high up above of white man spirit in forest. Woman with yams awaits. Come come.\u201d\n\nBefore long, there were people for whom the path of communications technology had leapt directly from the talking drum to the mobile phone, skipping over the intermediate stages.\n\n* The trip was sponsored by the Society for the Extinction of the Slave Trade and the Civilization of Africa for the purpose of interfering with slavers.\n\n* \u201cA very short experience, however, showed the superiority of the alphabetic mode,\u201d he wrote later, \u201cand the big leaves of the numbered dictionary, which cost me a world of labor,\u2026 were discarded and the alphabetic installed in its stead.\u201d\n\n* Operators soon distinguished spaces of different lengths\u2014intercharacter and interword\u2014so Morse code actually employed four signs.\n2 | THE PERSISTENCE OF THE WORD\n\n(There Is No Dictionary in the Mind)\n\nOdysseus wept when he heard the poet sing of his great deeds abroad because, once sung, they were no longer his alone. They belonged to anyone who heard the song.\n\n\u2014Ward Just (2004)\n\n\u201cTRY TO IMAGINE,\u201d proposed Walter J. Ong, Jesuit priest, philosopher, and cultural historian, \u201ca culture where no one has ever \u2018looked up\u2019 anything.\u201d To subtract the technologies of information internalized over two millennia requires a leap of imagination backward into a forgotten past. The hardest technology to erase from our minds is the first of all: writing. This arises at the very dawn of history, as it must, because the history begins with the writing. The pastness of the past depends on it.\n\nIt takes a few thousand years for this mapping of language onto a system of signs to become second nature, and then there is no return to na\u00efvet\u00e9. Forgotten is the time when our very awareness of words came from seeing them. \u201cIn a primary oral culture,\u201d as Ong noted,\n\nthe expression \u201cto look up something\u201d is an empty phrase: it would have no conceivable meaning. Without writing, words as such have no visual presence, even when the objects they represent are visual. They are sounds. You might \u201ccall\u201d them back\u2014\u201crecall\u201d them. But there is nowhere to \u201clook\u201d for them. They have no focus and no trace.\n\nIn the 1960s and \u201970s, Ong declared the electronic age to be a new age of orality\u2014but of \u201csecondary orality,\u201d the spoken word amplified and extended as never before, but always in the context of literacy: voices heard against a background of ubiquitous print. The first age of orality had lasted quite a bit longer. It covered almost the entire lifetime of the species, writing being a late development, general literacy being almost an afterthought. Like Marshall McLuhan, with whom he was often compared (\u201cthe other eminent Catholic-electronic prophet,\u201d said a scornful Frank Kermode), Ong had the misfortune to make his visionary assessments of a new age just before it actually arrived. The new media seemed to be radio, telephone, and television. But these were just the faint glimmerings in the night sky, signaling the light that still lay just beyond the\nThe Information\n\nhorizon. Whether Ong would have seen cyberspace as fundamentally oral or literary, he would surely have recognized it as transformative: not just a revitalization of older forms, not just an amplification, but something wholly new. He might have sensed a coming discontinuity akin to the emergence of literacy itself. Few understood better than Ong just how profound a discontinuity that had been.\n\nWhen he began his studies, \u201coral literature\u201d was a common phrase. It is an oxymoron laced with anachronism; the words imply an all-too-unconscious approach to the past by way of the present. Oral literature was generally treated as a variant of writing; this, Ong said, was \u201crather like thinking of horses as automobiles without wheels.\u201d\n\nYou can, of course, undertake to do this. Imagine writing a treatise on horses (for people who have never seen a horse) which starts with the concept not of \u201chorse\u201d but of \u201cautomobile,\u201d built on the readers\u2019 direct experience of automobiles. It proceeds to discourse on horses by always referring to them as \u201cwheelless automobiles,\u201d explaining to highly automobilized readers all the points of difference\u2026. Instead of wheels, the wheelless automobiles have enlarged toenails called hooves; instead of headlights, eyes; instead of a coat of lacquer, something called hair; instead of gasoline for fuel, hay, and so on. In the end, horses are only what they are not.\n\nWhen it comes to understanding the preliterate past, we modern folk are hopelessly automobilized. The written word is the mechanism by which we know what we know. It organizes our thought. We may wish to understand the rise of literacy both historically and logically, but history and logic are themselves the products of literate thought.\n\nWriting, as a technology, requires premeditation and special art. Language is not a technology, no matter how well developed and efficacious. It is not best seen as something separate from the mind; it is what the mind does. \u201cLanguage in fact bears the same relationship to the concept of mind that legislation bears to the concept of parliament,\u201d says Jonathan Miller: \u201cit is a competence forever bodying itself in a series of concrete performances.\u201d Much the same might be said of writing\u2014it is concrete performance\u2014but when the word is instantiated in paper or stone, it takes on a separate existence as artifice. It is a product of tools, and it is a tool. And like many technologies that followed, it thereby inspired immediate detractors.\n\nOne unlikely Luddite was also one of the first long-term beneficiaries. Plato (channeling the nonwriter Socrates) warned that this technology meant impoverishment:\n\nFor this invention will produce forgetfulness in the minds of those who learn to use it, because they will not practice their memory. Their trust in writing, produced by external characters which are no part of themselves, will discourage the use of their own memory within them. You have invented an elixir not of memory, but of reminding; and you offer your pupils the appearance of wisdom, not true wisdom.\nExternal characters which are no part of themselves\u2014this was the trouble. The written word seemed insincere. Ersatz scratchings on papyrus or clay were far abstracted from the real, the free-flowing sound of language, intimately bound up with thought so as to seem coterminous with it. Writing appeared to draw knowledge away from the person, to place their memories in storage. It also separated the speaker from the listener, by so many miles or years. The deepest consequences of writing, for the individual and for the culture, could hardly have been foreseen, but even Plato could see some of the power of this disconnection. The one speaks to the multitude. The dead speak to the living, the living to the unborn. As McLuhan said, \u201cTwo thousand years of manuscript culture lay ahead of the Western world when Plato made this observation.\u201d The power of this first artificial memory was incalculable: to restructure thought, to engender history. It is still incalculable, though one statistic gives a hint: whereas the total vocabulary of any oral language measures a few thousand words, the single language that has been written most widely, English, has a documented vocabulary of well over a million words, a corpus that grows by thousands of words a year. These words do not exist only in the present. Each word has a provenance and a history that melts into its present life.\n\nWith words we begin to leave traces behind us like breadcrumbs: memories in symbols for others to follow. Ants deploy their pheromones, trails of chemical information; Theseus unwound Ariadne\u2019s thread. Now people leave paper trails. Writing comes into being to retain information across time and across space. Before writing, communication is evanescent and local; sounds carry a few yards and fade to oblivion. The evanescence of the spoken word went without saying. So fleeting was speech that the rare phenomenon of the echo, a sound heard once and then again, seemed a sort of magic. \u201cThis miraculous rebounding of the voice, the Greeks have a pretty name for, and call it Echo,\u201d wrote Pliny. \u201cThe spoken symbol,\u201d as Samuel Butler observed, \u201cperishes instantly without material trace, and if it lives at all does so only in the minds of those who heard it.\u201d Butler was able to formulate this truth just as it was being falsified for the first time, at the end of the nineteenth century, by the arrival of the electric technologies for capturing speech. It was precisely because it was no longer completely true that it could be clearly seen. Butler completed the distinction: \u201cThe written symbol extends infinitely, as regards time and space, the range within which one mind can communicate with another; it gives the writer\u2019s mind a life limited by the duration of ink, paper, and readers, as against that of his flesh and blood body.\u201d\n\nBut the new channel does more than extend the previous channel. It enables reuse and \u201cre-collection\u201d\u2014new modes. It permits whole new architectures of information. Among them are history, law, business, mathematics, and logic. Apart from their content, these categories represent new techniques. The power\nlies not just in the knowledge, preserved and passed forward, valuable as it is, but in the methodology: encoded visual indications, the act of transference, substituting signs for things. And then, later, signs for signs.\n\nPaleolithic people began at least 30,000 years ago to scratch and paint shapes that recalled to the eye images of horses, fishes, and hunters. These signs in clay and on cave walls served purposes of art or magic, and historians are loath to call them writing, but they began the recording of mental states in external media. In another way, knots in cords and notches in sticks served as aids to memory. These could be carried as messages. Marks in pottery and masonry could signify ownership. Marks, images, pictographs, petroglyphs\u2014as these forms grew stylized, conventional, and thus increasingly abstract, they approached what we understand as writing, but one more transition was crucial, from the representation of things to the representation of spoken language: that is, representation twice removed. There is a progression from pictographic, *writing the picture*; to ideographic, *writing the idea*; and then logographic, *writing the word*.\n\nChinese script began this transition between 4,500 and 8,000 years ago: signs that began as pictures came to represent meaningful units of sound. Because the basic unit was the word, thousands of distinct symbols were required. This is efficient in one way, inefficient in another. Chinese unifies an array of distinct spoken languages: people who cannot speak to one another can write to one another. It employs at least fifty thousand symbols, about six thousand commonly used and known to most literate Chinese. In swift diagrammatic strokes they encode multidimensional semantic relationships. One device is simple repetition: tree + tree + tree = forest; more abstractly, sun + moon = brightness and east + east = everywhere. The process of compounding creates surprises: grain + knife = profit; hand + eye = look. Characters can be transformed in meaning by reorienting their elements: child to childbirth and man to corpse. Some elements are phonetic; some even punning. The entirety is the richest and most complex writing system that humanity has ever evolved. Considering scripts in terms of how many symbols are required and how much meaning each individual symbol conveys, Chinese thus became an extreme case: the largest set of symbols, and the most meaningful individually. Writing systems could take alternative paths: fewer symbols, each carrying less information. An intermediate stage is the syllabary, a phonetic writing system using individual characters to represent syllables, which may or may not be meaningful. A few hundred characters can serve a language.\n\nThe writing system at the opposite extreme took the longest to emerge: the alphabet, one symbol for one minimal sound. The alphabet is the most reductive,\nthe most subversive of all scripts.\n\nIn all the languages of earth there is only one word for alphabet (alfabet, alfabeto, \u03b1\u03bb\u03c6\u03b1\u03b2\u03b7\u03c4, \u03b1\u03bb\u03c6\u03b1\u03b2\u03b7\u03c4\u03bf). The alphabet was invented only once. All known alphabets, used today or found buried on tablets and stone, descend from the same original ancestor, which arose near the eastern littoral of the Mediterranean Sea, sometime not much before 1500 BCE, in a region that became a politically unstable crossroads of culture, covering Palestine, Phoenicia, and Assyria. To the east lay the great civilization of Mesopotamia, with its cuneiform script already a millennium old; down the shoreline to the southwest lay Egypt, where hieroglyphics developed simultaneously and independently. Traders traveled, too, from Cyprus and Crete, bringing their own incompatible systems. With glyphs from Minoan, Hittite, and Anatolian, it made for a symbolic stew. The ruling priestly classes were invested in their writing systems. Whoever owned the scripts owned the laws and the rites. But self-preservation had to compete with the desire for rapid communication. The scripts were conservative; the new technology was pragmatic. A stripped-down symbol system, just twenty-two signs, was the innovation of Semitic peoples in or near Palestine. Scholars naturally look to Kiriat-sepher, translatable as \u201ccity of the book,\u201d and Byblos, \u201ccity of papyrus,\u201d but no one knows exactly, and no one can know. The paleographer has a unique bootstrap problem. It is only writing that makes its own history possible. The foremost twentieth-century authority on the alphabet, David Diringer, quoted an earlier scholar: \u201cThere never was a man who could sit down and say: \u2018Now I am going to be the first man to write.\u2019 \u201d\n\nThe alphabet spread by contagion. The new technology was both the virus and the vector of transmission. It could not be monopolized, and it could not be suppressed. Even children could learn these few, lightweight, semantically empty letters. Divergent routes led to alphabets of the Arab world and of northern Africa; to Hebrew and Phoenician; across central Asia, to Brahmi and related Indian script; and to Greece. The new civilization arising there brought the alphabet to a high degree of perfection. Among others, the Latin and Cyrillic alphabets followed along.\n\nGreece had not needed the alphabet to create literature\u2014a fact that scholars realized only grudgingly, beginning in the 1930s. That was when Milman Parry, a structural linguist who studied the living tradition of oral epic poetry in Bosnia and Herzegovina, proposed that the *Iliad* and the *Odyssey* not only could have been but must have been composed and sung without benefit of writing. The meter, the formulaic redundancy, in effect the very poetry of the great works served first and foremost to aid memory. Its incantatory power made of the verse a time capsule, able to transmit a virtual encyclopedia of culture across generations. His argument was first controversial and then overwhelmingly\npersuasive\u2014but only because the poems were written down, sometime in the sixth or seventh century BCE. This act\u2014the transcribing of the Homeric epics\u2014echoes through the ages. \u201cIt was something like a thunder-clap in human history, which the bias of familiarity has converted into the rustle of papers on a desk,\u201d said Eric Havelock, a British classical scholar who followed Parry. \u201cIt constituted an intrusion into culture, with results that proved irreversible. It laid the basis for the destruction of the oral way of life and the oral modes of thought.\u201d\n\nThe transcription of Homer converted this great poetry into a new medium and made of it something unplanned: from a momentary string of words created every time anew by the rhapsode and fading again even as it echoed in the listener\u2019s ear, to a fixed but portable line on a papyrus sheet. Whether this alien, dry mode would suit the creation of poetry and song remained to be seen. In the meantime the written word helped more mundane forms of discourse: petitions to the gods, statements of law, and economic agreements. Writing also gave rise to discourse about discourse. Written texts became objects of a new sort of interest.\n\nBut how was one to speak about them? The words to describe the elements of this discourse did not exist in the lexicon of Homer. The language of an oral culture had to be wrenched into new forms; thus a new vocabulary emerged. Poems were seen to have topics\u2014the word previously meaning \u201cplace.\u201d They possessed structure, by analogy with buildings. They were made of plot and diction. Aristotle could now see the works of the bards as \u201crepresentations of life,\u201d born of the natural impulse toward imitation that begins in childhood. But he had also to account for other writing with other purposes\u2014the Socratic dialogues, for example, and medical or scientific treatises\u2014and this general type of work, including, presumably, his own, \u201chappens, up to the present day, to have no name.\u201d Under construction was a whole realm of abstraction, forcibly divorced from the concrete. Havelock described it as cultural warfare, a new consciousness and a new language at war with the old consciousness and the old language: \u201cTheir conflict produced essential and permanent contributions to the vocabulary of all abstract thought. Body and space, matter and motion, permanence and change, quality and quantity, combination and separation, are among the counters of common currency now available.\u201d\n\nAristotle himself, son of the physician to the king of Macedonia and an avid, organized thinker, was attempting to systematize knowledge. The persistence of writing made it possible to impose structure on what was known about the world and, then, on what was known about knowing. As soon as one could set words down, examine them, look at them anew the next day, and consider their meaning, one became a philosopher, and the philosopher began with a clean slate and a vast project of definition to undertake. Knowledge could begin to pull itself up by the bootstraps. For Aristotle the most basic notions were worth recording and were\nnecessary to record:\n\nA *beginning* is that which itself does not follow necessarily from anything else, but some second thing naturally exists or occurs after it. Conversely, an *end* is that which does itself naturally follow from something else, either necessarily or in general, but there is nothing else after it. A *middle* is that which itself comes after something else, and some other thing comes after it.\n\nThese are statements not about experience but about the uses of language to structure experience. In the same way, the Greeks created *categories* (this word originally meaning \u201caccusations\u201d or \u201cpredictions\u201d) as a means of classifying animal species, insects, and fishes. In turn, they could then classify ideas. This was a radical, alien mode of thought. Plato had warned that it would repel most people:\n\nThe multitude cannot accept the idea of beauty in itself rather than many beautiful things, nor anything conceived in its essence instead of the many specific things. Thus the multitude cannot be philosophic.\n\nFor \u201cthe multitude\u201d we may understand \u201cthe preliterate.\u201d They \u201close themselves and wander amid the multiplicities of multifarious things,\u201d declared Plato, looking back on the oral culture that still surrounded him. They \u201chave no vivid pattern in their souls.\u201d\n\nAnd what vivid pattern was that? Havelock focused on the process of converting, mentally, from a \u201cprose of narrative\u201d to a \u201cprose of ideas\u201d; organizing experience in terms of categories rather than events; embracing the discipline of abstraction. He had a word in mind for this process, and the word was *thinking*. This was the discovery, not just of the self, but of the *thinking* self\u2014in effect, the true beginning of consciousness.\n\nIn our world of ingrained literacy, thinking and writing seem scarcely related activities. We can imagine the latter depending on the former, but surely not the other way around: everyone thinks, whether or not they write. But Havelock was right. The written word\u2014the persistent word\u2014was a prerequisite for conscious thought as we understand it. It was the trigger for a wholesale, irreversible change in the human psyche\u2014*psyche* being the word favored by Socrates/Plato as they struggled to understand. Plato, as Havelock puts it,\n\nis trying for the first time in history to identify this group of general mental qualities, and seeking for a term which will label them satisfactorily under a single type\u2026. He it was who hailed the portent and correctly identified it. In so doing, he so to speak confirmed and clinched the guesses of a previous generation which had been feeling its way towards the *idea* that you could \u201cthink,\u201d and that thinking was a very special kind of psychic activity, very uncomfortable, but also very exciting, and one which required a very novel use of Greek.\n\nTaking the next step on the road of abstraction, Aristotle deployed categories and relationships in a regimented order to develop a symbolism of reasoning: logic\u2014\nfrom \\(\\lambda\\delta\\rho\\sigma\\), *logos*, the not-quite-translatable word from which so much flows, meaning \u201cspeech\u201d or \u201creason\u201d or \u201cdiscourse\u201d or, ultimately, just \u201cword.\u201d\n\nLogic might be imagined to exist independent of writing\u2014syllogisms can be spoken as well as written\u2014but it did not. Speech is too fleeting to allow for analysis. Logic descended from the written word, in Greece as well as India and China, where it developed independently. Logic turns the act of abstraction into a tool for determining what is true and what is false: truth can be discovered in words alone, apart from concrete experience. Logic takes its form in chains: sequences whose members connect one to another. Conclusions follow from premises. These require a degree of constancy. They have no power unless people can examine and evaluate them. In contrast, an oral narrative proceeds by accretion, the words passing by in a line of parade past the viewing stand, briefly present and then gone, interacting with one another via memory and association. There are no syllogisms in Homer. Experience is arranged in terms of events, not categories. Only with writing does narrative structure come to embody sustained rational argument. Aristotle crossed another level, by seeing the study of such argument\u2014not just the use of argument, but its study\u2014as a tool. His logic expresses an ongoing self-consciousness about the words in which they are composed. When Aristotle unfurls premises and conclusions\u2014*If it is possible for no man to be a horse, it is also admissible for no horse to be a man; and if it is admissible for no garment to be white, it is also admissible for nothing white to be a garment. For if any white thing must be a garment, then some garment will necessarily be white*\u2014he neither requires nor implies any personal experience of horses, garments, or colors. He has departed that realm. Yet he claims through the manipulation of words to create knowledge anyway, and a superior brand of knowledge at that.\n\n\u201cWe know that formal logic is the invention of Greek culture after it had interiorized the technology of alphabetic writing,\u201d Walter Ong says\u2014it is true of India and China as well\u2014and so made a permanent part of its noetic resources the kind of thinking that alphabetic writing made possible.\u201d For evidence Ong turns to fieldwork of the Russian psychologist Aleksandr Romanovich Luria among illiterate peoples in remote Uzbekistan and Kyrgyzstan in Central Asia in the 1930s. Luria found striking differences between illiterate and even slightly literate subjects, not in what they knew, but in how they thought. Logic implicates symbolism directly: things are members of classes; they possess qualities, which are abstracted and generalized. Oral people lacked the categories that become second nature even to illiterate individuals in literate cultures: for example, for geometrical shapes. Shown drawings of circles and squares, they named them as \u201cplate, sieve, bucket, watch, or moon\u201d and \u201cmirror, door, house, apricot drying board.\u201d They could not, or would not, accept logical syllogisms. A typical\nThe Information\n\nquestion:\n\nIn the Far North, where there is snow, all bears are white.\nNovaya Zembla is in the Far North and there is always snow there.\nWhat color are the bears?\n\nTypical response: \u201cI don\u2019t know. I\u2019ve seen a black bear. I\u2019ve never seen any others\u2026. Each locality has its own animals.\u201d\n\nBy contrast, a man who has just learned to read and write responds, \u201cTo go by your words, they should all be white.\u201d To go by your words\u2014in that phrase, a level is crossed. The information has been detached from any person, detached from the speaker\u2019s experience. Now it lives in the words, little life-support modules. Spoken words also transport information, but not with the self-consciousness that writing brings. Literate people take for granted their own awareness of words, along with the array of word-related machinery: classification, reference, definition. Before literacy, there is nothing obvious about such techniques. \u201cTry to explain to me what a tree is,\u201d Luria says, and a peasant replies, \u201cWhy should I? Everyone knows what a tree is, they don\u2019t need me telling them.\u201d\n\n\u201cBasically the peasant was right,\u201d Ong comments. \u201cThere is no way to refute the world of primary orality. All you can do is walk away from it into literacy.\u201d\n\nIt is a twisting journey from things to words, from words to categories, from categories to metaphor and logic. Unnatural as it seemed to define tree, it was even trickier to define word, and helpful ancillary words like define were not at first available, the need never having existed. \u201cIn the infancy of logic, a form of thought has to be invented before the content can be filled up,\u201d said Benjamin Jowett, Aristotle\u2019s nineteenth-century translator. Spoken languages needed further evolution.\n\nLanguage and reasoning fit so well that users could not always see the flaws and gaps. Still, as soon as any culture invented logic, paradoxes appeared. In China, nearly contemporaneously with Aristotle, the philosopher Gongsun Long captured some of these in the form of a dialogue, known as \u201cWhen a White Horse Is Not a Horse.\u201d It was written on bamboo strips, tied with string, before the invention of paper. It begins:\n\nCan it be that a white horse is not a horse?\nIt can.\nHow?\n\u201cHorse\u201d is that by means of which one names the shape. \u201cWhite\u201d is that by means of which one names the color. What names the color is not what names the shape. Hence, I say that a white horse is not a horse.\n\nOn its face, this is unfathomable. It begins to come into focus as a statement\nabout language and logic. Gongsun Long was a member of the Mingjia, the School of Names, and his delving into these paradoxes formed part of what Chinese historians call the \u201clanguage crisis,\u201d a running debate over the nature of language. Names are not the things they name. Classes are not coextensive with subclasses. Thus innocent-seeming inferences get derailed: \u201ca man dislikes white horses\u201d does not imply \u201ca man dislikes horses.\u201d\n\nYou think that horses that are colored are not horses. In the world, it is not the case that there are horses with no color. Can it be that there are no horses in the world?\n\nThe philosopher shines his light on the process of abstracting into classes based on properties: whiteness; horsiness. Are these classes part of reality, or do they exist only in language?\n\nHorses certainly have color. Hence, there are white horses. If it were the case that horses had no color, there would simply be horses, and then how could one select a white horse? A white horse is a horse and white. A horse and a white horse are different. Hence, I say that a white horse is not a horse.\n\nTwo millennia later, philosophers continue to struggle with these texts. The paths of logic into modern thought are roundabout, broken, and complex. Since the paradoxes seem to be in language, or about language, one way to banish them was to purify the medium: eliminate ambiguous words and woolly syntax, employ symbols that were rigorous and pure. To turn, that is, to mathematics. By the beginning of the twentieth century, it seemed that only a system of purpose-built symbols could make logic work properly\u2014free of error and paradoxes. This dream was to prove illusory; the paradoxes would creep back in, but no one could hope to understand until the paths of logic and mathematics converged.\n\nMathematics, too, followed from the invention of writing. Greece is often thought of as the springhead for the river that becomes modern mathematics, with all its many tributaries down the centuries. But the Greeks themselves alluded to another tradition\u2014to them, ancient\u2014which they called Chaldean, and which we understand to be Babylonian. That tradition vanished into the sands, not to surface until the end of the nineteenth century, when tablets of clay were dug up from the mounds of lost cities.\n\nFirst there were scores, then thousands of tablets, typically the size of a human hand, etched with a distinctive, edgy, angular writing called cuneiform, \u201cwedge shaped.\u201d Mature cuneiform was neither pictographic (the symbols were spare and abstract) nor alphabetic (they were far too numerous). By 3000 BCE a system with about seven hundred symbols flourished in Uruk, the walled city, probably the largest in the world, home of the hero-king Gilgamesh, in the alluvial marshes near the Euphrates River. German archeologists excavated Uruk in a series of digs all through the twentieth century. The materials for this most ancient of\ninformation technologies lay readily at hand. With damp clay held in one hand and a stylus of sharpened reed in the other, a scribe would imprint tiny characters in columns and rows.\n\nThe result: cryptic messages from an alien culture. They took generations to decipher. \u201cWriting, like a theater curtain going up on these dazzling civilizations, lets us stare directly but imperfectly at them,\u201d writes the psychologist Julian Jaynes. Some Europeans took umbrage at first. \u201cTo the Assyrians, the Chaldeans, and Egyptians,\u201d wrote the seventeenth-century divine Thomas Sprat, \u201cwe owe the Invention\u201d but also the \u201cCorruption of knowledge,\u201d when they concealed it with their strange scripts. \u201cIt was the custom of their Wise men, to wrap up their Observations on Nature, and the Manners of Men, in the dark Shadows of Hieroglyphicks\u201d (as though friendlier ancients would have used an alphabet more familiar to Sprat). The earliest examples of cuneiform baffled archeologists and paleolinguists the longest, because the first language to be written, Sumerian, left no other traces in culture or speech. Sumerian turned out to be a linguistic rarity, an isolate, with no known descendants. When scholars did learn to read the Uruk tablets, they found them to be, in their way, humdrum: civic memoranda, contracts and laws, and receipts and bills for barley, livestock, oil, reed mats, and pottery. Nothing like poetry or literature appeared in cuneiform for hundreds of years to come. The tablets were the quotidiana of nascent commerce and bureaucracy. The tablets not only recorded the commerce and the bureaucracy but, in the first place, made them possible.\n\nEven then, cuneiform incorporated signs for counting and measurement. Different characters, used in different ways, could denote numbers and weights. A more systematic approach to the writing of numbers did not take shape until the time of Hammurabi, 1750 BCE, when Mesopotamia was unified around the great city of Babylon. Hammurabi himself was probably the first literate king, writing his own cuneiform rather than depending on scribes, and his empire building\nmanifested the connection between writing and social control. \u201cThis process of conquest and influence is made possible by letters and tablets and stelae in an abundance that had never been known before,\u201d Jaynes declares. \u201cWriting was a new method of civil direction, indeed the model that begins our own memo-communicating government.\u201d\n\nThe writing of numbers had evolved into an elaborate system. Numerals were composed of just two basic parts, a vertical wedge for 1 (I) and an angle wedge for 10 (C). These were combined to form the standard characters, so that III represented 3 and CIII represented 16, and so on. But the Babylonian system was not decimal, base 10; it was sexagesimal, base 60. Each of the numerals from 1 to 60 had its own character. To form large numbers, the Babylonians used numerals in places: I was 70 (one 60 plus ten 1s); I CIII was 616 (ten 60s plus sixteen 1s), and so on. None of this was clear when the tablets first began to surface. A basic theme with variations, encountered many times, proved to be multiplication tables. In a sexagesimal system these had to cover the numbers from 1 to 19 as well as 20, 30, 40, and 50. Even more difficult to unravel were tables of reciprocals, making possible division and fractional numbers: in the 60-based system, reciprocals were 2:30, 3:20, 4:15, 5:12 \u2026 and then, using extra places, 8:7,30, 9:6,40, and so on.*\n\nThese symbols were hardly words\u2014or they were words of a peculiar, slender, rigid sort. They seemed to arrange themselves into visible patterns in the clay,\nrepetitious, almost artistic, not like any prose or poetry archeologists had encountered. They were like maps of a mysterious city. This was the key to deciphering them, finally: the ordered chaos that seems to guarantee the presence of meaning. It seemed like a task for mathematicians, anyway, and finally it was. They recognized geometric progressions, tables of powers, and even instructions for computing square roots and cube roots. Familiar as they were with the rise of mathematics a millennium later in ancient Greece, these scholars were astounded at the breadth and depth of mathematical knowledge that existed before in Mesopotamia. \u201cIt was assumed that the Babylonians had had some sort of number mysticism or numerology,\u201d wrote Asger Aaboe in 1963, \u201cbut we now know how far short of the truth this assumption was.\u201d The Babylonians computed linear equations, quadratic equations, and Pythagorean numbers long before Pythagoras. In contrast to the Greek mathematics that followed, Babylonian mathematics did not emphasize geometry, except for practical problems; the Babylonians calculated areas and perimeters but did not prove theorems. Yet they could (in effect) reduce elaborate second-degree polynomials. Their mathematics seemed to value computational power above all.\n\nThat could not be appreciated until computational power began to mean something. By the time modern mathematicians turned their attention to Babylon, many important tablets had already been destroyed or scattered. Fragments retrieved from Uruk before 1914, for example, were dispersed to Berlin, Paris, and Chicago and only fifty years later were discovered to hold the beginning methods of astronomy. To demonstrate this, Otto Neugebauer, the leading twentieth-century historian of ancient mathematics, had to reassemble tablets whose fragments had made their way to opposite sides of the Atlantic Ocean. In 1949, when the number of cuneiform tablets housed in museums reached (at his rough guess) a half million, Neugebauer lamented, \u201cOur task can therefore properly be compared with restoring the history of mathematics from a few torn pages which have accidentally survived the destruction of a great library.\u201d\n\nIn 1972, Donald Knuth, an early computer scientist at Stanford, looked at the remains of an Old Babylonian tablet the size of a paperback book, half lying in the British Museum in London, one-fourth in the Staatliche Museen in Berlin, and the rest missing, and saw what he could only describe, anachronistically, as an algorithm:\n\nA cistern.\nThe height is 3,20, and a volume of 27,46,40 has been excavated.\nThe length exceeds the width by 50.\nYou should take the reciprocal of the height, 3,20, obtaining 18.\nMultiply this by the volume, 27,46,40, obtaining 8,20.\nTake half of 50 and square it, obtaining 10,25.\nAdd 8,20, and you get 8,30,25.\n\nThe square root is 2,55.\n\nMake two copies of this, adding to the one and subtracting from the other.\n\nYou find that 3,20 is the length and 2,30 is the width.\n\nThis is the procedure.\n\n\u201cThis is the procedure\u201d was a standard closing, like a benediction, and for Knuth redolent with meaning. In the Louvre he found a \u201cprocedure\u201d that reminded him of a stack program on a Burroughs B5500. \u201cWe can commend the Babylonians for developing a nice way to explain an algorithm by example as the algorithm itself was being defined,\u201d said Knuth. By then he himself was engrossed in the project of defining and explaining the algorithm; he was amazed by what he found on the ancient tablets. The scribes wrote instructions for placing numbers in certain locations\u2014for making \u201ccopies\u201d of a number, and for keeping a number \u201cin your head.\u201d This idea, of abstract quantities occupying abstract places, would not come back to life till much later.\n\nWhere is a symbol? What is a symbol? Even to ask such questions required a self-consciousness that did not come naturally. Once asked, the questions continued to loom. Look at these signs, philosophers implored. What are they?\n\n\u201cFundamentally letters are shapes indicating voices,\u201d explained John of Salisbury in medieval England. \u201cHence they represent things which they bring to mind through the windows of the eyes.\u201d John served as secretary and scribe to the Archbishop of Canterbury in the twelfth century. He served the cause of Aristotle as an advocate and salesman. His Metalogicon not only set forth the principles of Aristotelian logic but urged his contemporaries to convert, as though to a new religion. (He did not mince words: \u201cLet him who is not come to logic be plagued with continuous and everlasting filth.\u201d) Putting pen to parchment in this time of barest literacy, he tried to examine the act of writing and the effect of words: \u201cFrequently they speak voicelessly the utterances of the absent.\u201d The idea of writing was still entangled with the idea of speaking. The mixing of the visual and the auditory continued to create puzzles, and so also did the mixing of past and future: utterances of the absent. Writing leapt across these levels.\n\nEvery user of this technology was a novice. Those composing formal legal documents, such as charters and deeds, often felt the need to express their sensation of speaking to an invisible audience: \u201cOh! all ye who shall have heard this and have seen!\u201d (They found it awkward to keep tenses straight, like voicemail novices leaving their first messages circa 1980.) Many charters ended with the word \u201cGoodbye.\u201d Before writing could feel natural in itself\u2014could become second nature\u2014these echoes of voices had to fade away. Writing in and\nof itself had to reshape human consciousness.\n\nAmong the many abilities gained by the written culture, not the least was the power of looking inward upon itself. Writers loved to discuss writing, far more than bards ever bothered to discuss speech. They could see the medium and its messages, hold them up to the mind\u2019s eye for study and analysis. And they could criticize it\u2014for from the very start, the new abilities were accompanied by a nagging sense of loss. It was a form of nostalgia. Plato felt it:\n\nI cannot help feeling, Phaedrus, [says Socrates] that writing is unfortunately like painting; for the creations of the painter have the attitude of life, and yet if you ask them a question they preserve a solemn silence\u2026. You would imagine that they had intelligence, but if you want to know anything and put a question to one of them, the speaker always gives one unvarying answer.\n\nUnfortunately the written word stands still. It is stable and immobile. Plato\u2019s qualms were mostly set aside in the succeeding millennia, as the culture of literacy developed its many gifts: history and the law; the sciences and philosophy; the reflective explication of art and literature itself. None of that could have emerged from pure orality. Great poetry could and did, but it was expensive and rare. To make the epics of Homer, to let them be heard, to sustain them across the years and the miles required a considerable share of the available cultural energy.\n\nThen the vanished world of primary orality was not much missed. Not until the twentieth century, amid a burgeoning of new media for communication, did the qualms and the nostalgia resurface. Marshall McLuhan, who became the most famous spokesman for the bygone oral culture, did so in the service of an argument for modernity. He hailed the new \u201celectric age\u201d not for its newness but for its return to the roots of human creativity. He saw it as a revival of the old orality. \u201cWe are in our century \u2018winding the tape backward,\u2019\u201d he declared, finding his metaphorical tape in one of the newest information technologies. He constructed a series of polemical contrasts: the printed word vs. the spoken word; cold/hot; static/fluid; neutral/magical; impoverished/rich; regimented/creative; mechanical/organic; separatist/integrative. \u201cThe alphabet is a technology of visual fragmentation and specialism,\u201d he wrote. It leads to \u201ca desert of classified data.\u201d\n\nOne way of framing McLuhan\u2019s critique of print would be to say that print offers only a narrow channel of communication. The channel is linear and even fragmented. By contrast, speech\u2014in the primal case, face-to-face human intercourse, alive with gesture and touch\u2014engages all the senses, not just hearing. If the ideal of communication is a meeting of souls, then writing is a sad shadow of the ideal.\n\nThe same criticism was made of other constrained channels, created by later technologies\u2014the telegraph, the telephone, radio, and e-mail. Jonathan Miller\nrephrases McLuhan\u2019s argument in quasi-technical terms of information: \u201cThe larger the number of senses involved, the better the chance of transmitting a reliable copy of the sender\u2019s mental state.\u201d* In the stream of words past the ear or eye, we sense not just the items one by one but their rhythms and tones, which is to say their music. We, the listener or the reader, do not hear, or read, one word at a time; we get messages in groupings small and large. Human memory being what it is, larger patterns can be grasped in writing than in sound. The eye can glance back. McLuhan considered this damaging, or at least diminishing. \u201cAcoustic space is organic and integral,\u201d he said, \u201cperceived through the simultaneous interplay of all the senses; whereas \u2018rational\u2019 or pictorial space is uniform, sequential and continuous and creates a closed world with none of the rich resonance of the tribal echoland.\u201d For McLuhan, the tribal echoland is Eden.\n\nBy their dependence on the spoken word for information, people were drawn together into a tribal mesh \u2026 the spoken word is more emotionally laden than the written\u2026. Audile-tactile tribal man partook of the collective unconscious, lived in a magical integral world patterned by myth and ritual, its values divine.*\n\nUp to a point, maybe. Yet three centuries earlier, Thomas Hobbes, looking from a vantage where literacy was new, had taken a less rosy view. He could see the preliterate culture more clearly: \u201cMen lived upon gross experience,\u201d he wrote. \u201cThere was no method; that is to say, no sowing nor planting of knowledge by itself, apart from the weeds and common plants of error and conjecture.\u201d A sorry place, neither magical nor divine.\n\nWas McLuhan right, or was Hobbes? If we are ambivalent, the ambivalence began with Plato. He witnessed writing\u2019s rising dominion; he asserted its force and feared its lifelessness. The writer-philosopher embodied a paradox. The same paradox was destined to reappear in different guises, each technology of information bringing its own powers and its own fears. It turns out that the \u201cforgetfulness\u201d Plato feared does not arise. It does not arise because Plato himself, with his mentor Socrates and his disciple Aristotle, designed a vocabulary of ideas, organized them into categories, set down rules of logic, and so fulfilled the promise of the technology of writing. All this made knowledge more durable stuff than before.\n\nAnd the atom of knowledge was the word. Or was it? For some time to come, the word continued to elude its pursuers, whether it was a fleeting burst of sound or a fixed cluster of marks. \u201cMost literate persons, when you say, \u2018Think of a word,\u2019 at least in some vague fashion think of something before their eyes,\u201d Ong says, \u201cwhere a real word can never be at all.\u201d Where do we look for the words, then? In the dictionary, of course. Ong also said: \u201cIt is demoralizing to remind oneself that there is no dictionary in the mind, that lexicographical apparatus is a very late accretion to language.\u201d\n* It is customary to transcribe a two-place sexagesimal cuneiform number with a comma\u2014such as \u201c7,30.\u201d But the scribes did not use such punctuation, and in fact their notation left the place values undefined; that is, their numbers were what we would call \u201cfloating point.\u201d A two-place number like 7,30 could be 450 (seven 60s + thirty 1s) or 7\u00bd (seven 1s + thirty 1/60s).\n\n* Not that Miller agrees. On the contrary: \u201cIt is hard to overestimate the subtle reflexive effects of literacy upon the creative imagination, providing as it does a cumulative deposit of ideas, images, and idioms upon whose rich and appreciating funds every artist enjoys an unlimited right of withdrawal.\u201d\n\n* The interviewer asked plaintively, \u201cBut aren\u2019t there corresponding gains in insight, understanding and cultural diversity to compensate detribalized man?\u201d McLuhan responded, \u201cYour question reflects all the institutionalized biases of literate man.\u201d\n3 | TWO WORDBOOKS\n\n(The Uncertainty in Our Writing, the Inconstancy in Our Letters)\n\nIn such busie, and active times, there arise more new thoughts of men, which must be signifi\u2019d, and varied by new expressions.\n\n\u2014Thomas Sprat (1667)\n\nA VILLAGE SCHOOLMASTER AND PRIEST made a book in 1604 with a rambling title that began \u201cA Table Alphabeticall, conteyning and teaching the true writing, and understanding of hard usuall English wordes,\u201d and went on with more hints to its purpose, which was unusual and needed explanation:\n\nWith the interpretation thereof by plaine English words, gathered for the benefit & helpe of Ladies, Gentlewomen, or any other unskilfull persons.\n\nWhereby they may the more easily and better understand many hard English wordes, which they shall heare or read in Scriptures, Sermons, or elsewhere, and also be made able to use the same aptly themselves.\n\nThe title page omitted the name of the author, Robert Cawdrey, but included a motto from Latin\u2014\u201cAs good not read, as not to understand\u201d\u2014and situated the publisher with as much formality and exactness as could be expected in a time when the address, as a specification of place, did not yet exist:\n\nAt London, Printed by I. R. for Edmund Weaver, & are to be sold at his shop at the great North doore of Paules Church.\n\nCAWDREY\u2019S TITLE PAGE\nEven in London\u2019s densely packed streets, shops and homes were seldom to be found by number. The alphabet, however, had a definite order\u2014the first and second letters providing its very name\u2014and that order had been maintained since the early Phoenician times, through all the borrowing and evolution that followed.\n\nCawdrey lived in a time of information poverty. He would not have thought so, even had he possessed the concept. On the contrary, he would have considered himself to be in the midst of an information explosion, which he himself was trying to abet and organize. But four centuries later, his own life is shrouded in the obscurity of missing knowledge. His *Table Alphabeticall* appears as a milestone in the history of information, yet of its entire first edition, just one worn copy survived into the future. When and where he was born remain unknown\u2014probably in the late 1530s; probably in the Midlands. Parish registers notwithstanding, people\u2019s lives were almost wholly undocumented. No one has even a definitive spelling for Cawdrey\u2019s name (Cowdrey, Cawdry). But then, no one agreed on the spelling of most names: they were spoken, seldom written.\n\nIn fact, few had any concept of \u201cspelling\u201d\u2014the idea that each word, when written, should take a particular predetermined form of letters. The word *cony* (rabbit) appeared variously as *conny*, *conye*, *conie*, *connie*, *coni*, *cuny*, *cunny*, and *cunnie* in a single 1591 pamphlet. Others spelled it differently. And for that matter Cawdrey himself, on the title page of his book for \u201cteaching the true writing,\u201d wrote *wordes* in one sentence and *words* in the next. Language did not function as a storehouse of words, from which users could summon the correct items, preformed. On the contrary, words were fugitive, on the fly, expected to vanish again thereafter. When spoken, they were not available to be compared with, or measured against, other instantiations of themselves. Every time people dipped quill in ink to form a word on paper they made a fresh choice of whatever letters seemed to suit the task. But this was changing. The availability\u2014the solidity\u2014of the printed book inspired a sense that the written word *should be* a certain way, that one form was right and others wrong. First this sense was unconscious; then it began to rise toward general awareness. Printers themselves made it their business.\n\n*To spell* (from an old Germanic word) first meant to speak or to utter. Then it meant to read, slowly, letter by letter. Then, by extension, just around Cawdrey\u2019s time, it meant to write words letter by letter. The last was a somewhat poetic usage. \u201cSpell Eva back and Ave shall you find,\u201d wrote the Jesuit poet Robert Southwell (shortly before being hanged and quartered in 1595). When certain educators did begin to consider the idea of spelling, they would say \u201cright writing\u201d\u2014or, to borrow from Greek, \u201corthography.\u201d Few bothered, but one who did was a school headmaster in London, Richard Mulcaster. He assembled a primer, titled \u201cThe first part [a second part was not to be] of the Elementarie\nwhich entreateth chefelie of the right writing of our English tung.\u201d He published it in 1582 (\u201cat London by Thomas Vautroullier dwelling in the blak-friers by Lud-gate\u201d), including his own list of about eight thousand words and a plea for the idea of a dictionary:\n\nIt were a thing verie praiseworthie in my opinion, and no lesse profitable than praise worthie, if some one well learned and as laborious a man, wold gather all the words which we use in our English tung \u2026 into one dictionarie, and besides the right writing, which is incident to the Alphabete, wold open unto us therein, both their naturall force, and their proper use.\n\nHe recognized another motivating factor: the quickening pace of commerce and transportation made other languages a palpable presence, forcing an awareness of the English language as just one among many. \u201cForenners and strangers do wonder at us,\u201d Mulcaster wrote, \u201cboth for the uncertaintie in our writing, and the inconstancie in our letters.\u201d Language was no longer invisible like the air.\n\nBarely 5 million people on earth spoke English (a rough estimate; no one tried to count the population of England, Scotland, or Ireland until 1801). Barely a million of those could write. Of all the world\u2019s languages English was already the most checkered, the most mottled, the most polygenetic. Its history showed continual corruption and enrichment from without. Its oldest core words, the words that felt most basic, came from the language spoken by the Angles, Saxons, and Jutes, Germanic tribes that crossed the North Sea into England in the fifth century, pushing aside the Celtic inhabitants. Not much of Celtic penetrated the Anglo-Saxon speech, but Viking invaders brought more words from Norse and Danish: egg, sky, anger, give, get. Latin came by way of Christian missionaries; they wrote in the alphabet of the Romans, which replaced the runic scripts that spread in central and northern Europe early in the first millennium. Then came the influence of French.\n\nInfluence, to Robert Cawdrey, meant \u201ca flowing in.\u201d The Norman Conquest was more like a deluge, linguistically. English peasants of the lower classes continued to breed cows, pigs, and oxen (Germanic words), but in the second millennium the upper classes dined on beef, pork, and mutton (French). By medieval times French and Latin roots accounted for more than half of the common vocabulary. More alien words came when intellectuals began consciously to borrow from Latin and Greek to express concepts the language had not before needed. Cawdrey found this habit irritating. \u201cSome men seek so far for outlandish English, that they forget altogether their mothers language, so that if some of their mothers were alive, they were not able to tell, or understand what they say,\u201d he complained. \u201cOne might well charge them, for counterfeiting the Kings English.\u201d\nFour hundred years after Cawdrey published his book of words, John Simpson retraced Cawdrey\u2019s path. Simpson was in certain respects his natural heir: the editor of a grander book of words, the *Oxford English Dictionary*. Simpson, a pale, soft-spoken man, saw Cawdrey as obstinate, uncompromising, and even pugnacious. The schoolteacher was ordained a deacon and then a priest of the Church of England in a restless time, when Puritanism was on the rise. Nonconformity led him into trouble. He seems to have been guilty of \u201cnot Conforming himself\u201d to some of the sacraments, such as \u201cthe Cross in Baptism, and the Ring in Marriage.\u201d As a village priest he did not care to bow down to bishops and archbishops. He preached a form of equality unwelcome to church authorities. \u201cThere was preferred secretly an Information against him for speaking diverse Words in the Pulpit, tending to the depraving of the Book of Common Prayer\u2026. And so being judged a dangerous Person, if he should continue preaching, but infecting the People with Principles different from the Religion established.\u201d Cawdrey was degraded from the priesthood and deprived of his benefice. He continued to fight the case for years, to no avail.\n\nAll that time, he collected words (\u201c*collect*, gather\u201d). He published two instructional treatises, one on catechism (\u201c*catechiser*, that teacheth the principles of Christian religion\u201d) and one on *A godlie forme of householde government for the ordering of private families*, and in 1604 he produced a different sort of book: nothing more than a list of words, with brief definitions.\n\nWhy? Simpson says, \u201cWe have already seen that he was committed to simplicity in language, and that he was strong-minded to the point of obstinacy.\u201d He was still preaching\u2014now, to preachers. \u201cSuch as by their place and calling (but especially Preachers) as have occasion to speak publiquely before the ignorant people,\u201d Cawdrey declared in his introductory note, \u201care to bee admonished.\u201d He admonishes them. \u201cNever affect any strange ynckhorne termes.\u201d (An *inkhorn* was an inkpot; by *inkhorn term* he meant a bookish word.) \u201cLabour to speake so as is commonly received, and so as the most ignorant may well understand them.\u201d And above all do not affect to speak like a foreigner:\n\nSome far journied gentlemen, at their returne home, like as they love to go in forraine apparrell, so they will poulder their talke with over-sea language. He that commeth lately out of France, will talk French English, and never blush at the matter.\n\nCawdrey had no idea of listing *all* the words\u2014whatever that would mean. By 1604 William Shakespeare had written most of his plays, employing a vocabulary of nearly 30,000, but these words were not available to Cawdrey or anyone else. Cawdrey did not bother with the most common words, nor the most inkhorn and Frenchified words; he listed only the \u201chard usual\u201d words, words difficult enough to need some explanation but still \u201cproper unto the tongue wherein we speake\u201d and \u201cplaine for all men to perceive.\u201d He compiled 2,500. He knew that many\nwere derived from Greek, French, and Latin (\"derive, fetch from\"), and he marked these accordingly. The book Cawdrey made was the first English dictionary. The word dictionary was not in it.\n\nAlthough Cawdrey cited no authorities, he had relied on some. He copied the remarks about inkhorn terms and the far-journeyed gentlemen in their foreign apparel from Thomas Wilson\u2019s successful book *The Arte of Rhetorique*. For the words themselves he found several sources (\"source, wave, or issuing fourth of water\"). He found about half his words in a primer for teaching reading, called *The English Schoole-maister*, by Edmund Coote, first published in 1596 and widely reprinted thereafter. Coote claimed that a schoolmaster could teach a hundred students more quickly with his text than forty without it. He found it worthwhile to explain the benefits of teaching people to read: \u201cSo more knowledge will be brought into this Land, and moe bookees bought, than otherwise would have been.\u201d Coote included a long glossary, which Cawdrey plundered.\n\nThat Cawdrey should arrange his words in alphabetical order, to make his *Table Alphabeticall*, was not self-evident. He knew he could not count on even his educated readers to be versed in alphabetical order, so he tried to produce a small how-to manual. He struggled with this: whether to describe the ordering in logical, schematic terms or in terms of a step-by-step procedure, an algorithm. \u201cGentle reader,\u201d he wrote\u2014again adapting freely from Coote\u2014\n\nthou must learne the Alphabet, to wit, the order of the Letters as they stand, perfectly without booke, and where every Letter standeth: as b neere the beginning, n about the middest, and t toward the end. Nowe if the word, which thou art desirous to finde, begin with a then looke in the beginning of this Table, but if with v looke towards the end. Againe, if thy word beginne with ca looke in the beginning of the letter c but if with cu then looke toward the end of that letter. And so of all the rest. &c.\n\nIt was not easy to explain. Friar Johannes Balbus of Genoa tried in his 1286 *Catholicon*. Balbus thought he was inventing alphabetical order for the first time, and his instructions were painstaking: \u201cFor example I intend to discuss amo and bibo. I will discuss amo before bibo because a is the first letter of amo and b is the first letter of bibo and a is before b in the alphabet. Similarly \u2026\u201d He rehearsed a long list of examples and concluded: \u201cI beg of you, therefore, good reader, do not scorn this great labor of mine and this order as something worthless.\u201d\n\nIn the ancient world, alphabetical lists scarcely appeared until around 250 BCE, in papyrus texts from Alexandria. The great library there seems to have used at least some alphabetization in organizing its books. The need for such an artificial ordering scheme arises only with large collections of data, not otherwise ordered.\nAnd the possibility of alphabetical order arises only in languages possessing an alphabet: a discrete small symbol set with its own conventional sequence (\u201cabecedarie, the order of the Letters, or hee that useth them\u201d). Even then the system is unnatural. It forces the user to detach information from meaning; to treat words strictly as character strings; to focus abstractly on the configuration of the word. Furthermore, alphabetical ordering comprises a pair of procedures, one the inverse of the other: organizing a list and looking up items; sorting and searching. In either direction the procedure is recursive (\u201crecourse, a running backe againe\u201d). The basic operation is a binary decision: greater than or less than. This operation is performed first on one letter; then, nested as a subroutine, on the next letter; and (as Cawdrey put it, struggling with the awkwardness) \u201cso of all the rest. &c.\u201d This makes for astounding efficiency. The system scales easily to any size, the macrostructure being identical to the microstructure. A person who understands alphabetical order homes in on any one item in a list of a thousand or a million, unerringly, with perfect confidence. And without knowing anything about the meaning.\n\nNot until 1613 was the first alphabetical catalogue made\u2014not printed, but written in two small handbooks\u2014for the Bodleian Library at Oxford. The first catalogue of a university library, made at Leiden, Holland, two decades earlier, was arranged by subject matter, as a shelf list (about 450 books), with no alphabetical index. Of one thing Cawdrey could be sure: his typical reader, a literate, book-buying Englishman at the turn of the seventeenth century, could live a lifetime without ever encountering a set of data ordered alphabetically.\n\nMore sensible ways of ordering words came first and lingered for a long time. In China the closest thing to a dictionary for many centuries was the *Erya*, author unknown, date unknown but probably around the third century BCE. It arranged its two thousand entries by meaning, in topical categories: kinship, building, tools and weapons, the heavens, the earth, plants and animals. Egyptian had word lists organized on philosophical or educational principles; so did Arabic. These lists were arranging not the words themselves, mainly, but rather the world: the things for which the words stood. In Germany, a century after Cawdrey, the philosopher and mathematician Gottfried Wilhelm Leibniz made this distinction explicit:\n\n> Let me mention that the words or names of all things and actions can be brought into a list in two different ways, according to the alphabet and according to nature\u2026. The former go from the word to the thing, the latter from the thing to the word.\n\nTopical lists were thought provoking, imperfect, and creative. Alphabetical lists were mechanical, effective, and automatic. Considered alphabetically, words are no more than tokens, each placed in a slot. In effect they may as well be numbers.\nMeaning comes into the dictionary in its definitions, of course. Cawdrey\u2019s crucial models were dictionaries for translation, especially a 1587 Latin-English *Dictionarium* by Thomas Thomas. A bilingual dictionary had a clearer purpose than a dictionary of one language alone: mapping Latin onto English made a kind of sense that translating English to English did not. Yet definitions were the point, Cawdrey\u2019s stated purpose being after all to help people understand and use hard words. He approached the task of definition with a trepidation that remains palpable. Even as he defined his words, Cawdrey still did not quite believe in their solidity. Meanings were even more fluid than spellings. *Define*, to Cawdrey, was for things, not for words: \u201c**define**, to shew clearely what a thing is.\u201d It was reality, in all its richness, that needed defining. *Interpret* meant \u201copen, make plaine, to shewe the sence and meaning of a thing.\u201d For him the relationship between the thing and the word was like the relationship between an object and its shadow.\n\nThe relevant concepts had not reached maturity:\n\n- **figureate**, to shadowe, or represent, or to counterfaite\n- **type**, figure, example, shadowe of any thing\n- **represent**, expresse, beare shew of a thing\n\nAn earlier contemporary of Cawdrey\u2019s, Ralph Lever, made up his own word: \u201c**saywhat**, corruptly called a definition: but it is a saying which telleth what a thing is, it may more aptly be called a saywhat.\u201d This did not catch on. It took almost another century\u2014and the examples of Cawdrey and his successors\u2014for the modern sense to come into focus: \u201cDefinition,\u201d John Locke finally writes in 1690, \u201cbeing nothing but making another understand by Words, what Idea the Term defin\u2019d stands for.\u201d And Locke still takes an operational view. Definition is communication: making another understand; sending a message.\n\nCawdrey borrows definitions from his sources, combines them, and adapts them. In many case he simply maps one word onto another:\n\n- **orifice**, mouth\n- **baud**, whore\n- **helmet**, head peece\n\nFor a small class of words he uses a special designation, the letter *k*: \u201cstandeth for a kind of.\u201d He does not consider it his job to say *what* kind. Thus:\n\n- **crocodile**, *k* beast\n- **alabaster**, *k* stone\n- **citron**, *k* fruit\n\nBut linking pairs of words, either as synonyms or as members of a class, can carry a lexicographer only so far. The relationships among the words of a\nlanguage are far too complex for so linear an approach (\"chaos, a confused heap of mingle-mangle\"). Sometimes Cawdrey tries to cope by adding one or more extra synonyms, definition by triangulation:\n\n- **specke**, spot, or marke\n- **cynicall**, doggish, froward\n- **vapor**, moisture, ayre, hote breath, or reaking\n\nFor other words, representing concepts and abstractions, further removed from the concrete realm of the senses, Cawdrey needs to find another style altogether. He makes it up as he goes along. He must speak to his reader, in prose but not quite in sentences, and we can hear him struggle, both to understand certain words and to express his understanding.\n\n- **gargarise**, to wash the mouth, and throate within, by stirring some liquor up and downe in the mouth\n- **hipocrite**, such a one as in his outward apparrell, countenaunce, & behaviour, pretendeth to be another man, then he is indeede, or a deceiver\n- **buggerie**, coniunction with one of the same kinde, or of men with beasts\n- **theologie**, divinitie, the science of living blessedly for ever\n\nAmong the most troublesome were technical terms from new sciences:\n\n- **cypher**, a circle in numbering, of no value of it selfe, but serveth to make up the number, and to make other figures of more value\n- **horizon**, a circle, deviding the halfe of the firmament, from the other halfe which we see not\n- **zodiack**, a circle in the heaven, wherein be placed the 12 signes, and in which the Sunne is mooved\n\nNot just the words but the knowledge was in flux. The language was examining itself. Even when Cawdrey is copying from Coote or Thomas, he is fundamentally alone, with no authority to consult.\n\nOne of Cawdrey\u2019s hard usual words was *science* (\"knowledge, or skill\"). Science did not yet exist as an institution responsible for learning about the material universe and its laws. Natural philosophers were beginning to have a special interest in the nature of words and their meaning. They needed better than they had. When Galileo pointed his first telescope skyward and discovered sunspots in 1611, he immediately anticipated controversy\u2014traditionally the sun was an epitome of purity\u2014and he sensed that science could not proceed without first solving a problem of language:\n\n> So long as men were in fact obliged to call the sun \u201cmost pure and most lucid,\u201d no shadows or impurities whatever had been perceived in it; but now that it shows itself to us as partly impure and spotty; why should we not call it \u201cspotted and not pure\u201d? For names and attributes must be accommodated to the essence of things, and not the essence to the names, since things come first and names afterwards.\nWhen Isaac Newton embarked on his great program, he encountered a fundamental lack of definition where it was most needed. He began with a semantic sleight of hand: \u201cI do not define time, space, place, and motion, as being well known to all,\u201d he wrote deceptively. Defining these words was his very purpose. There were no agreed standards for weights and measures. *Weight* and *measure* were themselves vague terms. Latin seemed more reliable than English, precisely because it was less worn by everyday use, but the Romans had not possessed the necessary words either. Newton\u2019s raw notes reveal a struggle hidden in the finished product. He tried expressions like *quantitas materiae*. Too hard for Cawdrey: \u201cmateriall, of some matter, or importance.\u201d Newton suggested (to himself) \u201cthat which arises from its density and bulk conjointly.\u201d He considered more words: \u201cThis quantity I designate under the name of body or mass.\u201d Without the right words he could not proceed. *Velocity, force, gravity*\u2014none of these were yet suitable. They could not be defined in terms of one another; there was nothing in visible nature at which anyone could point a finger; and there was no book in which to look them up.\n\nAs for Robert Cawdrey, his mark on history ends with the publication of his *Table Alphabeticall* in 1604. No one knows when he died. No one knows how many copies the printer made. There are no records (\u201crecords, writings layde up for remembrance\u201d). A single copy made its way to the Bodleian Library in Oxford, which has preserved it. All the others disappeared. A second edition appeared in 1609, slightly expanded (\u201cmuch inlarged,\u201d the title page claims falsely) by Cawdrey\u2019s son, Thomas, and a third and fourth appeared in 1613 and 1617, and there the life of this book ended.\n\nIt was overshadowed by a new dictionary, twice as comprehensive, *An English Expositour: Teaching the Interpretation of the hardest Words used in our Language, with sundry Explications, Descriptions, and Discourses*. Its compiler, John Bullokar, otherwise left as faint a mark on the historical record as Cawdrey did. He was doctor of physic; he lived for some time in Chichester; his dates of birth and death are uncertain; he is said to have visited London in 1611 and there to have seen a dead crocodile; and little else is known. His *Expositour* appeared in 1616 and went through several editions in the succeeding decades. Then in 1656 a London barrister, Thomas Blount, published his *Glossographia: or a Dictionary, Interpreting all such Hard Words of Whatsoever Language, now used in our refined English Tongue*. Blount\u2019s dictionary listed more than eleven thousand words, many of which, he recognized, were new, reaching London in the hurly-burly of trade and commerce\u2014\n\n*coffa* or *cauphe*, a kind of drink among the Turks and Persians, (and of late introduced among us) which is black, thick and bitter, destrained from Berries of that nature, and name, thought good and very wholesom: they say it expels melancholy.\n\u2014or home-grown, such as \u201ctom-boy, a girl or wench that leaps up and down like a boy.\u201d He seems to have known he was aiming at a moving target. The dictionary maker\u2019s \u201clabor,\u201d he wrote in his preface, \u201cwould find no end, since our English tongue daily changes habit.\u201d Blount\u2019s definitions were much more elaborate than Cawdrey\u2019s, and he tried to provide information about the origins of words as well.\n\nNeither Bullokar nor Blount so much as mentioned Cawdrey. He was already forgotten. But in 1933, upon the publication of the greatest word book of all, the first editors of the *Oxford English Dictionary* did pay their respects to his \u201cslim, small volume.\u201d They called it \u201cthe original acorn\u201d from which their oak had grown. (Cawdrey: \u201cakecorne, k fruit.\u201d)\n\nFour hundred and two years after the *Table Alphabeticall*, the International Astronomical Union voted to declare Pluto a nonplanet, and John Simpson had to make a quick decision. He and his band of lexicographers in Oxford were working on the P\u2019s. *Pletzel, plish, pod person, point-and-shoot,* and *polyamorous* were among the new words entering the *OED*. The entry for Pluto was itself relatively new. The planet had been discovered only in 1930, too late for the *OED*\u2019s first edition. The name Minerva was first proposed and then rejected because there was already an asteroid Minerva. In terms of names, the heavens were beginning to fill up. Then \u201cPluto\u201d was suggested by Venetia Burney, an eleven-year-old resident of Oxford. The *OED* caught up by adding an entry for Pluto in its second edition: \u201c1. A small planet of the solar system lying beyond the orbit of Neptune \u2026 2. The name of a cartoon dog that made its first appearance in Walt Disney\u2019s *Moose Hunt*, released in April 1931.\u201d\n\n\u201cWe really don\u2019t like being pushed into megachanges,\u201d Simpson said, but he had little choice. The Disney meaning of *Pluto* had proved more stable than the astronomical sense, which was downgraded to \u201csmall planetary body.\u201d Consequences rippled through the *OED*. *Pluto* was removed from the list under *planet n.* 3a. *Plutonian* was revised (not to be confused with *pluton, plutey, or plutonyl*).\n\nSimpson was the sixth in a distinguished line, the editors of the *Oxford English Dictionary*, whose names rolled fluently off his tongue\u2014\u201cMurray, Bradley, Craigie, Onions, Burchfield, so however many fingers that is\u201d\u2014and saw himself as a steward of their traditions, as well as traditions of English lexicography extending back to Cawdrey by way of Samuel Johnson. James Murray in the nineteenth century established a working method based on index cards, slips of paper 6 inches by 4 inches. At any given moment a thousand such slips sat on Simpson\u2019s desk, and within a stone\u2019s throw were millions more, filling metal files and wooden boxes with the ink of two centuries. But the word-slips had gone\nobsolete. They had become treeware. Treeware had just entered the *OED* as \u201ccomputing slang, freq. humorous\u201d; blog was recognized in 2003, dot-commer in 2004, cyberpet in 2005, and the verb to Google in 2006. Simpson himself Googled often. Beside the word-slips his desk held conduits into the nervous system of the language: instantaneous connection to a worldwide network of proxy amateur lexicographers and access to a vast, interlocking set of databases growing asymptotically toward the ideal of All Previous Text. The dictionary had met cyberspace, and neither would be the same thereafter. However much Simpson loved the *OED*\u2019s roots and legacy, he was leading a revolution, willy-nilly\u2014in what it was, what it knew, what it saw. Where Cawdrey had been isolated, Simpson was connected.\n\nThe English language, spoken now by more than a billion people globally, has entered a period of ferment, and the perspective available in these venerable Oxford offices is both intimate and sweeping. The language upon which the lexicographers eavesdrop has become wild and amorphous: a great, swirling, expanding cloud of messaging and speech; newspapers, magazines, pamphlets; menus and business memos; Internet news groups and chat-room conversations; television and radio broadcasts and phonograph records. By contrast, the dictionary itself has acquired the status of a monument, definitive and towering. It exerts an influence on the language it tries to observe. It wears its authoritative role reluctantly. The lexicographers may recall Ambrose Bierce\u2019s sardonic century-old definition: \u201cdictionary, a malevolent literary device for cramping the growth of a language and making it hard and inelastic.\u201d Nowadays they stress that they do not presume (or deign) to disapprove any particular usage or spelling. But they cannot disavow a strong ambition: the goal of completeness. They want every word, all the lingo: idioms and euphemisms, sacred or profane, dead or alive, the King\u2019s English or the street\u2019s. It is an ideal only: the constraints of space and time are ever present and, at the margins, the question of what qualifies as a word can become impossible to answer. Still, to the extent possible, the *OED* is meant to be a perfect record, perfect mirror of the language.\n\nThe dictionary ratifies the persistence of the word. It declares that the meanings of words come from other words. It implies that all words, taken together, form an interlocking structure: interlocking, because all words are defined in terms of other words. This could never have been an issue in an oral culture, where language was barely visible. Only when printing\u2014and the dictionary\u2014put the language into separate relief, as an object to be scrutinized, could anyone develop a sense of word meaning as interdependent and even circular. Words had to be considered as words, representing other words, apart from things. In the twentieth century, when the technologies of logic advanced to high levels, the potential for circularity became a problem. \u201cIn giving explanations I already have to use\nlanguage full blown,\u201d complained Ludwig Wittgenstein. He echoed Newton\u2019s frustration three centuries earlier, but with an extra twist, because where Newton wanted words for nature\u2019s laws, Wittgenstein wanted words for words: \u201cWhen I talk about language (words, sentences, etc.) I must speak the language of every day. Is this language somehow too coarse and material for what we want to say?\u201d Yes. And the language was always in flux.\n\nJames Murray was speaking of the language as well as the book when he said, in 1900, \u201cThe English Dictionary, like the English Constitution, is the creation of no one man, and of no one age; it is a growth that has slowly developed itself adown the ages.\u201d The first edition of what became the OED was one of the largest books that had ever been made: A New English Dictionary on Historical Principles, 414,825 words in ten weighty volumes, presented to King George V and President Calvin Coolidge in 1928. The work had taken decades; Murray himself was dead; and the dictionary was understood to be out of date even as the volumes were bound and sewn. Several supplements followed, but not till 1989 did the second edition appear: twenty volumes, totaling 22,000 pages. It weighed 138 pounds. The third edition is different. It is weightless, taking its shape in the digital realm. It may never again involve paper and ink. Beginning in the year 2000, a revision of the entire contents began to appear online in quarterly installments, each comprising several thousand revised entries and hundreds of new words.\n\nCawdrey had begun work naturally enough with the letter A, and so had James Murray in 1879, but Simpson chose to begin with M. He was wary of the A\u2019s. To insiders it had long been clear that the OED as printed was not a seamless masterpiece. The early letters still bore scars of the immaturity of the uncertain work in Murray\u2019s first days. \u201cBasically he got here, sorted his suitcases out and started setting up text,\u201d Simpson said. \u201cIt just took them a long time to sort out their policy and things, so if we started at A, then we\u2019d be making our job doubly difficult. I think they\u2019d sorted themselves out by \u2026 well, I was going to say D, but Murray always said that E was the worst letter, because his assistant, Henry Bradley, started E, and Murray always said that he did that rather badly. So then we thought, maybe it\u2019s safe to start with G, H. But you get to G and H and there\u2019s I, J, K, and you know, you think, well, start after that.\u201d\n\nThe first thousand entries from M to mahurat went online in the spring of 2000. A year later, the lexicographers reached words starting with me: me-ism (a creed for modern times), meds (colloq. for drugs), medsspeak (doctors\u2019 jargon), meet-and-greet (a N. Amer. type of social occasion), and an assortment of combined forms under media (baron, circus, darling, hype, savvy) and mega- (pixel, bitch, dose, hit, trend). This was no longer a language spoken by 5 million mostly illiterate inhabitants of a small island. As the OED revised the entries letter by\nletter, it also began adding neologisms wherever they arose; waiting for the alphabetical sequence became impractical. Thus one installment in 2001 saw the arrival of *acid jazz*, *Bollywood*, *channel surfing*, *double-click*, *emoticon*, *feel-good*, *gangsta*, *hyperlink*, and many more. *Kool-Aid* was recognized as a new word, not because the *OED* feels obliged to list proprietary names (the original Kool-Ade powdered drink had been patented in the United States in 1927) but because a special usage could no longer be ignored: \u201cto drink the Kool-Aid: to demonstrate unquestioning obedience or loyalty.\u201d The growth of this peculiar expression since the use of a powdered beverage in a mass poisoning in Guyana in 1978 bespoke a certain density of global communication.\n\nBut they were no slaves to fashion, these Oxford lexicographers. As a rule a neologism needs five years of solid evidence for admission to the canon. Every proposed word undergoes intense scrutiny. The approval of a new word is a solemn matter. It must be in general use, beyond any particular place of origin; the *OED* is global, recognizing words from everywhere English is spoken, but it does not want to capture local quirks. Once added, a word cannot come out. A word can go obsolete or rare, but the most ancient and forgotten words have a way of reappearing\u2014rediscovered or spontaneously reinvented\u2014and in any case they are part of the language\u2019s history. All 2,500 of Cawdrey\u2019s words are in the *OED*, perforce. For thirty-one of them Cawdrey\u2019s little book was the first known usage. For a few Cawdrey is all alone. This is troublesome. The *OED* is irrevocably committed. Cawdrey, for example, has \u201conust, loaded, overcharged\u201d; so the *OED* has \u201cloaded, burdened,\u201d but it is an outlier, a one-off. Did Cawdrey make it up? \u201cI\u2019m tending towards the view that he was attempting to reproduce vocabulary he had heard or seen,\u201d Simpson said. \u201cBut I can\u2019t be absolutely sure.\u201d Cawdrey has \u201challucinate, to deceive, or blind\u201d; the *OED* duly gave \u201cto deceive\u201d as the first sense of the word, though it never found anyone else who used it that way. In cases like these, the editors can add their double caveat \u201cObs. rare.\u201d But there it is.\n\nFor the twenty-first-century *OED* a single source is never enough. Strangely, considering the vastness of the enterprise and its constituency, individual men and women strive to have their own nonce-words ratified by the *OED*. *Nonce-word*, in fact, was coined by James Murray himself. He got it in. An American psychologist, Sondra Smalley, coined the word *codependency* in 1979 and began lobbying for it in the eighties; the editors finally drafted an entry in the nineties, when they judged the word to have become established. W. H. Auden declared that he wanted to be recognized as an *OED* word coiner\u2014and he was, at long last, for *motted*, *metalogue*, *spitzy*, and others. The dictionary had thus become engaged in a feedback loop. It inspired a twisty self-consciousness in the language\u2019s users and creators. Anthony Burgess whinged in print about his\ninability to break through: \u201cI invented some years ago the word *amation*, for the art or act of making love, and still think it useful. But I have to persuade others to use it *in print* before it is eligible for lexicographicizing (if that word exists)\u201d \u2014 he knew it did not. \u201cT. S. Eliot\u2019s large authority got the shameful (in my view) *juvescence* into the previous volume of the Supplement.\u201d Burgess was quite sure that Eliot simply misspelled *juvenescence*. If so, the misspelling was either copied or reprised twenty-eight years later by Stephen Spender, so *juvescence* has two citations, not one. The *OED* admits that it is rare.\n\nAs hard as the *OED* tries to embody the language\u2019s fluidity, it cannot help but serve as an agent of its crystallization. The problem of spelling poses characteristic difficulties. \u201cEvery form in which a word has occurred throughout its history\u201d is meant to be included. So for *mackerel* (\u201ca well-known sea-fish, *Scomber scombrus*, much used for food\u201d) the second edition in 1989 listed nineteen alternative spellings. The unearthing of sources never ends, though, so the third edition revised entry in 2002 listed no fewer than thirty: *maccarel, mackaral, mackarel, mackarell, mackerell, mackeril, mackreel, mackrel, mackrell, mackril, macquerel, macquerell, macrel, macrell, macrelle, macril, macrill, makarell, makcaral, makerel, makerell, makerelle, makral, makrall, makreill, makrel, makrell, makyrelle, maquerel, and maycril*. As lexicographers, the editors would never declare these alternatives to be wrong: misspellings. They do not wish to declare their choice of spelling for the headword, *mackerel*, to be \u201ccorrect.\u201d They emphasize that they examine the evidence and choose \u201cthe most common current spelling.\u201d Even so, arbitrary considerations come into play: \u201cOxford\u2019s house style occasionally takes precedence, as with verbs which can end -ize or -ise, where the -ize spelling is always used.\u201d They know that no matter how often and how firmly they disclaim a prescriptive authority, a reader will turn to the dictionary to find out how a word should be spelled. They cannot escape inconsistencies. They feel obliged to include words that make purists wince. A new entry as of December 2003 memorialized *nucular*: \u201c= nuclear a. (in various senses).\u201d Yet they refuse to count evident misprints found by way of Internet searches. They do not recognize *straight-laced*, even though statistical evidence finds that bastardized form outnumbering *strait-laced*. For the crystallization of spelling, the *OED* offers a conventional explanation: \u201cSince the invention of the printing press, spelling has become much less variable, partly because printers wanted uniformity and partly because of a growing interest in language study during the Renaissance.\u201d This is true. But it omits the role of the dictionary itself, arbitrator and exemplar.\n\nFor Cawdrey the dictionary was a snapshot; he could not see past his moment in time. Samuel Johnson was more explicitly aware of the dictionary\u2019s historical\ndimension. He justified his ambitious program in part as a means of bringing a wild thing under control\u2014the wild thing being the language, \u201cwhich, while it was employed in the cultivation of every species of literature, has itself been hitherto neglected; suffered to spread, under the direction of chance, into wild exuberance; resigned to the tyranny of time and fashion; and exposed to the corruptions of ignorance, and caprices of innovation.\u201d Not until the *OED*, though, did lexicography attempt to reveal the whole shape of a language across time. The *OED* becomes a historical panorama. The project gains poignancy if the electronic age is seen as a new age of orality, the word breaking free from the bonds of cold print. No publishing institution better embodies those bonds, but the *OED*, too, tries to throw them off. The editors feel they can no longer wait for a new word to appear in print, let alone in a respectably bound book, before they must take note. For *tighty-whities* (men\u2019s underwear), new in 2007, they cite a typescript of North Carolina campus slang. For *kitesurfer*, they cite a posting to the Usenet newsgroup alt.kite and later a New Zealand newspaper found via an online database. Bits in the ether.\n\nWhen Murray began work on the new dictionary, the idea was to find the words, and with them the signposts to their history. No one had any idea how many words were there to be found. By then the best and most comprehensive dictionary of English was American: Noah Webster\u2019s, seventy thousand words. That was a baseline. Where were the rest to be discovered? For the first editors of what became the *OED*, it went almost without saying that the source, the wellspring, should be the literature of the language\u2014particularly the books of distinction and quality. The dictionary\u2019s first readers combed Milton and Shakespeare (still the single most quoted author, with more than thirty thousand references), Fielding and Swift, histories and sermons, philosophers and poets. Murray announced in a famous public appeal in 1879:\n\n> A thousand readers are wanted. The later sixteenth-century literature is very fairly done; yet here several books remain to be read. The seventeenth century, with so many more writers, naturally shows still more unexplored territory.\n\nHe considered the territory to be large but bounded. The founders of the dictionary explicitly meant to find every word, however many that would ultimately be. They planned a complete inventory. Why should they not? The number of books was unknown but not unlimited, and the number of words in those books was countable. The task seemed formidable but finite.\n\nIt no longer seems finite. Lexicographers are accepting the language\u2019s boundlessness. They know by heart Murray\u2019s famous remark: \u201cThe circle of the English language has a well-defined centre but no discernable circumference.\u201d In the center are the words everyone knows. At the edges, where Murray placed slang and cant and scientific jargon and foreign border crossers, everyone\u2019s sense\nof the language differs and no one\u2019s can be called \u201cstandard.\u201d\n\nMurray called the center \u201cwell defined,\u201d but infinitude and fuzziness can be seen there. The easiest, most common words\u2014the words Cawdrey had no thought of including\u2014require, in the *OED*, the most extensive entries. The entry for *make* alone would fill a book: it teases apart ninety-eight distinct senses of the verb, and some of these senses have a dozen or more subsenses. Samuel Johnson saw the problem with these words and settled on a solution: he threw up his hands.\n\nMy labor has likewise been much increased by a class of verbs too frequent in the English language, of which the signification is so loose and general, the use so vague and indeterminate, and the senses detorted so widely from the first idea, that it is hard to trace them through the maze of variation, to catch them on the brink of utter inanity, to circumscribe them by any limitations, or interpret them by any words of distinct and settled meaning; such are *bear, break, come, cast, full, get, give, do, put, set, go, run, make, take, turn, throw*. If of these the whole power is not accurately delivered, it must be remembered, that while our language is yet living, and variable by the caprice of every one that speaks it, these words are hourly shifting their relations, and can no more be ascertained in a dictionary, than a grove, in the agitation of a storm, can be accurately delineated from its picture in the water.\n\nJohnson had a point. These are words that any speaker of English can press into new service at any time, on any occasion, alone or in combination, inventively or not, with hopes of being understood. In every revision, the *OED*\u2019s entry for a word like *make* subdivides further and thus grows larger. The task is unbounded in an inward-facing direction.\n\nThe more obvious kind of unboundedness appears at the edges. Neologism never ceases. Words are coined by committee: *transistor*, Bell Laboratories, 1948. Or by wags: *booboisie*, H. L. Mencken, 1922. Most arise through spontaneous generation, organisms appearing in a petri dish, like *blog* (c. 1999). One batch of arrivals includes *agroterrorism, bada-bing, bahookie* (a body part), *beer pong* (a drinking game), *bippy* (as in, you bet your \u2014\u2014\u2014), *chucklesome, cypherpunk, tuneage,* and *wonky*. None are what Cawdrey would have seen as \u201chard, usual words,\u201d and none are anywhere near Murray\u2019s well-defined center, but they now belong to the common language. Even *bada-bing*: \u201cSuggesting something happening suddenly, emphatically, or easily and predictably; \u2018Just like that!\u2019, \u2018Presto!\u2019\u201d The historical citations begin with a 1965 audio recording of a comedy routine by Pat Cooper and continue with newspaper clippings, a television news transcript, and a line of dialogue from the first *Godfather* movie: \u201cYou\u2019ve gotta get up close like this and bada-bing! you blow their brains all over your nice Ivy League suit.\u201d The lexicographers also provide an etymology, an exquisite piece of guesswork: \u201cOrigin uncertain. Perh. imitative of the sound of a drum roll and cymbal clash. Perh. cf. Italian *bada bene* mark well.\u201d\n\nThe English language no longer has such a thing as a geographic center, if it\nThe Information\n\never did. The universe of human discourse always has backwaters. The language spoken in one valley diverges from the language of the next valley, and so on. There are more valleys now than ever, even if the valleys are not so isolated. \u201cWe are listening to the language,\u201d said Peter Gilliver, an *OED* lexicographer and resident historian. \u201cWhen you are listening to the language by collecting pieces of paper, that\u2019s fine, but now it\u2019s as if we can hear everything said anywhere. Take an expatriate community living in a non-English-speaking part of the world, expatriates who live at Buenos Aires or something. Their English, the English that they speak to one another every day, is full of borrowings from local Spanish. And so they would regard those words as part of their idiolect, their personal vocabulary.\u201d Only now they may also speak in chat rooms and on blogs. When they coin a word, anyone may hear. Then it may or may not become part of the language.\n\nIf there is an ultimate limit to the sensitivity of lexicographers\u2019 ears, no one has yet found it. Spontaneous coinages can have an audience of one. They can be as ephemeral as atomic particles in a bubble chamber. But many neologisms require a level of shared cultural knowledge. Perhaps *bada-bing* would not truly have become part of twenty-first-century English had it not been for the common experience of viewers of a particular American television program (though it is not cited by the *OED*).\n\nThe whole word hoard\u2014the lexis\u2014constitutes a symbol set of the language. It is the fundamental symbol set, in one way: words are the first units of meaning any language recognizes. They are recognized universally. But in another way it is far from fundamental: as communication evolves, messages in a language can be broken down and composed and transmitted in much smaller sets of symbols: the alphabet; dots and dashes; drumbeats high and low. These symbol sets are discrete. The lexis is not. It is messier. It keeps on growing. Lexicography turns out to be a science poorly suited to exact measurement. English, the largest and most widely shared language, can be said very roughly to possess a number of units of meaning that approaches a million. Linguists have no special yardsticks of their own; when they try to quantify the pace of neologism, they tend to look to the dictionary for guidance, and even the best dictionary runs from that responsibility. The edges always blur. A clear line cannot be drawn between word and unword.\n\nSo we count as we can. Robert Cawdrey\u2019s little book, making no pretense to completeness, contained a vocabulary of only 2,500. We possess now a more complete dictionary of English as it was circa 1600: the subset of the *OED* comprising words then current. That vocabulary numbers 60,000 and keeps growing, because the discovery of sixteenth-century sources never ends. Even so,\nit is a tiny fraction of the words used four centuries later. The explanation for this explosive growth, from 60,000 to a million, is not simple. Much of what now needs naming did not yet exist, of course. And much of what existed was not recognized. There was no call for *transistor* in 1600, nor *nanobacterium*, nor *webcam*, nor *fen-phen*. Some of the growth comes from mitosis. The guitar divides into the electric and the acoustic; other words divide in reflection of delicate nuances (as of March 2007 the *OED* assigned a new entry to *prevert* as a form of *pervert*, taking the view that *prevert* was not just an error but a deliberately humorous effect). Other new words appear without any corresponding innovation in the world of real things. They crystallize in the solvent of universal information.\n\nWhat, in the world, is a *mondegreen*? It is a misheard lyric, as when, for example, the Christian hymn is heard as \u201cLead on, O kinky turtle \u2026\u201d). In sifting the evidence, the *OED* first cites a 1954 essay in *Harper\u2019s Magazine* by Sylvia Wright: \u201cWhat I shall hereafter call mondegreens, since no one else has thought up a word for them.\u201d She explained the idea and the word this way:\n\n> When I was a child, my mother used to read aloud to me from Percy\u2019s Reliques, and one of my favorite poems began, as I remember:\n>\n> *Ye Highlands and ye Lowlands,*\n> *Oh, where hae ye been?*\n> *They hae slain the Earl Amurray,*\n> *And Lady Mondegreen.*\n\nThere the word lay, for some time. A quarter-century later, William Safire discussed the word in a column about language in *The New York Times Magazine*. Fifteen years after that, Steven Pinker, in his book *The Language Instinct*, offered a brace of examples, from \u201cA girl with colitis goes by\u201d to \u201cGladly the cross-eyed bear,\u201d and observed, \u201cThe interesting thing about mondegreens is that the mishearings are generally *less* plausible than the intended lyrics.\u201d But it was not books or magazines that gave the word its life; it was Internet sites, compiling mondegreens by the thousands. The *OED* recognized the word in June 2004.\n\nA mondegreen is not a transistor, inherently modern. Its modernity is harder to explain. The ingredients\u2014songs, words, and imperfect understanding\u2014are all as old as civilization. Yet for mondegreens to arise in the culture, and for *mondegreen* to exist in the lexis, required something new: a modern level of linguistic self-consciousness and interconnectedness. People needed to mishear lyrics not just once, not just several times, but often enough to become aware of the mishearing as a thing worth discussing. They needed to have other such people with whom to share the recognition. Until the most modern times, mondegreens, like countless other cultural or psychological phenomena, simply\ndid not need to be named. Songs themselves were not so common; not heard, anyway, on elevators and mobile phones. The word *lyrics*, meaning the words of a song, did not exist until the nineteenth century. The conditions for mondegreens took a long time to ripen. Similarly, the verb *to gaslight* now means \u201cto manipulate a person by psychological means into questioning his or her own sanity\u201d; it exists only because enough people saw the 1944 film of that title and could assume that their listeners had seen it, too. Might not the language Cawdrey spoke\u2014which was, after all, the abounding and fertile language of Shakespeare\u2014have found use for such a word? No matter: the technology for *gaslight* had not been invented. Nor had the technology for motion pictures.\n\nThe lexis is a measure of shared experience, which comes from interconnectedness. The number of users of the language forms only the first part of the equation: jumping in four centuries from 5 million English speakers to a billion. The driving factor is the number of connections between and among those speakers. A mathematician might say that messaging grows not geometrically, but combinatorially, which is much, much faster. \u201cI think of it as a saucepan under which the temperature has been turned up,\u201d Gilliver said. \u201cAny word, because of the interconnectedness of the English-speaking world, can spring from the backwater. And they are still backwaters, but they have this instant connection to ordinary, everyday discourse.\u201d Like the printing press, the telegraph, and the telephone before it, the Internet is transforming the language simply by transmitting information differently. What makes cyberspace different from all previous information technologies is its intermixing of scales from the largest to the smallest without prejudice, broadcasting to the millions, narrowcasting to groups, instant messaging one to one.\n\nThis comes as quite an unexpected consequence of the invention of computing machinery. At first, that had seemed to be about numbers.\n4 | TO THROW THE POWERS OF THOUGHT INTO WHEEL-WORK\n\n(Lo, the Raptured Arithmetician)\n\nLight almost solar has been extracted from the refuse of fish; fire has been sifted by the lamp of Davy; and machinery has been taught arithmetic instead of poetry.\n\n\u2014Charles Babbage (1832)\n\nNO ONE DOUBTED THAT Charles Babbage was brilliant. Nor did anyone quite understand the nature of his genius, which remained out of focus for a long time. What did he hope to achieve? For that matter, what, exactly, was his vocation? On his death in London in 1871 the Times obituarist declared him \u201cone of the most active and original of original thinkers\u201d but seemed to feel he was best known for his long, cranky crusade against street musicians and organ-grinders. He might not have minded. He was multifarious and took pride in it. \u201cHe showed great desire to inquire into the causes of things that astonish childish minds,\u201d said an American eulogist. \u201cHe eviscerated toys to ascertain their manner of working.\u201d Babbage did not quite belong in his time, which called itself the Steam Age or the Machine Age. He did revel in the uses of steam and machinery and considered himself a thoroughly modern man, but he also pursued an assortment of hobbies and obsessions\u2014cipher cracking, lock picking, lighthouses, tree rings, the post\u2014whose logic became clearer a century later. Examining the economics of the mail, he pursued a counterintuitive insight, that the significant cost comes not from the physical transport of paper packets but from their \u201cverification\u201d\u2014the calculation of distances and the collection of correct fees\u2014and thus he invented the modern idea of standardized postal rates. He loved boating, by which he meant not \u201cthe manual labor of rowing but the more intellectual art of sailing.\u201d He was a train buff. He devised a railroad recording device that used inking pens to trace curves on sheets of paper a thousand feet long: a combination seismograph and speedometer, inscribing the history of a train\u2019s velocity and all the bumps and shakes along the way.\n\nAs a young man, stopping at an inn in the north of England, he was amused to hear that his fellow travelers had been debating his trade:\n\n\u201cThe tall gentleman in the corner,\u201d said my informant, \u201cmaintained you were in the hardware line; whilst the fat gentleman who sat next to you at supper was\nquite sure that you were in the spirit trade. Another of the party declared that they were both mistaken: he said you were travelling for a great iron-master.\u201d\n\n\u201cWell,\u201d said I, \u201cyou, I presume, knew my vocation better than our friends.\u201d\n\n\u201cYes,\u201d said my informant, \u201cI knew perfectly well that you were in the Nottingham lace trade.\u201d\n\nHe might have been described as a professional mathematician, yet here he was touring the country\u2019s workshops and manufactories, trying to discover the state of the art in machine tools. He noted, \u201cThose who enjoy leisure can scarcely find a more interesting and instructive pursuit than the examination of the workshops of their own country, which contain within them a rich mine of knowledge, too generally neglected by the wealthier classes.\u201d He himself neglected no vein of knowledge. He did become expert on the manufacture of Nottingham lace; also the use of gunpowder in quarrying limestone; precision glass cutting with diamonds; and all known uses of machinery to produce power, save time, and communicate signals. He analyzed hydraulic presses, air pumps, gas meters, and screw cutters. By the end of his tour he knew as much as anyone in England about the making of pins. His knowledge was practical and methodical. He estimated that a pound of pins required the work of ten men and women for at least seven and a half hours, drawing wire, straightening wire, pointing the wire, twisting and cutting heads from the spiral coils, tinning or whitening, and finally papering. He computed the cost of each phase in millionths of a penny. And he noted that this process, when finally perfected, had reached its last days: an American had invented an automatic machine to accomplish the same task, faster.\n\nBabbage invented his own machine, a great, gleaming engine of brass and pewter, comprising thousands of cranks and rotors, cogs and gearwheels, all tooled with the utmost precision. He spent his long life improving it, first in one and then in another incarnation, but all, mainly, in his mind. It never came to fruition anywhere else. It thus occupies an extreme and peculiar place in the annals of invention: a failure, and also one of humanity\u2019s grandest intellectual achievements. It failed on a colossal scale, as a scientific-industrial project \u201cat the expense of the nation, to be held as national property,\u201d financed by the Treasury for almost twenty years, beginning in 1823 with a Parliamentary appropriation of \u00a31,500 and ending in 1842, when the prime minister shut it down. Later, Babbage\u2019s engine was forgotten. It vanished from the lineage of invention. Later still, however, it was rediscovered, and it became influential in retrospect, to shine as a beacon from the past.\n\nLike the looms, forges, naileries, and glassworks he studied in his travels across northern England, Babbage\u2019s machine was designed to manufacture vast quantities of a certain commodity. The commodity was numbers. The engine opened a channel from the corporeal world of matter to a world of pure\nabstraction. The engine consumed no raw materials\u2014input and output being weightless\u2014but needed a considerable force to turn the gears. All that wheel-work would fill a room and weigh several tons. Producing numbers, as Babbage conceived it, required a degree of mechanical complexity at the very limit of available technology. Pins were easy, compared with numbers.\n\nIt was not natural to think of numbers as a manufactured commodity. They existed in the mind, or in ideal abstraction, in their perfect infinitude. No machine could add to the world\u2019s supply. The numbers produced by Babbage\u2019s engine were meant to be those with significance: numbers with a meaning. For example, $2.096910013$ has a meaning, as the logarithm of 125. (Whether every number has a meaning would be a conundrum for the next century.) The meaning of a number could be expressed as a relationship to other numbers, or as the answer to a certain question of arithmetic. Babbage himself did not speak in terms of meaning; he tried to explain his engine pragmatically, in terms of putting numbers into the machine and seeing other numbers come out, or, a bit more fancifully, in terms of posing questions to the machine and expecting an answer. Either way, he had trouble getting the point across. He grumbled:\n\nOn two occasions I have been asked,\u2014\u201cPray, Mr. Babbage, if you put into the machine wrong figures, will the right answers come out?\u201d In one case a member of the Upper, and in the other a member of the Lower, House put this question. I am not able rightly to apprehend the kind of confusion of ideas that could provoke such a question.\n\nAnyway, the machine was not meant to be a sort of oracle, to be consulted by individuals who would travel from far and wide for mathematical answers. The engine\u2019s chief mission was to print out numbers en masse. For portability, the facts of arithmetic could be expressed in tables and bound in books.\n\nTo Babbage the world seemed made of such facts. They were the \u201cconstants of Nature and Art.\u201d He collected them everywhere. He compiled a Table of Constants of the Class Mammalia: wherever he went he timed the breaths and heartbeats of pigs and cows. He invented a statistical methodology with tables of life expectancy for the somewhat shady business of life insurance. He drew up a table of the weight in Troy grains per square yard of various fabrics: cambric, calico, nankeen, muslins, silk gauze, and \u201ccaterpillar veils.\u201d Another table revealed the relative frequencies of all the double-letter combinations in English, French, Italian, German, and Latin. He researched, computed, and published a Table of the Relative Frequency of the Causes of Breaking of Plate Glass Windows, distinguishing 464 different causes, no less than fourteen of which involved \u201cdrunken men, women, or boys.\u201d But the tables closest to his heart were the purest: tables of numbers and only numbers, marching neatly across and down the pages in stately rows and columns, patterns for abstract appreciation.\nA book of numbers: amid all the species of information technology, how peculiar and powerful an object this is. \u201cLo! the raptured arithmetician!\u201d wrote \u00c9lie de Joncourt in 1762. \u201cEasily satisfied, he asks no Brussels lace, nor a coach and six.\u201d Joncourt\u2019s own contribution was a small quarto volume registering the first 19,999 triangular numbers. It was a treasure box of exactitude, perfection, and close reckoning. These numbers were so simple, just the sums of the first $n$ whole numbers: 1, 3 (1+2), 6 (1+2+3), 10 (1+2+3+4), 15, 21, 28, and so on. They had interested number theorists since Pythagoras. They offered little in the way of utility, but Joncourt rhapsodized about his pleasure in compiling them and Babbage quoted him with heartfelt sympathy: \u201cNumbers have many charms, unseen by vulgar eyes, and only discovered to the unwearied and respectful sons of Art. Sweet joy may arise from such contemplations.\u201d\n\nTables of numbers had been part of the book business even before the beginning of the print era. Working in Baghdad in the ninth century, Abu Abdullah Mohammad Ibn Musa al-Khwarizmi, whose name survives in the word algorithm, devised tables of trigonometric functions that spread west across Europe and east to China, made by hand and copied by hand, for hundreds of years. Printing brought number tables into their own: they were a natural first application for the mass production of data in the raw. For people in need of arithmetic, multiplication tables covered more and more territory: $10 \\times 1,000$, then $10 \\times 10,000$, and later as far as $1,000 \\times 1,000$. There were tables of squares and cubes, roots and reciprocals. An early form of table was the ephemeris or almanac, listing positions of the sun, moon, and planets for sky-gazers. Tradespeople found uses for number books. In 1582 Simon Stevin produced Tafelen van Interest, a compendium of interest tables for bankers and moneylenders. He promoted the new decimal arithmetic \u201cto astrologers, land-measurers, measurers of tapestry and wine casks and stereometricians, in general, mint masters and merchants all.\u201d He might have added sailors. When Christopher Columbus set off for the Indies, he carried as an aid to navigation a book of tables by Regiomontanus printed in Nuremberg two decades after the invention of moveable type in Europe.\n\nJoncourt\u2019s book of triangular numbers was purer than any of these\u2014which is also to say useless. Any arbitrary triangular number can be found (or made) by an algorithm: multiply $n$ by $n + 1$ and divide by 2. So Joncourt\u2019s whole compendium, as a bundle of information to be stored and transmitted, collapses in a puff to a one-line formula. The formula contains all the information. With it, anyone capable of simple multiplication (not many were) could generate any triangular number on demand. Joncourt knew this. Still he and his publisher, M. Husson, at the Hague, found it worthwhile to set the tables in metal type, three pairs of columns to a page, each pair listing thirty natural numbers alongside their\ncorresponding triangular numbers, from $1(1)$ to $19,999(199,990,000)$, every numeral chosen individually by the compositor from his cases of metal type and lined up in a galley frame and wedged into an iron chase to be placed upon the press.\n\nWhy? Besides the obsession and the ebullience, the creators of number tables had a sense of their economic worth. Consciously or not, they reckoned the price of these special data by weighing the difficulty of computing them versus looking them up in a book. Precomputation plus data storage plus data transmission usually came out cheaper than ad hoc computation. \u201cComputers\u201d and \u201ccalculators\u201d existed: they were people with special skills, and all in all, computing was costly.\n\nBeginning in 1767, England\u2019s Board of Longitude ordered published a yearly Nautical Almanac, with position tables for the sun, moon, stars, planets, and moons of Jupiter. Over the next half century a network of computers did the work\u2014thirty-four men and one woman, Mary Edwards of Ludlow, Shropshire, all working from their homes. Their painstaking labor paid \u00a370 a year. Computing was a cottage industry. Some mathematical sense was required but no particular genius; rules were laid out in steps for each type of calculation. In any case the computers, being human, made errors, so the same work was often farmed out twice for the sake of redundancy. (Unfortunately, being human, computers were sometimes caught saving themselves labor by copying from one other.) To manage the information flow the project employed a Comparer of the Ephemeris and Corrector of the Proofs. Communication between the computers and comparer went by post, men on foot or on horseback, a few days per message.\n\nA seventeenth-century invention had catalyzed the whole enterprise. This invention was itself a species of number, given the name logarithm. It was number as tool. Henry Briggs explained:\n\nLogarithmes are Numbers invented for the more easie working of questions in Arithmetike and Geometrie. The name is derived of Logos, which signifies Reason, and Arithmos, signifying Numbers. By them all troublesome Multiplications and Divisions in Arithmetike are avoided, and performed onely by Addition in stead of Multiplication, and by Subtraction in stead of Division.\n\nIn 1614 Briggs was a professor of geometry\u2014the first professor of geometry\u2014at Gresham College, London, later to be the birthplace of the Royal Society. Without logarithms he had already created two books of tables, A Table to find the Height of the Pole, the Magnetic Declination being given and Tables for the Improvement of Navigation, when a book came from Edinburgh promising to \u201ctake away all the difficultie that heretofore hath beene in mathematical calculations.\u201d\n\nThere is nothing (right well beloved Students in the Mathematices) that is so\ntroublesome to Mathematicall practice, not that doth more molest and hinder Calculators, then the Multiplications, Divisions, square and cubical Extractions of great numbers, which besides the tedious expence of time, are for the most part subject to many slippery errors.\n\nThis new book proposed a method that would do away with most of the expense and the errors. It was like an electric flashlight sent to a lightless world. The author was a wealthy Scotsman, John Napier (or Napper, Nepair, Naper, or Neper), the eighth laird of Merchiston Castle, a theologian and well-known astrologer who also made a hobby of mathematics. Briggs was agog. \u201cNaper, lord of Markinston, hath set my head and hands a work,\u201d he wrote. \u201cI hope to see him this summer, if it please God, for I never saw book, which pleased me better, and made me more wonder.\u201d He made his pilgrimage to Scotland and their first meeting, as he reported later, began with a quarter hour of silence: \u201cspent, each beholding other almost with admiration before one word was spoke.\u201d\n\nBriggs broke the trance: \u201cMy Lord, I have undertaken this long journey purposely to see your person, and to know by what engine of wit or ingenuity you came first to think of this most excellent help unto astronomy, viz. the Logarithms; but, my Lord, being by you found out, I wonder nobody else found it out before, when now known it is so easy.\u201d He stayed with the laird for several weeks, studying.\n\nIn modern terms a logarithm is an exponent. A student learns that the logarithm of 100, using 10 as the base, is 2, because $100 = 10^2$. The logarithm of 1,000,000 is 6, because 6 is the exponent in the expression $1,000,000 = 10^6$. To multiply two numbers, a calculator could just look up their logarithms and add those. For example:\n\n$$100 \\times 1,000,000 = 10^2 \\times 10^6 = 10^{(2+6)}$$\n\nLooking up and adding are easier than multiplying.\n\nBut Napier did not express his idea this way, in terms of exponents. He grasped the thing viscerally: he was thinking in terms of a relationship between differences and ratios. A series of numbers with a fixed difference is an arithmetic progression: 0, 1, 2, 3, 4, 5 \u2026 When the numbers are separated by a fixed ratio, the progression is geometric: 1, 2, 4, 8, 16, 32 \u2026 Set these progressions side by side,\n\n| 0 | 1 | 2 | 3 | 4 | 5 \u2026 |\n|---|---|---|---|---|---|\n| 1 | 2 | 4 | 8 | 16 | 32 \u2026 |\n\n(base 2 logarithms)\n\n(natural numbers)\n\nand the result is a crude table of logarithms\u2014crude, because the whole-number exponents are the easy ones. A useful table of logarithms had to fill in the gaps, with many decimal places of accuracy.\nIn Napier\u2019s mind was an analogy: differences are to ratios as addition is to multiplication. His thinking crossed over from one plane to another, from spatial relationships to pure numbers. Aligning these scales side by side, he gave a calculator a practical means of converting multiplication into addition\u2014downshifting, in effect, from the difficult task to the easier one. In a way, the method is a kind of translation, or encoding. The natural numbers are encoded as logarithms. The calculator looks them up in a table, the code book. In this new language, calculation is easy: addition instead of multiplication, or multiplication instead of exponentiation. When the work is done, the result is translated back into the language of natural numbers. Napier, of course, could not think in terms of encoding.\n\nBriggs revised and extended the necessary number sequences and published a book of his own, *Logarithmicall Arithmetike*, full of pragmatic applications. Besides the logarithms he presented tables of latitude of the sun\u2019s declination year by year; showed how to find the distance between any two places, given their latitudes and longitudes; and laid out a star guide with declinations, distance to the pole, and right ascension. Some of this represented knowledge never compiled and some was oral knowledge making the transition to print, as could be seen in the not-quite-formal names of the stars: the *Pole Starre, girdle of Andromeda, Whales Bellie, the brightest in the harpe, and the first in the great Beares taile next her rump*. Briggs also considered matters of finance, offering rules for computing with interest, backward and forward in time. The new technology was a watershed: \u201cIt may be here also noted that the use of a 100 pound for a day at the rate of 8, 9, 10, or the like for a yeare hath beene scarcely known, till by Logarithms it was found out: for otherwise it requires so many laborious extractions of roots, as will cost more paines than the knowledge of the thing is accompted to be worth.\u201d Knowledge has a value and a discovery cost, each to be counted and weighed.\n\nEven this exciting discovery took several years to travel as far as Johannes Kepler, who employed it in perfecting his celestial tables in 1627, based on the laboriously acquired data of Tycho Brahe. \u201cA Scottish baron has appeared on the scene (his name I have forgotten) who has done an excellent thing,\u201d Kepler wrote a friend, \u201ctransforming all multiplication and division into addition and subtraction.\u201d Kepler\u2019s tables were far more accurate\u2014perhaps thirty times more\u2014than any of his medieval predecessors, and the accuracy made possible an entirely new thing, his harmonious heliocentric system, with planets orbiting the sun in ellipses. From that time until the arrival of electronic machines, the majority of human computation was performed by means of logarithms. A teacher of Kepler\u2019s sniffed, \u201cIt is not fitting for a professor of mathematics to manifest childish joy just because reckoning is made easier.\u201d But why not?\nThe Information\n\nAcross the centuries they all felt that joy in reckoning: Napier and Briggs, Kepler and Babbage, making their lists, building their towers of ratio and proportion, perfecting their mechanisms for transforming numbers into numbers. And then the world\u2019s commerce validated their pleasure.\n\n| Natural Numbers | Logarithms base 2 |\n|-----------------|-------------------|\n| 1               | 0                 |\n| 2               | 1                 |\n| 3               | 1.5850            |\n| 4               | 2                 |\n| 5               | 2.3219            |\n| 6               | 2.5850            |\n| 7               | 2.8074            |\n| 8               | 3                 |\n| 9               | 3.1699            |\n| 10              | 3.3219            |\n| 11              | 3.4594            |\n| 12              | 3.5850            |\n| 13              | 3.7004            |\n| 14              | 3.8074            |\n| 15              | 3.9069            |\n| 16              | 4                 |\n| 17              | 4.0875            |\n| 18              | 4.1699            |\n| 19              | 4.2479            |\n| 20              | 4.3219            |\n| 21              | 4.3923            |\n| 22              | 4.4594            |\n| 23              | 4.5236            |\n| 24              | 4.5850            |\n| 25              | 4.6439            |\n| 26              | 4.7004            |\n| 27              | 4.7549            |\n| 28              | 4.8074            |\n| 29              | 4.8580            |\nCharles Babbage was born on Boxing Day 1791, near the end of the century that began with Newton. His home was on the south side of the River Thames in Walworth, Surrey, still a rural hamlet, though the London Bridge was scarcely a half hour\u2019s walk even for a small boy. He was the son of a banker, who was himself the son and grandson of goldsmiths. In the London of Babbage\u2019s childhood, the Machine Age made itself felt everywhere. A new breed of impresario was showing off machinery in exhibitions. The shows that drew the biggest crowds featured automata\u2014mechanical dolls, ingenious and delicate, with wheels and pinions mimicking life itself. Charles Babbage went with his mother to John Merlin\u2019s Mechanical Museum in Hanover Square, full of clockwork and music boxes and, most interesting, simulacra of living things. A metal swan bent its neck to catch a metal fish, moved by hidden motors and cams. In the artist\u2019s attic workshop Charles saw a pair of naked dancing women, gliding and bowing, crafted in silver at one-fifth life size. Merlin himself, their elderly creator, said he had devoted years to these machines, his favorites, still unfinished.\nOne of the figurines especially impressed Charles with its (or her) grace and seeming liveliness. \u201cThis lady attitudinized in a most fascinating manner,\u201d he recalled. \u201cHer eyes were full of imagination, and irresistible.\u201d Indeed, when he was a man in his forties he found Merlin\u2019s silver dancer at an auction, bought it for \u00a335, installed it on a pedestal in his home, and dressed its nude form in custom finery.\n\nThe boy also loved mathematics\u2014an interest far removed from the mechanical arts, as it seemed. He taught himself in bits and pieces from such books as he could find. In 1810 he entered Trinity College, Cambridge\u2014Isaac Newton\u2019s domain and still the moral center of mathematics in England. Babbage was immediately disappointed: he discovered that he already knew more of the modern subject than his tutors, and the further knowledge he sought was not to be found there, maybe not anywhere in England. He began to acquire foreign books\u2014especially books from Napoleon\u2019s France, with which England was at war. From a specialty bookseller in London he got Lagrange\u2019s *Th\u00e9orie des fonctions analytiques* and \u201cthe great work of Lacroix, on the Differential and Integral Calculus.\u201d\n\nHe was right: at Cambridge mathematics was stagnating. A century earlier Newton had been only the second professor of mathematics the university ever had; all the subject\u2019s power and prestige came from his legacy. Now his great shadow lay across English mathematics as a curse. The most advanced students learned his brilliant and esoteric \u201cfluxions\u201d and the geometrical proofs of his *Principia*. In the hands of anyone but Newton, the old methods of geometry brought little but frustration. His peculiar formulations of the calculus did his heirs little good. They were increasingly isolated. The English professoriate \u201cregarded any attempt at innovation as a sin against the memory of Newton,\u201d one nineteenth-century mathematician said. For the running river of modern mathematics a student had to look elsewhere, to the Continent, to \u201canalysis\u201d and the language of differentiation as invented by Newton\u2019s rival and nemesis, Gottfried Wilhelm Leibniz. Fundamentally, there was only one calculus. Newton and Leibniz knew how similar their work was\u2014enough that each accused the other of plagiarism. But they had devised incompatible systems of notation\u2014different languages\u2014and in practice these surface differences mattered more than the underlying sameness. Symbols and operators were what a mathematician had to work with, after all. Babbage, unlike most students, made himself fluent in both\u2014\u201cthe dots of Newton, the d\u2019s of Leibnitz\u201d\u2014and felt he had seen the light. \u201cIt is always difficult to think and reason in a new language.\u201d\n\nIndeed, language itself struck him as a fit subject for philosophical study\u2014a subject into which he found himself sidetracked from time to time. Thinking about language, while thinking in language, leads to puzzles and paradoxes.\nBabbage tried for a while to invent, or construct, a universal language, a symbol system that would be free of local idiosyncrasies and imperfections. He was not the first to try. Leibniz himself had claimed to be on the verge of a *characteristica universalis* that would give humanity \u201ca new kind of an instrument increasing the powers of reason far more than any optical instrument has ever aided the power of vision.\u201d As philosophers came face to face with the multiplicity of the world\u2019s dialects, they so often saw language not as a perfect vessel for truth but as a leaky sieve. Confusion about the meanings of words led to contradictions. Ambiguities and false metaphors were surely not inherent in the nature of things, but arose from a poor choice of signs. If only one could find a proper mental technology, a true philosophical language! Its symbols, properly chosen, must be universal, transparent, and immutable, Babbage argued. Working systematically, he managed to create a grammar and began to write down a lexicon but ran aground on a problem of storage and retrieval\u2014stopped \u201cby the apparent impossibility of arranging signs in any consecutive order, so as to find, as in a dictionary, the meaning of each when wanted.\u201d Nevertheless he felt that language was a thing a person could invent. Ideally, language should be rationalized, made predictable and mechanical. The gears should mesh.\n\nStill an undergraduate, he aimed at a new revival of English mathematics\u2014a suitable cause for founding an advocacy group and launching a crusade. He joined with two other promising students, John Herschel and George Peacock, to form what they named the Analytical Society, \u201cfor the propagation of *d\u2019s*\u201d and against \u201cthe heresy of dots,\u201d or as Babbage said, \u201cthe Dot-age of the University.\u201d (He was pleased with his own \u201cwicked pun.\u201d) In their campaign to free the calculus from English dotage, Babbage lamented \u201cthe cloud of dispute and national acrimony, which has been thrown over its origin.\u201d Never mind if it seemed French. He declared, \u201cWe have now to re-import the exotic, with nearly a century of foreign improvement, and to render it once more indigenous among us.\u201d They were rebels against Newton in the heart of Newton-land. They met over breakfast every Sunday after chapel.\n\n\u201cOf course we were much ridiculed by the Dons,\u201d Babbage recalled. \u201cIt was darkly hinted that we were young infidels, and that no good would come of us.\u201d Yet their evangelism worked: the new methods spread from the bottom up, students learning faster than their teachers. \u201cThe brows of many a Cambridge moderator were elevated, half in ire, half in admiration, at the unusual answers which began to appear in examination papers,\u201d wrote Herschel. The dots of Newton faded from the scene, his fluxions replaced by the notation and language of Leibniz.\n\nMeanwhile Babbage never lacked companions with whom he could quaff wine or play whist for six-penny points. With one set of friends he formed a Ghost\nClub, dedicated to collecting evidence for and against occult spirits. With another set he founded a club called the Extractors, meant to sort out issues of sanity and insanity according to a set of procedures:\n\n1. Every member shall communicate his address to the Secretary once in six months.\n2. If this communication is delayed beyond twelve months, it shall be taken for granted that his relatives had shut him up as insane.\n3. Every effort legal and illegal shall be made to get him out of the madhouse [hence the name \u201cExtractors\u201d].\n4. Every candidate for admission as a member shall produce six certificates. Three that he is sane and three others that he is insane.\n\nBut the Analytical Society was serious. It was with no irony, all earnestness, that these mathematical friends, Babbage and Herschel and Peacock, resolved to \u201cdo their best to leave the world a wiser place than they found it.\u201d They rented rooms and read papers to one another and published their \u201cTransactions.\u201d And in those rooms, as Babbage nodded over a book of logarithms, one of them interrupted: \u201cWell, Babbage, what are you dreaming about?\u201d\n\n\u201cI am thinking that all these Tables might be calculated by machinery,\u201d he replied.\n\nAnyway that was how Babbage reported the conversation fifty years later. Every good invention needs a eureka story, and he had another in reserve. He and Herschel were laboring together to produce a manuscript of logarithm tables for the Cambridge Astronomical Society. These very logarithms had been computed before; logarithms must always be computed and recomputed and compared and mistrusted. No wonder Babbage and Herschel, laboring over their own manuscript at Cambridge, found the work tedious. \u201cI wish to God these calculations had been executed by steam,\u201d cried Babbage, and Herschel replied simply, \u201cIt is quite possible.\u201d\n\nSteam was the driver of all engines, the enabler of industry. If only for these few decades, the word stood for power and force and all that was vigorous and modern. Formerly, water or wind drove the mills, and most of the world\u2019s work still depended on the brawn of people and horses and livestock. But hot steam, generated by burning coal and brought under control by ingenious inventors, had portability and versatility. It replaced muscles everywhere. It became a watchword: people on the go would now \u201csteam up\u201d or \u201cget more steam on\u201d or \u201cblow off steam.\u201d Benjamin Disraeli hailed \u201cyour moral steam which can work the world.\u201d Steam became the most powerful transmitter of energy known to humanity.\nIt was odd even so that Babbage thought to exert this potent force in a weightless realm\u2014applying steam to thought and arithmetic. Numbers were the grist for his mill. Racks would slide, pinions would turn, and the mind\u2019s work would be done.\n\nIt should be done automatically, Babbage declared. What did it mean to call a machine \u201cautomatic\u201d? For him it was not just a matter of semantics but a principle for judging a machine\u2019s usefulness. Calculating devices, such as they were, could be divided into two classes: the first requiring human intervention, the second truly self-acting. To decide whether a machine qualified as automatic, he needed to ask a question that would have been simpler if the words input and output had been invented: \u201cWhether, when the numbers on which it is to operate are placed in the instrument, it is capable of arriving at its result by the mere motion of a spring, a descending weight, or any other constant force.\u201d This was a farsighted standard. It eliminated virtually all the devices ever used or conceived as tools for arithmetic\u2014and there had been many, from the beginning of recorded history. Pebbles in bags, knotted strings, and tally sticks of wood or bone served as short-term memory aids. Abacuses and slide rules applied more complex hardware to abstract reckoning. Then, in the seventeenth century, a few mathematicians conceived the first calculating devices worthy of the name machine, for adding and\u2014through repetition of the adding\u2014multiplying. Blaise Pascal made an adding machine in 1642 with a row of revolving disks, one for each decimal digit. Three decades later Leibniz improved on Pascal by using a cylindrical drum with protruding teeth to manage \u201ccarrying\u201d from one digit to the next.* Fundamentally, however, the prototypes of Pascal and Leibniz remained closer to the abacus\u2014a passive register of memory states\u2014than to a kinetic machine. As Babbage saw, they were not automatic.\n\nIt would not occur to him to use a device for a one-time calculation, no matter how difficult. Machinery excelled at repetition\u2014\u201cintolerable labour and fatiguing monotony.\u201d The demand for computation, he foresaw, would grow as the uses of commerce, industry, and science came together. \u201cI will yet venture to predict, that a time will arrive, when the accumulating labour which arises from the arithmetical application of mathematical formulae, acting as a constantly retarding force, shall ultimately impede the useful progress of the science, unless this or some equivalent method is devised for relieving it from the overwhelming incumbrance of numerical detail.\u201d\n\nIn the information-poor world, where any table of numbers was a rarity, centuries went by before people began systematically to gather different printed tables in order to check one against another. When they did, they found unexpected flaws. For example, Taylor\u2019s Logarithms, the standard quarto printed in London in 1792, contained (it eventually transpired) nineteen errors of either\none or two digits. These were itemized in the *Nautical Almanac*, for, as the Admiralty knew well, every error was a potential shipwreck.\n\nUnfortunately, one of the nineteen corrections proved erroneous, so the next year\u2019s *Nautical Almanac* printed an \u201cerratum of the errata.\u201d This in turn introduced yet another error. \u201cConfusion is worse confounded,\u201d declared *The Edinburgh Review*. The next almanac would have to put forth an \u201cErratum of the Erratum of the Errata in Taylor\u2019s Logarithms.\u201d\n\nParticular mistakes had their own private histories. When Ireland established its Ordnance Survey, to map the entire country on a finer scale than any nation had ever accomplished, the first order of business was to ensure that the surveyors\u2014teams of sappers and miners\u2014had 250 sets of logarithmic tables, relatively portable and accurate to seven places. The survey office compared thirteen tables published in London over the preceding two hundred years, as well as tables from Paris, Avignon, Berlin, Leipzig, Gouda, Florence, and China. Six errors were discovered in almost every volume\u2014and they were the *same* six errors. The conclusion was inescapable: these tables had been copied, one from another, at least in part.\n\nErrors arose from mistakes in carrying. Errors arose from the inversion of digits, sometimes by the computers themselves and sometimes by the printer. Printers were liable to transpose digits in successive lines of type. What a mysterious, fallible thing the human mind seemed to be! All these errors, one commentator mused, \u201cwould afford a curious subject of metaphysical speculation respecting the operation of the faculty of memory.\u201d Human computers had no future, he saw: \u201cIt is only by the *mechanical fabrication of tables* that such errors can be rendered impossible.\u201d\n\nBabbage proceeded by exposing mechanical principles within the numbers. He saw that some of the structure could be revealed by computing differences between one sequence and another. The \u201ccalculus of finite differences\u201d had been explored by mathematicians (especially the French) for a hundred years. Its power was to reduce high-level calculations to simple addition, ready to be routinized. For Babbage the method was so crucial that he named his machine from its first conception the Difference Engine.\n\nBy way of example (for he felt the need to publicize and explain his conception many times as the years passed) Babbage offered the Table of Triangular Numbers. Like many of the sequences of concern, this was a ladder, starting on the ground and rising ever higher:\n\n1, 3, 6, 10, 15, 21\u2026\n\nHe illustrated the idea by imagining a child placing groups of marbles on the sand:\nSuppose the child wants to know \u201chow many marbles the thirtieth or any other distant group might contain.\u201d (It is a child after Babbage\u2019s own heart.) \u201cPerhaps he might go to papa to obtain this information; but I much fear papa would snub him, and would tell him that it was nonsense\u2014that it was useless\u2014that nobody knew the number, and so forth.\u201d Understandably papa knows nothing of the Table of Triangular Numbers published at the Hague by \u00c9. de Joncourt, professor of philosophy. \u201cIf papa fail to inform him, let him go to mamma, who will not fail to find means to satisfy her darling\u2019s curiosity.\u201d Meanwhile, Babbage answers the question by means of a table of differences. The first column contains the number sequence in question. The next columns are derived by repeated subtractions, until a constant is reached\u2014a column made up entirely of a single number.\n\n| Number of the Group | Number of Marbles in Each Group | 1st Difference | 2nd Difference |\n|---------------------|---------------------------------|----------------|---------------|\n| 1                   | 1                               | 1              | 1             |\n| 2                   | 3                               | 2              | 1             |\n| 3                   | 6                               | 3              | 1             |\n| 4                   | 10                              | 4              | 1             |\n| 5                   | 15                              | 5              | 1             |\n| 6                   | 21                              | 6              | 1             |\n| 7                   | 28                              | 7              | 1             |\n\nAny polynomial function can be reduced by the method of differences, and all well-behaved functions, including logarithms, can be effectively approximated. Equations of higher degree require higher-order differences. Babbage offered another concrete geometrical example that requires a table of third differences: piles of cannonballs in the form of a triangular pyramid\u2014the triangular numbers translated to three dimensions.\nThe Difference Engine would run this process in reverse: instead of repeated subtraction to find the differences, it would generate sequences of numbers by a cascade of additions. To accomplish this, Babbage conceived a system of figure wheels, marked with the numerals 0 to 9, placed along an axis to represent the decimal digits of a number: the units, the tens, the hundreds, and so on. The wheels would have gears. The gears along each axis would mesh with the gears of the next, to add the successive digits. As the machinery transmitted motion, wheel to wheel, it would be transmitting information, in tiny increments, the numbers summing across the axes. A mechanical complication arose, of course, when any sum passed 9. Then a unit had to be carried to the next decimal place. To manage this, Babbage placed a projecting tooth on each wheel, between the 9 and 0. The tooth would push a lever, which would in turn transmit its motion to the next wheel above.\n\n| Number | Table | 1st Difference | 2nd Difference | 3rd Difference |\n|--------|-------|----------------|----------------|----------------|\n| 1      | 1     | 3              | 3              | 1              |\n| 2      | 4     | 6              | 4              | 1              |\n| 3      | 10    | 10             | 5              | 1              |\n| 4      | 20    | 15             | 6              | 1              |\n| 5      | 35    | 21             | 7              | 1              |\n| 6      | 56    | 28             | 8              | 1              |\n\nBABBAGE\u2019S WHEEL-WORK\nAt this point in the history of computing machinery, a new theme appears: the obsession with time. It occurred to Babbage that his machine had to compute faster than the human mind and as fast as possible. He had an idea for parallel processing: number wheels arrayed along an axis could add a row of the digits all at once. \u201cIf this could be accomplished,\u201d he noted, \u201cit would render additions and subtractions with numbers having ten, twenty, fifty, or any number of figures, as rapid as those operations are with single figures.\u201d He could see a problem, however. The digits of a single addition could not be managed with complete independence because of the carrying. The carries could overflow and cascade through a whole set of wheels. If the carries were known in advance, then the additions could proceed in parallel. But that knowledge did not become available in timely fashion. \u201cUnfortunately,\u201d he wrote, \u201cthere are multitudes of cases in which the carriages that become due are only known in successive periods of time.\u201d He counted up the time, assuming one second per operation: to add two fifty-digit numbers might take only nine seconds in itself, but the carrying, in the worst case, could require fifty seconds more. Bad news indeed. \u201cMultitudes of contrivances were designed, and almost endless drawings made, for the purpose of economizing the time,\u201d Babbage wrote ruefully. By 1820 he had settled on a design. He acquired his own lathe, used it himself and hired metalworkers, and in 1822 managed to present the Royal Society with a small working model, gleaming and futuristic.\n\nHe was living in London near the Regent\u2019s Park as a sort of gentleman philosopher, publishing mathematical papers and occasionally lecturing to the public on astronomy. He married a wealthy young woman from Shropshire, Georgiana Whitmore, the youngest of eight sisters. Beyond what money she had, he was supported mainly by a \u00a3300 allowance from his father\u2014whom he resented as a tyrannical, ungenerous, and above all close-minded old man. \u201cIt is scarcely too much to assert that he believes nothing he hears, and only half of what he sees,\u201d Babbage wrote his friend Herschel. When his father died, in 1827, Babbage inherited a fortune of \u00a3100,000. He briefly became an actuary for a new Protector Life Assurance Company and computed statistical tables rationalizing life expectancies. He tried to get a university professorship, so far unsuccessfully, but he had an increasingly lively social life, and in scholarly circles people were beginning to know his name. With Herschel\u2019s help he was elected a fellow of the Royal Society.\n\nEven his misfires kindled his reputation. On behalf of *The Edinburgh Journal of Science* Sir David Brewster sent him a classic in the annals of rejection letters: \u201cIt is with no inconsiderable degree of reluctance that I decline the offer of any Paper from you. I think, however, you will upon reconsideration of the subject be of opinion that I have no other alternative. The subjects you propose for a series\nof Mathematical and Metaphysical Essays are so very profound, that there is perhaps not a single subscriber to our Journal who could follow them.\u201d On behalf of his nascent invention, Babbage began a campaign of demonstrations and letters. By 1823 the Treasury and the Exchequer had grown interested. He promised them \u201clogarithmic tables as cheap as potatoes\u201d\u2014how could they resist? Logarithms saved ships. The Lords of the Treasury authorized a first appropriation of \u00a31,500.\n\nAs an abstract conception the Difference Engine generated excitement that did not need to wait for anything so mundane as the machine\u2019s actual construction. The idea was landing in fertile soil. Dionysius Lardner, a popular lecturer on technical subjects, devoted a series of public talks to Babbage, hailing his \u201cproposition to reduce arithmetic to the dominion of mechanism,\u2014to substitute an automaton for a compositor,\u2014to throw the powers of thought into wheel-work.\u201d The engine \u201cmust, when completed,\u201d he said, \u201cproduce important effects, not only on the progress of science, but on that of civilization.\u201d It would be the rational machine. It would be a junction point for two roads\u2014mechanism and thought. Its admirers sometimes struggled with their explanations of this intersection: \u201cThe question is set to the instrument,\u201d Henry Colebrooke told the Astronomical Society, \u201cor the instrument is set to the question.\u201d Either way, he said, \u201cby simply giving motion the solution is wrought.\u201d\n\nBut the engine made slower progress in the realm of brass and wrought iron. Babbage tore out the stables in back of his London house and replaced them with a forge, foundry, and fireproofed workshop. He engaged Joseph Clement, a draftsman and inventor, self-educated, the son of a village weaver who had made himself into England\u2019s preeminent mechanical engineer. Babbage and Clement realized that they would have to make new tools. Inside a colossal iron frame the design called for the most intricate and precise parts\u2014axles, gears, springs, and pins, and above all figure wheels by the hundreds and then thousands. Hand tools could never produce the components with the needed precision. Before Babbage could have a manufactory of number tables, he would have to build new manufactories of parts. The rest of the Industrial Revolution, too, needed standardization in its parts: interchangeable screws of uniform thread count and pitch; screws as fundamental units. The lathes of Clement and his journeymen began to produce them.\nAs the difficulties grew, so did Babbage\u2019s ambitions. After ten years, the engine stood twenty-four inches high, with six vertical axles and dozens of wheels, capable of computing six-figure results. Ten years after that, the scale\u2014on paper\u2014had reached 160 cubic feet, 15 tons, and 25,000 parts, and the paper had spread, too, the drawings covering more than 400 square feet. The level of complexity was confounding. Babbage solved the problem of adding many digits at once by separating the \u201cadding motions\u201d from the \u201ccarrying motions\u201d and then staggering the timing of the carries. The addition would begin with a rush of grinding gears, first the odd-numbered columns of dials, then the even columns. Then the carries would recoil across the rows. To keep the motion synchronized, parts of the machine would need to \u201cknow\u201d at critical times that a carry was pending. The information was conveyed by the state of a latch. For the first time, but not the last, a device was invested with memory. \u201cIt is in effect a memorandum taken by the machine,\u201d wrote his publicizer, Dionysius Lardner. Babbage himself was self-conscious about anthropomorphizing but could not resist. \u201cThe mechanical means I employed to make these carriages,\u201d he suggested, \u201cbears some slight analogy to the operation of the faculty of memory.\u201d\n\nIn ordinary language, to describe even this basic process of addition required a great effulgence of words, naming the metal parts, accounting for their interactions, and sorting out interdependencies that multiplied to form a long\nchain of causality. Lardner\u2019s own explanation of \u201ccarrying,\u201d for example, was epic. A single isolated instant of the action involved a dial, an index, a thumb, an axis, a trigger, a notch, a hook, a claw, a spring, a tooth, and a ratchet wheel:\n\nNow, at the moment that the division between 9 and 0 on the dial $B^2$ passes under the index, a thumb placed on the axis of this dial touches a trigger which raises out of the notch of the hook which sustains the claw just mentioned, and allows it to fall back by the recoil of the spring, and drop into the next tooth of the ratchet wheel.\n\nHundreds of words later, summing up, Lardner resorted to a metaphor suggesting fluid dynamics:\n\nThere are two systems of waves of mechanical action continually flowing from the bottom to the top; and two streams of similar action constantly passing from the right to the left. The crests of the first system of adding waves fall upon the last difference, and upon every alternate one proceeding upwards\u2026. The first stream of carrying action passes from right to left along the highest row and every alternate row.\n\nThis was one way of abstracting from the particular\u2014the particulars being so intricate. And then he surrendered. \u201cIts wonders, however, are still greater in its details,\u201d he wrote. \u201cWe despair of doing it justice.\u201d\n\nNor were ordinary draftsman\u2019s plans sufficient for describing this machine that was more than a machine. It was a dynamical system, its many parts each capable of several modes or states, sometimes at rest and sometimes in motion, propagating their influence along convoluted channels. Could it ever be specified completely, on paper? Babbage, for his own purposes, devised a new formal tool, a system of \u201cmechanical notation\u201d (his term). This was a language of signs meant to represent not just the physical form of a machine but its more elusive properties: its timing and its logic. It was an extraordinary ambition, as Babbage himself appreciated. In 1826 he proudly reported to the Royal Society \u201cOn a Method of Expressing by Signs the Action of Machinery.\u201d In part it was an exercise in classification. He analyzed the different ways in which something\u2014motion, or power\u2014could be \u201ccommunicated\u201d through a system. There were many ways. A part could receive its influence simply by being attached to another part, \u201cas a pin on a wheel, or a wheel and pinion on the same axis.\u201d Or transmission could occur \u201cby stiff friction.\u201d A part might be driven constantly by another part \u201cas happens when a wheel is driven by a pinion\u201d\u2014or not constantly, \u201cas is the case when a stud lifts a bolt once in the course of a revolution.\u201d Here a vision of logical branching entered the scheme: the path of communication would vary depending on the alternative states of some part of the machine. Babbage\u2019s mechanical notation followed naturally from his work on symbolic notation in mathematical analysis. Machinery, like mathematics, needed rigor and definition for progress. \u201cThe forms of ordinary language were far too diffuse,\u201d he wrote. \u201cThe signs, if they have been properly chosen, and if they should be generally\nadopted, will form as it were an universal language.\u201d Language was never a side issue for Babbage.\n\nHe finally won a university post, at Cambridge: the prestigious Lucasian Professorship of Mathematics, formerly occupied by Newton. As in Newton\u2019s time, the work was not onerous. Babbage did not have to teach students, deliver lectures, or even live in Cambridge, and this was just as well, because he was also becoming a popular fixture of London social life. At home at One Dorset Street he hosted a regular Saturday soir\u00e9e that drew a glittering crowd\u2014politicians, artists, dukes and duchesses, and the greatest English scientists of the age: Charles Darwin, Michael Faraday, and Charles Lyell, among others.* They marveled at his calculating machine and, on display nearby, the dancing automaton of his youth. (In invitations he would write, \u201cI hope you intend to patronise the \u2018Silver Lady.\u2019 She is to appear in new dresses and decorations.\u201d) He was a mathematical raconteur\u2014that was no contradiction, in this time and place. Lyell reported approvingly that he \u201cjokes and reasons in high mathematics.\u201d He published a much-quoted treatise applying probability theory to the theological question of miracles. With tongue in cheek he wrote Alfred, Lord Tennyson, to suggest a correction for the poet\u2019s couplet: \u201cEvery minute dies a man, / Every minute one is born.\u201d\n\nI need hardly point out to you that this calculation would tend to keep the sum total of the world\u2019s population in a state of perpetual equipoise, whereas it is a well-known fact that the said sum total is constantly on the increase. I would therefore take the liberty of suggesting that in the next edition of your excellent poem the erroneous calculation to which I refer should be corrected as follows: \u201cEvery moment dies a man / And one and a sixteenth is born.\u201d I may add that the exact figures are 1.167, but something must, of course, be conceded to the laws of metre.\n\nFascinated with his own celebrity, he kept a scrapbook\u2014\u201cthe pros and cons in parallel columns, from which he obtained a sort of balance,\u201d as one visitor described it. \u201cI was told repeatedly that he spent all his days in gloating and grumbling over what people said of him.\u201d\n\nBut progress on the engine, the main source of his fame, was faltering. In 1832 he and his engineer Clement produced a working demonstration piece. Babbage displayed it at his parties to guests who found it miraculous or merely puzzling. The Difference Engine stands\u2014for a replica works today, in the Science Museum in London\u2014as a milestone of what could be achieved in precision engineering. In the composition of its alloys, the exactness of its dimensions, the interchangeability of its parts, nothing surpassed this segment of an unfinished machine. Still, it was a curio. And it was as far as Babbage could go.\n\nHe and his engineer fell into disputes. Clement demanded more and more money from Babbage and from the Treasury, which began to suspect profiteering. He withheld parts and drawings and fought over control of the specialized\nmachine tools in their workshops. The government, after more than a decade and \u00a317,000, was losing faith in Babbage, and he in the government. In his dealing with lords and ministers Babbage could be imperious. He was developing a sour view of the Englishman\u2019s attitude toward technological innovation: \u201cIf you speak to him of a machine for peeling a potato, he will pronounce it impossible: if you peel a potato with it before his eyes, he will declare it useless, because it will not slice a pineapple.\u201d They no longer saw the point.\n\n\u201cWhat shall we do to get rid of Mr. Babbage and his calculating machine?\u201d Prime Minister Robert Peel wrote one of his advisers in August 1842. \u201cSurely if completed it would be worthless as far as science is concerned\u2026. It will be in my opinion a very costly toy.\u201d He had no trouble finding voices inimical to Babbage in the civil service. Perhaps the most damning was George Biddell Airy, the Astronomer Royal, a starched and methodical figure, who with no equivocation told Peel precisely what he wanted to hear: that the engine was useless. He added this personal note: \u201cI think it likely he lives in a sort of dream as to its utility.\u201d Peel\u2019s government terminated the project. As for Babbage\u2019s dream, it continued. It had already taken another turn. The engine in his mind had advanced into a new dimension. And he had met Ada Byron.\n\nIn the Strand, at the north end of the Lowther shopping arcade, visitors thronged to the National Gallery of Practical Science, \u201cBlending Instruction with\nAmusement,\u201d a combination toy store and technology show set up by an American entrepreneur. For the admission price of a shilling, a visitor could touch the \u201celectrical eel,\u201d listen to lectures on the newest science, and watch a model steamboat cruising a seventy-foot trough and the Perkins steam gun emitting a spray of bullets. For a guinea, she could sit for a \u201cdaguerreotype\u201d or \u201cphotographic\u201d portrait, by which a faithful and pleasing likeness could be obtained in \u201cless than One Second.\u201d Or she could watch, as young Augusta Ada Byron did, a weaver demonstrating the automated Jacquard loom, in which the patterns to be woven in cloth were encoded as holes punched into pasteboard cards.\n\nAda was \u201cthe child of love,\u201d her father had written, \u201c\u2014though born in bitterness, and nurtured in convulsion.\u201d Her father was a poet. When she was barely a month old, in 1816, the already notorious Lord Byron, twenty-seven, and the bright, wealthy, and mathematically knowledgeable Anne Isabella Milbanke (Annabella), twenty-three, separated after a year of marriage. Byron left England and never saw his daughter again. Her mother refused to tell her who her father was until she was eight and he died in Greece, an international celebrity. The poet had begged for any news of his daughter: \u201cIs the Girl imaginative?\u2014at her present age I have an idea that I had many feelings & notions which people would not believe if I stated them now.\u201d Yes, she was imaginative.\n\nShe was a prodigy, clever at mathematics, encouraged by tutors, talented in drawing and music, fantastically inventive and profoundly lonely. When she was twelve, she set about inventing a means of flying. \u201cI am going to begin my paper wings tomorrow,\u201d she wrote to her mother. She hoped \u201cto bring the art of flying to very great perfection. I think of writing a book of Flyology illustrated with plates.\u201d For a while she signed her letters \u201cyour very affectionate Carrier Pigeon.\u201d She asked her mother to find a book illustrating bird anatomy, because she was reluctant \u201cto dissect even a bird.\u201d She analyzed her daily situation with a care for logic.\n\nMiss Stamp desires me to say that at present she is not particularly pleased with me on account of some very foolish conduct yesterday about a simple thing, and which she said was not only foolish but showed a spirit of inattention, and though today she has not had reason to be dissatisfied with me on the whole yet she says that she can not directly efface the recollection of the past.\n\nShe was growing up in a well-kept cloister of her mother\u2019s arranging. She had years of sickliness, a severe bout of measles, and episodes of what was called neurasthenia or hysteria. (\u201cWhen I am weak,\u201d she wrote, \u201cI am always so exceedingly terrified, at nobody knows what, that I can hardly help having an agitated look & manner.\u201d) Green drapery enclosed the portrait of her father that hung in one room. In her teens she developed a romantic interest in her tutor,\nwhich led to a certain amount of sneaking about the house and gardens and to lovemaking as intimate as possible without, she said, actual \u201cconnection.\u201d The tutor was dismissed. Then, in the spring, wearing white satin and tulle, the seventeen-year-old made her ritual debut at court, where she met the king and queen, the most important dukes, and the French diplomat Talleyrand, whom she described as an \u201cold monkey.\u201d\n\nAUGUSTA ADA BYRON KING, COUNTESS OF LOVELACE, AS PAINTED IN 1836 BY MARGARET CARPENTER. \u201cI CONCLUDE SHE IS BENT ON DISPLAYING THE WHOLE EXPANSE OF MY CAPACIOUS JAW BONE, UPON WHICH I THINK THE WORD MATHEMATICS SHOULD BE WRITTEN.\u201d\n\nA month later she met Charles Babbage. With her mother, she went to see what Lady Byron called his \u201cthinking machine,\u201d the portion of the Difference Engine in his salon. Babbage saw a sparkling, self-possessed young woman with porcelain features and a notorious name, who managed to reveal that she knew more mathematics than most men graduating from university. She saw an imposing forty-one-year-old, authoritative eyebrows anchoring his strong-boned face, who possessed wit and charm and did not wear these qualities lightly. He seemed a kind of visionary\u2014just what she was seeking. She admired the machine, too. An onlooker reported: \u201cWhile other visitors gazed at the working of this beautiful instrument with the sort of expression, and I dare say the sort of feeling,\nthat some savages are said to have shown on first seeing a looking-glass or hearing a gun, Miss Byron, young as she was, understood its working, and saw the great beauty of the invention.\u201d Her feeling for the beauty and abstractions of mathematics, fed only in morsels from her succession of tutors, was overflowing. It had no outlet. A woman could not attend university in England, nor join a scientific society (with two exceptions: the botanical and horticultural).\n\nAda became a tutor for the young daughters of one of her mother\u2019s friends. When writing to them, she signed herself, \u201cyour affectionate & untenable Instructress.\u201d On her own she studied Euclid. Forms burgeoned in her mind. \u201cI do not consider that I know a proposition,\u201d she wrote another tutor, \u201cuntil I can imagine to myself a figure in the air, and go through the construction & demonstration without any book or assistance whatever.\u201d She could not forget Babbage, either, or his \u201cgem of all mechanism.\u201d To another friend she reported her \u201cgreat anxiety about the machine.\u201d Her gaze turned inward, often. She liked to think about herself thinking.\n\nBabbage himself had moved far beyond the machine on display in his drawing room; he was planning a new machine, still an engine of computation but transmuted into another species. He called this the Analytical Engine. Motivating him was a quiet awareness of the Difference Engine\u2019s limitations: it could not, merely by adding differences, compute every sort of number or solve any mathematical problem. Inspiring him, as well, was the loom on display in the Strand, invented by Joseph-Marie Jacquard, controlled by instructions encoded and stored as holes punched in cards.\n\nWhat caught Babbage\u2019s fancy was not the weaving, but rather the encoding, from one medium to another, of patterns. The patterns would appear in damask, eventually, but first were \u201csent to a peculiar artist.\u201d This specialist, as he said,\n\npunches holes in a set of pasteboard cards in such a manner that when those cards are placed in a Jacquard loom, it will then weave upon its produce the exact pattern designed by the artist.\n\nThe notion of abstracting information away from its physical substrate required careful emphasis. Babbage explained, for example, that the weaver might choose different threads and different colors\u2014\u201cbut in all these cases the form of the pattern will be precisely the same.\u201d As Babbage conceived his machine now, it raised this very process of abstraction to higher and higher degrees. He meant the cogs and wheels to handle not just numbers but variables standing in for numbers. Variables were to be filled or determined by the outcomes of prior calculations, and, further, the very operations\u2014such as addition or multiplication\u2014were to be changeable, depending on prior outcomes. He imagined these abstract information quantities being stored in cards: variable cards and operation cards.\nHe thought of the machine as embodying laws and of the cards as communicating these laws. Lacking a ready-made vocabulary, he found it awkward to express his fundamental working concepts; for example,\n\nhow the machine could perform the act of judgment sometimes required during an analytical inquiry, when two or more different courses presented themselves, especially as the proper course to be adopted could not be known in many cases until all the previous portion had been gone through.\n\nHe made clear, though, that information\u2014representations of number and process\u2014would course through the machinery. It would pass to and from certain special physical locations, which Babbage named a store, for storage, and a mill, for action.\n\nIn all this he had an intellectual companion now in Ada, first his acolyte and then his muse. She married a sensible and promising aristocrat, William King, her senior by a decade and a favorite of her mother. In the space of a few years he was elevated to the peerage as earl of Lovelace\u2014making Ada, therefore, a countess\u2014and, still in her early twenties, she bore three children. She managed their homes, in Surrey and London, practiced the harp for hours daily (\u201cI am at present a condemned slave to my harp, no easy Task master\u201d), danced at balls, met the new queen, Victoria, and sat for her portrait, self-consciously (\u201cI conclude [the artist] is bent on displaying the whole expanse of my capacious jaw bone, upon which I think the word Mathematics should be written\u201d). She suffered terrible dark moods and bouts of illness, including cholera. Her interests and behavior still set her apart. One morning she went alone in her carriage, dressed plainly, to see a model of Edward Davy\u2019s \u201celectrical telegraph\u201d at Exeter Hall\n\n& the only other person was a middle-aged gentleman who chose to behave as if I were the show [she wrote to her mother] which of course I thought was the most impudent and unpardonable.\u2014I am sure he took me for a very young (& I suppose he thought rather handsome) governess\u2026. He stopped as long as I did, & then followed me out.\u2014I took care to look as aristocratic & as like a Countess as possible\u2026. I must try & add a little age to my appearance\u2026. I would go & see something everyday & I am sure London would never be exhausted.\n\nLady Lovelace adored her husband but reserved much of her mental life for Babbage. She had dreams, waking dreams, of something she could not be and something she could not achieve, except by proxy, through his genius. \u201cI have a peculiar way of learning,\u201d she wrote to him, \u201c& I think it must be a peculiar man to teach me successfully.\u201d Her growing desperation went side by side with a powerful confidence in her untried abilities. \u201cI hope you are bearing me in mind,\u201d she wrote some months later, \u201cI mean my mathematical interests. You know this is the greatest favour any one can do me.\u2014Perhaps, none of us can estimate how great\u2026.\u201d\nThe Information\n\nYou know I am by nature a bit of a philosopher, & a very great speculator,\u2014so that I look on through a very immeasurable vista, and though I see nothing but vague & cloudy uncertainty in the foreground of our being, yet I fancy I discern a very bright light a good way further on, and this makes me care much less about the cloudiness & indistinctness which is near.\u2014Am I too imaginative for you? I think not.\n\nThe mathematician and logician Augustus De Morgan, a friend of Babbage and of Lady Byron, became Ada\u2019s teacher by post. He sent her exercises. She sent him questions and musings and doubts (\u201cI could wish I went on quicker\u201d; \u201cI am sorry to say I am sadly obstinate about the Term at which Convergence begins\u201d; \u201cI have enclosed my Demonstration of my view of the case\u201d; \u201cfunctional Equations are complete Will-o-the-wisps to me\u201d; \u201cHowever I try to keep my metaphysical head in order\u201d). Despite her na\u00efvet\u00e9, or because of it, he recognized a \u201cpower of thinking \u2026 so utterly out of the common way for any beginner, man or woman.\u201d She had rapidly mastered trigonometry and integral and differential calculus, and he told her mother privately that if he had encountered \u201csuch power\u201d in a Cambridge student he would have anticipated \u201can original mathematical investigator, perhaps of first rate eminence.\u201d She was fearless about drilling down to first principles. Where she felt difficulties, real difficulties lay.\n\nOne winter she grew obsessed with a fashionable puzzle known as Solitaire, the Rubik\u2019s Cube of its day. Thirty-two pegs were arranged on a board with thirty-three holes, and the rules were simple: Any peg may jump over another immediately adjacent, and the peg jumped over is removed, until no more jumps are possible. The object is to finish with only one peg remaining. \u201cPeople may try thousands of times, and not succeed in this,\u201d she wrote Babbage excitedly.\n\nI have done it by trying & observation & can now do it at any time, but I want to know if the problem admits of being put into a mathematical Formula, & solved in this manner\u2026. There must be a definite principle, a compound I imagine of numerical & geometrical properties, on which the solution depends, & which can be put into symbolic language.\nThe Information\n\nA formal solution to a game\u2014the very idea of such a thing was original. The desire to create a language of symbols, in which the solution could be encoded\u2014this way of thinking was Babbage\u2019s, as she well knew.\n\nShe pondered her growing powers of mind. They were not strictly mathematical, as she saw it. She saw mathematics as merely a part of a greater imaginative world. Mathematical transformations reminded her \u201cof certain sprites & fairies one reads of, who are at one\u2019s elbows in one shape now, & the next minute in a form most dissimilar; and uncommonly deceptive, troublesome & tantalizing are the mathematical sprites & fairies sometimes; like the types I have found for them in the world of Fiction.\u201d Imagination\u2014the cherished quality. She mused on it; it was her heritage from her never-present father.\n\nWe talk much of Imagination. We talk of the Imagination of Poets, the Imagination of Artists &c; I am inclined to think that in general we don\u2019t know very exactly what we are talking about\u2026.\n\nIt is that which penetrates into the unseen worlds around us, the worlds of Science. It is that which feels & discovers what is, the real which we see not, which exists not for our senses. Those who have learned to walk on the threshold of the unknown worlds \u2026 may then with the fair white wings of Imagination hope to soar further into the unexplored amidst which we live.\n\nShe began to believe she had a divine mission to fulfill. She used that word, mission. \u201cI have on my mind most strongly the impression that Heaven has allotted me some peculiar intellectual-moral mission to perform.\u201d She had powers. She confided in her mother:\n\nI believe myself to possess a most singular combination of qualities exactly fitted to make me pre-eminently a discoverer of the hidden realities of nature\u2026. The belief has been forced upon me, & most slow have I been to admit it even.\n\nShe listed her qualities:\n\nFirstly: Owing to some peculiarity in my nervous system, I have perceptions of some things, which no one else has; or at least very few, if any\u2026. Some might say an intuitive perception of hidden things;\u2014that is of things hidden from eyes, ears & the ordinary senses\u2026.\n\nSecondly;\u2014my immense reasoning faculties;\n\nThirdly;\u2026 the power not only of throwing my whole energy & existence into whatever I choose, but also bring to bear on any one subject or idea, a vast apparatus from all sorts of apparently irrelevant & extraneous sources. I can throw rays from every quarter of the universe into one vast focus.\n\nShe admitted that this sounded mad but insisted she was being logical and cool. She knew her life\u2019s course now, she told her mother. \u201cWhat a mountain I have to climb! It is enough to frighten anyone who had not all that most insatiable & restless energy, which from my babyhood has been the plague of your life & my own. However it has found food I believe at last.\u201d She had found it in the\nAnalytical Engine.\n\nBabbage meanwhile, restless and omnivorous, was diverting his energies to another burgeoning technology, steam\u2019s most powerful expression, the railroad. The newly formed Great Western Railway was laying down track and preparing trial runs of locomotive engines from Bristol to London under the supervision of Isambard Kingdom Brunel, the brilliant engineer, then just twenty-seven years old. Brunel asked Babbage for help, and Babbage decided to begin with an information-gathering program\u2014characteristically ingenious and grandiose. He outfitted an entire railway carriage. On a specially built, independently suspended table, rollers unwound sheets of paper a thousand feet long, while pens drew lines to \u201cexpress\u201d (as Babbage put it) measurements of the vibrations and forces felt by the carriage in every direction. A chronometer marked the passage of time in half seconds. He covered two miles of paper this way.\n\nAs he traversed the rails, he realized that a peculiar danger of steam locomotion lay in its outracing every previous means of communication. Trains lost track of one another. Until the most regular and disciplined scheduling was imposed, hazard ran with every movement. One Sunday Babbage and Brunel, operating in different engines, barely avoided smashing into each other. Other people, too, worried about this new gap between the speeds of travel and messaging. An important London banker told Babbage he disapproved: \u201cIt will enable our clerks to plunder us, and then be off to Liverpool on their way to America at the rate of twenty miles an hour.\u201d Babbage could only express the hope that science might yet find a remedy for the problem it had created. (\u201cPossibly we might send lightning to outstrip the culprit.\u201d)\n\nAs for his own engine\u2014the one that would travel nowhere\u2014he had found a fine new metaphor. It would be, he said, \u201ca locomotive that lays down its own railway.\u201d\n\nBitter as he was about England\u2019s waning interest in his visionary plans, Babbage found admirers on the continent, particular in Italy\u2014\u201cthe country of Archimedes and Galileo,\u201d as he put it to his new friends. In the summer of 1840 he gathered up his sheaves of drawings and journeyed by way of Paris and Lyon, where he watched the great Jacquard loom at Manufacture d\u2019\u00c9toffes pour Ameublements et Ornaments d\u2019\u00c9glise, to Turin, the capital of Sardinia, for an assembly of mathematicians and engineers. There he made his first (and last) public presentation of the Analytical Engine. \u201cThe discovery of the Analytical Engine is so much in advance of my own country, and I fear even of the age,\u201d he said. He met the Sardinian king, Charles Albert, and, more significantly, an ambitious young mathematician named Luigi Menabrea. Later Menabrea was to\nbecome a general, a diplomat, and the prime minister of Italy; now he prepared a scientific report, \u201cNotions sur la machine analytique,\u201d to introduce Babbage\u2019s plan to a broader community of European philosophers.\n\nAs soon as this reached Ada Lovelace, she began translating it into English, correcting errors on the basis of her own knowledge. She did that on her own, without telling either Menabrea or Babbage.\n\nWhen she finally did show Babbage her draft, in 1843, he responded enthusiastically, urging her to write on her own behalf, and their extraordinary collaboration began in earnest. They sent letters by messenger back and forth across London at a ferocious pace\u2014\u201cMy Dear Babbage\u201d and \u201cMy Dear Lady Lovelace\u201d\u2014and met whenever they could at her home in St. James\u2019s Square. The pace was almost frantic. Though he was the eminence, fifty-one years old to her twenty-seven, she took charge, mixing stern command with banter. \u201cI want you to answer me the following question by return of post\u201d; \u201cBe kind enough to write this out properly for me\u201d; \u201cYou were a little harum-scarum and inaccurate\u201d; \u201cI wish you were as accurate and as much to be relied on as myself.\u201d She proposed to sign her work with her initials\u2014nothing so forward as her name\u2014not to \u201cproclaim who has written it,\u201d merely to \u201cindividualize and identify it with other productions of the said A.A.L.\u201d\n\nHer exposition took the form of notes lettered A through G, extending to nearly three times the length of Menabrea\u2019s essay. They offered a vision of the future more general and more prescient than any expressed by Babbage himself. How general? The engine did not just calculate; it performed operations, she said, defining an operation as \u201cany process which alters the mutual relation of two or more things,\u201d and declaring: \u201cThis is the most general definition, and would include all subjects in the universe.\u201d The science of operations, as she conceived it,\n\nis a science of itself, and has its own abstract truth and value; just as logic has its own peculiar truth and value, independently of the subjects to which we may apply its reasonings and processes\u2026. One main reason why the separate nature of the science of operations has been little felt, and in general little dwelt on, is the shifting meaning of many of the symbols used.\n\nSymbols and meaning: she was emphatically not speaking of mathematics alone. The engine \u201cmight act upon other things besides number.\u201d Babbage had inscribed numerals on those thousands of dials, but their working could represent symbols more abstractly. The engine might process any meaningful relationships. It might manipulate language. It might create music. \u201cSupposing, for instance, that the fundamental relations of pitched sounds in the science of harmony and of musical composition were susceptible of such expression and adaptations, the engine might compose elaborate and scientific pieces of music of any degree of\ncomplexity or extent.\u201d\n\nIt had been an engine of numbers; now it became an engine of information. A.A.L. perceived that more distinctly and more imaginatively than Babbage himself. She explained his prospective, notional, virtual creation as though it already existed:\n\nThe Analytical Engine does not occupy common ground with mere \u201ccalculating machines.\u201d It holds a position wholly its own\u2026. A new, a vast, and a powerful language is developed \u2026 in which to wield its truths so that these may become of more speedy and accurate practical application for the purposes of mankind than the means hitherto in our possession have rendered possible. Thus not only the mental and the material, but the theoretical and the practical in the mathematical world, are brought into more intimate and effective connexion with each other.\n\n\u2026 We may say most aptly, that the Analytical Engine weaves algebraical patterns just as the Jacquard-loom weaves flowers and leaves.\n\nFor this flight of fancy she took full responsibility. \u201cWhether the inventor of this engine had any such views in his mind while working out the invention, or whether he may subsequently ever have regarded it under this phase, we do not know; but it is one that forcibly occurred to ourselves.\u201d\n\nShe proceeded from the poetic to the practical. She set forth on a virtuoso excursion through a hypothetical program by which this hypothetical machine might compute a famously deep-seated infinite series, the Bernoulli numbers. These numbers arise in the summing of numbers from 1 to \\( n \\) raised to integral powers, and they occur in various guises all through number theory. No direct formula generates them, but they can be worked out methodically, by expanding certain formulas further and further and looking at the coefficients each time. She began with examples; the simplest, she wrote, would be the expansion of\n\n\\[\n\\frac{x}{e^x - 1} = \\frac{1}{1 + \\frac{x}{2} + \\frac{x^2}{2 \\cdot 3} + \\frac{x^3}{2 \\cdot 3 \\cdot 4} + \\&c.}\n\\]\n\nand another approach would be via\nbut she would take a more challenging path, because \u201cour object is not simplicity \u2026 but the illustration of the powers of the engine.\u201d\n\nShe devised a process, a set of rules, a sequence of operations. In another century this would be called an algorithm, later a computer program, but for now the concept demanded painstaking explanation. The trickiest point was that her algorithm was recursive. It ran in a loop. The result of one iteration became food for the next. Babbage had alluded to this approach as \u201cthe Engine eating its own tail.\u201d A.A.L. explained: \u201cWe easily perceive that since every successive function is arranged in a series following the same law, there would be a cycle of a cycle of a cycle, &c\u2026. The question is so exceedingly complicated, that perhaps few persons can be expected to follow\u2026. Still it is a very important case as regards the engine, and suggests ideas peculiar to itself, which we should regret to pass wholly without allusion.\u201d\n\nA core idea was the entity she and Babbage called the variable. Variables were, in hardware terms, the machine\u2019s columns of number dials. But there were \u201cVariable cards,\u201d too. In software terms they were a sort of receptacle or envelope, capable of representing, or storing, a number of many decimal digits. (\u201cWhat is there in a name?\u201d Babbage wrote. \u201cIt is merely an empty basket until you put something in it.\u201d) Variables were the machine\u2019s units of information. This was quite distinct from the algebraic variable. As A.A.L. explained, \u201cThe origin of this appellation is, that the values on the columns are destined to change, that is to vary, in every conceivable manner.\u201d Numbers traveled, in effect, from variable cards to variables, from variables to the mill (for operations), from the mill to the store. To solve the problem of generating Bernoulli numbers, she choreographed an intricate dance. She worked days and sometimes through the night, messaging Babbage across London, struggling with sickness and ominous pains, her mind soaring:\n\nThat brain of mine is something more than merely mortal; as time will show; (if only\nmy breathing & some other et-ceteras do not make too rapid a progress towards instead of from mortality).\n\nBefore ten years are over, the Devil\u2019s in it if I have not sucked out some of the life-blood from the mysteries of this universe, in a way that no purely mortal lips or brains could do.\n\nNo one knows what almost awful energy & power lie yet undeveloped in that wiry little system of mine. I say awful, because you may imagine what it might be under certain circumstances\u2026.\n\nI am doggedly attacking & sifting to the very bottom, all the ways of deducing the Bernoulli Numbers\u2026. I am grappling with this subject, & connecting it with others.\n\nShe was programming the machine. She programmed it in her mind, because the machine did not exist. The complexities she encountered for the first time became familiar to programmers of the next century:\n\nHow multifarious and how mutually complicated are the considerations which the working of such an engine involve. There are frequently several distinct sets of effects going on simultaneously; all in a manner independent of each other, and yet to a greater or less degree exercising a mutual influence. To adjust each to every other, and indeed even to perceive and trace them out with perfect correctness and success, entails difficulties whose nature partakes to a certain extent of those involved in every question where conditions are very numerous and inter-complicated.\n\nShe reported her feelings to Babbage: \u201cI am in much dismay at having got into so amazing a quagmire & botheration.\u201d And nine days later: \u201cI find that my plans & ideas keep gaining in clearness, & assuming more of the crystalline & less & less of the nebulous form.\u201d She knew she had achieved something utterly new. Ten days later still, struggling over the final proofs with \u201cMr Taylors Printing Office\u201d in Fleet Street, she declared: \u201cI do not think you possess half my forethought, & power of foreseeing all possible contingencies (probable & improbable, just alike).\u2014\u2026 I do not believe that my father was (or ever could have been) such a Poet as I shall be an Analyst; (& Metaphysician); for with me the two go together indissolubly.\u201d\n\nWho would have used this machine? Not clerks or shopkeepers, said Babbage\u2019s son, many years later. Common arithmetic was never the purpose\u2014\u201cIt would be like using the steam hammer to crush the nut.\u201d He paraphrased Leibniz: \u201cIt is not made for those who sell vegetables or little fishes, but for observatories, or the private rooms of calculators, or for others who can easily bear the expense, and need a good deal of calculation.\u201d Babbage\u2019s engine had not been well understood, not by his government and not by the many friends who passed through his salon, but in its time its influence traveled far.\n\nIn America, a country bursting with invention and scientific optimism, Edgar Allan Poe wrote, \u201cWhat shall we think of the calculating machine of Mr. Babbage? What shall we think of an engine of wood and metal which can \u2026 render the\nexactitude of its operations mathematically certain through its power of correcting its possible errors?\u201d Ralph Waldo Emerson had met Babbage in London and declared in 1870, \u201cSteam is an apt scholar and a strong-shouldered fellow, but it has not yet done all its work.\u201d\n\nIt already walks about the field like a man, and will do anything required of it. It irrigates crops, and drags away a mountain. It must sew our shirts, it must drive our gigs; taught by Mr. Babbage, it must calculate interest and logarithms\u2026. It is yet coming to render many higher services of a mechanico-intellectual kind.\n\nIts wonders met disapproval, too. Some critics feared a rivalry between mechanism and mind. \u201cWhat a satire is that machine on the mere mathematician!\u201d said Oliver Wendell Holmes Sr. \u201cA Frankenstein-monster, a thing without brains and without heart, too stupid to make a blunder; which turns out results like a corn-sheller, and never grows any wiser or better, though it grind a thousand bushels of them!\u201d They all spoke as though the engine were real, but it never was. It remained poised before its own future.\n\nMidway between his time and ours, the Dictionary of National Biography granted Charles Babbage a brief entry\u2014almost entirely devoid of relevance or consequence:\n\nmathematician and scientific mechanician;\u2026 obtained government grant for making a calculating machine \u2026 but the work of construction ceased, owning to disagreements with the engineer; offered the government an improved design, which was refused on grounds of expense;\u2026 Lucasian professor of mathematics, Cambridge, but delivered no lectures.\n\nBabbage\u2019s interests, straying so far from mathematics, seeming so miscellaneous, did possess a common thread that neither he nor his contemporaries could perceive. His obsessions belonged to no category\u2014that is, no category yet existing. His true subject was information: messaging, encoding, processing.\n\nHe took up two quirky and apparently unphilosophical challenges, which he himself noted had a deep connection one to the other: picking locks and deciphering codes. Deciphering, he said, was \u201cone of the most fascinating of arts, and I fear I have wasted upon it more time than it deserves.\u201d To rationalize the process, he set out to perform a \u201ccomplete analysis\u201d of the English language. He created sets of special dictionaries: lists of the words of one letter, two letters, three letters, and so on; and lists of words alphabetized by their initial letter, second letter, third letter, and so on. With these at hand he designed methodologies for solving anagram puzzles and word squares.\n\nIn tree rings he saw nature encoding messages about the past. A profound lesson: that a tree records a whole complex of information in its solid substance. \u201cEvery shower that falls, every change of temperature that occurs, and every wind\nthat blows, leaves on the vegetable world the traces of its passage; slight, indeed, and imperceptible, perhaps, to us, but not the less permanently recorded in the depths of those woody fabrics.\u201d\n\nIn London workshops he had observed speaking tubes, made of tin, \u201cby which the directions of the superintendent are instantly conveyed to the remotest parts.\u201d He classified this technology as a contribution to the \u201ceconomy of time\u201d and suggested that no one had yet discovered a limit on the distance over which spoken messages might travel. He made a quick calculation: \u201cAdmitting it to be possible between London and Liverpool, about seventeen minutes would elapse before the words spoken at one end would reach the other extremity of the pipe.\u201d In the 1820s he had an idea for transmitting written messages, \u201cenclosed in small cylinders along wires suspended from posts, and from towers, or from church steeples,\u201d and he built a working model in his London house. He grew obsessed with other variations on the theme of sending messages over the greatest possible distances. The post bag dispatched nightly from Bristol, he noted, weighed less than one hundred pounds. To send these messages 120 miles, \u201ca coach and apparatus, weighing above thirty hundred weight, are put in motion, and also conveyed over the same space.\u201d What a waste! Suppose, instead, he suggested, post towns were linked by a series of high pillars erected every hundred feet or so. Steel wires would stretch from pillar to pillar. Within cities, church steeples might serve as the pillars. Tin cases with wheels would roll along the wires and carry batches of letters. The expense would be \u201ccomparatively trifling,\u201d he said, \u201cnor is it impossible that the stretched wire might itself be available for a species of telegraphic communication yet more rapid.\u201d\n\nDuring the Great Exhibition of 1851, when England showcased its industrial achievement in a Crystal Palace, Babbage placed an oil lamp with a moveable shutter in an upstairs window at Dorset Street to create an \u201cocculting light\u201d apparatus that blinked coded signals to passersby. He drew up a standardized system for lighthouses to use in sending numerical signals and posted twelve copies to, as he said, \u201cthe proper authorities of the great maritime countries.\u201d In the United States, the Congress approved $5,000 for a trial program of Babbage\u2019s system. He studied sun signals and \u201czenith-light signals\u201d flashed by mirrors, and Greenwich time signals for transmission to mariners. For communicating between stranded ships and rescuers on shore, he proposed that all nations adopt a standard list of a hundred questions and answers, assigned numbers, \u201cto be printed on cards, and nailed up on several parts of every vessel.\u201d Similar signals, he suggested, could help the military, the police, the railways, or even, \u201cfor various social purposes,\u201d neighbors in the country.\n\nThese purposes were far from obvious. \u201cFor what purposes will the electric telegraph become useful?\u201d the king of Sardinia, Charles Albert, asked Babbage in\n1840. Babbage searched his mind for an illustration, \u201cand at last I pointed out the probability that, by means of the electric telegraphs, his Majesty\u2019s fleet might receive warning of coming storms....\u201d\n\nThis led to a new theory of storms, about which the king was very curious. By degrees I endeavoured to make it clear. I cited, as an illustration, a storm which had occurred but a short time before I left England. The damage done by it at Liverpool was very great, and at Glasgow immense.... I added that if there had been electric communication between Genoa and a few other places the people of Glasgow might have had information of one of those storms twenty-four hours previously to its arrival.\n\nAs for the engine, it had to be forgotten before it was remembered. It had no obvious progeny. It rematerialized like buried treasure and inspired a sense of puzzled wonder. With the computer era in full swing, the historian Jenny Uglow felt in Babbage\u2019s engines \u201ca different sense of anachronism.\u201d Such failed inventions, she wrote, contain \u201cideas that lie like yellowing blueprints in dark cupboards, to be stumbled on afresh by later generations.\u201d\n\nMeant first to generate number tables, the engine in its modern form instead rendered number tables obsolete. Did Babbage anticipate that? He did wonder how the future would make use of his vision. He guessed that a half century would pass before anyone would try again to create a general-purpose computing machine. In fact, it took most of a century for the necessary substrate of technology to be laid down. \u201cIf, unwarned by my example,\u201d he wrote in 1864, \u201cany man shall undertake and shall succeed in really constructing an engine embodying in itself the whole of the executive department of mathematical analysis upon different principles or by simpler mechanical means, I have no fear of leaving my reputation in his charge, for he alone will be fully able to appreciate the nature of my efforts and the value of their results.\u201d\n\nAs he looked to the future, he saw a special role for one truth above all: \u201cthe maxim, that knowledge is power.\u201d He understood that literally. Knowledge \u201cis itself the generator of physical force,\u201d he declared. Science gave the world steam, and soon, he suspected, would turn to the less tangible power of electricity: \u201cAlready it has nearly chained the ethereal fluid.\u201d And he looked further:\n\nIt is the science of calculation\u2014which becomes continually more necessary at each step of our progress, and which must ultimately govern the whole of the applications of science to the arts of life.\n\nSome years before his death, he told a friend that he would gladly give up whatever time he had left, if only he could be allowed to live for three days, five centuries in the future.\n\nAs for his young friend Ada, countess of Lovelace, she died many years before him\u2014a protracted, torturous death from cancer of the womb, her agony barely\nThe Information\n\nlessened by laudanum and cannabis. For a long time her family kept from her the truth of her illness. In the end she knew she was dying. \u201cThey say that \u2018coming events cast their shadows before,\u2019 \u201d she wrote to her mother. \u201cMay they not sometimes cast their lights before?\u201d They buried her next to her father.\n\nShe, too, had a last dream of the future: \u201cmy being in time an Autocrat, in my own way.\u201d She would have regiments, marshaled before her. The iron rulers of the earth would have to give way. And of what would her regiments consist? \u201cI do not at present divulge. I have however the hope that they will be most harmoniously disciplined troops;\u2014consisting of vast numbers, & marching in irresistible power to the sound of Music. Is not this very mysterious? Certainly my troops must consist of numbers, or they can have no existence at all\u2026. But then, what are these Numbers? There is a riddle\u2014\u201d\n\n* Leibniz dreamed grandly of mechanizing algebra and even reason itself. \u201cWe may give final praise to the machine,\u201d he wrote. \u201cIt will be desirable to all who are engaged in computations \u2026 the managers of financial affairs, the administrators of others\u2019 estates, merchants, surveyors, geographers, navigators, astronomers\u2026. For it is unworthy of excellent men to lose hours like slaves in the labor of calculation.\u201d\n\n* Another guest, Charles Dickens, put something of Babbage into the character of Daniel Doyce in Little Dorrit. Doyce is an inventor mistreated by the government he tries to serve: \u201cHe is well known as a very ingenious man\u2026. He perfects an invention (involving a very curious secret process) of great importance to his country and his fellow-creatures. I won\u2019t say how much money it cost him, or how many years of his life he had been about it, but he brought it to perfection.\u201d Dickens added: \u201cA composed and unobtrusive self-sustainment was noticeable in Daniel Doyce\u2014a calm knowledge that what was true must remain true.\u201d\n5 | A NERVOUS SYSTEM FOR THE EARTH\n\n(What Can One Expect of a Few Wretched Wires?)\n\nIs it a fact\u2014or have I dreamt it\u2014that, by means of electricity, the world of matter has become a great nerve, vibrating thousands of miles in a breathless point of time? Rather, the round globe is a vast head, a brain, instinct with intelligence! Or, shall we say, it is itself a thought, nothing but thought, and no longer the substance which we deemed it!\n\n\u2014Nathaniel Hawthorne (1851)\n\nTHREE CLERKS IN A SMALL ROOM UPSTAIRS in the Ferry House of Jersey City handled the entire telegraph traffic of the city of New York in 1846 and did not have to work very hard. They administered one end of a single pair of wires leading to Baltimore and Washington. Incoming messages were written down by hand, relayed by ferry across the Hudson River to the Liberty Street pier, and delivered to the first office of the Magnetic Telegraph Company at 16 Wall Street.\n\nIn London, where the river caused less difficulty, capitalists formed the Electric Telegraph Company and began to lay their first copper wires, twisted into cables, covered with gutta-percha, and drawn through iron pipes, mainly alongside new railroad tracks. To house the central office the company rented Founders\u2019 Hall, Lothbury, opposite the Bank of England, and advertised its presence by installing an electric clock\u2014modern and apt, for already railroad time was telegraphic time. By 1849 the telegraph office boasted eight instruments, operated day and night. Four hundred battery cells provided the power. \u201cWe see before us a stuccoed wall, ornamented with an electric illuminated clock,\u201d reported Andrew Wynter, a journalist, in 1854. \u201cWho would think that behind this narrow forehead lay the great brain\u2014if we may so term it\u2014of the nervous system of Britain?\u201d He was neither the first nor the last to liken the electric telegraph to biological wiring: comparing cables to nerves; the nation, or the whole earth, to the human body.\n\nThe analogy linked one perplexing phenomenon with another. Electricity was an enigma wrapped in mystery verging on magic, and no one understood nerves, either. Nerves were at least known to conduct a form of electricity and thus,\nperhaps, to serve as conduits for the brain\u2019s control of the body. Anatomists examining nerve fibers wondered whether they might be insulated with the body\u2019s own version of gutta-percha. Maybe nerves were not just *like* wires; maybe they *were* wires, carrying messages from the nether regions to the sensorium. Alfred Smee, in his 1849 *Elements of Electro-Biology*, likened the brain to a battery and the nerves to \u201cbio-telegraphs.\u201d Like any overused metaphor, this one soon grew ripe for satire. A newspaper reporter in Menlo Park, discovering Thomas A. Edison in the grip of a head cold, wrote: \u201cThe doctor came and looked at him, explained the relations of the trigeminal nerves and their analogy to an electric telegraph with three wires, and observed incidentally that in facial neuralgia each tooth might be regarded as a telegraph station with an operator.\u201d When the telephone arrived, it reinforced the analogy. \u201cThe time is close at hand,\u201d declared *Scientific American* in 1880, \u201cwhen the scattered members of civilized communities will be as closely united, so far as instant telephonic communication is concerned, as the various members of the body now are by the nervous system.\u201d Considering how speculative the analogy was, it turned out well. Nerves really do transmit messages, and the telegraph and telephone did begin to turn human society, for the first time, into something like a coherent organism.\n\nIn their earliest days these inventions inspired exhilaration without precedent in the annals of technology. The excitement passed from place to place in daily newspapers and monthly magazines and, more to the point, along the wires themselves. A new sense of futurity arose: a sense that the world was in a state of change, that life for one\u2019s children and grandchildren would be very different, all because of this force and its uses. \u201cElectricity is the poetry of science,\u201d an American historian declared in 1852.\n\nNot that anyone knew what electricity was. \u201cAn invisible, intangible, imponderable agent,\u201d said one authority. Everyone agreed that it involved a \u201cpeculiar condition\u201d either of molecules or of the ether (itself a nebulous, and ultimately doomed, conception). Thomas Browne, in the seventeenth century, described electrical effluvia as \u201cthreads of syrup, which elongate and contract.\u201d In the eighteenth, the kite-flying Benjamin Franklin proved \u201cthe sameness of lightning with electricity\u201d\u2014identifying those fearsome bolts from the sky with the odd terrestrial sparks and currents. Franklin followed the Abb\u00e9 Jean-Antoine Nollet, a natural philosopher and a bit of a showman, who said in 1748, \u201cElectricity in our hands is the same as thunder in the hands of nature\u201d and to prove it organized an experiment employing a Leyden jar and iron wire to send a shock through two hundred Carthusian monks arranged in a circle one mile around. From the monks\u2019 almost simultaneous hops, starts, jerks, and cries, onlookers judged that the message\u2014its information content small but not zero\u2014\nsped round the circle at fantastic speed.\n\nLater, it was Michael Faraday in England who did more than anyone to turn electricity from magic to science, but even so, in 1854, when Faraday was at the height of his investigations, Dionysius Lardner, the scientific writer who so admired Babbage, could quite accurately declare, \u201cThe World of Science is not agreed as to the physical character of Electricity.\u201d Some believed it to be a fluid \u201clighter and more subtle\u201d than any gas; others suspected a compound of two fluids \u201chaving antagonistic properties\u201d; and still others thought electricity was not a fluid at all, but something analogous to sound: \u201ca series of undulations or vibrations.\u201d Harper\u2019s Magazine warned that \u201ccurrent\u201d was just a metaphor and added mysteriously, \u201cWe are not to conceive of the electricity as carrying the message that we write, but rather as enabling the operator at the other end of the line to write a similar one.\u201d\n\nWhatever its nature, electricity was appreciated as a natural force placed under human control. A young New York newspaper, The Times, explained it by way of contrast with steam:\n\nBoth of them are powerful and even formidable agents wrested from nature, by the skill and power of man. But electricity is by far the subtlest energy of the two. It is an original natural element, while steam is an artificial production\u2026. Electricity combined with magnetism, is a more subjective agent, and when evolved for transmission is ready to go forth, a safe and expeditious messenger to the ends of the habitable globe.\n\nLooking back, rhapsodists found the modern age foretold in a verse from the book of Job: \u201cCanst thou send lightnings, that they may go and say unto thee, Here we are?\u201d\n\nBut lightning did not say anything\u2014it dazzled, cracked, and burned, but to convey a message would require some ingenuity. In human hands, electricity could hardly accomplish anything, at first. It could not make a light brighter than a spark. It was silent. But it could be sent along wires to great distances\u2014this was discovered early\u2014and it seemed to turn wires into faint magnets. Those wires could be long: no one had found any limit to the range of the electric current. It took no time at all to see what this meant for the ancient dream of long-distance communication. It meant sympathetic needles.\n\nPractical problems had to be solved: making wires, insulating them, storing currents, measuring them. A whole realm of engineering had to be invented. Apart from the engineering was a separate problem: the problem of the message itself. This was more a logic puzzle than a technical one. It was a problem of crossing levels, from kinetics to meaning. What form would the message take? How would the telegraph convert this fluid into words? By virtue of magnetism, the influence propagated across a distance could perform work upon physical\nobjects, such as needles, or iron filings, or even small levers. People had different ideas: the electromagnet might sound an alarum-bell; might govern the motion of wheel-work; might turn a handle, which might carry a pencil (but nineteenth-century engineering was not up to robotic handwriting). Or the current might discharge a cannon. Imagine discharging a cannon by sending a signal from miles away! Would-be inventors naturally looked to previous communications technologies, but the precedents were mostly the wrong sort.\n\nBefore there were electric telegraphs, there were just telegraphs: *les t\u00e9l\u00e9graphes*, invented and named by Claude Chappe in France during the Revolution.* They were optical; a \u201ctelegraph\u201d was a tower for sending signals to other towers in line of sight. The task was to devise a signaling system more efficient and flexible than, say, bonfires. Working with his messaging partner, his brother Ignace, Claude tried out a series of different schemes, evolving over a period of years.\n\nThe first was peculiar and ingenious. The Chappe brothers set a pair of pendulum clocks to beat in synchrony, each with its pointer turning around a dial at relatively high speed. They experimented with this in their hometown, Br\u00fblon, about one hundred miles west of Paris. Ignace, the sender, would wait till the pointer reached an agreed number and at that instant signal by ringing a bell or firing a gun or, more often, banging upon a *casserole*. Upon hearing the sound, Claude, stationed a quarter mile away, would read the appropriate number off his own clock. He could convert number to words by looking them up in a prearranged list. This notion of communication via synchronized clocks reappeared in the twentieth century, in physicists\u2019 thought experiments and in electronic devices, but in 1791 it led nowhere. One drawback was that the two stations had to be linked both by sight and by sound\u2014and if they were, the clocks had little to add. Another was the problem of getting the clocks synchronized in the first place and keeping them synchronized. Ultimately, fast long-distance messaging was what made synchronization possible\u2014not the reverse. The scheme collapsed under the weight of its own cleverness.\n\nMeanwhile the Chappes managed to draw more of their brothers, Pierre and Ren\u00e9, into the project, with a corps of municipal officers and royal notaries to bear witness. The next attempt dispensed with clockwork and sound. The Chappes constructed a large wooden frame with five sliding shutters, to be raised and lowered with pulleys. By using each possible combination, this \u201ctelegraph\u201d could transmit an alphabet of thirty-two symbols\u2014$2^5$, another binary code, though the details do not survive. Claude was pleading for money from the newly formed Legislative Assembly, so he tried this hopeful message from Br\u00fblon: \u201cL\u2019Assembl\u00e9e nationale r\u00e9compensera les experiences utiles au public\u201d (\u201cThe National Assembly will reward experiments useful to the public\u201d). The eight\nwords took 6 minutes, 20 seconds to transmit, and they failed to come true.\n\nRevolutionary France was both a good and a bad place for modernistic experimentation. When Claude erected a prototype telegraph in the parc Saint-Fargeau, in the northeast of Paris, a suspicious mob burned it to the ground, fearful of secret messaging. Citizen Chappe continued looking for a technology as swift and reliable as that other new device, the guillotine. He designed an apparatus with a great crossbeam supporting two giant arms manipulated by ropes. Like so many early machines, this was somewhat anthropomorphic in form. The arms could take any of seven angles, at 45-degree increments (not eight, because one would leave the arm hidden behind the beam), and the beam, too, could rotate, all under the control of an operator down below, manipulating a system of cranks and pulleys. To perfect this complex mechanism Chappe enlisted Abraham-Louis Breguet, the well-known watchmaker.\n\nAs intricate as the control problem was, the question of devising a suitable code proved even more difficult. From a strictly mechanical point of view, the arms and the beam could take any angle at all\u2014the possibilities were infinite\u2014but for efficient signaling Chappe had to limit the possibilities. The fewer meaningful positions, the less likelihood of confusion. He chose only two for the crossbeam, on top of the seven for each arm, giving a symbol space of 98 possible arrangements \\((7 \\times 7 \\times 2)\\). Rather than just use these for letters and numerals, Chappe set out to devise an elaborate code. Certain signals were reserved for error correction and control: start and stop, acknowledgment, delay, conflict (a tower could not send messages in both directions at once), and failure. Others were used in pairs, pointing the operator to pages and line numbers in special code books with more than eight thousand potential entries: words and syllables as well as proper names of people and places. All this remained a carefully guarded secret. After all, the messages were to be broadcast in the sky, for anyone to see. Chappe took it for granted that the telegraph network of which he dreamed would be a department of the state, government owned and operated. He saw it not as an instrument of knowledge or of riches, but as an instrument of power. \u201cThe day will come,\u201d he wrote, \u201cwhen the Government will be able to achieve the grandest idea we can possibly have of power, by using the telegraph system in order to spread directly, every day, every hour, and simultaneously, its influence over the whole republic.\u201d\n\nWith the country at war and authority now residing with the National Convention, Chappe managed to gain the attention of some influential legislators. \u201cCitizen Chappe offers an ingenious method to write in the air, using a small number of symbols, simply formed from straight line segments,\u201d reported one of them, Gilbert Romme, in 1793. He persuaded the Convention to appropriate six thousand francs for the construction of three telegraph towers in a line north of\nParis, seven to nine miles apart. The Chappe brothers moved rapidly now and by the end of summer arranged a triumphant demonstration for the watching deputies. The deputies liked what they saw: a means of receiving news from the military frontier and transmitting their orders and decrees. They gave Chappe a salary, the use of a government horse, and an official appointment to the post of ing\u00e9nieur t\u00e9l\u00e9graphe. He began work on a line of stations 120 miles long, from the Louvre in Paris to Lille, on the northern border. In less than a year he had eighteen in operation, and the first messages arrived from Lille: happily, news of victories over the Prussians and Austrians. The Convention was ecstatic. One deputy named a pantheon of four great human inventions: printing, gunpowder, the compass, and \u201cthe language of telegraph signs.\u201d He was right to focus on the language. In terms of hardware\u2014ropes, levers, and wooden beams\u2014the Chappes had invented nothing new.\n\nA CHAPPE TELEGRAPH\n\nConstruction began on stations in branches extending east to Strasbourg, west to Brest, and south to Lyon. When Napoleon Bonaparte seized power in 1799, he ordered a message sent in every direction\u2014\u201cParis est tranquille et les bons citoyens sont contents\u201d (\u201cParis is quiet and the good citizens are happy\u201d)\u2014and soon commissioned a line of new stations all the way to Milan. The telegraph system was setting a new standard for speed of communication, since the only real competition was a rider on horseback. But speed could be measured in two ways: in terms of distance or in terms of symbols and words. Chappe once claimed that a signal could go from Toulon to Paris\u2014a line of 120 stations across 475 miles\u2014in just ten or twelve minutes. But he could not make that claim for a full message, even a relatively short one. Three signals per minute was the most that could be expected of even the fastest telegraph operator. The next operator in the chain, watching through a telescope, had to log each signal by hand in a notebook, reproduce it by turning his own cranks and pulleys, and watch to make sure it was received correctly by the next station. The signal chain was vulnerable\nand delicate: rain, fog, or an inattentive operator would break any message. When success rates were measured in the 1840s, only two out of three messages were found to arrive within a day during the warm months, and in winter the rate dropped to one in three. Coding and decoding took time, too, but only at the beginning and end of the line. Operators at intermediate stations were meant to relay signals without understanding them. Indeed, many stationaires were illiterate.\n\nTHE FRENCH TELEGRAPH NETWORK IN ITS HEYDAY\n\nWhen messages did arrive, they could not always be trusted. Many relay stations meant many chances for error. Children everywhere know this, from playing the messaging game known in Britain as Chinese Whispers, in China as \u4ee5\u8bb9\u4f20\u8bb9, in Turkey as From Ear to Ear, and in the modern United States simply as Telephone. When his colleagues disregarded the problem of error correction, Ignace Chappe complained, \u201cThey have probably never performed experiments with more than two or three stations.\u201d\nToday the old telegraphs are forgotten, but they were a sensation in their time. In London, a Drury Lane entertainer and songwriter named Charles Dibdin put the invention into a 1794 musical show and foresaw a marvelous future:\n\nIf you\u2019ll only just promise you\u2019ll none of you laugh,\nI\u2019ll be after explaining the French telegraph!\nA machine that\u2019s endow\u2019d with such wonderful pow\u2019r,\nIt writes, reads, and sends news fifty miles in an hour.\n\nOh! the dabblers in lott\u2019ries will grow rich as Jews:\n\u2019Sead of flying of pigeons, to bring them the news,\nThey\u2019ll a telegraph place upon Old Ormond Quay;\nPut another \u2019board ship, in the midst of the sea.\n\nAdieu, penny-posts! mails and coaches, adieu;\nYour occupation\u2019s gone, \u2019tis all over wid you:\nIn your place, telegraphs on our houses we\u2019ll see,\nTo tell time, conduct lightning, dry shirts, and send news.\n\nThe telegraph towers spread across Europe and beyond, and their ruins dot the countrysides today. Telegraph Hill, Telegrafberget, Telegraphen-Berg are vestigial place names. Sweden, Denmark, and Belgium were early to develop systems on the French model. Germany soon followed. A line between Calcutta and Chunar began operating in 1823; between Alexandria and Cairo in 1824; and in Russia, Nicholas I organized 220 stations from Warsaw to St. Petersburg and Moscow. They held dominion over the world\u2019s communication and then, faster than they had arisen, went obsolete. Colonel Taliaferro Shaffner, a Kentucky inventor and historian, traveled to Russia in 1859 and was struck by the towers\u2019 height and their beauty, the care taken with their painting and landscaping with flowers, and by their sudden, universal death.\n\nThese stations are now silent. No movements of the indicators are to be seen. They are still upon their high positions, fast yielding to the wasting hand of time. The electric wire, though less grand in its appearance, traverses the empire, and with burning flames inscribes in the distance the will of the emperor to sixty-six millions of human beings scattered over his wide-spread dominions.\n\nIn Shaffner\u2019s mind this was a one-way conversation. The sixty-six millions were not talking back to the emperor, nor to one another.\n\nWhat was to be said, when writing in the air? Claude Chappe had proposed, \u201cAnything that could be the subject of a correspondence.\u201d But his example\u2014\u201cLukner has left for Mons to besiege that city, Bender is advancing for its defense\u201d\u2014made clear what he meant: dispatches of military and state import.\nLater Chappe proposed sending other types of information: shipping news, and financial quotations from bourses and stock exchanges. Napoleon would not allow it, though he did use the telegraph to proclaim the birth of his son, Napoleon II, in 1811. A communications infrastructure built with enormous government investment and capable of transmitting some hundreds of total words per day could hardly be used for private messaging. That was unimaginable\u2014and when, in the next century, it became imaginable, some governments found it undesirable. No sooner did entrepreneurs begin to organize private telegraphy than France banned it outright: an 1837 law mandated imprisonment and fines for \u201canyone performing unauthorized transmissions of signals from one place to another, with the aid of telegraphic machines or by any other means.\u201d The idea of a global nervous system had to arise elsewhere. In the next year, 1838, the French authorities received a visit from an American with a proposal for a \u201ctelegraph\u201d utilizing electrical wires: Samuel F. B. Morse. They turned him down flat. Compared to the majestic semaphore, electricity seemed gimcrack and insecure. No one could interfere with telegraph signals in the sky, but wire could be cut by saboteurs. Jules Guyot, a physician and scientist assigned to assess the technology, sniffed, \u201cWhat can one expect of a few wretched wires?\u201d What indeed.\n\nTHE TELEGRAPH AT MONTMARTRE\n\nThe care and feeding of the delicate galvanic impulse presented a harsh set of technical challenges, and a different set appeared where electricity met language: where words had to be transmuted into a twinkling in the wire. The crossing point between electricity and language\u2014also the interface between device and human\u2014required new ingenuity. Many different schemes occurred to inventors.\nVirtually all were based in one way or another on the written alphabet, employing letters as an intermediate layer. This seemed so natural as to be not worth remarking. *Telegraph* meant \u201cfar writing,\u201d after all. So in 1774 Georges-Louis Le Sage of Geneva arranged twenty-four separate wires to designate twenty-four letters, each wire conveying just enough current to stir a piece of gold leaf or a pith ball suspended in a glass jar or \u201cother bodies that can be as easily attracted, and are, at the same time, easily visible.\u201d That was too many wires to be practicable. A Frenchman named Lomond in 1787 ran a single wire across his apartment and claimed to be able to signal different letters by making a pith ball dance in different directions. \u201cIt appears that he has formed an alphabet of motions,\u201d reported a witness, but apparently only Lomond\u2019s wife could understand the code. In 1809 a German, Samuel Thomas von S\u00f6mmerring, made a bubble telegraph. Current passing through wires in a vessel of water produced bubbles of hydrogen; each wire, and thus each jet of bubbles, could indicate a single letter. While he was at it, von S\u00f6mmerring managed to make electricity ring a bell: he balanced a spoon in the water, upside down, so that enough bubbles would make it tilt, releasing a weight, driving a lever, and ringing the bell. \u201cThis secondary object, the alarum,\u201d he wrote in his diary, \u201ccost me a great deal of reflection and many useless trials with wheelwork.\u201d Across the Atlantic, an American named Harrison Gray Dyer tried sending signals by making electric sparks form nitric acid that discolored litmus paper. He strung a wire on trees and stakes around a Long Island race track. The litmus paper had to be moved by hand.\n\nThen came needles. The physicist Andr\u00e9-Marie Amp\u00e8re, a developer of the galvanometer, proposed using that as a signaling device: it was a needle deflected by electromagnetism\u2014a compass pointing to a momentary artificial north. He, too, thought in terms of one needle for every letter. In Russia, Baron Pavel Schilling demonstrated a system with five needles and later reduced that to one: he assigned combinations of right and left signals to the letters and numerals. At G\u00f6ttingen in 1833 the mathematician Carl Friedrich Gauss, working with a physicist, Wilhelm Weber, organized a similar scheme with one needle. The first deflection of the needle gave two possible signals, left or right. Two deflections combined gave four more possibilities (right + right, right + left, left + right, and left + left). Three deflections gave eight combinations, and four gave sixteen, for a total of thirty distinct signals. An operator would use pauses to separate the signals. Gauss and Weber organized their alphabet of deflections logically, beginning with the vowels and otherwise taking letters and digits in order:\n\n\\[\n\\begin{align*}\n\\text{right} & = a \\\\\n\\text{left} & = e\n\\end{align*}\n\\]\nright, right = i  \nright, left = o  \nleft, right = u  \nleft, left = b  \nright, right, right = c (and k)  \nright, right, left = d  \netc.\n\nThis scheme for encoding letters was binary, in a way. Each minimal unit, each little piece of signal, amounted to a choice between two possibilities, left or right. Each letter required a number of such choices, and that number was not predetermined. It could be one, as in right for \\(a\\) and left for \\(e\\). It could be more, so the scheme was open-ended, allowing an alphabet of as many letters as needed. Gauss and Weber strung a doubled wire over a mile of houses and steeples between the G\u00f6ttingen observatory and the physics institute. What they managed to say to each other has not been preserved.\n\nFar away from these inventors\u2019 workrooms, the telegraph still meant towers, semaphores, shutters, and flags, but enthusiasm for new possibilities was beginning to build. Lecturing to the Boston Marine Society in 1833, a lawyer and philologist, John Pickering, declared, \u201cIt must be evident to the most common observer, that no means of conveying intelligence can ever be devised, that shall exceed or even equal the rapidity of the Telegraph, for, with the exception of the scarcely perceptible relay at each station, its rapidity may be compared with that of light itself.\u201d He was thinking particularly of the Telegraph on Central Wharf, a Chappe-like tower communicating shipping news with three other stations in a twelve-mile line across Boston Harbor. Meanwhile, dozens of young newspapers around the nation were modernistically calling themselves \u201cThe Telegraph.\u201d They, too, were in the far-writing business.\n\n\u201cTelegraphy is an element of power and order,\u201d Abraham Chappe had said, but the rising financial and mercantile classes were the next to grasp the value of information leaping across distance. Only two hundred miles separated the Stock Exchange on Threadneedle Street in London from the Bourse at the Palais Brongniart, but two hundred miles meant days. Fortunes could be made by bridging that gap. For speculators a private telegraph would be as useful as a time machine. The Rothschild banking family was using pigeons as postal carriers and, more reliably, a small fleet of boats to carry messengers across the Channel. The phenomenon of fast information from a distance, having been discovered, generated a cascade of excitement. Pickering in Boston did the math: \u201cIf there are\nnow essential advantages to business in obtaining intelligence from New York in two days, or less, or at the rate of eight or ten miles an hour, any man can perceive that there may be a proportionate benefit, when we can transmit the same information for that distance by telegraph at the rate of four miles in a minute, or in the space of a single hour, from New York to Boston.\u201d The interest of governments in receiving military bulletins and projecting authority was surpassed by the desires of capitalists and newspapers, railroads and shipping companies. Still, in the sprawling United States, even the pressure of commerce was not enough to make optical telegraphy a reality. Only one prototype succeeded in linking two cities: New York and Philadelphia, in 1840. It transmitted stock prices and then lottery numbers and then was obsolete.\n\nAll the would-be inventors of the electrical telegraph\u2014and there were many\u2014worked from the same toolkit. They had their wires, and they had magnetic needles. They had batteries: galvanic cells, linked together, producing electricity from the reaction of metal strips immersed in acid baths. They did not have lights. They did not have motors. They had whatever mechanisms they could construct from wood and brass: pins, screws, wheels, springs, and levers. In the end they had the shared target at which they all aimed: the letters of the alphabet. (Edward Davy thought it was necessary to explain, in 1836, how and why the letters would suffice: \u201cA single letter may be indicated at a time, each letter being taken down by the attendant as it arrives, so as to form words and sentences; but it will be easy to see that, from the infinite changes upon a number of letters, a great number of ordinary communications may be conveyed.\u201d) Along with this common stock list, in Vienna, Paris, London, G\u00f6ttingen, St. Petersburg, and the United States, these pioneers shared a sense of their excited, competitive landscape, but no one knew clearly what anyone else was doing. They could not keep up with the relevant science; crucial advances in the science of electricity remained unknown to the people who most needed them. Every inventor ached to understand what happened to current flowing through wires of different lengths and thickness, and they continued to struggle for more than a decade after Georg Ohm, in Germany, worked out a precise mathematical theory for current, voltage, and resistance. Such news traveled slowly.\n\nIt was in this context that Samuel Morse and Alfred Vail, in the United States, and, in England, William Cooke and Charles Wheatstone made the electric telegraph a reality and a business. In one way or another, all of them later claimed to have \u201cinvented\u201d the telegraph, though none of them had done so\u2014certainly not Morse. Their partnerships were destined to end in brutal, turbulent, and bitter patent disputes embroiling most of the leading electrical scientists on two continents. The trail of invention, leading through so many countries, had been\npoorly recorded and even more poorly communicated.\n\nIn England, Cooke was a young entrepreneur\u2014he saw a prototype needle telegraph while traveling in Heidelberg\u2014and Wheatstone a King\u2019s College, London, physicist with whom Cooke formed a partnership in 1837. Wheatstone had performed experiments on the velocity of sound and of electricity, and once again the real problem lay in connecting the physics with language. They consulted England\u2019s authority on electricity, Michael Faraday, and Peter Roget, author of a *Treatise on Electro-Magnetism* as well as the system of verbal classification he called the *Thesaurus*. The Cooke-Wheatstone telegraph went through a series of prototypes. One used six wires to form three circuits, each controlling a magnetic needle. \u201cI worked out every possible permutation and practical combination of the signals given by the three needles, and I thus obtained an alphabet of twenty-six signals,\u201d noted Cooke, somewhat obscurely. There was also an alarm, in case the operator\u2019s attention wandered from the apparatus; Cooke said he had been inspired by the only mechanical device he knew well: a musical snuffbox. In the next version, a synchronized pair of rotating clockwork disks displayed the letters of the alphabet through a slot. More ingenious still, and just as awkward, was a five-needle design: twenty letters were arranged on a diamond-shaped grid and an operator, by depressing numbered buttons, would cause two of five needles to point, uniquely, to the desired letter. This Cooke-Wheatstone telegraph managed to do without C, J, Q, U, X, and Z. Their American competitor, Vail, later described the operation as follows:\n\nSuppose the message to be sent from the Paddington station to the Slough station, is this, \u201cWe have met the enemy and they are ours.\u201d The operator at Paddington presses down the buttons, 11 and 18, for signalizing upon the dial of the Slough station, the letter W. The operator there, who is supposed to be constantly on watch, observes the two needles pointing at W. He writes it down, or calls it aloud, to another, who records it, taking, according to a calculation given in a recent account, two seconds at least for each signal.\n\nVail considered this inefficient. He was in a position to be smug.\n\nAs for Samuel Finley Breese Morse, his later recollections came in the context of controversy\u2014what his son called \u201cthe wordy battles waged in the scientific world over the questions of priority, exclusive discovery or invention, indebtedness to others, and conscious or unconscious plagiarism.\u201d All these thrived on failures of communication and record-keeping. Educated at Yale College, the son of a Massachusetts preacher, Morse was an artist, not a scientist. In the 1820s and 1830s he spent much of his time traveling in England, France, Switzerland, and Italy to study painting. It was on one of these trips that he first heard about electric telegraphy or, in the terms of his memoirs, had his sudden insight: \u201clike a flash of the subtle fluid which afterwards became his servant,\u201d as his son put it. Morse told a friend who was rooming with him in Paris: \u201cThe mails\nin our country are too slow; this French telegraph is better, and would do even better in our clear atmosphere than here, where half the time fogs obscure the skies. But this will not be fast enough\u2014the lightning would serve us better.\u201d As he described his epiphany, it was an insight not about lightning but about signs: \u201cIt would not be difficult to construct a system of signs by which intelligence could be instantaneously transmitted.\u201d\n\nTELEGRAPHIC WRITING BY MORSE\u2019S FIRST INSTRUMENT\n\nMorse had a great insight from which all the rest flowed. Knowing nothing about pith balls, bubbles, or litmus paper, he saw that a sign could be made from something simpler, more fundamental, and less tangible\u2014the most minimal event, the closing and opening of a circuit. Never mind needles. The electric current flowed and was interrupted, and the interruptions could be organized to create meaning. The idea was simple, but Morse\u2019s first devices were convoluted, involving clockwork, wooden pendulums, pencils, ribbons of paper, rollers, and cranks. Vail, an experienced machinist, cut all this back. For the sending end, Vail devised what became an iconic piece of user interface: a simple spring-loaded lever, with which an operator could control the circuit by the touch of a finger. First he called this lever a \u201ccorrespondent\u201d; then just a \u201ckey.\u201d Its simplicity made it at least an order of magnitude faster than the buttons and cranks employed by Wheatstone and Cooke. With the telegraph key, an operator could send signals\u2014which were, after all, mere interruptions of the current\u2014at a rate of hundreds per minute.\n\nALFRED VAIL\u2019S TELEGRAPH \u201cKEY\u201d\n\nSo at one end they had a lever, for closing and opening the circuit, and at the other end the current controlled an electromagnet. One of them, probably Vail,\nthought of putting the two together. The magnet could operate the lever. This combination (invented more or less simultaneously by Joseph Henry at Princeton and Edward Davy in England) was named the \u201crelay,\u201d from the word for a fresh horse that replaced an exhausted one. It removed the greatest obstacle standing in the way of long-distance electrical telegraphy: the weakening of currents as they passed through lengths of wire. A weakened current could still operate a relay, enabling a new circuit, powered by a new battery. The relay had greater potential than its inventors realized. Besides letting a signal propagate itself, a relay might reverse the signal. And relays might combine signals from more than one source. But that was for later.\n\nThe turning point came in 1844, both in England and the United States. Cooke and Wheatstone had their first line up and running along the railway from the Paddington station. Morse and Vail had theirs from Washington to the Pratt Street railway station in Baltimore, on wires wrapped in yarn and tar, suspended from twenty-foot wooden posts. The communications traffic was light at first, but Morse was able to report proudly to Congress that an instrument could transmit thirty characters per minute and that the lines had \u201cremained undisturbed from the wantonness or evil disposition of any one.\u201d From the outset the communications content diverged sharply\u2014comically\u2014from the martial and official dispatches familiar to French telegraphists. In England the first messages recorded in the telegraph book at Paddington concerned lost luggage and retail transactions. \u201cSend a messenger to Mr Harris, Duke-street, Manchester-square, and request him to send 6 lbs of white bait and 4 lbs of sausages by the 5.30 train to Mr Finch of Windsor; they must be sent by 5.30 down train, or not at all.\u201d At the stroke of the new year, the superintendent at Paddington sent salutations to his counterpart in Slough and received a reply that the wish was a half-minute early; midnight had not yet arrived there. That morning, a druggist in Slough named John Tawell poisoned his mistress, Sarah Hart, and ran for the train to Paddington. A telegraph message outraced him with his description (\u201cin the garb of a kwaker, with a brown great coat on\u201d\u2014no Q\u2019s in the English system); he was captured in London and hanged in March. The drama filled the newspapers for months. It was later said of the telegraph wires, \u201cThem\u2019s the cords that hung John Tawell.\u201d In April, a Captain Kennedy, at the South-Western Railway terminus, played a game of chess with a Mr. Staunton, at Gosport; it was reported that \u201cin conveying the moves, the electricity travelled backward and forward during the game upwards of 10,000 miles.\u201d The newspapers loved that story, too\u2014and, more and more, they valued any story revealing the marvels of the electric telegraph.\n\nWhen the English and the American enterprises opened their doors to the\ngeneral public, it was far from clear who, besides the police and the occasional chess player, would line up to pay the tariff. In Washington, where pricing began in 1845 at one-quarter cent per letter, total revenues for the first three months amounted to less than two hundred dollars. The next year, when a Morse line opened between New York and Philadelphia, the traffic grew a little faster. \u201cWhen you consider that business is extremely dull [and] we have not yet the confidence of the public,\u201d a company official wrote, \u201cyou will see we are all well satisfied with results so far.\u201d He predicted that revenues would soon rise to fifty dollars a day. Newspaper reporters caught on. In the fall of 1846 Alexander Jones sent his first story by wire from New York City to the Washington Union: an account of the launch of the USS Albany at the Brooklyn Navy Yard. In England a writer for *The Morning Chronicle* described the thrill of receiving his first report across the Cooke-Wheatstone telegraph line,\n\n> the first instalment of the intelligence by a sudden stir of the stationary needle, and the shrill ring of the alarum. We looked delightedly into the taciturn face of our friend, the mystic dial, and pencilled down with rapidity in our note-book, what were his utterances some ninety miles off.\n\nThis was contagious. Some worried that the telegraph would be the death of newspapers, heretofore \u201cthe rapid and indispensable carrier of commercial, political and other intelligence,\u201d as an American journalist put it.\n\n> For this purpose the newspapers will become emphatically useless. Anticipated at every point by the lightning wings of the Telegraph, they can only deal in local \u201citems\u201d or abstract speculations. Their power to create sensations, even in election campaigns, will be greatly lessened\u2014as the infallible Telegraph will contradict their falsehoods as fast as they can publish them.\n\nUndaunted, newspapers could not wait to put the technology to work. Editors found that any dispatch seemed more urgent and thrilling with the label \u201cCommunicated by Electric Telegraph.\u201d Despite the expense\u2014at first, typically, fifty cents for ten words\u2014the newspapers became the telegraph services\u2019 most enthusiastic patrons. Within a few years, 120 provincial newspapers were getting reports from Parliament nightly. News bulletins from the Crimean War radiated from London to Liverpool, York, Manchester, Leeds, Bristol, Birmingham, and Hull. \u201cSwifter than a rocket could fly the distance, like a rocket it bursts and is again carried by the diverging wires into a dozen neighbouring towns,\u201d one journalist noted. He saw dangers, though: \u201cIntelligence, thus hastily gathered and transmitted, has also its drawbacks, and is not so trustworthy as the news which starts later and travels slower.\u201d The relationship between the telegraph and the newspaper was symbiotic. Positive feedback loops amplified the effect. Because the telegraph was an information technology, it served as an agent of its own ascendency.\n\nThe global expansion of the telegraph continued to surprise even its backers.\nWhen the first telegraph office opened in New York City on Wall Street, its biggest problem was the Hudson River. The Morse system ran a line sixty miles up the eastern side until it reached a point narrow enough to stretch a wire across. Within a few years, though, an insulated cable was laid under the harbor. Across the English Channel, a submarine cable twenty-five miles long made the connection between Dover and Calais in 1851. Soon after, a knowledgeable authority warned: \u201cAll idea of connecting Europe with America, by lines extending directly across the Atlantic, is utterly impracticable and absurd.\u201d That was in 1852; the impossible was accomplished by 1858, at which point Queen Victoria and President Buchanan exchanged pleasantries and *The New York Times* announced \u201ca result so practical, yet so inconceivable \u2026 so full of hopeful prognostics for the future of mankind \u2026 one of the grand way-marks in the onward and upward march of the human intellect.\u201d What was the essence of the achievement? \u201cThe transmission of thought, the vital impulse of matter.\u201d The excitement was global but the effects were local. Fire brigades and police stations linked their communications. Proud shopkeepers advertised their ability to take telegraph orders.\n\nInformation that just two years earlier had taken days to arrive at its destination could now be there\u2014anywhere\u2014in seconds. This was not a doubling or tripling of transmission speed; it was a leap of many orders of magnitude. It was like the bursting of a dam whose presence had not even been known. The social consequences could not have been predicted, but some were observed and appreciated almost immediately. People\u2019s sense of the weather began to change\u2014weather, that is, as a generalization, an abstraction. Simple weather reports began crossing the wires on behalf of corn speculators: *Derby, very dull; York, fine; Leeds, fine; Nottingham, no rain but dull and cold.* The very idea of a \u201cweather report\u201d was new. It required some approximation of instant knowledge of a distant place. The telegraph enabled people to think of weather as a widespread and interconnected affair, rather than an assortment of local surprises. \u201cThe phenomena of the atmosphere, the mysteries of meteors, the cause and effect of skiey combinations, are no longer matters of superstition or of panic to the husbandman, the sailor or the shepherd,\u201d noted an enthusiastic commentator in 1848:\n\n> The telegraph comes in to tell him, for his every-day uses and observances, not only that \u201cfair weather cometh out of the north,\u201d but the electric wire can tell him in a moment the character of the weather simultaneously in all quarters of our island\u2026. In this manner, the telegraph may be made a vast national barometer, electricity becoming the handmaid of the mercury.\n\nThis was a transformative idea. In 1854 the government established a Meteorological Office in the Board of Trade. The department\u2019s chief, Admiral Robert FitzRoy, formerly a captain of HMS *Beagle*, moved into an office on King\nStreet, furnished it with barometers, aneroids, and stormglasses, and dispatched observers equipped with the same instruments to ports all around the coastline. They telegraphed their cloud and wind reports twice daily. FitzRoy began issuing weather predictions, which he dubbed \u201cforecasts,\u201d and in 1860 *The Times* began publishing these daily. Meteorologists began to understand that all great winds, when seen in the large, were circular, or at least \u201chighly curved.\u201d\n\nThe most fundamental concepts were now in play as a consequence of instantaneous communication between widely separated points. Cultural observers began to say that the telegraph was \u201cannihilating\u201d time and space. It \u201cenables us to send communications, by means of the mysterious fluid, with the quickness of thought, and to annihilate time as well as space,\u201d announced an American telegraph official in 1860. This was an exaggeration that soon became a clich\u00e9. The telegraph did seem to vitiate or curtail time in one specific sense: time as an obstacle or encumbrance to human intercourse. \u201cFor all practical purposes,\u201d one newspaper announced, \u201ctime, in the transit, may be regarded as entirely eliminated.\u201d It was the same with space. \u201cDistance and time have been so changed in our imaginations,\u201d said Josiah Latimer Clark, an English telegraph engineer, \u201cthat the globe has been practically reduced in magnitude, and there can be no doubt that our conception of its dimensions is entirely different to that held by our forefathers.\u201d\n\nFormerly all time was local: when the sun was highest, that was noon. Only a visionary (or an astronomer) would know that people in a different place lived by a different clock. Now time could be either local or standard, and the distinction baffled most people. The railroads required standard time, and the telegraph made it feasible. For standard time to prevail took decades; the process could only begin in the 1840s, when the Astronomer Royal arranged wires from the Observatory in Greenwich to the Electric Telegraph Company in Lothbury, intending to synchronize the clocks of the nation. Previously, the state of the art in time-signaling technology was a ball dropped from a mast atop the observatory dome. When faraway places were coordinated in time, they could finally measure their longitude precisely. The key to measuring longitude was knowing the time someplace else and the distance to that place. Ships therefore carried clocks, preserving time in imperfect mechanical capsules. Lieutenant Charles Wilkes of the U.S. Exploring Expedition used the first Morse line in 1844 to locate the Battle Monument in Baltimore at 1 minute, 34.868 seconds east of the Capitol in Washington.\n\nFar from annihilating time, synchrony extended its dominion. The very idea of synchrony, and the awareness that the idea was new, made heads spin. *The New York Herald* declared:\n\nProfessor Morse\u2019s telegraph is not only an era in the transmission of intelligence, but\nThe Information\n\nit has originated in the mind an entirely new class of ideas, a new species of consciousness. Never before was any one conscious that he knew with certainty what events were at that moment passing in a distant city\u201440, 100, or 500 miles off.\n\nImagine, continued this exhilarated writer, that it is now 11 o\u2019clock. The telegraph relays what a legislator is now saying in Washington.\n\nIt requires no small intellectual effort to realize that this is a fact that now is, and not one that has been.\n\nThis is a fact that now is.\n\nHistory (and history making) changed, too. The telegraph caused the preservation of quantities of minutiae concerning everyday life. For a while, until it became impractical, the telegraph companies tried to maintain a record of every message. This was information storage without precedent. \u201cFancy some future Macaulay rummaging among such a store, and painting therefrom the salient features of the social and commercial life of England in the nineteenth century,\u201d mused one essayist. \u201cWhat might not be gathered some day in the twenty-first century from a record of the correspondence of an entire people?\u201d In 1845, after a year\u2019s experience with the line between Washington and Baltimore, Alfred Vail attempted a catalogue of all the telegraph had conveyed thus far. \u201cMuch important information,\u201d he wrote,\n\nconsisting of messages to and from merchants, members of Congress, officers of the government, banks, brokers, police officers; parties, who by agreement had met each other at the two stations, or had been sent for by one of the parties; items of news, election returns, announcement of deaths, inquiries respecting the health of families and individuals, the daily proceedings of the Senate and House of Representatives, orders for goods, inquiries respecting the sailing of vessels, proceedings of cases in the various courts, summoning of witnesses, messages in relation to special and express trains, invitations, the receipt of money at one station and its payment at the other, for persons requesting the transmission of funds from debtors, consultations of physicians \u2026\n\nThese diverse items had never before been aggregated under one heading. The telegraph gave them their commonality. In patent applications and legal agreements, too, the inventors had reason to think about their topic in the broadest possible terms: e.g., the giving, printing, stamping, or otherwise transmitting of signals, or the sounding of alarms, or the communication of intelligence.\n\nIn this time of conceptual change, mental readjustments were needed to understand the telegraph itself. Confusion inspired anecdotes, which often turned on awkward new meanings of familiar terms: innocent words like send, and heavily laden ones, like message. There was the woman who brought a dish of sauerkraut into the telegraph office in Karlsruhe to be \u201csent\u201d to her son in Rastatt. She had heard of soldiers being \u201csent\u201d to the front by telegraph. There was the man who brought a \u201cmessage\u201d into the telegraph office in Bangor, Maine. The\noperator manipulated the telegraph key and then placed the paper on the hook. The customer complained that the message had not been sent, because he could still see it hanging on the hook. To *Harper\u2019s New Monthly Magazine*, which recounted this story in 1873, the point was that even the \u201cintelligent and well-informed\u201d continued to find these matters inscrutable:\n\nThe difficulty of forming a clear conception of the subject is increased by the fact that while we have to deal with novel and strange facts, we have also to use old words in novel and inconsistent senses.\n\nA message had seemed to be a physical object. That was always an illusion; now people needed consciously to divorce their conception of the message from the paper on which it was written. Scientists, *Harper\u2019s* explained, will say that the electric current \u201ccarries a message,\u201d but one must not imagine that anything\u2014any *thing*\u2014is transported. There is only \u201cthe action and reaction of an imponderable force, and the making of intelligible signals by its means at a distance.\u201d No wonder people were misled. \u201cSuch language the world must, perhaps for a long time to come, continue to employ.\u201d\n\nThe physical landscape changed, too. Wires everywhere made for strange ornamentation, on city streets and country roads. \u201cTelegraphic companies are running a race to take possession of the air over our heads,\u201d wrote an English journalist, Andrew Wynter. \u201cLook where we will aloft, we cannot avoid seeing either thick cables suspended by gossamer threads, or parallel lines of wire in immense numbers sweeping from post to post, fixed on the house-tops and suspended over long distances.\u201d They did not for some time fade into the background. People looked at the wires and thought of their great invisible cargo. \u201cThey string an instrument against the sky,\u201d said Robert Frost, \u201cWherein words whether beaten out or spoken / Will run as hushed as when they were a thought.\u201d\n\nThe wires resembled nothing in architecture and not much in nature. Writers seeking similes thought of spiders and their webs. They thought of labyrinths and mazes. And one more word seemed appropriate: the earth was being covered, people said, with an iron *net-work*. \u201cA net-work of nerves of iron wire, strung with lightning, will ramify from the brain, New York, to the distant limbs and members,\u201d said the *New York Tribune*. \u201cThe whole net-work of wires,\u201d wrote *Harper\u2019s*, \u201call quivering from end to end with signals of human intelligence.\u201d\n\nWynter offered a prediction. \u201cThe time is not distant,\u201d he wrote, \u201cwhen everybody will be able to talk with everybody without going out of the house.\u201d He meant \u201ctalk\u201d metaphorically.\n\nIn more ways than one, using the telegraph meant writing in code.\n\nThe Morse system of dots and dashes was not called a code at first. It was just\ncalled an alphabet: \u201cthe Morse Telegraphic Alphabet,\u201d typically. But it was not an alphabet. It did not represent sounds by signs. The Morse scheme took the alphabet as a starting point and leveraged it, by substitution, replacing signs with new signs. It was a meta-alphabet, an alphabet once removed. This process\u2014the transferring of meaning from one symbolic level to another\u2014already had a place in mathematics. In a way it was the very essence of mathematics. Now it became a familiar part of the human toolkit. Entirely because of the telegraph, by the late nineteenth century people grew comfortable, or at least familiar, with the idea of codes: signs used for other signs, words used for other words. Movement from one symbolic level to another could be called encoding.\n\nTwo motivations went hand in glove: secrecy and brevity. Short messages saved money\u2014that was simple. So powerful was that impulse that English prose style soon seemed to be feeling the effects. Telegraphic and telegraphese described the new way of writing. Flowers of rhetoric cost too much, and some regretted it. \u201cThe telegraphic style banishes all the forms of politeness,\u201d wrote Andrew Wynter:\n\n\u201cMay I ask you to do me the favour\u201d is 6d. for a distance of 50 miles. How many of those fond adjectives therefore must our poor fellow relentlessly strike out to bring his billet down to a reasonable charge?\n\nAlmost immediately, newspaper reporters began to contrive methods for transmitting more information with fewer billable words. \u201cWe early invented a short-hand system, or cipher,\u201d boasted one, \u201cso arranged, that the receipts of produce and the sales and prices of all leading articles of breadstuffs, provisions, &c., could be sent from Buffalo and Albany daily, in twenty words, for both cities, which, when written out, would make one hundred or more words.\u201d The telegraph companies tried to push back, on the grounds that private codes were gaming the system, but ciphers flourished. One typical system assigned dictionary words to whole phrases, organizing them semantically and alphabetically. For example, all words starting with B referred to the flour market: baal = \u201cThe transactions are smaller than yesterday\u201d; babble = \u201cThere is a good business doing\u201d; baby = \u201cWestern is firm, with moderate demand for home trade and export\u201d; button = \u201cmarket quiet and prices easier.\u201d It was necessary, of course, for sender and recipient to work from identical word lists. To the telegraph operators themselves, the encoded messages looked like nonsense, and that, in itself, proved an extra virtue.\n\nAs soon as people conceived of sending messages by telegraph, they worried that their communication was exposed to the world\u2014at the very least, to the telegraph operators, unreliable strangers who could not help but read the words they fed through their devices. Compared to handwritten letters, folded and sealed with wax, the whole affair seemed public and insecure\u2014the messages passing\nalong those mysterious conduits, the electric wires. Vail himself wrote in 1847, \u201cThe great advantage which this telegraph possesses in transmitting messages with the rapidity of lightning, annihilating time and space, would perhaps be much lessened in its usefulness, could it not avail itself of the application of a secret alphabet.\u201d There were, he said, \u201csystems\u201d\u2014by which a message may pass between two correspondents, through the medium of the telegraph, and yet the contents of that message remain a profound secret to all others, not excepting the operators of the telegraphic stations, through whose hands it must pass.\n\nThis was all very difficult. The telegraph served not just as a device but as a medium\u2014a middle, intermediary state. The message passes through this medium. Distinct from the message, one must also consider the contents of that message. Even when the message must be exposed, the contents could be concealed. Vail explained what he meant by *secret alphabet*: an alphabet whose characters have been \u201ctransposed and interchanged.\u201d\n\nThen the representative of *a*, in the *permanent* alphabet, may be represented by *y*, or *c*, or *x*, in the *secret* alphabet; and so of every other letter.\n\nThus, \u201cThe firm of G. Barlow & Co. have failed\u201d becomes \u201cEjn stwz ys & qhwkyf p iy jhan shtknr.\u201d For less sensitive occasions, Vail proposed using abbreviated versions of common phrases. Instead of \u201cgive my love to,\u201d he suggested sending \u201cgmlt.\u201d He offered a few more suggestions:\n\n- **mhii** My health is improving\n- **shf** Stocks have fallen\n- **ymir** Your message is received\n- **wmietg** When may I expect the goods?\n- **wyegfef** Will you exchange gold for eastern funds?\n\nAll these systems required prearrangement between sender and recipient: the message was to be supplemented, or altered, by preexisting knowledge shared at both ends. A convenient repository for this knowledge was a code book, and when the first Morse line opened for business, one of its key investors and promoters, the Maine congressman Francis O. J. Smith, known as Fog, produced one: *The Secret Corresponding Vocabulary; adapted for use to Morse\u2019s Electro-Magnetic Telegraph: and also in conducting written correspondence, transmitted by the mails, or otherwise*. It was nothing but a numbered, alphabetical list of 56,000 English words, *Aaronic* to *zygodactylous*, plus instructions. \u201cWe will suppose the person writing, and the person written to, are each in possession of a copy of this work,\u201d Smith explained. \u201cInstead of sending their communications in\nwords, they send numbers only, or partly in numbers, and partly in words.\u201d For greater security, they might agree in advance to add or subtract a private number of their own choosing, or different numbers for alternate words. \u201cA few such conventional substitutes,\u201d he promised, \u201cwill render the whole language a perfectly dead letter to all persons not consonant to the concerted arrangement.\u201d\n\nCryptographers had a mysterious history, their secrets handed along in clandestine manuscripts, like the alchemists\u2019. Now code making emerged into the light, exposed in the hardware of commerce, inspiring the popular imagination. In the succeeding decades, many other schemes were contrived and published. They ranged from penny pamphlets to volumes of hundreds of pages of densely packed type. From London came E. Erskine Scott\u2019s *Three Letter Code for Condensed Telegraphic and Inscrutably Secret Messages and Correspondence*. Scott was an actuary and accountant and, like so many in the code business, a man evidently driven by an obsession with data. The telegraph opened up a world of possibilities for such people\u2014cataloguers and taxonomists, wordsmiths and numerologists, completists of all kinds. Scott\u2019s chapters included not only a vocabulary of common words and two-word combinations, but also geographic names, Christian names, names of all shares quoted on the London Stock Exchange, all the days in the year, all regiments belonging to the British army, registries of shipping, and the names of all the peers of the realm. Organizing and numbering all this data made possible a form of compression, too. Shortening messages meant saving money. Customers found that the mere substitution of numbers for words helped little if at all: it cost just as much to send \u201c3747\u201d as \u201cazotite.\u201d So code books became phrase books. Their object was a sort of packing of messages into capsules, impenetrable to prying eyes and suitable for efficient transmission. And of course, at the recipient\u2019s end, for unpacking.\n\nAn especially successful volume in the 1870s and \u201980s was *The A B C Universal Commercial Electric Telegraphic Code*, devised by William Clauson-Thue. He advertised his code to \u201cfinanciers, merchants, shipowners, brokers, agents, &c.\u201d His motto: \u201cSimplicity and Economy Palpable, Secrecy Absolute.\u201d Clauson-Thue, another information obsessive, tried to arrange the entire language\u2014or at least the language of commerce\u2014into phrases, and to organize the phrases by keyword. The result is a peculiar lexicographic achievement, a window into a nation\u2019s economic life, and a trove of odd nuance and unwitting lyricism. For the keyword *panic* (assigned numbers 10054\u201310065), the inventory includes:\n\n- A great panic prevails in \u2014\u2014\u2014\n- The panic is settling down\n- The panic still continues\n- The worst of the panic is over\nThe panic may be considered over\n\nFor *rain* (11310\u201311330):\n\n- Cannot work on account of rain\n- The rain has done much good\n- The rain has done a great amount of damage\n- The rain is now pouring down in good earnest\n- Every prospect of the rain continuing\n- Rain much needed\n- Rain at times\n- Rainfall general\n\nFor *wreck* (15388\u201315403):\n\n- Parted from her anchors and became a wreck\n- I think it best to sell the wreck as it lies\n- Every attention will be made to save wreck\n- Must become a total wreck\n- Customs authorities have sold the wreck\n- Consul has engaged men to salve wreck\n\nThe world being full of things as well as words, he endeavored, too, to assign numbers to as many proper names as he could list: names of railways, banks, mines, commodities, vessels, ports, and stocks (British, colonial, and foreign).\n\nAs the telegraph networks spread under the oceans and across the globe, and international tariffs ran to many dollars per word, the code books thrived. Economy mattered even more than secrecy. The original trans-Atlantic rate was about one hundred dollars for a message\u2014a \u201ccable,\u201d as it was metonymically called\u2014of ten words. For not much less, messages could travel between England and India, by way of Turkey or Persia and Russia. To save on the tariff, clever middlemen devised a practice called \u201cpacking.\u201d A packer would collect, say, four messages of five words each and bundle them into a fixed-price telegram of twenty words. The code books got bigger and they got smaller. In 1885 W. H. Beer & Company in Covent Garden published a popular *Pocket Telegraphic Code*, price one penny, containing \u201cmore than 300 one-word telegrams,\u201d neatly organized by subject matter. Essential subjects were Betting (\u201cTo what amount shall I back for you at present odds?\u201d), Bootmaker (\u201cThese boots don\u2019t fit, send for them directly\u201d), Washerwoman (\u201cCall for the washing to-day\u201d), and Weather\u2014In Connexion with Voyages (\u201cIt is far too rough for you to cross to-day\u201d). And a blank page was provided for \u201cSecret Code. (Fill up by arrangement with friends.)\u201d There were specialized codes for railways and yachts and trades from pharmacist to carpetmaker. The grandest and most expensive code books\nborrowed freely from one another. \u201cIt has been brought to the Author\u2019s knowledge that some persons have purchased a single copy of the \u2018A B C Telegraphic Code\u2019 for service in compiling Codes of their own,\u201d complained Clauson-Thue. \u201cThe Author would intimate that such an operation is a breach of the Copyright Act, and liable to become a matter of legal and unpleasant procedure.\u201d This was just bluster. By the turn of the century, the world\u2019s telegraphers, through the medium of International Telegraphic Conferences held in Berne and in London, had systematized codes with words in English, Dutch, French, German, Italian, Latin, Portuguese, and Spanish. The code books prospered and expanded through the first decades of the twentieth century and then vanished into obscurity.\n\nThose who used the telegraph codes slowly discovered an unanticipated side effect of their efficiency and brevity. They were perilously vulnerable to the smallest errors. Because they lacked the natural redundancy of English prose\u2014even the foreshortened prose of telegraphese\u2014these cleverly encoded messages could be disrupted by a mistake in a single character. By a single dot, for that matter. For example, on June 16, 1887, a Philadelphia wool dealer named Frank Primrose telegraphed his agent in Kansas to say that he had bought\u2014abbreviated in their agreed code as \\textit{bay}\u2014500,000 pounds of wool. When the message arrived, the key word had become \\textit{buy}. The agent began buying wool, and before long the error cost Primrose $20,000, according to the lawsuit he filed against the Western Union Telegraph Company. The legal battle dragged on for six years, until finally the Supreme Court upheld the fine print on the back of the telegraph blank, which spelled out a procedure for protecting against errors:\n\nTo guard against mistakes or delays, the sender of a message should order it REPEATED; that is telegraphed back to the originating office for comparison\u2026. Said company shall not be liable for mistakes in \u2026 any UNREPEATED message \u2026 nor in any case for errors in cipher or obscure messages.\n\nThe telegraph company had to tolerate ciphers but did not have to like them. The court found in favor of Primrose in the amount of $1.15, the price of sending the telegram.\n\nSecret writing was as old as writing. When writing began, it was in itself secret to all but the few. As the mystery dissolved, people found new ways to keep their words privileged and recondite. They rearranged words into anagrams. They reversed their script in the mirror. They invented ciphers.\n\nIn 1641, just as the English Civil War began, an anonymous little book catalogued the many known methods of what it called \u201ccryptography.\u201d These included special paper and ink: the juice of lemons or onions, raw egg, or \u201cthe\ndistilled Juice of Gloworms,\u201d which might or might not be visible in the dark. Alternatively, writing could be obscured by substituting letters for other letters, or inventing new symbols, or writing from right to left, or \u201ctransposing each Letter, according to some unusual Order, as, suppose the first Letter should be at the latter End of the Line, the second at the Beginning, or the like.\u201d Or a message could be written across two lines:\n\n```\nTeoliraelmsfmespluoweutel\nhsudesralotaihd,upysremsyid\n```\n\n*The Souldiers are almost famished, supply us or wee must yeild.*\n\nThrough transposition and substitution of letters, the Romans and the Jews had devised other methods, more intricate and thus more obscure.\n\nThis little book was titled *Mercury: or the Secret and Swift Messenger. Shewing, How a Man may with Privacy and Speed communicate his Thoughts to a Friend at any Distance*. The author eventually revealed himself as John Wilkins, a vicar and mathematician, later to become master of Trinity College, Cambridge, and a founder of the Royal Society. \u201cHe was a very ingenious man and had a very mechanical head,\u201d one contemporary said. \u201cOne of much and deep thinking,... lusty, strong grown, well set, broad shouldered.\u201d He was also thorough. If he could not mention every cipher tried since ancient times, he nonetheless included all that could have been known to a scholar in seventeenth-century England. He surveyed secret writing both as a primer and a compendium.\n\nFor Wilkins the issues of cryptography stood near the fundamental problem of communication. He considered writing and secret writing as essentially the same. Leaving secrecy aside, he expressed the problem this way: \u201cHow a Man may with the greatest Swiftness and Speed, discover his Intentions to one that is far distant from him.\u201d By *swiftness* and *speed* he meant, in 1641, something philosophical; the birth of Isaac Newton was a year away. \u201cThere is nothing (we say) so swift as Thought,\u201d he noted. Next to thought, the swiftest action seemed to be that of sight. As a clergyman, he observed that the swiftest motion of all must belong to angels and spirits. If only a man could send an angel on an errand, he could dispatch business at any distance. The rest of us, stuck with Organical Bodies, \u201ccannot communicate their Thoughts so easie and immediate a way.\u201d No wonder, Wilkins wrote, that angels are called messengers.\n\nAs a mathematician, he considered the problem from another side. He set out to determine how a restricted set of symbols\u2014perhaps just two, three, or five\u2014might be made to stand for a whole alphabet. They would have to be used in combination. For example, a set of five symbols\u2014a, b, c, d, e\u2014used in pairs could replace an alphabet of twenty-five letters:\nAccording to which,\u201d wrote Wilkins, \u201cthese words, I am betrayed, may be thus described: Bd aacb abaeddbaaecaead.\u201d So even a small symbol set could be arranged to express any message at all. However, with a small symbol set, a given message requires a longer string of characters\u2014\u201cmore Labour and Time,\u201d he wrote. Wilkins did not explain that $25 = 5^2$, nor that three symbols taken in threes (aaa, aab, aac,...) produce twenty-seven possibilities because $3^3 = 27$. But he clearly understood the underlying mathematics. His last example was a binary code, awkward though this was to express in words:\n\nTwo Letters of the Alphabet being transposed through five Places, will yield thirty two Differences, and so will more than serve for the Four and twenty Letters; unto which they may be thus applied.\n\n| A   | B   | C   | D   | E   | F   | G   |\n|-----|-----|-----|-----|-----|-----|-----|\n| aaaaa| aaaab| aaaba| aaabb| aabaa| aabab| aabba|\n| H   | I   | K   | L   | M   | N   | O   |\n| aabbb| abaaa| abaab| ababa| ababb| abbaa| abbab|\n| P   | Q   | R   | S   | T   | V   | W   |\n| abbba| abbbb| baaaa| baaab| baaba| baabb| babaa|\n| X   | Y   | Z   |     |     |     |     |\n| babab| babha| babbb|     |     |     |     |\n\nTwo symbols. In groups of five. \u201cYield thirty two Differences.\u201d\n\nThat word, differences, must have struck Wilkins\u2019s readers (few though they were) as an odd choice. But it was deliberate and pregnant with meaning. Wilkins was reaching for a conception of information in its purest, most general form. Writing was only a special case: \u201cFor in the general we must note, That whatever is capable of a competent Difference, perceptible to any Sense, may be a sufficient Means whereby to express the Cogitations.\u201d A difference could be \u201ctwo Bells of different Notes\u201d; or \u201cany Object of Sight, whether Flame, Smoak, &c.\u201d; or trumpets, cannons, or drums. Any difference meant a binary choice. Any binary choice began the expressing of cogitations. Here, in this arcane and anonymous treatise of 1641, the essential idea of information theory poked to the surface of human thought, saw its shadow, and disappeared again for four hundred years.\n\nThe contribution of the dilettantes is what the historian of cryptography David Kahn calls the excited era triggered by the advent of the telegraph. A new public interest in ciphers arose just as the subject bloomed in certain intellectual circles.\nAncient methods of secret writing appealed to an odd assortment of people, puzzle makers and game players, mathematically or poetically inclined. They analyzed ancient methods of secret writing and invented new ones. Theorists debated who should prevail, the best code maker or the best code breaker. The great American popularizer of cryptography was Edgar Allan Poe. In his fantastic tales and magazine essays he publicized the ancient art and boasted of his own skill as a practitioner. \u201cWe can scarcely imagine a time when there did not exist a necessity, or at least a desire,\u201d he wrote in Graham\u2019s Magazine in 1841, \u201cof transmitting information from one individual to another, in such manner as to elude general comprehension.\u201d For Poe, code making was more than just a historical or technical enthusiasm; it was an obsession. It reflected his sense of how we communicate our selves to the world. Code makers and writers are trafficking in the same goods. \u201cThe soul is a cypher, in the sense of a cryptograph; and the shorter a cryptograph is, the more difficulty there is in comprehension,\u201d he wrote. Secrecy was in Poe\u2019s nature; he preferred mystery to transparency.\n\n\u201cSecret intercommunication must have existed almost contemporaneously with the invention of letters,\u201d he declared. This was for Poe a bridge between science and the occult, between the rational mind and the savant. To analyze cryptography\u2014\u201ca serious thing, as the means of imparting information\u201d\u2014required a special form of mental power, a penetrating mind, and might well be taught in academies. He said again and again that \u201ca peculiar mental action is called into play.\u201d He published as challenges to his readers a series of substitution ciphers.\n\nAlong with Poe, Jules Verne and Honor\u00e9 de Balzac also introduced ciphers into their fiction. In 1868, Lewis Carroll had a card printed on two sides with what he called \u201cThe Telegraph-Cipher,\u201d which employed a \u201ckey-alphabet\u201d and a \u201cmessage-alphabet,\u201d to be transposed according to a secret word agreed on by the correspondents and carried in their memories. But the most advanced cryptanalyst in Victorian England was Charles Babbage. The process of substituting symbols, crossing levels of meaning, lay near the heart of so many issues. And he enjoyed the challenge. \u201cOne of the most singular characteristics of the art of deciphering,\u201d he asserted, \u201cis the strong conviction possessed by every person, even moderately acquainted with it, that he is able to construct a cipher which nobody else can decipher. I have also observed that the cleverer the person, the more intimate is his conviction.\u201d He believed that himself, at first, but later switched to the side of the code breakers. He planned an authoritative work to be known as The Philosophy of Decyphering but never managed to complete it. He did solve, among others, a polyalphabetic cipher known as the Vigen\u00e8re, le chiffre ind\u00e9chiffrable, thought to be the most secure in Europe. As in his other work, he applied algebraic methods, expressing cryptanalysis in the form of equations.\nEven so, he remained a dilettante and knew it.\n\nWhen Babbage attacked cryptography with a calculus, he was employing the same tools he had explored more conventionally in their home, mathematics, and less conventionally in the realm of machinery, where he created a symbolism for the moving parts of gears and levers and switches. Dionysius Lardner had said of the mechanical notation, \u201cThe various parts of the machinery being once expressed on paper by proper symbols, the enquirer dismisses altogether from his thoughts the mechanism itself and attends only to the symbols \u2026 an almost metaphysical system of abstract signs, by which the motion of the hand performs the office of the mind.\u201d Two younger Englishmen, Augustus De Morgan and George Boole, turned the same methodology to work on an even more abstract material: the propositions of logic. De Morgan was Babbage\u2019s friend and Ada Byron\u2019s tutor and a professor at University College, London. Boole was the son of a Lincolnshire cobbler and a lady\u2019s maid and became, by the 1840s, a professor at Queen\u2019s College, Cork. In 1847 they published separately and simultaneously books that amounted to the greatest milestone in the development of logic since Aristotle: Boole\u2019s *Mathematical Analysis of Logic, Being an Essay Towards a Calculus of Deductive Reasoning*, and De Morgan\u2019s *Formal Logic: or, the Calculus of Inference, Necessary and Probable*. The subject, esoteric as it was, had stagnated for centuries.\n\nDe Morgan knew more about the scholastic traditions of the subject, but Boole was the more original and free-thinking mathematician. By post, for years, they exchanged ideas about converting language, or truth, into algebraic symbols. $X$ could mean \u201ccow\u201d and $Y$ \u201chorse.\u201d That might be one cow, or a member of the set of all cows. (The same?) In the algebraic fashion the symbols were to be manipulated. $XY$ could be \u201cname of everything which is both $X$ and $Y$\u201d while $X,Y$ stood in for \u201cname of everything which is either $X$ or $Y$.\u201d Simple enough\u2014but language is not simple and complications reared up. \u201cNow some $Z$s are not $X$s, the $ZY$s,\u201d wrote De Morgan at one point. \u201cBut they are nonexistent. You may say that nonexistents are not $X$s. A nonexistent horse is not even a horse; and (*a fortiori*?) not a cow.\u201d\n\nHe added wistfully, \u201cI do not despair of seeing you give meaning to this new kind of negative quantity.\u201d He did not post this and he did not throw it away.\n\nBoole thought of his system as a mathematics without numbers. \u201cIt is simply a fact,\u201d he wrote, \u201cthat the ultimate laws of logic\u2014those alone on which it is possible to construct a science of logic\u2014are mathematical in their form and expression, although not belonging to the mathematics of quantity.\u201d The only numbers allowed, he proposed, were zero and one. It was all or nothing: \u201cThe respective interpretation of the symbols 0 and 1 in the system of logic are Nothing and Universe.\u201d Until now logic had belonged to philosophy. Boole was claiming\npossession on behalf of mathematics. In doing so, he devised a new form of encoding. Its code book paired two types of symbolism, each abstracted far from the world of things. On one side was a set of characters drawn from the formalism of mathematics: \\( p \\)'s and \\( q \\)'s, \\( + \\)'s and \\( - \\)'s, braces and brackets. On the other were operations, propositions, relations ordinarily expressed in the fuzzy and mutable speech of everyday life: words about truth and falsity, membership in classes, premises and conclusions. There were \u201cparticles\u201d: if, either, or. These were the elements of Boole\u2019s credo:\n\nThat Language is an instrument of human reason, and not merely a medium for the expression of thought.\n\nThe elements of which all language consists are signs or symbols.\n\nWords are signs. Sometimes they are said to represent things; sometimes the operations by which the mind combines together the simple notions of things into complex conceptions.\n\nWords \u2026 are not the only signs which we are capable of employing. Arbitrary marks, which speak only to the eye, and arbitrary sounds or actions \u2026 are equally of the nature of signs.\n\nThe encoding, the conversion from one modality to the other, served a purpose. In the case of Morse code, the purpose was to turn everyday language into a form suitable for near-instantaneous transmission across miles of copper wire. In the case of symbolic logic, the new form was suitable for manipulation by a calculus. The symbols were like little capsules, protecting their delicate cargo from the wind and fog of everyday communication. How much safer to write:\n\n\\[\n1 - x = y(1 - z) + z(1 - y) + (1 - y)(1 - z)\n\\]\n\nthan the real-language proposition for which, in a typical Boolean example, it stood:\n\nUnclean beasts are all which divide the hoof without chewing the cud, all which chew the cud without dividing the hoof, and all which neither divide the hoof nor chew the cud.\n\nThe safety came in no small part from draining the words of meaning. Signs and symbols were not just placeholders; they were operators, like the gears and levers in a machine. Language, after all, is an instrument.\n\nIt was seen distinctly now as an instrument with two separate functions: expression and thought. Thinking came first, or so people assumed. To Boole, logic was thought\u2014polished and purified. He chose The Laws of Thought as the title for his 1854 masterwork. Not coincidentally, the telegraphists also felt they were generating insight into messaging within the brain. \u201cA word is a tool for thinking, before the thinker uses it as a signal for communicating his thought,\u201d asserted an essayist in Harper\u2019s New Monthly Magazine in 1873.\n\nPerhaps the most extended and important influence which the telegraph is destined to\nexert upon the human mind is that which it will ultimately work out through its influence on language\u2026. By the principle which Darwin describes as natural selection short words are gaining the advantage over long words, direct forms of expression are gaining the advantage over indirect, words of precise meaning the advantage of the ambiguous, and local idioms are everywhere at a disadvantage.\n\nBoole\u2019s influence was subtle and slow. He corresponded only briefly with Babbage; they never met. One of his champions was Lewis Carroll, who, at the very end of his life, a quarter century after Alice in Wonderland, wrote two volumes of instruction, puzzles, diagrams, and exercises in symbolic logic. Although his symbolism was impeccable, his syllogisms ran toward whimsy:\n\n1. Babies are illogical;\n2. Nobody is despised who can manage a crocodile;\n3. Illogical persons are despised.\n\n(Concl.) Babies cannot manage crocodiles.\n\nThe symbolic version\u2014\\( b_d \\uparrow a_c \\uparrow d_c \\uparrow b_d \\uparrow d_c \\uparrow a_c \\uparrow b_d \\uparrow b_1 \\), i.e. \\( b_d \\uparrow b_1 \\)\u2014having been suitably drained of meaning, allowed the user to reach the desired conclusion without tripping over awkward intermediate propositions along the lines of \u201cbabies are despised.\u201d\n\nAs the century turned, Bertrand Russell paid George Boole an extraordinary compliment: \u201cPure mathematics was discovered by Boole, in a work which he called the Laws of Thought.\u201d It has been quoted often. What makes the compliment extraordinary is the seldom quoted disparagement that follows on its heels:\n\nHe was also mistaken in supposing that he was dealing with the laws of thought: the question how people actually think was quite irrelevant to him, and if his book had really contained the laws of thought, it was curious that no one should ever have thought in such a way before.\n\nOne might almost think Russell enjoyed paradoxes.\n\n* But Count Miot de Melito claimed in his memoirs that Chappe submitted his idea to the War Office with the name tachygraphe (\u201cswift writer\u201d) and that he, Miot, proposed t\u00e9l\u00e9graphe instead\u2014which \u201chas become, so to speak, a household word.\u201d\nThe Information\n\n6 | NEW WIRES, NEW LOGIC\n\n(No Other Thing Is More Enswathed in the Unknown)\n\nThe perfect symmetry of the whole apparatus\u2014the wire in the middle, the two telephones at the ends of the wire, and the two gossips at the ends of the telephones\u2014may be very fascinating to a mere mathematician.\n\n\u2014James Clerk Maxwell (1878)\n\nA CURIOUS CHILD IN A COUNTRY TOWN in the 1920s might naturally form an interest in the sending of messages along wires, as Claude Shannon did in Gaylord, Michigan. He saw wires every day, fencing the pastures\u2014double strands of steel, twisted and barbed, stretched from post to post. He scrounged what parts he could and jerry-rigged his own barbed-wire telegraph, tapping messages to another boy a half mile away. He used the code devised by Samuel F. B. Morse. That suited him. He liked the very idea of codes\u2014not just secret codes, but codes in the more general sense, words or symbols standing in for other words or symbols. He was an inventive and playful spirit. The child stayed with the man. All his life, he played games and invented games. He was a gadgeteer. The grown-up Shannon juggled and devised theories about juggling. When researchers at the Massachusetts Institute of Technology or Bell Laboratories had to leap aside to let a unicycle pass, that was Shannon. He had more than his share of playfulness, and as a child he had a large portion of loneliness, too, which along with his tinkerer\u2019s ingenuity helped motivate his barbed-wire telegraph.\n\nGaylord amounted to little more than a few streets and stores interrupting the broad northern farmland of the Michigan peninsula. Here and onward across the plains and prairie to the Rocky Mountains barbed wire had spread like a vine, begetting industrial fortunes though it was not a particularly glamorous technology amid the excitement of what was already called the Age of Electricity. Beginning in 1874, when an Illinois farmer received U. S. Patent No. 157,124 for \u201ca new and valuable Improvement in Wire-Fences,\u201d battles for ownership raged, ultimately reaching the Supreme Court, while the wire defined territory and closed the open range. At the peak, American farmers, ranchers, and railroads laid more than a million miles a year. Taken collectively the nation\u2019s fence wire formed no web or network, just a broken lattice. Its purpose had been to separate, not to connect. For electricity it made a poor conductor even in dry weather. But wire was wire, and Claude Shannon was not the first to see this wide-ranging\nlattice as a potential communications grid. Thousands of farmers in remote places had the same idea. Unwilling to wait for the telephone companies to venture out from the cities, rural folk formed barbed-wire telephone cooperatives. They replaced metal staples with insulated fasteners. They attached dry batteries and speaking tubes and added spare wire to bridge the gaps. In the summer of 1895 *The New York Times* reported: \u201cThere can be no doubt that many rough-and-ready utilizations of the telephone are now being made. For instance, a number of South Dakota farmers have helped themselves to a telephone system covering eight miles of wire by supplying themselves with transmitters and making connections with the barb wire which constitutes the fence in that part of the country.\u201d The reporter observed: \u201cThe idea is gaining ground that the day of cheap telephones for the million is at hand. Whether this impression is soundly based is an open question.\u201d Clearly people wanted the connections. Cattlemen who despised fences for making parcels of the free range now hooked up their speaking tubes to hear market quotations, weather reports, or just, crackling along the wires, the attenuated simulacrum of the human voice, a thrill in itself.\n\nThree great waves of electrical communication crested in sequence: telegraphy, telephony, and radio. People began to feel that it was natural to possess machines dedicated to the sending and receiving of messages. These devices changed the topology\u2014ripped the social fabric and reconnected it, added gateways and junctions where there had only been blank distance. Already at the turn of the twentieth century there was worry about unanticipated effects on social behavior. The superintendent of the line in Wisconsin fretted about young men and women \u201cconstantly sparking over the wire\u201d between Eau Claire and Chippewa Falls. \u201cThis free use of the line for flirtation purposes has grown to an alarming extent,\u201d he wrote, \u201cand if it is to go on somebody must pay for it.\u201d The Bell companies tried to discourage frivolous telephony, particularly by women and servants. A freer spirit prevailed at the farmer cooperatives, which avoided paying the telephone companies well into the 1920s. The Montana East Line Telephone Association\u2014eight members\u2014sent \u201cup to the minute\u201d news reports around its network, because the men also owned a radio. Children wanted to play this game, too.\n\nClaude Elwood Shannon, born in 1916, was given the full name of his father, a self-made businessman\u2014furniture, undertaking, and real estate\u2014and probate judge, already well into middle age. Claude\u2019s grandfather, a farmer, had invented a machine for washing clothes: a waterproof tub, a wooden arm, and a plunger. Claude\u2019s mother, Mabel Catherine Wolf, daughter of German immigrants, worked as a language teacher and sometime principal of the high school. His older sister, Catherine Wolf Shannon (the parents doled out names parsimoniously), studied mathematics and regularly entertained Claude with\npuzzles. They lived on Center Street a few blocks north of Main Street. The town of Gaylord boasted barely three thousand souls, but this was enough to support a band with Teutonic uniforms and shiny instruments, and in grade school Claude played an E-flat alto horn broader than his chest. He had Erector Sets and books. He made model planes and earned money delivering telegrams for the local Western Union office. He solved cryptograms. Left on his own, he read and reread books; a story he loved was Edgar Allan Poe\u2019s \u201cThe Gold-Bug,\u201d set on a remote southern island, featuring a peculiar William Legrand, a man with an \u201cexcitable brain\u201d and \u201cunusual powers of mind\u201d but \u201csubject to perverse moods of alternate enthusiasm and melancholy\u201d\u2014in other words, a version of his creator. Such ingenious protagonists were required by the times and duly conjured by Poe and other prescient writers, like Arthur Conan Doyle and H. G. Wells. The hero of \u201cThe Gold-Bug\u201d finds buried treasure by deciphering a cryptograph written on parchment. Poe spells out the string of numerals and symbols (\u201crudely traced, in a red tint, between the death\u2019s-head and the goat\u201d)\n\n\\[53\\dddot{305} \\)6* :4826)4\u2020.)4\u2021\\) ;806* :48\u20208\u00b6(60) )85;1\u2020( ;\u2021*8\u202083(88)5\u2021\u2021 :46;(88*96*?;8) *\u2021(485);5*\u20202:*\u2021(4956*2(5* -4) 8\u00a78* ;4069285) ;:6\u20208)4\u2021\u2021;1\u20219;48081 ;8:8\u20211 ;48\u202085;4) 485\u2020528806*81 (\u20219:48;(88;4 (\u2021?34;48)4\u2021;161;;188; \u2021?;\n\n\u2014and walks the reader through every twist of its construction and deconstruction. \u201cCircumstances, and a certain bias of mind, have led me to take interest in such riddles,\u201d his dark hero proclaims, thrilling a reader who might have the same bias of mind. The solution leads to the gold, but no one cares about the gold, really. The thrill is in the code: mystery and transmutation.\n\nClaude finished Gaylord High School in three years instead of four and went on in 1932 to the University of Michigan, where he studied electrical engineering and mathematics. Just before graduating, in 1936, he saw a postcard on a bulletin board advertising a graduate-student job at the Massachusetts Institute of Technology. Vannevar Bush, then the dean of engineering, was looking for a research assistant to run a new machine with a peculiar name: the Differential Analyzer. This was a 100-ton iron platform of rotating shafts and gears. In the newspapers it was being called a \u201cmechanical brain\u201d or \u201cthinking machine\u201d; a typical headline declared:\n\n\u201cThinking Machine\u201d Does Higher Mathematics;\nSolves Equations That Take Humans Months\n\nCharles Babbage\u2019s Difference Engine and Analytical Engine loomed as ancestral ghosts, but despite the echoes of nomenclature and the similarity of purpose, the Differential Analyzer owed virtually nothing to Babbage. Bush had barely heard of him. Bush, like Babbage, hated the numbing, wasteful labor of\nmere calculation. \u201cA mathematician is not a man who can readily manipulate figures; often he cannot,\u201d Bush wrote. \u201cHe is primarily an individual who is skilled in the use of symbolic logic on a high plane, and especially he is a man of intuitive judgment.\u201d\n\nMIT in the years after World War I was one of the nation\u2019s three focal points for the burgeoning practical science of electrical engineering, along with the Bell Telephone Laboratories and General Electric. It was also a place with a voracious need for the solving of equations\u2014especially differential equations, and particularly differential equations of the second order. Differential equations express rates of change, as in ballistic projectiles and oscillating electric currents. Second-order differential equations concern rates of change in rates of change: from position to velocity to acceleration. They are hard to solve analytically, and they pop up everywhere. Bush designed his machine to handle this entire class of problems and thus the whole range of physical systems that generated them. Like Babbage\u2019s machines, it was essentially mechanical, though it used electric motors to drive the weighty apparatus and, as it evolved, more and more electromechanical switches to control it.\n\nUnlike Babbage\u2019s machine, it did not manipulate numbers. It worked on quantities\u2014generating curves, as Bush liked to say, to represent the future of a dynamical system. We would say now that it was analog rather than digital. Its wheels and disks were arranged to produce a physical analog of the differential equations. In a way it was a monstrous descendant of the planimeter, a little measuring contraption that translated the integration of curves into the motion of a wheel. Professors and students came to the Differential Analyzer as supplicants, and when it could solve their equations with 2 percent accuracy, the operator, Claude Shannon, was happy. In any case he was utterly captivated by this \u201ccomputer,\u201d and not just by the grinding, rasping, room-filling analog part, but by the nearly silent (save for the occasional click and tap) electrical controls.\nThese were of two kinds: ordinary switches and the special switches called relays\u2014the telegraph\u2019s progeny. The relay was an electrical switch controlled by electricity (a looping idea). For the telegraph, the point was to reach across long distances by making a chain. For Shannon, the point was not distance but control. A hundred relays, intricately interconnected, switching on and off in particular sequence, coordinated the Differential Analyzer. The best experts on complex relay circuits were telephone engineers; relays controlled the routing of calls through telephone exchanges, as well as machinery on factory assembly lines. Relay circuitry was designed for each particular case. No one had thought to study the idea systematically, but Shannon was looking for a topic for his master\u2019s thesis, and he saw a possibility. In his last year of college he had taken a course in symbolic logic, and, when he tried to make an orderly list of the possible arrangements of switching circuits, he had a sudden feeling of d\u00e9j\u00e0 vu. In a deeply abstract way, these problems lined up. The peculiar artificial notation of symbolic logic, Boole\u2019s \u201calgebra,\u201d could be used to describe circuits.\n\nThis was an odd connection to make. The worlds of electricity and logic seemed incongruous. Yet, as Shannon realized, what a relay passes onward from one circuit to the next is not really electricity but rather a fact: the fact of whether the circuit is open or closed. If a circuit is open, then a relay may cause the next circuit to open. But the reverse arrangement is also possible, the negative arrangement: when a circuit is open, a relay may cause the next circuit to close. It was clumsy to describe the possibilities with words; simpler to reduce them to symbols, and natural, for a mathematician, to manipulate the symbols in equations. (Charles Babbage had taken steps down the same path with his mechanical notation, though Shannon knew nothing of this.)\n\n\u201cA calculus is developed for manipulating these equations by simple mathematical processes\u201d\u2014with this clarion call, Shannon began his thesis in 1937. So far the equations just represented combinations of circuits. Then, \u201cthe calculus is shown to be exactly analogous to the calculus of propositions used in the symbolic study of logic.\u201d Like Boole, Shannon showed that he needed only two numbers for his equations: zero and one. Zero represented a closed circuit; one represented an open circuit. On or off. Yes or no. True or false. Shannon pursued the consequences. He began with simple cases: two-switch circuits, in series or in parallel. Circuits in series, he noted, corresponded to the logical connective \\textit{and}; whereas circuits in parallel had the effect of \\textit{or}. An operation of logic that could be matched electrically was negation, converting a value into its opposite. As in logic, he saw that circuitry could make \u201cif \u2026 then\u201d choices. Before he was done, he had analyzed \u201cstar\u201d and \u201cmesh\u201d networks of increasing\ncomplexity, by setting down postulates and theorems to handle systems of simultaneous equations. He followed this tower of abstraction with practical examples\u2014inventions, on paper, some practical and some just quirky. He diagrammed the design of an electric combination lock, to be made from five push-button switches. He laid out a circuit that would \u201cautomatically add two numbers, using only relays and switches\u201d; for convenience, he suggested arithmetic using base two. \u201cIt is possible to perform complex mathematical operations by means of relay circuits,\u201d he wrote. \u201cIn fact, any operation that can be completely described in a finite number of steps using the words if, or, and, etc. can be done automatically with relays.\u201d As a topic for a student in electrical engineering this was unheard of: a typical thesis concerned refinements to electric motors or transmission lines. There was no practical call for a machine that could solve puzzles of logic, but it pointed to the future. Logic circuits. Binary arithmetic. Here in a master\u2019s thesis by a research assistant was the essence of the computer revolution yet to come.\n\nShannon spent a summer working at the Bell Telephone Laboratories in New York City and then, at Vannevar Bush\u2019s suggestion, switched from electrical engineering to mathematics at MIT. Bush also suggested that he look into the possibility of applying an algebra of symbols\u2014his \u201cqueer algebra\u201d\u2014to the nascent science of genetics, whose basic elements, genes and chromosomes, were just dimly understood. So Shannon began work on an ambitious doctoral dissertation to be called \u201cAn Algebra for Theoretical Genetics.\u201d Genes, as he noted, were a theoretical construct. They were thought to be carried in the rodlike bodies known as chromosomes, which could be seen under a microscope, but no one knew exactly how genes were structured or even if they were real. \u201cStill,\u201d as Shannon noted, \u201cit is possible for our purposes to act as though they were\u2026. We shall speak therefore as though the genes actually exist and as though our simple representation of hereditary phenomena were really true, since so far as we are concerned, this might just as well be so.\u201d He devised an arrangement of letters and numbers to represent \u201cgenetic formulas\u201d for an individual; for example, two chromosome pairs and four gene positions could be represented thus:\n\nA1B2C3D5 E4F1G6H1  \nA3B1C4D3 E4F2G6H2\n\nThen, the processes of genetic combination and cross-breeding could be predicted by a calculus of additions and multiplications. It was a sort of road map, far abstracted from the messy biological reality. He explained: \u201cTo non-mathematicians we point out that it is a commonplace of modern algebra for symbols to represent concepts other than numbers.\u201d The result was complex, original, and quite detached from anything people in the field were doing.* He\nnever bothered to publish it.\n\nMeanwhile, late in the winter of 1939, he wrote Bush a long letter about an idea closer to his heart:\n\nOff and on I have been working on an analysis of some of the fundamental properties of general systems for the transmission of intelligence, including telephony, radio, television, telegraphy, etc. Practically all systems of communication may be thrown into the following general form:\n\n\\[ f_1(t) \\rightarrow T \\rightarrow F(t) \\rightarrow R \\rightarrow f_2(t) \\]\n\n\\( T \\) and \\( R \\) were a transmitter and a receiver. They mediated three \u201cfunctions of time,\u201d \\( f(t) \\): the \u201cintelligence to be transmitted,\u201d the signal, and the final output, which, of course, was meant to be as nearly identical to the input as possible. (\u201cIn an ideal system it would be an exact replica.\u201d) The problem, as Shannon saw it, was that real systems always suffer distortion\u2014a term for which he proposed to give a rigorous definition in mathematical form. There was also noise (\u201ce.g., static\u201d). Shannon told Bush he was trying to prove some theorems. Also, and not incidentally, he was working on a machine for performing symbolic mathematical operations, to do the work of the Differential Analyzer and more, entirely by means of electric circuits. He had far to go. \u201cAlthough I have made some progress in various outskirts of the problem I am still pretty much in the woods, as far as actual results are concerned,\u201d he said.\n\nI have a set of circuits drawn up which actually will perform symbolic differentiation and integration on most functions, but the method is not quite general or natural enough to be perfectly satisfactory. Some of the general philosophy underlying the machine seems to evade me completely.\n\nHe was painfully thin, almost gaunt. His ears stuck out a little from his close-trimmed wavy hair. In the fall of 1939, at a party in the Garden Street apartment he shared with two roommates, he was standing shyly in his own doorway, a jazz record playing on the phonograph, when a young woman started throwing popcorn at him. She was Norma Levor, an adventurous nineteen-year-old Radcliffe student from New York. She had left school to live in Paris that summer but returned when Nazi Germany invaded Poland; even at home, the looming war had begun to unsettle people\u2019s lives. Claude struck her as dark in temperament and sparkling in intellect. They began to see each other every day; he wrote sonnets for her, uncapitalized in the style of E. E. Cummings. She loved the way he loved words, the way he said Boolean algebra. By January they were married (Boston judge, no ceremony), and she followed him to Princeton, where he had received a postdoctoral fellowship.\n\nThe invention of writing had catalyzed logic, by making it possible to reason about reasoning\u2014to hold a train of thought up before the eyes for examination\u2014\nand now, all these centuries later, logic was reanimated with the invention of machinery that could work upon symbols. In logic and mathematics, the highest forms of reasoning, everything seemed to be coming together.\n\nBy melding logic and mathematics in a system of axioms, signs, formulas, and proofs, philosophers seemed within reach of a kind of perfection\u2014a rigorous, formal certainty. This was the goal of Bertrand Russell and Alfred North Whitehead, the giants of English rationalism, who published their great work in three volumes from 1910 to 1913. Their title, *Principia Mathematica*, grandly echoed Isaac Newton; their ambition was nothing less than the perfection of all mathematics. This was finally possible, they claimed, through the instrument of symbolic logic, with its obsidian signs and implacable rules. Their mission was to prove every mathematical fact. The process of proof, when carried out properly, should be mechanical. In contrast to words, symbolism (they declared) enables \u201cperfectly precise expression.\u201d This elusive quarry had been pursued by Boole, and before him, Babbage, and long before either of them, Leibniz, all believing that the perfection of reasoning could come with the perfect encoding of thought. Leibniz could only imagine it: \u201ca certain script of language,\u201d he wrote in 1678, \u201cthat perfectly represents the relationships between our thoughts.\u201d With such encoding, logical falsehoods would be instantly exposed.\n\nThe characters would be quite different from what has been imagined up to now\u2026. The characters of this script should serve invention and judgment as in algebra and arithmetic\u2026. It will be impossible to write, using these characters, chimerical notions [chim\u00e8res].\n\nRussell and Whitehead explained that symbolism suits the \u201chighly abstract processes and ideas\u201d used in logic, with its trains of reasoning. Ordinary language works better for the muck and mire of the ordinary world. A statement like *a whale is big* uses simple words to express \u201ca complicated fact,\u201d they observed, whereas *one is a number* \u201cleads, in language, to an intolerable prolixity.\u201d Understanding whales, and bigness, requires knowledge and experience of real things, but to manage *1*, and *number*, and all their associated arithmetical operations, when properly expressed in desiccated symbols, should be automatic.\n\nThey had noticed some bumps along the way, though\u2014some of the chim\u00e8res that should have been impossible. \u201cA very large part of the labour,\u201d they said in their preface, \u201chas been expended on the contradictions and paradoxes which have infected logic.\u201d \u201cInfected\u201d was a strong word but barely adequate to express the agony of the paradoxes. They were a cancer.\n\nSome had been known since ancient times:\n\nEpimenides the Cretan said that all Cretans were liars, and all other statements made by Cretans were certainly lies. Was this a lie?\n\nA cleaner formulation of Epimenides\u2019 paradox\u2014cleaner because one need not\nworry about Cretans and their attributes\u2014is the liar\u2019s paradox: *This statement is false*. The statement cannot be true, because then it is false. It cannot be false, because then it becomes true. It is neither true nor false, or it is both at once. But the discovery of this twisting, backfiring, mind-bending circularity does not bring life or language crashing to a halt\u2014one grasps the idea and moves on\u2014because life and language lack the perfection, the absolutes, that give them force. In real life, all Cretans cannot be liars. Even liars often tell the truth. The pain begins only with the attempt to build an airtight vessel. Russell and Whitehead aimed for perfection\u2014for proof\u2014otherwise the enterprise had little point. The more rigorously they built, the more paradoxes they found. \u201cIt was in the air,\u201d Douglas Hofstadter has written, \u201cthat truly peculiar things could happen when modern cousins of various ancient paradoxes cropped up inside the rigorously logical world of numbers,\u2026 a pristine paradise in which no one had dreamt paradox might arise.\u201d\n\nOne was Berry\u2019s paradox, first suggested to Russell by G. G. Berry, a librarian at the Bodleian. It has to do with counting the syllables needed to specify each integer. Generally, of course, the larger the number the more syllables are required. In English, the smallest integer requiring two syllables is seven. The smallest requiring three syllables is eleven. The number 121 seems to require six syllables (\u201cone hundred twenty-one\u201d), but actually four will do the job, with some cleverness: \u201celeven squared.\u201d Still, even with cleverness, there are only a finite number of possible syllables and therefore a finite number of names, and, as Russell put it, \u201cHence the names of some integers must consist of at least nineteen syllables, and among these there must be a least. Hence the least integer not nameable in fewer than nineteen syllables must denote a definite integer.\u201d*\n\nNow comes the paradox. This phrase, *the least integer not nameable in fewer than nineteen syllables*, contains only eighteen syllables. So the least integer not nameable in fewer than nineteen syllables has just been named in fewer than nineteen syllables.\n\nAnother paradox of Russell\u2019s is the Barber paradox. The barber is the man (let us say) who shaves all the men, and only those, who do not shave themselves. Does the barber shave himself? If he does he does not, and if he does not he does. Few people are troubled by such puzzles, because in real life the barber does as he likes and the world goes on. We tend to feel, as Russell put it, that \u201cthe whole form of words is just a noise without meaning.\u201d But the paradox cannot be dismissed so easily when a mathematician examines the subject known as set theory, or the theory of classes. Sets are groups of things\u2014for example, integers. The set 0, 2, 4 has integers as its members. A set can also be a member of other sets. For example, the set 0, 2, 4 belongs to the set of *sets of integers* and the set of *sets with three members* but not the set of *sets of prime numbers*. So Russell\ndefined a certain set this way:\n\n\\[ S \\text{ is the set of all sets that are not members of themselves.} \\]\n\nThis version is known as Russell\u2019s paradox. It cannot be dismissed as noise.\n\nTo eliminate Russell\u2019s paradox Russell took drastic measures. The enabling factor seemed to be the peculiar recursion within the offending statement: the idea of sets belonging to sets. Recursion was the oxygen feeding the flame. In the same way, the liar paradox relies on statements about statements. \u201cThis statement is false\u201d is meta-language: language about language. Russell\u2019s paradoxical set relies on a meta-set: a set of sets. So the problem was a crossing of levels, or, as Russell termed it, a mixing of types. His solution: declare it illegal, taboo, out of bounds. No mixing different levels of abstraction. No self-reference; no self-containment. The rules of symbolism in *Principia Mathematica* would not allow the reaching-back-around, snake-eating-its-tail feedback loop that seemed to turn on the possibility of self-contradiction. This was his firewall.\n\nEnter Kurt G\u00f6del.\n\nHe was born in 1906 in Brno, at the center of the Czech province of Moravia. He studied physics at the University of Vienna, seventy-five miles south, and as a twenty-year-old became part of the Vienna Circle, a group of philosophers and mathematicians who met regularly in smoky coffeehouses like the Caf\u00e9 Josephinum and the Caf\u00e9 Reichsrat to propound logic and realism as a bulwark against metaphysics\u2014by which they meant spiritualism, phenomenology, irrationality. G\u00f6del talked to them about the New Logic (this term was in the air) and before long about metamathematics\u2014der Metamathematik. Metamathematics was not to mathematics what metaphysics was to physics. It was mathematics once removed\u2014mathematics about mathematics\u2014a formal system \u201clooked at from the outside\u201d (\u201c\u00e4u\u00dferlich betrachtet\u201d). He was about to make the most important statement, prove the most important theorem about knowledge in the twentieth century. He was going to kill Russell\u2019s dream of a perfect logical system. He was going to show that the paradoxes were not excrescences; they were fundamental.\n\nG\u00f6del praised the Russell and Whitehead project before he buried it: mathematical logic was, he wrote, \u201ca science prior to all others, which contains the ideas and principles underlying all sciences.\u201d *Principia Mathematica*, the great opus, embodied a formal system that had become, in its brief lifetime, so comprehensive and so dominant that G\u00f6del referred to it in shorthand: PM. By PM he meant the system, as opposed to the book. In PM, mathematics had been contained\u2014a ship in a bottle, no longer buffeted and turned by the vast unruly seas. By 1930, when mathematicians proved something, they did it according to PM. In PM, as G\u00f6del said, \u201cone can prove any theorem using nothing but a few\nmechanical rules.\u201d\n\nAny theorem: for the system was, or claimed to be, complete. Mechanical rules: for the logic operated inexorably, with no room for varying human interpretation. Its symbols were drained of meaning. Anyone could verify a proof step by step, by following the rules, without understanding it. Calling this quality mechanical invoked the dreams of Charles Babbage and Ada Lovelace, machines grinding through numbers, and numbers standing for anything at all.\n\nAmid the doomed culture of 1930 Vienna, listening to his new friends debate the New Logic, his manner reticent, his eyes magnified by black-framed round spectacles, the twenty-four-year-old G\u00f6del believed in the perfection of the bottle that was PM but doubted whether mathematics could truly be contained. This slight young man turned his doubt into a great and horrifying discovery. He found that lurking within PM\u2014and within any consistent system of logic\u2014there must be monsters of a kind hitherto unconceived: statements that can never be proved, and yet can never be disproved. There must be truths, that is, that cannot be proved\u2014and G\u00f6del could prove it.\n\nHe accomplished this with iron rigor disguised as sleight of hand. He employed the formal rules of PM and, as he employed them, also approached them metamathematically\u2014viewed them, that is, from the outside. As he explained, all the symbols of PM\u2014numbers, operations of arithmetic, logical connectors, and punctuation\u2014constituted a limited alphabet. Every statement or formula of PM was written in this alphabet. Likewise every proof comprised a finite sequence of formulas\u2014just a longer passage written in the same alphabet. This is where metamathematics came in. Metamathematically, G\u00f6del pointed out, one sign is as good as another; the choice of a particular alphabet is arbitrary. One could use the traditional assortment of numerals and glyphs (from arithmetic: $+, -, =, \\times$; from logic: $\\neg, \\lor, \\supset, \\exists$), or one could use letters, or one could use dots and dashes. It was a matter of encoding, slipping from one symbol set to another.\n\nG\u00f6del proposed to use numbers for all his signs. Numbers were his alphabet. And because numbers can be combined using arithmetic, any sequence of numbers amounts to one (possibly very large) number. So every statement, every formula of PM can be expressed as a single number, and so can every proof. G\u00f6del outlined a rigorous scheme for doing the encoding\u2014an algorithm, mechanical, just rules to follow, no intelligence necessary. It works forward and backward: given any formula, following the rules generates one number, and given any number, following the rules produces the corresponding formula.\n\nNot every number translates into a correct formula, however. Some numbers decode back into gibberish, or formulas that are false within the rules of the system. The string of symbols \u201c0 0 0 = = =\u201d does not make a formula at all, though it translates to some number. The statement \u201c0 = 1\u201d is a recognizable\nformula, but it is false. The formula \u201c\\(0 + x = x + 0\\)\u201d is true, and it is provable.\n\nThis last quality\u2014the property of being provable according to PM\u2014was not meant to be expressible in the language of PM. It seems to be a statement from outside the system, a metamathematical statement. But G\u00f6del\u2019s encoding reeled it in. In the framework he constructed, the natural numbers led a double life, as numbers and also as statements. A statement could assert that a given number is even, or prime, or a perfect square, and a statement could also assert that a given number is a provable formula. Given the number 1,044,045,317,700, for example, one could make various statements and test their truth or falsity: this number is even, it is not a prime, it is not a perfect square, it is greater than 5, it is divisible by 121, and (when decoded according to the official rules) it is a provable formula.\n\nG\u00f6del laid all this out in a little paper in 1931. Making his proof watertight required complex logic, but the basic argument was simple and elegant. G\u00f6del showed how to construct a formula that said A certain number, \\(x\\), is not provable. That was easy: there were infinitely many such formulas. He then demonstrated that, in at least some cases, the number \\(x\\) would happen to represent that very formula. This was just the looping self-reference that Russell had tried to forbid in the rules of PM\u2014\n\nThis statement is not provable\n\n\u2014and now G\u00f6del showed that such statements must exist anyway. The Liar returned, and it could not be locked out by changing the rules. As G\u00f6del explained (in one of history\u2019s most pregnant footnotes),\n\nContrary to appearances, such a proposition involves no faulty circularity, for it only asserts that a certain well-defined formula \u2026 is unprovable. Only subsequently (and so to speak by chance) does it turn out that this formula is precisely the one by which the proposition itself was expressed.\n\nWithin PM, and within any consistent logical system capable of elementary arithmetic, there must always be such accursed statements, true but unprovable. Thus G\u00f6del showed that a consistent formal system must be incomplete; no complete and consistent system can exist.\n\nThe paradoxes were back, nor were they mere quirks. Now they struck at the core of the enterprise. It was, as G\u00f6del said afterward, an \u201camazing fact\u201d\u2014\u201cthat our logical intuitions (i.e., intuitions concerning such notions as: truth, concept, being, class, etc.) are self-contradictory.\u201d It was, as Douglas Hofstadter says, \u201ca sudden thunderbolt from the bluest of skies,\u201d its power arising not from the edifice it struck down but the lesson it contained about numbers, about symbolism, about encoding:\nG\u00f6del\u2019s conclusion sprang not from a weakness in PM but from a strength. That strength is the fact that numbers are so flexible or \u201cchameleonic\u201d that their patterns can mimic patterns of reasoning\u2026. PM\u2019s expressive power is what gives rise to its incompleteness.\n\nThe long-sought universal language, the *characteristica universalis* Leibniz had pretended to invent, had been there all along, in the numbers. Numbers could encode all of reasoning. They could represent any form of knowledge.\n\nG\u00f6del\u2019s first public mention of his discovery, on the third and last day of a philosophical conference in K\u00f6nigsberg in 1930, drew no response; only one person seems to have heard him at all, a Hungarian named Neumann J\u00e1nos. This young mathematician was in the process of moving to the United States, where he would soon and for the rest of his life be called John von Neumann. He understood G\u00f6del\u2019s import at once; it stunned him, but he studied it and was persuaded. No sooner did G\u00f6del\u2019s paper appear than von Neumann was presenting it to the mathematics colloquium at Princeton. Incompleteness was real. It meant that mathematics could never be proved free of self-contradiction. And \u201cthe important point,\u201d von Neumann said, \u201cis that this is not a philosophical principle or a plausible intellectual attitude, but the result of a rigorous mathematical proof of an extremely sophisticated kind.\u201d Either you believed in mathematics or you did not.\n\nBertrand Russell (who, of course, *did*) had moved on to more gentle sorts of philosophy. Much later, as an old man, he admitted that G\u00f6del had troubled him: \u201cIt made me glad that I was no longer working at mathematical logic. If a given set of axioms leads to a contradiction, it is clear that at least one of the axioms must be false.\u201d On the other hand, Vienna\u2019s most famous philosopher, Ludwig Wittgenstein (who, fundamentally, *did not*), dismissed the incompleteness theorem as trickery (\u201c*Kunstst\u00fccken*\u201d) and boasted that rather than try to refute it, he would simply pass it by:\n\nMathematics cannot be incomplete; any more than a *sense* can be incomplete. Whatever I can understand, I must completely understand.\n\nG\u00f6del\u2019s retort took care of them both. \u201cRussell evidently misinterprets my result; however, he does so in a very interesting manner,\u201d he wrote. \u201cIn contradistinction Wittgenstein \u2026 advances a completely trivial and uninteresting misinterpretation.\u201d\n\nIn 1933 the newly formed Institute for Advanced Study, with John von Neumann and Albert Einstein among its first faculty members, invited G\u00f6del to Princeton for the year. He crossed the Atlantic several more times that decade, as fascism rose and the brief glory of Vienna began to fade. G\u00f6del, ignorant of politics and na\u00efve about history, suffered depressive breakdowns and bouts of hypochondria that forced him into sanatoria. Princeton beckoned but G\u00f6del\nvacillated. He stayed in Vienna in 1938, through the *Anschluss*, as the Vienna Circle ceased to be, its members murdered or exiled, and even in 1939, when Hitler\u2019s army occupied his native Czechoslovakia. He was not a Jew, but mathematics was *verjudet* enough. He finally managed to leave in January 1940 by way of the Trans-Siberian Railway, Japan, and a ship to San Francisco. His name was recoded by the telephone company as \u201cK. Goedel\u201d when he arrived in Princeton, this time to stay.\n\nClaude Shannon had also arrived at the Institute for Advanced Study, to spend a postdoctoral year. He found it a lonely place, occupying a new red-brick building with clocktower and cupola framed by elms on a former farm a mile from Princeton University. The first of its fifteen or so professors was Einstein, whose office was at the back of the first floor; Shannon seldom laid eyes on him. G\u00f6del, who had arrived in March, hardly spoke to anyone but Einstein. Shannon\u2019s nominal supervisor was Hermann Weyl, another German exile, the most formidable mathematical theorist of the new quantum mechanics. Weyl was only mildly interested in Shannon\u2019s thesis on genetics\u2014\u201cyour bio-mathematical problems\u201d\u2014but thought Shannon might find common ground with the institute\u2019s other great young mathematician, von Neumann. Mostly Shannon stayed moodily in his room in Palmer Square. His twenty-year-old wife, having left Radcliffe to be with him, found it increasingly grim, staying home while Claude played clarinet accompaniment to his Bix Beiderbecke record on the phonograph. Norma thought he was depressed and wanted him to see a psychiatrist. Meeting Einstein was nice, but the thrill wore off. Their marriage was over; she was gone by the end of the year.\n\nNor could Shannon stay in Princeton. He wanted to pursue the transmission of intelligence, a notion poorly defined and yet more pragmatic than the heady theoretical physics that dominated the institute\u2019s agenda. Furthermore, war approached. Research agendas were changing everywhere. Vannevar Bush was now heading the National Defense Research Committee, which assigned Shannon \u201cProject 7\u201d: the mathematics of fire-control mechanisms for antiaircraft guns\u2014\u201cthe job,\u201d as the NDRC reported dryly, \u201cof applying corrections to the gun control so that the shell and the target will arrive at the same position at the same time.\u201d Airplanes had suddenly rendered obsolete almost all the mathematics used in ballistics: for the first time, the targets were moving at speeds not much less than the missiles themselves. The problem was complex and critical, on ships and on land. London was organizing batteries of heavy guns firing 3.7-inch shells. Aiming projectiles at fast-moving aircraft needed either intuition and luck or a vast amount of implicit computation by gears and linkages and servos. Shannon analyzed physical problems as well as computational problems: the machinery had to track rapid paths in three dimensions, with shafts and gears controlled by\nrate finders and integrators. An antiaircraft gun in itself behaved as a dynamical system, subject to \u201cbacklash\u201d and oscillations that might or might not be predictable. (Where the differential equations were nonlinear, Shannon made little headway and knew it.)\n\nHe had spent two of his summers working for Bell Telephone Laboratories in New York; its mathematics department was also taking on the fire-control project and asked Shannon to join. This was work for which the Differential Analyzer had prepared him well. An automated antiaircraft gun was already an analog computer: it had to convert what were, in effect, second-order differential equations into mechanical motion; it had to accept input from rangefinder sightings or new, experimental radar; and it had to smooth and filter this data, to compensate for errors.\n\nAt Bell Labs, the last part of this problem looked familiar. It resembled an issue that plagued communication by telephone. The noisy data looked like static on the line. \u201cThere is an obvious analogy,\u201d Shannon and his colleagues reported, \u201cbetween the problem of smoothing the data to eliminate or reduce the effect of tracking errors and the problem of separating a signal from interfering noise in communications systems.\u201d The data constituted a signal; the whole problem was \u201ca special case of the transmission, manipulation, and utilization of intelligence.\u201d Their specialty, at Bell Labs.\n\nTransformative as the telegraph had been, miraculous as the wireless radio now seemed, electrical communication now meant the telephone. The \u201celectrical speaking telephone\u201d first appeared in the United States with the establishment of a few experimental circuits in the 1870s. By the turn of the century, the telephone industry surpassed the telegraph by every measure\u2014number of messages, miles of wire, capital invested\u2014and telephone usage was doubling every few years. There was no mystery about why: anyone could use a telephone. The only skills required were talking and listening: no writing, no codes, no keypads. Everyone responded to the sound of the human voice; it conveyed not just words but feeling.\n\nThe advantages were obvious\u2014but not to everyone. Elisha Gray, a telegraph man who came close to trumping Alexander Graham Bell as inventor of the telephone, told his own patent lawyer in 1875 that the work was hardly worthwhile: \u201cBell seems to be spending all his energies in [the] talking telegraph. While this is very interesting scientifically it has no commercial value at present, for they can do much more business over a line by methods already in use.\u201d Three years later, when Theodore N. Vail quit the Post Office Department to become the first general manager (and only salaried officer) of the new Bell Telephone Company, the assistant postmaster general wrote angrily, \u201cI can scarce believe that a man of your sound judgment \u2026 should throw it up for a d\u2014\u2014d old\nYankee notion (a piece of wire with two Texan steer horns attached to the ends, with an arrangement to make the concern blate like a calf) called a telephone!\u201d\n\nThe next year, in England, the chief engineer of the General Post Office, William Preece, reported to Parliament: \u201cI fancy the descriptions we get of its use in America are a little exaggerated, though there are conditions in America which necessitate the use of such instruments more than here. Here we have a superabundance of messengers, errand boys and things of that kind\u2026. I have one in my office, but more for show. If I want to send a message\u2014I use a sounder or employ a boy to take it.\u201d\n\nOne reason for these misguesses was just the usual failure of imagination in the face of a radically new technology. The telegraph lay in plain view, but its lessons did not extrapolate well to this new device. The telegraph demanded literacy; the telephone embraced orality. A message sent by telegraph had first to be written, encoded, and tapped out by a trained intermediary. To employ the telephone, one just talked. A child could use it. For that very reason it seemed like a toy. In fact, it seemed like a familiar toy, made from tin cylinders and string. The telephone left no permanent record. *The Telephone* had no future as a newspaper name. Business people thought it unserious. Where the telegraph dealt in facts and numbers, the telephone appealed to emotions.\n\nThe new Bell company had little trouble turning this into a selling point. Its promoters liked to quote Pliny, \u201cThe living voice is that which sways the soul,\u201d and Thomas Middleton, \u201cHow sweetly sounds the voice of a good woman.\u201d On the other hand, there was anxiety about the notion of capturing and reifying voices\u2014the phonograph, too, had just arrived. As one commentator said, \u201cNo matter to what extent a man may close his doors and windows, and hermetically seal his key-holes and furnace-registers with towels and blankets, whatever he may say, either to himself or a companion, will be overheard.\u201d Voices, hitherto, had remained mostly private.\n\nThe new contraption had to be explained, and generally this began by comparison to telegraphy. There were a transmitter and receiver, and wires connected them, and *something* was carried along the wire in the form of electricity. In the case of the telephone, that thing was sound, simply converted from waves of pressure in the air to waves of electric current. One advantage was apparent: the telephone would surely be useful to musicians. Bell himself, traveling around the country as impresario for the new technology, encouraged this way of thinking, giving demonstrations in concert halls, where full orchestras and choruses played \u201cAmerica\u201d and \u201cAuld Lang Syne\u201d into his gadgetry. He encouraged people to think of the telephone as a broadcasting device, to send music and sermons across long distances, bringing the concert hall and the church into the living room. Newspapers and commentators mostly went along. That is\nwhat comes of analyzing a technology in the abstract. As soon as people laid their hands on telephones, they worked out what to do. They talked.\n\nIn a lecture at Cambridge, the physicist James Clerk Maxwell offered a scientific description of the telephone conversation: \u201cThe speaker talks to the transmitter at one end of the line, and at the other end of the line the listener puts his ear to the receiver, and hears what the speaker said. The process in its two extreme states is so exactly similar to the old-fashioned method of speaking and hearing that no preparatory practice is required on the part of either operator.\u201d He, too, had noticed its ease of use.\n\nSo by 1880, four years after Bell conveyed the words \u201cMr. Watson, come here, I want to see you,\u201d and three years after the first pair of telephones rented for twenty dollars, more than sixty thousand telephones were in use in the United States. The first customers bought pairs of telephones for communication point to point: between a factory and its business office, for example. Queen Victoria installed one at Windsor Castle and one at Buckingham Palace (fabricated in ivory; a gift from the savvy Bell). The topology changed when the number of sets reachable by other sets passed a critical threshold, and that happened surprisingly soon. Then community networks arose, their multiple connections managed through a new apparatus called a switch-board.\n\nThe initial phase of ignorance and skepticism passed in an eyelid. The second phase of amusement and entertainment did not last much longer. Businesses quickly forgot their qualms about the device\u2019s seriousness. Anyone could be a telephone prophet now\u2014some of the same predictions had already been heard in regard to the telegraph\u2014but the most prescient comments came from those who focused on the exponential power of interconnection. *Scientific American* assessed \u201cThe Future of the Telephone\u201d as early as 1880 and emphasized the forming of \u201clittle clusters of telephonic communicants.\u201d The larger the network and the more diverse its interests, the greater its potential would be.\n\nWhat the telegraph accomplished in years the telephone has done in months. One year it was a scientific toy, with infinite possibilities of practical use; the next it was the basis of a system of communication the most rapidly expanding, intricate, and convenient that the world has known\u2026. Soon it will be the rule and not the exception for business houses, indeed for the dwellings of well-to-do people as well, to be interlocked by means of telephone exchange, not merely in our cities, but in all outlying regions. The result can be nothing less than a new organization of society\u2014a state of things in which every individual, however secluded, will have at call every other individual in the community, to the saving of no end of social and business complications, of needless goings to and fro, of disappointments, delays, and a countless host of those great and little evils and annoyances.\n\nThe time is close at hand when the scattered members of civilized communities will be as closely united, so far as instant telephonic communication is concerned, as the\nThe scattered members using telephones numbered half a million by 1890; by 1914, 10 million. The telephone was already thought, correctly, to be responsible for rapid industrial progress. The case could hardly be overstated. The areas depending on \u201cinstantaneous communication across space\u201d were listed by the United States Commerce Department in 1907: \u201cagriculture, mining, commerce, manufacturing, transportation, and, in fact, all the various branches of production and distribution of natural and artificial resources.\u201d Not to mention \u201ccobblers, cleaners of clothing, and even laundresses.\u201d In other words, every cog in the engine of the economy. \u201cExistence of telephone traffic is essentially an indication that time is being saved,\u201d the department commented. It observed changes in the structure of life and society that would still seem new a century later: \u201cThe last few years have seen such an extension of telephone lines through the various summer-resort districts of the country that it has become practicable for business men to leave their offices for several days at a time, and yet keep in close touch with their offices.\u201d In 1908 John J. Carty, who became the first head of the Bell Laboratories, offered an information-based analysis to show how the telephone had shaped the New York skyline\u2014arguing that the telephone, as much as the elevator, had made skyscrapers possible.\n\nIt may sound ridiculous to say that Bell and his successors were the fathers of modern commercial architecture\u2014of the skyscraper. But wait a minute. Take the Singer Building, the Flatiron Building, the Broad Exchange, the Trinity, or any of the giant office buildings. How many messages do you suppose go in and out of those buildings every day? Suppose there was no telephone and every message had to be carried by a personal messenger? How much room do you think the necessary elevators would leave for offices? Such structures would be an economic impossibility.\n\nTo enable the fast expansion of this extraordinary network, the telephone demanded new technologies and new science. They were broadly of two kinds. One had to do with electricity itself: measuring electrical quantities; controlling the electromagnetic wave, as it was now understood\u2014its modulation in amplitude and in frequency. Maxwell had established in the 1860s that electrical pulses and magnetism and light itself were all manifestations of a single force: \u201caffectations of the same substance,\u201d light being one more case of \u201can electromagnetic disturbance propagated through the field according to electromagnetic laws.\u201d These were the laws that electrical engineers now had to apply, unifying telephone and radio among other technologies. Even the telegraph employed a simple kind of amplitude modulation, in which only two values mattered, a maximum for \u201con\u201d and a minimum for \u201coff.\u201d To convey sound required far stronger current, far more delicately controlled. The engineers had to understand feedback: a coupling of the output of a power amplifier, such as a telephone mouthpiece, with its input. They had to design vacuum-tube repeaters to carry the\nelectric current over long distance, making possible the first transcontinental line in 1914, between New York and San Francisco, 3,400 miles of wire suspended from 130,000 poles. The engineers also discovered how to modulate individual currents so as to combine them in a single channel\u2014multiplexing\u2014without losing their identity. By 1918 they could get four conversations into a single pair of wires. But it was not currents that preserved identity. Before the engineers quite realized it, they were thinking in terms of the transmission of a signal, an abstract entity, quite distinct from the electrical waves in which it was embodied.\n\nA second, less well defined sort of science concerned the organizing of connections\u2014switching, numbering, and logic. This branch descended from Bell\u2019s original realization, dating from 1877, that telephones need not be sold in pairs; that each individual telephone could be connected to many other telephones, not by direct wires but through a central \u201cexchange.\u201d George W. Coy, a telegraph man in New Haven, Connecticut, built the first \u201cswitch-board\u201d there, complete with \u201cswitch-pins\u201d and \u201cswitch-plugs\u201d made from carriage bolts and wire from discarded bustles. He patented it and served as the world\u2019s first telephone \u201coperator.\u201d With all the making and breaking of connections, switch-pins wore out quickly. An early improvement was a hinged two-inch plate resembling a jackknife: the \u201cjack-knife switch,\u201d or as it was soon called, the \u201cjack.\u201d In January 1878, Coy\u2019s switchboard could manage two simultaneous conversations between any of the exchange\u2019s twenty-one customers. In February, Coy published a list of subscribers: himself and some friends; several physicians and dentists; the post office, police station, and mercantile club; and some meat and fish markets. This has been called the world\u2019s first telephone directory, but it was hardly that: one page, not alphabetized, and no numbers associated with the names. The telephone number had yet to be invented.\n\nThat innovation came the next year in Lowell, Massachusetts, where by the end of 1879 four operators managed the connections among two hundred subscribers by shouting to one another across the switchboard room. An epidemic of measles broke out, and Dr. Moses Greeley Parker worried that if the operators succumbed, they would be hard to replace. He suggested identifying each telephone by number. He also suggested listing the numbers in an alphabetical directory of subscribers. These ideas could not be patented and arose again in telephone exchanges across the country, where the burgeoning networks were creating clusters of data in need of organization. Telephone books soon represented the most comprehensive listings of, and directories to, human populations ever attempted. (They became the thickest and densest of the world\u2019s books\u2014four volumes for London; a 2,600-page tome for Chicago\u2014and seemed a permanent, indispensable part of the world\u2019s information ecology until, suddenly, they were not. They went obsolete, effectively, at the turn of the twenty-first century.\nAmerican telephone companies were officially phasing them out by 2010; in New York, the end of automatic delivery of telephone directories was estimated to save 5,000 tons of paper.)\n\nAt first, customers resented the impersonality of telephone numbers, and engineers doubted whether people could remember a number of more than four or five digits. The Bell Company finally had to insist. The first telephone operators were teenage boys, cheaply hired from the ranks of telegraph messengers, but exchanges everywhere discovered that boys were wild, given to clowning and practical jokes, and more likely to be found wrestling on the floor than sitting on stools to perform the exacting, repetitive work of a switchboard operator. A new source of cheap labor was available, and by 1881 virtually every telephone operator was a woman. In Cincinnati, for example, W. H. Eckert reported hiring sixty-six \u201cyoung ladies\u201d who were \u201cvery much superior\u201d to boys: \u201cThey are steadier, do not drink beer, and are always on hand.\u201d He hardly needed to add that the company could pay a woman as little as or less than a teenage boy. It was challenging work that soon required training. Operators had to be quick in distinguishing many different voices and accents, had to maintain a polite equilibrium in the face of impatience and rudeness, as they engaged in long hours of athletic upper-body exercise, wearing headsets like harnesses. Some men thought this was good for them. \u201cThe action of stretching her arms up above her head, and to the right and left of her, develops her chest and arms,\u201d said Every Woman\u2019s Encyclopedia, \u201cand turns thin and weedy girls into strong ones. There are no anaemic, unhealthy looking girls in the operating rooms.\u201d Along with another new technology, the typewriter, the telephone switchboard catalyzed the introduction of women into the white-collar workforce, but battalions of human operators could not sustain a network on the scale now arising. Switching would have to be performed automatically.\n\nThis meant a mechanical linkage to take from callers not just the sound of their voice but also a number\u2014identifying a person, or at least another telephone. The challenge of converting a number into electrical form still required ingenuity: first push buttons were tried, then an awkward-seeming rotary dial, with ten finger positions for the decimal digits, sending pulses down the line. Then the coded pulses served as an agent of control at the central exchange, where another mechanism selected from an array of circuits and set up a connection. Altogether this made for an unprecedented degree of complexity in the translations between human and machine, number and circuitry. The point was not lost on the company, which liked to promote its automatic switches as \u201celectrical brains.\u201d Having borrowed from telegraphy the electromechanical relay\u2014using one circuit to control another\u2014the telephone companies had reduced it in size and weight to less than four ounces and now manufactured several million each year.\n\u201cThe telephone remains the acme of electrical marvels,\u201d wrote a historian in 1910\u2014a historian of the telephone, already. \u201cNo other thing does so much with so little energy. No other thing is more enswathed in the unknown.\u201d New York City had several hundred thousand listed telephone customers, and *Scribner\u2019s Magazine* highlighted this astounding fact: \u201cAny two of that large number can, in five seconds, be placed in communication with each other, so well has engineering science kept pace with public needs.\u201d To make the connections, the switchboard had grown to a monster of 2 million soldered parts, 4,000 miles of wire, and 15,000 signal lamps. By 1925, when an assortment of telephone research groups were formally organized into the Bell Telephone Laboratories, a mechanical \u201cline finder\u201d with a capacity of 400 lines was replacing 22-point electromechanical rotary switches. The American Telephone & Telegraph Company was consolidating its monopoly. Engineers struggled to minimize the hunt time. At first, long-distance calling required reaching a second, \u201ctoll\u201d operator and waiting for a call back; soon the interconnection of local exchanges would have to allow for automatic dialing. The complexities multiplied. Bell Labs needed mathematicians.\n\nWhat began as the Mathematics Consulting Department grew into a center of practical mathematics like none other. It was not like the prestigious citadels, Harvard and Princeton. To the academic world it was barely visible. Its first director, Thornton C. Fry, enjoyed the tension between theory and practice\u2014the clashing cultures. \u201cFor the mathematician, an argument is either perfect in every detail or else it is wrong,\u201d he wrote in 1941. \u201cHe calls this \u2018rigorous thinking.\u2019 The typical engineer calls it \u2018hair-splitting.\u2019 \u201d\n\nThe mathematician also tends to idealize any situation with which he is confronted. His gases are \u201cideal,\u201d his conductors \u201cperfect,\u201d his surfaces \u201csmooth.\u201d He calls this \u201cgetting down to essentials.\u201d The engineer is likely to dub it \u201cignoring the facts.\u201d\n\nIn other words, the mathematicians and engineers could not do without each other. Every electrical engineer could now handle the basic analysis of waves treated as sinusoidal signals. But new difficulties arose in understanding the action of networks; network theorems were devised to handle these mathematically. Mathematicians applied queuing theory to usage conflicts; developed graphs and trees to manage issues of intercity trunks and lines; and used combinatorial analysis to break down telephone probability problems.\n\nThen there was noise. This did not at first (to Alexander Graham Bell, for example) seem like a problem for theorists. It was just there, always crowding the line\u2014pops, hisses, crackles interfering with, or degrading, the voice that had entered the mouthpiece. It plagued radio, too. At best it stayed in the background and people hardly noticed; at worst the weedy profusion spurred the customers\u2019\nimaginations:\n\nThere was sputtering and bubbling, jerking and rasping, whistling and screaming. There was the rustling of leaves, the croaking of frogs, the hissing of steam, and the flapping of birds\u2019 wings. There were clicks from telegraph wires, scraps of talk from other telephones, curious little squeals that were unlike any known sound\u2026. The night was noisier than the day, and at the ghostly hour of midnight, for what strange reasons no one knows, the babel was at its height.\n\nBut engineers could now see the noise on their oscilloscopes, interfering with and degrading their clean waveforms, and naturally they wanted to measure it, even if there was something quixotic about measuring a nuisance so random and ghostly. There was a way, in fact, and Albert Einstein had shown what it was.\n\nIn 1905, his finest year, Einstein published a paper on Brownian motion, the random, jittery motion of tiny particles suspended in a fluid. Antony van Leeuwenhoek had discovered it with his early microscope, and the phenomenon was named after Robert Brown, the Scottish botanist who studied it carefully in 1827: first pollen in water, then soot and powdered rock. Brown convinced himself that these particles were not alive\u2014they were not animalcules\u2014yet they would not sit still. In a mathematical tour de force, Einstein explained this as a consequence of the heat energy of molecules, whose existence he thereby proved. Microscopically visible particles, like pollen, are bombarded by molecular collisions and are light enough to be jolted randomly this way and that. The fluctuations of the particles, individually unpredictable, collectively express the laws of statistical mechanics. Although the fluid may be at rest and the system in thermodynamic equilibrium, the irregular motion perseveres, as long as the temperature is above absolute zero. By the same token, he showed that random thermal agitation would also affect free electrons in any electrical conductor\u2014making noise.\n\nPhysicists paid little attention to the electrical aspects of Einstein\u2019s work, and it was not until 1927 that thermal noise in circuits was put on a rigorous mathematical footing, by two Swedes working at Bell Labs. John B. Johnson was the first to measure what he realized was noise intrinsic to the circuit, as opposed to evidence of flawed design. Then Harry Nyquist explained it, deriving formulas for the fluctuations in current and in voltage in an idealized network. Nyquist was the son of a farmer and shoemaker who was originally called Lars Jonsson but had to find a new name because his mail was getting mixed up with another Lars Jonsson\u2019s. The Nyquists immigrated to the United States when Harry was a teenager; he made his way from North Dakota to Bell Labs by way of Yale, where he got a doctorate in physics. He always seemed to have his eye on the big picture\u2014which did not mean telephony per se. As early as 1918, he began working on a method for transmitting pictures by wire: \u201ctelephotography.\u201d His\nidea was to mount a photograph on a spinning drum, scan it, and generate currents proportional to the lightness or darkness of the image. By 1924 the company had a working prototype that could send a five-by-seven-inch picture in seven minutes. But Nyquist meanwhile was looking backward, too, and that same year, at an electrical engineers\u2019 convention in Philadelphia, gave a talk with the modest title \u201cCertain Factors Affecting Telegraph Speed.\u201d\n\nIt had been known since the dawn of telegraphy that the fundamental units of messaging were discrete: dots and dashes. It became equally obvious in the telephone era that, on the contrary, useful information was continuous: sounds and colors, shading into one another, blending seamlessly along a spectrum of frequencies. So which was it? Physicists like Nyquist were dealing with electric currents as waveforms, even when they were conveying discrete telegraph signals. Nowadays most of the current in a telegraph line was being wasted. In Nyquist\u2019s way of thinking, if those continuous signals could represent anything as complex as voices, then the simple stuff of telegraphy was just a special case. Specifically, it was a special case of amplitude modulation, in which the only interesting amplitudes were on and off. By treating the telegraph signals as pulses in the shape of waveforms, engineers could speed their transmission and could combine them in a single circuit\u2014could combine them, too, with voice channels. Nyquist wanted to know how much\u2014how much telegraph data, how fast. To answer that question he found an ingenious approach to converting continuous waves into data that was discrete, or \u201cdigital.\u201d Nyquist\u2019s method was to sample the waves at intervals, in effect converting them into countable pieces.\n\nA circuit carried waves of many different frequencies: a \u201cband\u201d of waves, engineers would say. The range of frequencies\u2014the width of that band, or \u201cband width\u201d\u2014served as a measure of the capacity of the circuit. A telephone line could handle frequencies from about 400 to 3,400 hertz, or waves per second, for a bandwidth of 3,000 hertz. (That would cover most of the sound from an orchestra, but the high notes of the piccolo would be cut off.) Nyquist wanted to put this as generally as he could. He calculated a formula for the \u201cspeed of transmission of intelligence.\u201d To transmit intelligence at a certain speed, he showed, a channel needs a certain, measurable bandwidth. If the bandwidth was too small, it would be necessary to slow down the transmission. (But with time and ingenuity, it was realized later, even complex messages could be sent across a channel of very small bandwidth: a drum, for example, beaten by hand, sounding notes of only two pitches.)\n\nNyquist\u2019s colleague Ralph Hartley, who had begun his career as an expert on radio receivers, extended these results in a presentation in the summer of 1927, at an international congress on the shore of Lake Como, Italy. Hartley used a different word, \u201cinformation.\u201d It was a good occasion for grand ideas. Scientists\nhad gathered from around the world for the centennial of Alessandro Volta\u2019s death. Niels Bohr spoke on the new quantum theory and introduced for the first time his concept of complementarity. Hartley offered his listeners both a fundamental theorem and a new set of definitions.\n\nThe theorem was an extension of Nyquist\u2019s formula, and it could be expressed in words: the most information that can be transmitted in any given time is proportional to the available frequency range (he did not yet use the term bandwidth). Hartley was bringing into the open a set of ideas and assumptions that were becoming part of the unconscious culture of electrical engineering, and the culture of Bell Labs especially. First was the idea of information itself. He needed to pin a butterfly to the board. \u201cAs commonly used,\u201d he said, \u201cinformation is a very elastic term.\u201d It is the stuff of communication\u2014which, in turn, can be direct speech, writing, or anything else. Communication takes place by means of symbols\u2014Hartley cited for example \u201cwords\u201d and \u201cdots and dashes.\u201d The symbols, by common agreement, convey \u201cmeaning.\u201d So far, this was one slippery concept after another. If the goal was to \u201celiminate the psychological factors involved\u201d and to establish a measure \u201cin terms of purely physical quantities,\u201d Hartley needed something definite and countable. He began by counting symbols\u2014never mind what they meant. Any transmission contained a countable number of symbols. Each symbol represented a choice; each was selected from a certain set of possible symbols\u2014an alphabet, for example\u2014and the number of possibilities, too, was countable. The number of possible words is not so easy to count, but even in ordinary language, each word represents a selection from a set of possibilities:\n\nFor example, in the sentence, \u201cApples are red,\u201d the first word eliminated other kinds of fruit and all other objects in general. The second directs attention to some property or condition of apples, and the third eliminates other possible colors\u2026.\n\nThe number of symbols available at any one selection obviously varies widely with the type of symbols used, with the particular communicators and with the degree of previous understanding existing between them.\n\nHartley had to admit that some symbols might convey more information, as the word was commonly understood, than others. \u201cFor example, the single word \u2018yes\u2019 or \u2018no,\u2019 when coming at the end of a protracted discussion, may have an extraordinarily great significance.\u201d His listeners could think of their own examples. But the point was to subtract human knowledge from the equation. Telegraphs and telephones are, after all, stupid.\n\nIt seemed intuitively clear that the amount of information should be proportional to the number of symbols: twice as many symbols, twice as much information. But a dot or dash\u2014a symbol in a set with just two members\u2014carries less information than a letter of the alphabet and much less information than a\nword chosen from a thousand-word dictionary. The more possible symbols, the more information each selection carries. How much more? The equation, as Hartley wrote it, was this:\n\n\\[ H = n \\log s \\]\n\nwhere \\( H \\) is the amount of information, \\( n \\) is the number of symbols transmitted, and \\( s \\) is the size of the alphabet. In a dot-dash system, \\( s \\) is just 2. A single Chinese character carries so much more weight than a Morse dot or dash; it is so much more valuable. In a system with a symbol for every word in a thousand-word dictionary, \\( s \\) would be 1,000.\n\nThe amount of information is not proportional to the alphabet size, however. That relationship is logarithmic: to double the amount of information, it is necessary to square the alphabet size. Hartley illustrated this in terms of a printing telegraph\u2014one of the hodgepodge of devices, from obsolete to newfangled, being hooked up to electrical circuits. Such telegraphs used keypads arranged according to a system devised in France by \u00c9mile Baudot. The human operators used keypads, that is\u2014the device translated these key presses, as usual, into the opening and closing of telegraph contacts. The Baudot code used five units to transmit each character, so the number of possible characters was \\( 2^5 \\) or 32. In terms of information content, each such character was five times as valuable\u2014not thirty-two times\u2014as its basic binary units.\n\nTelephones, meanwhile, were sending their human voices across the network in happy, curvaceous analog waves. Where were the symbols in those? How could they be counted?\n\nHartley followed Nyquist in arguing that the continuous curve should be thought of as the limit approached by a succession of discrete steps, and that the steps could be recovered, in effect, by sampling the waveform at intervals. That way telephony could be made subject to the same mathematical treatment as telegraphy. By a crude but convincing analysis, he showed that in both cases the total amount of information would depend on two factors: the time available for transmission and the bandwidth of the channel. Phonograph records and motion pictures could be analyzed the same way.\n\nThese odd papers by Nyquist and Hartley attracted little immediate attention. They were hardly suitable for any prestigious journal of mathematics or physics, but Bell Labs had its own, *The Bell System Technical Journal*, and Claude Shannon read them there. He absorbed the mathematical insights, sketchy though they were\u2014first awkward steps toward a shadowy goal. He noted also the difficulties both men had in defining their terms. \u201cBy the speed of transmission of intelligence is meant the number of characters, representing different letters, figures, etc., which can be transmitted in a given length of time.\u201d Characters,\nletters, figures: hard to count. There were concepts, too, for which terms had yet to be invented: \u201cthe capacity of a system to transmit a particular sequence of symbols \u2026\u201d\n\nTHE BAUDOT CODE\n\nShannon felt the promise of unification. The communications engineers were talking not just about wires but also the air, the \u201cether,\u201d and even punched tape. They were contemplating not just words but also sounds and images. They were representing the whole world as symbols, in electricity.\n\n* In an evaluation forty years later the geneticist James F. Crow wrote: \u201cIt seems to have been written in complete isolation from the population genetics community\u2026. [Shannon] discovered principles that were rediscovered later\u2026. My regret is that [it] did not become widely known in 1940. It would have changed the history of the subject substantially, I think.\u201d\n\n* In standard English, as Russell noted, it is one hundred and eleven thousand seven hundred and seventy-seven.\n7 | INFORMATION THEORY\n\n(All I\u2019m After Is Just a Mundane Brain)\n\nPerhaps coming up with a theory of information and its processing is a bit like building a transcontinental railway. You can start in the east, trying to understand how agents can process anything, and head west. Or you can start in the west, with trying to understand what information is, and then head east. One hopes that these tracks will meet.\n\n\u2014Jon Barwise (1986)\n\nAT THE HEIGHT OF THE WAR, in early 1943, two like-minded thinkers, Claude Shannon and Alan Turing, met daily at teatime in the Bell Labs cafeteria and said nothing to each other about their work, because it was secret. Both men had become cryptanalysts. Even Turing\u2019s presence at Bell Labs was a sort of secret. He had come over on the Queen Elizabeth, zigzagging to elude U-boats, after a clandestine triumph at Bletchley Park in deciphering Enigma, the code used by the German military for its critical communication (including signals to the U-boats). Shannon was working on the X System, used for encrypting voice conversations between Franklin D. Roosevelt at the Pentagon and Winston Churchill in his War Rooms. It operated by sampling the analog voice signal fifty times a second\u2014\u201cquantizing\u201d or \u201cdigitizing\u201d it\u2014and masking it by applying a random key, which happened to bear a strong resemblance to the circuit noise with which the engineers were so familiar. Shannon did not design the system; he was assigned to analyze it theoretically and\u2014it was hoped\u2014prove it to be unbreakable. He accomplished this. It was clear later that these men, on their respective sides of the Atlantic, had done more than anyone else to turn cryptography from an art into a science, but for now the code makers and code breakers were not talking to each other.\n\nWith that subject off the table, Turing showed Shannon a paper he had written seven years earlier, called \u201cOn Computable Numbers,\u201d about the powers and limitations of an idealized computing machine. They talked about another topic that turned out to be close to their hearts, the possibility of machines learning to think. Shannon proposed feeding \u201ccultural things,\u201d such as music, to an electronic brain, and they outdid each other in brashness, Turing exclaiming once, \u201cNo, I\u2019m not interested in developing a powerful brain. All I\u2019m after is just a mundane brain, something like the president of the American Telephone & Telegraph\nCompany.\u201d It bordered on impudence to talk about thinking machines in 1943, when both the transistor and the electronic computer had yet to be born. The vision Shannon and Turing shared had nothing to do with electronics; it was about logic.\n\n*Can machines think?* was a question with a relatively brief and slightly odd tradition\u2014odd because machines were so adamantly physical in themselves. Charles Babbage and Ada Lovelace lay near the beginning of this tradition, though they were all but forgotten, and now the trail led to Alan Turing, who did something really outlandish: thought up a machine with ideal powers in the mental realm and showed what it could *not* do. His machine never existed (except that now it exists everywhere). It was only a thought experiment.\n\nRunning alongside the issue of what a machine could do was a parallel issue: what tasks were *mechanical* (an old word with new significance). Now that machines could play music, capture images, aim antiaircraft guns, connect telephone calls, control assembly lines, and perform mathematical calculations, the word did not seem quite so pejorative. But only the fearful and superstitious imagined that machines could be creative or original or spontaneous; those qualities were opposite to *mechanical*, which meant automatic, determined, and routine. This concept now came in handy for philosophers. An example of an intellectual object that could be called mechanical was the algorithm: another new term for something that had always existed (a recipe, a set of instructions, a step-by-step procedure) but now demanded formal recognition. Babbage and Lovelace trafficked in algorithms without naming them. The twentieth century gave algorithms a central role\u2014beginning here.\n\nTuring was a fellow and a recent graduate at King\u2019s College, Cambridge, when he presented his computable-numbers paper to his professor in 1936. The full title finished with a flourish in fancy German: it was \u201cOn Computable Numbers, with an Application to the *Entscheidungsproblem*.\u201d The \u201cdecision problem\u201d was a challenge that had been posed by David Hilbert at the 1928 International Congress of Mathematicians. As perhaps the most influential mathematician of his time, Hilbert, like Russell and Whitehead, believed fervently in the mission of rooting all mathematics in a solid logical foundation\u2014\u201c*In der Mathematik gibt es kein Ignorabimus,*\u201d he declared. (\u201cIn mathematics there is no *we will not know.*\u201d) Of course mathematics had many unsolved problems, some quite famous, such as Fermat\u2019s Last Theorem and the Goldbach conjecture\u2014statements that seemed true but had not been proved. Had not *yet* been proved, most people thought. There was an assumption, even a faith, that any mathematical truth would be provable, someday.\n\nThe *Entscheidungsproblem* was to find a rigorous step-by-step procedure by which, given a formal language of deductive reasoning, one could perform a\nproof automatically. This was Leibniz\u2019s dream revived once again: the expression of all valid reasoning in mechanical rules. Hilbert posed it in the form of a question, but he was an optimist. He thought or hoped that he knew the answer. It was just then, at this watershed moment for mathematics and logic, that G\u00f6del threw his incompleteness theorem into the works. In flavor, at least, G\u00f6del\u2019s result seemed a perfect antidote to Hilbert\u2019s optimism, as it was to Russell\u2019s. But G\u00f6del actually left the Entscheidungsproblem unanswered. Hilbert had distinguished among three questions:\n\n- Is mathematics complete?\n- Is mathematics consistent?\n- Is mathematics decidable?\n\nG\u00f6del showed that mathematics could not be both complete and consistent but had not definitively answered the third question, at least not for all mathematics. Even though a particular closed system of formal logic must contain statements that could neither be proved nor disproved from within the system, it might conceivably be decided, as it were, by an outside referee\u2014by external logic or rules.\n\nAlan Turing, just twenty-two years old, unfamiliar with much of the relevant literature, so alone in his work habits that his professor worried about his becoming \u201ca confirmed solitary,\u201d posed an entirely different question (it seemed): Are all numbers computable? This was an unexpected question to begin with, because hardly anyone had considered the idea of an uncomputable number. Most numbers that people work with, or think about, are computable by definition. The rational numbers are computable because they can be expressed as the quotient of two integers, \\( \\frac{a}{b} \\). The algebraic numbers are computable because they are solutions of polynomial equations. Famous numbers like \\( \\pi \\) and \\( e \\) are computable; people compute them all the time. Nonetheless Turing made the seemingly mild statement that numbers might exist that are somehow nameable, definable, and not computable.\n\nWhat did this mean? He defined a computable number as one whose decimal expression can be calculated by finite means. \u201cThe justification,\u201d he said, \u201clies in the fact that the human memory is necessarily limited.\u201d He also defined calculation as a mechanical procedure, an algorithm. Humans solve problems with intuition, imagination, flashes of insight\u2014arguably nonmechanical calculation, or then again perhaps just computation whose steps are hidden. Turing needed to eliminate the ineffable. He asked, quite literally, what would a machine do? \u201cAccording to my definition, a number is computable if its decimal can be written down by a machine.\u201d\n\nNo actual machine offered a relevant model. \u201cComputers\u201d were, as ever,\npeople. Nearly all the world\u2019s computation was still performed through the act of writing marks on paper. Turing did have one information machine for a starting point: the typewriter. As an eleven-year-old sent to boarding school he had imagined inventing one. \u201cYou see,\u201d he wrote to his parents, \u201cthe funny little rounds are letters cut out on one side slide along to the round \u24d0 along an ink pad and stamp down and make the letter, thats not nearly all though.\u201d Of course, a typewriter is not automatic; it is more a tool than a machine. It does not flow a stream of language onto the page; rather, the page shifts its position space by space under the hammer, where one character is laid down after another. With this model in mind, Turing imagined another kind of machine, of the utmost purity and simplicity. Being imaginary, it was unencumbered by the real-world details one would need for a blueprint, an engineering specification, or a patent application. Turing, like Babbage, meant his machine to compute numbers, but he had no need to worry about the limitations of iron and brass. Turing did not plan ever to build his machine.\n\nHe listed the very few items his machine must possess: tape, symbols, and states. Each of these required definition.\n\n*Tape* is to the Turing machine what paper is to a typewriter. But where a typewriter uses two dimensions of its paper, the machine uses only one\u2014thus, a tape, a long strip, divided into squares. \u201cIn elementary arithmetic the two-dimensional character of the paper is sometimes used,\u201d he wrote. \u201cBut such a use is always avoidable, and I think that it will be agreed that the two-dimensional character of paper is no essential of computation.\u201d The tape is to be thought of as infinite: there is always more when needed. But just one square is \u201cin the machine\u201d at any given time. The tape (or the machine) can move left or right, to the next square.\n\n*Symbols* can be written onto the tape, one per square. How many symbols could be used? This required some thought, especially to make sure the number was finite. Turing observed that words\u2014in European languages, at least\u2014behaved as individual symbols. Chinese, he said, \u201cattempts to have an enumerable infinity of symbols.\u201d Arabic numerals might also be considered infinite, if 17 and 999,999,999,999,999 were treated as single symbols, but he preferred to treat them as compound: \u201cIt is always possible to use sequences of symbols in the place of single symbols.\u201d In fact, in keeping with the machine\u2019s minimalist spirit, he favored the absolute minimum of two symbols: binary notation, zeroes and ones. Symbols were not only to be written but also read from the tape\u2014\u201cscanned\u201d was the word Turing used. In reality, of course, no technology could yet scan symbols written on paper back into a machine, but there were equivalents: for example, punched cards, now used in tabulating machines. Turing specified one more limitation: the machine is \u201caware\u201d (only the\nanthropomorphic word would do) of one symbol at a time\u2014the one on the square that is in the machine.\n\nStates required more explaining. Turing used the word \u201cconfigurations\u201d and pointed out that these resembled \u201cstates of mind.\u201d The machine has a few of these\u2014some finite number. In any given state, the machine takes one or more actions depending on the current symbol. For example, in state $a$, the machine might move one square to the right if the current symbol is 1, or move one square to the left if the current symbol is 0, or print 1 if the current symbol is blank. In state $b$, the machine might erase the current symbol. In state $c$, if the symbol is 0 or 1, the machine might move to the right, and otherwise stop. After each action, the machine finishes in a new state, which might be the same or different. The various states used for a given calculation were stored in a table\u2014how this was to be managed physically did not matter. The state table was, in effect, the machine\u2019s set of instructions.\n\nAnd this was all.\n\nTuring was programming his machine, though he did not yet use that word. From the primitive actions\u2014moving, printing, erasing, changing state, and stopping\u2014larger processes were built up, and these were used again and again: \u201ccopying down sequences of symbols, comparing sequences, erasing all symbols of a given form, etc.\u201d The machine can see just one symbol at a time, but can in effect use parts of the tape to store information temporarily. As Turing put it, \u201cSome of the symbols written down \u2026 are just rough notes \u2018to assist the memory.\u2019 \u201d The tape, unfurling to the horizon and beyond, provides an unbounded record. In this way all arithmetic lies within the machine\u2019s grasp. Turing showed how to add a pair of numbers\u2014that is, he wrote out the necessary table of states. He showed how to make the machine print out (endlessly) the binary representation of $\\pi$. He spent considerable time working out what the machine could do and how it would accomplish particular tasks. He demonstrated that this short list covers everything a person does in computing a number. No other knowledge or intuition is necessary. Anything computable can be computed by this machine.\n\nThen came the final flourish. Turing\u2019s machines, stripped down to a finite table of states and a finite set of input, could themselves be represented as numbers. Every possible state table, combined with its initial tape, represents a different machine. Each machine itself, then, can be described by a particular number\u2014a certain state table combined with its initial tape. Turing was encoding his machines just as G\u00f6del had encoded the language of symbolic logic. This obliterated the distinction between data and instructions: in the end they were all numbers. For every computable number, there must be a corresponding machine number.\nTuring produced (still in his mind\u2019s eye) a version of the machine that could simulate every other possible machine\u2014every digital computer. He called this machine $U$, for \u201cuniversal,\u201d and mathematicians fondly use the name $U$ to this day. It takes machine numbers as input. That is, it reads the descriptions of other machines from its tape\u2014their algorithms and their own input. No matter how complex a digital computer may grow, its description can still be encoded on tape to be read by $U$. If a problem can be solved by any digital computer\u2014encoded in symbols and solved algorithmically\u2014the universal machine can solve it as well.\n\nNow the microscope is turned onto itself. The Turing machine sets about examining every number to see whether it corresponds to a computable algorithm. Some will prove computable. Some might prove uncomputable. And there is a third possibility, the one that most interested Turing. Some algorithms might defy the inspector, causing the machine to march along, performing its inscrutable business, never coming to a halt, never obviously repeating itself, and leaving the logical observer forever in the dark about whether it would halt.\n\nBy now Turing\u2019s argument, as published in 1936, has become a knotty masterpiece of recursive definitions, symbols invented to represent other symbols, numbers standing in for numbers, for state tables, for algorithms, for machines. In print it looked like this:\n\nBy combining the machines $D$ and $U$ we could construct a machine $M$ to compute the sequence $\\beta'$. The machine $D$ may require a tape. We may suppose that it uses the $E$-squares beyond all symbols on $F$-squares, and that when it has reached its verdict all the rough work done by $D$ is erased\u2026.\n\nWe can show further that there can be no machine $E$ which, when applied with the S.D of an arbitrary machine $M$, will determine whether $M$ ever prints a given symbol (0 say).\n\nFew could follow it. It seems paradoxical\u2014it is paradoxical\u2014but Turing proved that some numbers are uncomputable. (In fact, most are.)\n\nAlso, because every number corresponds to an encoded proposition of mathematics and logic, Turing had resolved Hilbert\u2019s question about whether every proposition is decidable. He had proved that the Entscheidungsproblem has an answer, and the answer is no. An uncomputable number is, in effect, an undecidable proposition.\n\nSo Turing\u2019s computer\u2014a fanciful, abstract, wholly imaginary machine\u2014led him to a proof parallel to G\u00f6del\u2019s. Turing went further than G\u00f6del by defining the general concept of a formal system. Any mechanical procedure for generating formulas is essentially a Turing machine. Any formal system, therefore, must have undecidable propositions. Mathematics is not decidable. Incompleteness follows from uncomputability.\n\nOnce again, the paradoxes come to life when numbers gain the power to\nencode the machine\u2019s own behavior. That is the necessary recursive twist. The entity being reckoned is fatally entwined with the entity doing the reckoning. As Douglas Hofstadter put it much later, \u201cThe thing hinges on getting this halting inspector to try to predict its own behavior when looking at itself trying to predict its own behavior when looking at itself trying to predict its own behavior when \u2026\u201d A conundrum that at least smelled similar had lately appeared in physics, too: Werner Heisenberg\u2019s new uncertainty principle. When Turing learned about that, he expressed it in terms of self-reference: \u201cIt used to be supposed in Science that if everything was known about the Universe at any particular moment then we can predict what it will be through all the future\u2026. More modern science however has come to the conclusion that when we are dealing with atoms and electrons we are quite unable to know the exact state of them; our instruments being made of atoms and electrons themselves.\u201d\n\nA century had passed between Babbage\u2019s Analytical Engine and Turing\u2019s Universal Machine\u2014a grand and unwieldy contraption and an elegant unreal abstraction. Turing never even tried to be a machinist. \u201cOne can picture an industrious and diligent clerk, well supplied with scratch paper, tirelessly following his instructions,\u201d as the mathematician and logician Herbert Enderton remarked years later. Like Ada Lovelace, Turing was a programmer, looking inward to the step-by-step logic of his own mind. He imagined himself as a computer. He distilled mental procedures into their smallest constituent parts, the atoms of information processing.\n\nAlan Turing and Claude Shannon had codes in common. Turing encoded instructions as numbers. He encoded decimal numbers as zeroes and ones. Shannon made codes for genes and chromosomes and relays and switches. Both men applied their ingenuity to mapping one set of objects onto another: logical operators and electric circuits; algebraic functions and machine instructions. The play of symbols and the idea of mapping, in the sense of finding a rigorous correspondence between two sets, had a prominent place in their mental arsenals. This kind of coding was not meant to obscure but to illuminate: to discover that apples and oranges were after all equivalent, or if not equivalent then fungible. The war brought both men to cryptography in its most riddling forms.\n\nTuring\u2019s mother often asked him what use his mathematics had, and he told her as early as 1936 that he had discovered a possible application: \u201ca lot of particular and interesting codes.\u201d He added, \u201cI expect I could sell them to H. M. Government for quite a substantial sum, but am rather doubtful about the morality of such things.\u201d Indeed, a Turing machine could make ciphers. But His Majesty\u2019s Government turned out to have a different problem. As war loomed, the task of reading messages intercepted from German cable and wireless traffic fell to the\nGovernment Code and Cypher School, originally part of the Admiralty, with a staff at first composed of linguists, clerks, and typists, but no mathematicians. Turing was recruited in the summer of 1938. When the Code and Cypher School evacuated from London to Bletchley Park, a country mansion in Buckinghamshire, he went along with a team that also included some champions at chess and crossword-puzzle solving. It was clear now that classical language scholarship had little to contribute to cryptanalysis.\n\nThe German system, named Enigma, employed a polyalphabetic cipher implemented by a rotor machine the size of a suitcase, with a typewriter keyboard and signal lamps. The cipher had evolved from a famous ancestor, the Vigen\u00e8re cipher, thought to be unbreakable until Charles Babbage cracked it in 1854, and Babbage\u2019s mathematical insight gave Bletchley early help, as did work by Polish cryptographers who had the first hard years of experience with the Wehrmacht\u2019s signal traffic. Working from a warren known as Hut 8, Turing took the theoretical lead and solved the problem, not just mathematically but physically.\n\nThis meant building a machine to invert the enciphering of any number of Enigmas. Where his first machine was a phantasm of hypothetical tape, this one, dubbed the Bombe, filled ninety cubic feet with a ton of wire and metal leaking oil and effectively mapping the rotors of the German device onto electric circuitry. The scientific triumph at Bletchley\u2014secret for the duration of the war and for thirty years after\u2014had a greater effect on the outcome than even the Manhattan Project, the real bomb. By the war\u2019s end, the Turing Bombes were deciphering thousands of military intercepts every day: processing information, that is, on a scale never before seen.\nAlthough nothing of this passed between Turing and Shannon when they met for meals at Bell Labs, they did talk indirectly about a notion of Turing\u2019s about how to measure all this stuff. He had watched analysts weigh the messages passing through Bletchley, some uncertain and some contradictory, as they tried to assess the probability of some fact\u2014a particular Enigma code setting, for example, or the location of a submarine. He felt that something here needed measuring, mathematically. It was not the probability, which would traditionally be expressed as an odds ratio (such as three to two) or a number from zero to one (such as 0.6, or 60 percent). Rather, Turing cared about the data that changed the probability: a probability factor, something like the weight of evidence. He invented a unit he named a \u201cban.\u201d He found it convenient to use a logarithmic scale, so that bans would be added rather than multiplied. With a base of ten, a ban was the weight of evidence needed to make a fact ten times as likely. For more fine-grained measurement there were \u201cdecibans\u201d and \u201ccentibans.\u201d\n\nShannon had a notion along similar lines.\n\nWorking in the old West Village headquarters, he developed theoretical ideas about cryptography that helped him focus the dream he had intimated to Vannevar Bush: his \u201canalysis of some of the fundamental properties of general systems for the transmission of intelligence.\u201d He followed parallel tracks all during the war, showing his supervisors the cryptography work and concealing the rest. Concealment was the order of the day. In the realm of pure mathematics, Shannon treated some of the same ciphering systems that Turing was attacking with real intercepts and brute hardware\u2014for example, the specific question of the safety of Vigen\u00e8re cryptograms when \u201cthe enemy knows the system being used.\u201d (The Germans were using just such cryptograms, and the British were the enemy who knew the system.) Shannon was looking at the most general cases, all involving, as he put it, \u201cdiscrete information.\u201d That meant sequences of symbols, chosen from a finite set, mainly letters of the alphabet but also words of a language and even \u201cquantized speech,\u201d voice signals broken into packets with different amplitude levels. To conceal these meant substituting wrong symbols for the right ones, according to some systematic procedure in which a key is known to the receiver of the message, who can use it to reverse the substitutions. A secure system works even when the enemy knows the procedure, as long as the key remains secret.\n\nThe code breakers see a stream of data that looks like junk. They want to find the real signal. \u201cFrom the point of view of the cryptanalyst,\u201d Shannon noted, \u201ca secrecy system is almost identical with a noisy communication system.\u201d (He completed his report, \u201cA Mathematical Theory of Cryptography,\u201d in 1945; it was\nimmediately classified.) The data stream is meant to look stochastic, or random, but of course it is not: if it were truly random the signal would be lost. The cipher must transform a patterned thing, ordinary language, into something apparently without pattern. But pattern is surprisingly persistent. To analyze and categorize the transformations of ciphering, Shannon had to understand the patterns of language in a way that scholars\u2014linguists, for example\u2014had never done before. Linguists had, however, begun to focus their discipline on structure in language\u2014system to be found amid the vague billowing shapes and sounds. The linguist Edward Sapir wrote of \u201csymbolic atoms\u201d formed by a language\u2019s underlying phonetic patterns. \u201cThe mere sounds of speech,\u201d he wrote in 1921, \u201care not the essential fact of language, which lies rather in the classification, in the formal patterning\u2026. Language, as a structure, is on its inner face the mold of thought.\u201d Mold of thought was exquisite. Shannon, however, needed to view language in terms more tangible and countable.\n\nPattern, as he saw it, equals redundancy. In ordinary language, redundancy serves as an aid to understanding. In cryptanalysis, that same redundancy is the Achilles\u2019 heel. Where is this redundancy? As a simple example in English, wherever the letter q appears, the u that follows is redundant. (Or almost\u2014it would be entirely redundant were it not for rare borrowed items like qin and Qatar.) After q, a u is expected. There is no surprise. It contributes no information. After the letter t, an h has a certain amount of redundancy, because it is the likeliest letter to appear. Every language has a certain statistical structure, Shannon argued, and with it a certain redundancy. Let us call this (he suggested) D. \u201cD measures, in a sense, how much a text in the language can be reduced in length without losing any information.\u201d\n\nShannon estimated that English has redundancy of about 50 percent.* Without computers to process masses of text, he could not be sure, but his estimate proved correct. Typical passages can be shortened by half without loss of information. (If u cn rd ths \u2026) With the simplest early substitution ciphers, this redundancy provided the point of first weakness. Edgar Allan Poe knew that when a cryptogram contained more z\u2019s than any other letter, then z was probably the substitute for e, since e is the most frequent letter in English. As soon as q was solved, so was u. A code breaker looked for recurring patterns that might match common words or letter combinations: the, and, -tion. To perfect this kind of frequency analysis, code breakers needed better information about letter frequencies than Alfred Vail or Samuel Morse had been able to get by examining printers\u2019 type trays, and anyway, more clever ciphers overcame this weakness, by constantly varying the substitution alphabet, so that every letter had many possible substitutes. The obvious, recognizable patterns vanished. But as long as a cryptogram retained any trace of patterning\u2014any form or sequence or statistical\nregularity\u2014a mathematician could, in theory, find a way in.\n\nWhat all secrecy systems had in common was the use of a key: a code word, or phrase, or an entire book, or something even more complex, but in any case a source of characters known to both the sender and receiver\u2014knowledge shared apart from the message itself. In the German Enigma system, the key was internalized in hardware and changed daily; Bletchley Park had to rediscover it anew each time, its experts sussing out the patterns of language freshly transformed. Shannon, meanwhile, removed himself to the most distant, most general, most theoretical vantage point. A secrecy system comprised a finite (though possibly very large) number of possible messages, a finite number of possible cryptograms, and in between, transforming one to the other, a finite number of keys, each with an associated probability. This was his schematic diagram:\n\n(Illustration credit 7.2)\n\nThe enemy and the recipient are trying to arrive at the same target: the message. By framing it this way, in terms of mathematics and probabilities, Shannon had utterly abstracted the idea of the message from its physical details. Sounds, waveforms, all the customary worries of a Bell Labs engineer\u2014none of these mattered. The message was seen as a choice: one alternative selected from a set. At Old North Church the night of Paul Revere\u2019s ride, the number of possible messages was two. Nowadays the numbers were almost uncountable\u2014but still susceptible to statistical analysis.\n\nStill in the dark about the very real and utterly relevant experience at Bletchley Park, Shannon built an edifice of algebraic methods, theorems, and proofs that gave cryptologists what they had never before possessed: a rigorous way of assessing the security of any secrecy system. He established the scientific\nprinciples of cryptography. Among other things, he proved that perfect ciphers were possible\u2014\u201cperfect\u201d meaning that even an infinitely long captured message would not help a code breaker (\u201cthe enemy is no better off after intercepting any amount of material than before\u201d). But as he gave, so he took away, because he also proved that the requirements were so severe as to make them practically useless. In a perfect cipher, all keys must be equally likely, in effect, a random stream of characters; each key can be used only once; and, worst of all, each key must be as long as the entire message.\n\nAlso in this secret paper, almost in passing, Shannon used a phrase he had never used before: \u201cinformation theory.\u201d\n\nFirst Shannon had to eradicate \u201cmeaning.\u201d The germicidal quotation marks were his. \u201cThe \u2018meaning\u2019 of a message is generally irrelevant,\u201d he proposed cheerfully.\n\nHe offered this provocation in order to make his purpose utterly clear. Shannon needed, if he were to create a theory, to hijack the word *information*. \u201c\u2018Information\u2019 here,\u201d he wrote, \u201calthough related to the everyday meaning of the word, should not be confused with it.\u201d Like Nyquist and Hartley before him, he wished to leave aside \u201cthe psychological factors\u201d and focus only on \u201cthe physical.\u201d But if information was divorced from semantic content, what was left? A few things could be said, and at first blush they all sounded paradoxical. Information is uncertainty, surprise, difficulty, and entropy:\n\n- \u201cInformation is closely associated with uncertainty.\u201d Uncertainty, in turn, can be measured by counting the number of possible messages. If only one message is possible, there is no uncertainty and thus no information.\n- Some messages may be likelier than others, and information implies surprise. Surprise is a way of talking about probabilities. If the letter following $t$ (in English) is $h$, not so much information is conveyed, because the probability of $h$ was relatively high.\n- \u201cWhat is significant is the difficulty in transmitting the message from one point to another.\u201d Perhaps this seemed backward, or tautological, like defining mass in terms of the force needed to move an object. But then, mass *can* be defined that way.\n- Information is entropy. This was the strangest and most powerful notion of all. Entropy\u2014already a difficult and poorly understood concept\u2014is a measure of disorder in thermodynamics, the science of heat and energy.\n\nFire control and cryptography aside, Shannon had been pursuing this haze of ideas all through the war. Living alone in a Greenwich Village apartment, he seldom socialized with his colleagues, who mainly worked now in the New\nJersey headquarters, while Shannon preferred the old West Street hulk. He did not have to explain himself. His war work got him deferred from military service and the deferment continued after the war ended. Bell Labs was a rigorously male enterprise, but in wartime the computing group, especially, badly needed competent staff and began hiring women, among them Betty Moore, who had grown up on Staten Island. It was like a typing pool for math majors, she thought. After a year she was promoted to the microwave research group, in the former Nabisco building\u2014the \u201ccracker factory\u201d\u2014across West Street from the main building. The group designed tubes on the second floor and built them on the first floor and every so often Claude wandered over to visit. He and Betty began dating in 1948 and married early in 1949. Just then he was the scientist everyone was talking about.\n\nFew libraries carried *The Bell System Technical Journal*, so researchers heard about \u201cA Mathematical Theory of Communication\u201d the traditional way, by word of mouth, and obtained copies the traditional way, by writing directly to the author for an offprint. Many scientists used preprinted postcards for such requests, and these arrived in growing volume over the next year. Not everyone understood the paper. The mathematics was difficult for many engineers, and mathematicians meanwhile lacked the engineering context. But Warren Weaver, the director of natural sciences for the Rockefeller Foundation uptown, was already telling his president that Shannon had done for communication theory \u201cwhat Gibbs did for physical chemistry.\u201d Weaver had headed the government\u2019s applied mathematics research during the war, supervising the fire-control project as well as nascent work in electronic calculating machines. In 1949 he wrote up an appreciative and not too technical essay about Shannon\u2019s theory for *Scientific American*, and late that year the two pieces\u2014Weaver\u2019s essay and Shannon\u2019s monograph\u2014were published together as a book, now titled with a grander first word *The Mathematical Theory of Communication*. To John Robinson Pierce, the Bell Labs engineer who had been watching the simultaneous gestation of the transistor and Shannon\u2019s paper, it was the latter that \u201ccame as a bomb, and something of a delayed action bomb.\u201d\nWhere a layman might have said that the fundamental problem of communication is to make oneself understood\u2014to convey meaning\u2014Shannon set the stage differently:\n\nThe fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point.\n\n\u201cPoint\u201d was a carefully chosen word: the origin and destination of a message could be separated in space or in time; information storage, as in a phonograph record, counts as a communication. Meanwhile, the message is not created; it is selected. It is a choice. It might be a card dealt from a deck, or three decimal digits chosen from the thousand possibilities, or a combination of words from a fixed code book. He could hardly overlook meaning altogether, so he dressed it with a scientist\u2019s definition and then showed it the door:\n\nFrequently the messages have *meaning*: that is they refer to or are correlated according to some system with certain physical or conceptual entities. These semantic aspects of communication are irrelevant to the engineering problem.\n\nNonetheless, as Weaver took pains to explain, this was not a narrow view of communication. On the contrary, it was all-encompassing: \u201cnot only written and oral speech, but also music, the pictorial arts, the theatre, the ballet, and in fact all human behavior.\u201d Nonhuman as well: why should machines not have messages to send?\nShannon\u2019s model for communication fit a simple diagram\u2014essentially the same diagram, by no coincidence, as in his secret cryptography paper.\n\nA communication system must contain the following elements:\n\n- The information source is the person or machine generating the message, which may be simply a sequence of characters, as in a telegraph or teletype, or may be expressed mathematically as functions\u2014$f(x, y, t)$\u2014of time and other variables. In a complex example like color television, the components are three functions in a three-dimensional continuum, Shannon noted.\n\n- The transmitter \u201coperates on the message in some way\u201d\u2014that is, encodes the message\u2014to produce a suitable signal. A telephone converts sound pressure into analog electric current. A telegraph encodes characters in dots, dashes, and spaces. More complex messages may be sampled, compressed, quantized, and interleaved.\n\n- The channel: \u201cmerely the medium used to transmit the signal.\u201d\n\n- The receiver inverts the operation of the transmitter. It decodes the message, or reconstructs it from the signal.\n\n- The destination \u201cis the person (or thing)\u201d at the other end.\n\nIn the case of ordinary speech, these elements are the speaker\u2019s brain, the speaker\u2019s vocal cords, the air, the listener\u2019s ear, and the listener\u2019s brain.\n\nAs prominent as the other elements in Shannon\u2019s diagram\u2014because for an engineer it is inescapable\u2014is a box labeled \u201cNoise Source.\u201d This covers everything that corrupts the signal, predictably or unpredictably: unwanted additions, plain errors, random disturbances, static, \u201catmospherics,\u201d interference, and distortion. An unruly family under any circumstances, and Shannon had two different types of systems to deal with, continuous and discrete. In a discrete system, message and signal take the form of individual detached symbols, such as characters or digits or dots and dashes. Telegraphy notwithstanding, continuous systems of waves and functions were the ones facing electrical engineers every day. Every engineer, when asked to push more information through a channel,\nknew what to do: boost the power. Over long distances, however, this approach was failing, because amplifying a signal again and again leads to a crippling buildup of noise.\n\nShannon sidestepped this problem by treating the signal as a string of discrete symbols. Now, instead of boosting the power, a sender can overcome noise by using extra symbols for error correction\u2014just as an African drummer makes himself understood across long distances, not by banging the drums harder, but by expanding the verbosity of his discourse. Shannon considered the discrete case to be more fundamental in a mathematical sense as well. And he was considering another point: that treating messages as discrete had application not just for traditional communication but for a new and rather esoteric subfield, the theory of computing machines.\n\nSo back he went to the telegraph. Analyzed precisely, the telegraph did not use a language with just two symbols, dot and dash. In the real world telegraphers used dot (one unit of \u201cline closed\u201d and one unit of \u201cline open\u201d), dash (three units, say, of line closed and one unit of line open), and also two distinct spaces: a letter space (typically three units of line open) and a longer space separating words (six units of line open). These four symbols have unequal status and probability. For example, a space can never follow another space, whereas a dot or dash can follow anything. Shannon expressed this in terms of states. The system has two states: in one, a space was the previous symbol and only a dot or dash is allowed, and the state then changes; in the other, any symbol is allowed, and the state changes only if a space is transmitted. He illustrated this as a graph:\n\n![Diagram](Illustration credit 7.4)\n\nThis was far from a simple, binary system of encoding. Nonetheless Shannon showed how to derive the correct equations for information content and channel capacity. More important, he focused on the effect of the statistical structure of the language of the message. The very existence of this structure\u2014the greater\nfrequency of $e$ than $q$, of $th$ than $xp$, and so forth\u2014allows for a saving of time or channel capacity.\n\nThis is already done to a limited extent in telegraphy by using the shortest channel sequence, a dot, for the most common English letter E; while the infrequent letters, Q, X, Z are represented by longer sequences of dots and dashes. This idea is carried still further in certain commercial codes where common words and phrases are represented by four- or five-letter code groups with a considerable saving in average time. The standardized greeting and anniversary telegrams now in use extend this to the point of encoding a sentence or two into a relatively short sequence of numbers.\n\nTo illuminate the structure of the message Shannon turned to some methodology and language from the physics of stochastic processes, from Brownian motion to stellar dynamics. (He cited a landmark 1943 paper by the astrophysicist Subrahmanyan Chandrasekhar in *Reviews of Modern Physics*.) A stochastic process is neither deterministic (the next event can be calculated with certainty) nor random (the next event is totally free). It is governed by a set of probabilities. Each event has a probability that depends on the state of the system and perhaps also on its previous history. If for *event* we substitute *symbol*, then a natural written language like English or Chinese is a stochastic process. So is digitized speech; so is a television signal.\n\nLooking more deeply, Shannon examined statistical structure in terms of how much of a message influences the probability of the next symbol. The answer could be none: each symbol has its own probability but does not depend on what came before. This is the first-order case. In the second-order case, the probability of each symbol depends on the symbol immediately before, but not on any others. Then each two-character combination, or digram, has its own probability: $th$ greater than $xp$, in English. In the third-order case, one looks at trigrams, and so forth. Beyond that, in ordinary text, it makes sense to look at the level of words rather than individual characters, and many types of statistical facts come into play. Immediately after the word *yellow*, some words have a higher probability than usual and others virtually zero. After the word *an*, words beginning with consonants become exceedingly rare. If the letter $u$ ends a word, the word is probably *you*. If two consecutive letters are the same, they are probably *ll*, *ee*, *ss*, or *oo*. And structure can extend over long distances: in a message containing the word *cow*, even after many other characters intervene, the word *cow* is relatively likely to occur again. As is the word *horse*. A message, as Shannon saw, can behave like a dynamical system whose future course is conditioned by its past history.\n\nTo illustrate the differences between these different orders of structure, he wrote down\u2014computed, really\u2014a series of \u201capproximations\u201d of English text. He used an alphabet of twenty-seven characters, the letters plus a space between words, and generated strings of characters with the help of a table of random\nnumbers. (These he drew from a book newly published for such purposes by Cambridge University Press: 100,000 digits for three shillings nine pence, and the authors \u201chave furnished a guarantee of the random arrangement.\u201d) Even with random numbers presupplied, working out the sequences was painstaking. The sample texts looked like this:\n\n- **\u201cZero-order approximation\u201d\u2014that is, random characters, no structure or correlations.**\n  \n  XFOML RXKHRJFFJUJ ZLPWCFWKCYJ\n  FFJEYVKCQSGHYD GPAAMKBZAACIBZLHJGD.\n\n- **First order\u2014each character is independent of the rest, but the frequencies are those expected in English: more e\u2019s and t\u2019s, fewer z\u2019s and j\u2019s, and the word lengths look realistic.**\n  \n  OCRO HLI RGWR NIMILWIS EU LL NBNESEBYA\n  TH EEI ALHENHTTPA OOBTTVA NAH BRL.\n\n- **Second order\u2014the frequencies of each character match English and so also do the frequencies of each digram, or letter pair. (Shannon found the necessary statistics in tables constructed for use by code breakers. The most common digram in English is th, with a frequency of 168 per thousand words, followed by he, an, re, and er. Quite a few digrams have zero frequency.)**\n  \n  ON IE ANTSOUTINYS ARE T INCTORE ST BE S DEAMY ACHIN\n  D ILONASIVE TUCOOWE AT TEASONARE FUSO TIZIN ANDY\n  TOBESEACE CTISBE.\n\n- **Third order\u2014trigram structure.**\n  \n  IN NO IST LAT WHEY CRACTICT FROURE BIRS GROCID\n  PONDENOME OF DEMONSTURES OF THE REPTAGIN IS\n  REGOACTIONA OF CRE.\n\n- **First-order word approximation.**\n  \n  REPRESENTING AND SPEEDILY IS AN GOOD APT OR COME CAN\n  DIFFERENT NATURAL HERE HE THE A IN CAME THE TO\n  OF TO EXPERT GRAY COME TO FURNISHES THE LINE MESSAGE HAD\n  BE THESE.\n\n- **Second-order word approximation\u2014now pairs of words appear in the expected frequency, so we do not see \u201ca in\u201d or \u201cto of.\u201d**\n  \n  THE HEAD AND IN FRONTAL ATTACK ON AN ENGLISH\n  WRITER THAT THE CHARACTER OF THIS POINT IS\n  THEREFORE ANOTHER METHOD FOR THE LETTERS THAT\n  THE TIME OF WHO EVER TOLD THE PROBLEM FOR AN\nThese sequences increasingly \u201clook\u201d like English. Less subjectively, it turns out that touch typists can handle them with increasing speed\u2014another indication of the ways people unconsciously internalize a language\u2019s statistical structure.\n\nShannon could have produced further approximations, given enough time, but the labor involved was becoming enormous. The point was to represent a message as the outcome of a process that generated events with discrete probabilities. Then what could be said about the amount of information, or the rate at which information is generated? For each event, the possible choices each have a known probability (represented as $p_1$, $p_2$, $p_3$, and so on). Shannon wanted to define the measure of information (represented as $H$) as the measure of uncertainty: \u201cof how much \u2018choice\u2019 is involved in the selection of the event or of how uncertain we are of the outcome.\u201d The probabilities might be the same or different, but generally more choices meant more uncertainty\u2014more information. Choices might be broken down into successive choices, with their own probabilities, and the probabilities had to be additive; for example, the probability of a particular digram should be a weighted sum of the probabilities of the individual symbols. When those probabilities were equal, the amount of information conveyed by each symbol was simply the logarithm of the number of possible symbols\u2014Nyquist and Hartley\u2019s formula:\n\n$$H = n \\log s$$\n\nFor the more realistic case, Shannon reached an elegant solution to the problem of how to measure information as a function of probabilities\u2014an equation that summed the probabilities with a logarithmic weighting (base 2 was most convenient). It is the average logarithm of the improbability of the message; in effect, a measure of unexpectedness:\n\n$$H = -\\sum p_i \\log_2 p_i$$\n\nwhere $p_i$ is the probability of each message. He declared that we would be seeing this again and again: that quantities of this form \u201cplay a central role in information theory as measures of information, choice, and uncertainty.\u201d Indeed, $H$ is ubiquitous, conventionally called the entropy of a message, or the Shannon entropy, or, simply, the information.\n\nA new unit of measure was needed. Shannon said: \u201cThe resulting units may be called binary digits, or more briefly, bits.\u201d As the smallest possible quantity of information, a bit represents the amount of uncertainty that exists in the flipping of a coin. The coin toss makes a choice between two possibilities of equal likelihood: in this case $p_1$ and $p_2$ each equal $\\frac{1}{2}$; the base 2 logarithm of $\\frac{1}{2}$ is $-1$; so $H = 1$ bit. A single character chosen randomly from an alphabet of 32 conveys...\nmore information: 5 bits, to be exact, because there are 32 possible messages and the logarithm of 32 is 5. A string of 1,000 such characters carries 5,000 bits\u2014not just by simple multiplication, but because the amount of information represents the amount of uncertainty: the number of possible choices. With 1,000 characters in a 32-character alphabet, there are $32^{1000}$ possible messages, and the logarithm of that number is 5,000.\n\nThis is where the statistical structure of natural languages reenters the picture. If the thousand-character message is known to be English text, the number of possible messages is smaller\u2014much smaller. Looking at correlations extending over eight letters, Shannon estimated that English has a built-in redundancy of about 50 percent: that each new character of a message conveys not 5 bits but only about 2.3. Considering longer-range statistical effects, at the level of sentences and paragraphs, he raised that estimate to 75 percent\u2014warning, however, that such estimates become \u201cmore erratic and uncertain, and they depend more critically on the type of text involved.\u201d One way to measure redundancy was crudely empirical: carry out a psychology test with a human subject. This method \u201cexploits the fact that anyone speaking a language possesses, implicitly, an enormous knowledge of the statistics of the language.\u201d\n\nFamiliarity with the words, idioms, clich\u00e9s and grammar enables him to fill in missing or incorrect letters in proof-reading, or to complete an unfinished phrase in conversation.\n\nHe might have said \u201cher,\u201d because in point of fact his test subject was his wife, Betty. He pulled a book from the shelf (it was a Raymond Chandler detective novel, *Pickup on Noon Street*), put his finger on a short passage at random, and asked Betty to start guessing the letter, then the next letter, then the next. The more text she saw, of course, the better her chances of guessing right. After \u201cA SMALL OBLONG READING LAMP ON THE,\u201d she got the next letter wrong. But once she knew it was D, she had no trouble guessing the next three letters. Shannon observed, \u201cThe errors, as would be expected, occur most frequently at the beginning of words and syllables where the line of thought has more possibility of branching out.\u201d\n\nQuantifying predictability and redundancy in this way is a backward way of measuring information content. If a letter can be guessed from what comes before, it is redundant; to the extent that it is redundant, it provides no new information. If English is 75 percent redundant, then a thousand-letter message in English carries only 25 percent as much information as one thousand letters chosen at random. Paradoxical though it sounded, random messages carry more information. The implication was that natural-language text could be encoded more efficiently for transmission or storage.\n\nShannon demonstrated one way to do this, an algorithm that exploits differing probabilities of different symbols. And he delivered a stunning package of\nfundamental results. One was a formula for channel capacity, the absolute speed limit of any communication channel (now known simply as the Shannon limit). Another was the discovery that, within that limit, it must always be possible to devise schemes of error correction that will overcome any level of noise. The sender may have to devote more and more bits to correcting errors, making transmission slower and slower, but the message will ultimately get through. Shannon did not show how to design such schemes; he only proved that it was possible, thereby inspiring a future branch of computer science. \u201cTo make the chance of error as small as you wish? Nobody had thought of that,\u201d his colleague Robert Fano recalled years later. \u201cHow he got that insight, how he came to believe such a thing, I don\u2019t know. But almost all modern communication theory is based on that work.\u201d Whether removing redundancy to increase efficiency or adding redundancy to enable error correction, the encoding depends on knowledge of the language\u2019s statistical structure to do the encoding. Information cannot be separated from probabilities. A bit, fundamentally, is always a coin toss.\n\nIf the two sides of a coin were one way of representing a bit, Shannon offered a more practical hardware example as well:\n\nA device with two stable positions, such as a relay or a flip-flop circuit, can store one bit of information. $N$ such devices can store $N$ bits, since the total number of possible states is $2^N$ and $\\log_2 2^N = N$.\n\nShannon had seen devices\u2014arrays of relays, for example\u2014that could store hundreds, even thousands of bits. That seemed like a great many. As he was finishing his write-up, he wandered one day into the office of a Bell Labs colleague, William Shockley, an Englishman in his thirties. Shockley belonged to a group of solid-state physicists working on alternatives to vacuum tubes for electronics, and sitting on his desk was a tiny prototype, a piece of semiconducting crystal. \u201cIt\u2019s a solid-state amplifier,\u201d Shockley told Shannon. At that point it still needed a name.\n\nOne day in the summer of 1949, before the book version of *The Mathematical Theory of Communication* appeared, Shannon took a pencil and a piece of notebook paper, drew a line from top to bottom, and wrote the powers of ten from $10^0$ to $10^{13}$. He labeled this axis \u201cbits storage capacity.\u201d He began listing some items that might be said to \u201cstore\u201d information. A digit wheel, of the kind used in a desktop adding machine\u2014ten decimal digits\u2014represents just over 3 bits. At just under $10^3$ bits, he wrote \u201cpunched card (all config. allowed).\u201d At $10^4$ he put \u201cpage single spaced typing (32 possible symbols).\u201d Near $10^5$ he wrote something offbeat: \u201cgenetic constitution of man.\u201d There was no real precedent for this in current scientific thinking. James D. Watson was a twenty-one-year-old student of zoology in Indiana; the discovery of the structure of DNA lay several years in\nThe Information\n\nthe future. This was the first time anyone suggested the genome was an information store measurable in bits. Shannon\u2019s guess was conservative, by at least four orders of magnitude. He thought a \u201cphono record (128 levels)\u201d held more information: about 300,000 bits. To the 10 million level he assigned a thick professional journal (*Proceedings of the Institute of Radio Engineers*) and to 1 billion the *Encyclopaedia Britannica*. He estimated one hour of broadcast television at $10^{11}$ bits and one hour of \u201ctechnicolor movie\u201d at more than a trillion. Finally, just under his pencil mark for $10^{14}$, 100 trillion bits, he put the largest information stockpile he could think of: the Library of Congress.\n\n* Toward the end of his life G\u00f6del wrote, \u201cIt was only by Turing\u2019s work that it became completely clear, that my proof is applicable to every formal system containing arithmetic.\u201d\n\n* \u201cnot considering statistical structure over greater distances than about eight letters.\u201d\nIt is probably dangerous to use this theory of information in fields for which it was not designed, but I think the danger will not keep people from using it.\n\n\u2014J. C. R. Licklider (1950)\n\nMOST MATHEMATICAL THEORIES take shape slowly; Shannon\u2019s information theory sprang forth like Athena, fully formed. Yet the little book of Shannon and Weaver drew scant public attention when it appeared in 1949. The first review came from a mathematician, Joseph L. Doob, who complained that it was more \u201csuggestive\u201d than mathematical\u2014\u201cand it is not always clear that the author\u2019s mathematical intentions are honorable.\u201d A biology journal said, \u201cAt first glance, it might appear that this is primarily an engineering monograph with little or no application to human problems. Actually, the theory has some rather exciting implications.\u201d *The Philosophical Review* said it would be a mistake for philosophers to overlook this book: \u201cShannon develops a concept of *information* which, surprisingly enough, turns out to be an extension of the thermodynamic concept of *entropy*.\u201d The strangest review was barely a review at all: five paragraphs in *Physics Today*, September 1950, signed by Norbert Wiener, Massachusetts Institute of Technology.\n\nWiener began with a faintly patronizing anecdote:\n\nSome fifteen years ago, a very bright young student came to the authorities at MIT with an idea for a theory of electric switching dependent on the algebra of logic. The student was Claude E. Shannon.\n\nIn the present book (Wiener continued), Shannon, along with Warren Weaver, \u201chas summed up his views on communication engineering.\u201d\n\nThe fundamental idea developed by Shannon, said Wiener, \u201cis that of the amount of information as negative entropy.\u201d He added that he himself\u2014\u201cthe author of the present review\u201d\u2014had developed the same idea at about the same time.\n\nWiener declared the book to be work \u201cwhose origins were independent of my own work, but which has been bound from the beginning to my investigations by cross influences spreading in both directions.\u201d He mentioned \u201cthose of us who have tried to pursue this analogy into the study of Maxwell\u2019s demon\u201d and added\nthat much work remained to be done.\n\nThen he suggested that the treatment of language was incomplete without greater emphasis on the human nervous system: \u201cnervous reception and the transmission of language into the brain. I say these things not as a hostile criticism.\u201d\n\nFinally, Wiener concluded with a paragraph devoted to another new book: \u201cmy own Cybernetics.\u201d Both books, he said, represent opening salvos in a field that promises to grow rapidly.\n\nIn my book, I have taken the privilege of an author to be more speculative, and to cover a wider range than Drs. Shannon and Weaver have chosen to do\u2026. There is not only room, but a definite need for different books.\n\nHe saluted his colleagues for their well-worked and independent approach\u2014to cybernetics.\n\nShannon, meanwhile, had already contributed a short review of Wiener\u2019s book to the Proceedings of the Institute of Radio Engineers, offering praise that could be described as faint. It is \u201can excellent introduction,\u201d he said. There was a little tension between these men. It could be felt weighing down the long footnote that anchored the opening page of Weaver\u2019s portion of The Mathematical Theory of Communication:\n\nDr. Shannon has himself emphasized that communication theory owes a great debt to Professor Norbert Wiener for most of its basic philosophy. Professor Wiener, on the other hand, points out that much of Shannon\u2019s early work on switching and mathematical logic antedated his own interest in this field; and generously adds that Shannon certainly deserves credit for independent development of such fundamental aspects of the theory as the introduction of entropic ideas.\n\nShannon\u2019s colleague John Pierce wrote later: \u201cWiener\u2019s head was full of his own work\u2026. Competent people have told me that Wiener, under the misapprehension that he already knew what Shannon had done, never actually found out.\u201d\n\nCybernetics was a coinage, future buzzword, proposed field of study, would-be philosophical movement entirely conceived by this brilliant and prickly thinker. The word he took from the Greek for steersman: \u03ba\u03c5\u03b2\u03b5\u03c1\u03bd\u03ae\u03c4\u03b7\u03c2, kubernites, from which comes also (not coincidentally) the word governor. He meant cybernetics to be a field that would synthesize the study of communication and control, also the study of human and machine. Norbert Wiener had first become known to the world as a curiosity: a sport, a prodigy, driven and promoted by his father, a professor at Harvard. \u201cA lad who has been proudly termed by his friends the brightest boy in the world,\u201d The New York Times reported on page 1 when he was fourteen years old, \u201cwill graduate next month from Tufts College\u2026. Aside from the fact that Norbert Wiener\u2019s capacity for learning is phenomenal, he is as other boys\u2026. His intense black eyes are his most striking feature.\u201d When he wrote his\nmemoirs, he always used the word *prodigy* in the titles: *Ex-Prodigy: My Childhood and Youth* and *I Am a Mathematician: The Later Life of a Prodigy.*\n\nAfter Tufts (mathematics), Harvard graduate school (zoology), Cornell (philosophy), and Harvard again, Wiener left for Cambridge, England, where he studied symbolic logic and *Principia Mathematica* with Bertrand Russell himself. Russell was not entirely charmed. \u201cAn infant prodigy named Wiener, Ph.D. (Harvard), aged 18, turned up,\u201d he wrote a friend. \u201cThe youth has been flattered, and thinks himself God Almighty\u2014there is a perpetual contest between him and me as to which is to do the teaching.\u201d For his part, Wiener detested Russell: \u201cHe is an iceberg. His mind impresses one as a keen, cold, narrow logical machine, that cuts the universe into neat little packets, that measure, as it were, just three inches each way.\u201d On his return to the United States, Wiener joined the faculty of MIT in 1919, the same year as Vannevar Bush. When Shannon got there in 1936, he took one of Wiener\u2019s mathematics courses. When war loomed, Wiener was one of the first to join the hidden, scattered teams of mathematicians working on antiaircraft fire control.\n\nHe was short and rotund, with heavy glasses and a Mephistophelian goatee. Where Shannon\u2019s fire-control work drilled down to the signal amid the noise, Wiener stayed with the noise: swarming fluctuations in the radar receiver, unpredictable deviations in flight paths. The noise behaved statistically, he understood, like Brownian motion, the \u201cextremely lively and wholly haphazard movement\u201d that van Leeuwenhoek had observed through his microscope in the seventeenth century. Wiener had undertaken a thoroughgoing mathematical treatment of Brownian motion in the 1920s. The very discontinuity appealed to him\u2014not just the particle trajectories but the mathematical functions, too, seemed to misbehave. This was, as he wrote, discrete chaos, a term that would not be well understood for several generations. On the fire-control project, where Shannon\nmade a modest contribution to the Bell Labs team, Wiener and his colleague Julian Bigelow produced a legendary 120-page monograph, classified and known to the several dozen people allowed to see it as the Yellow Peril because of the color of its binder and the difficulty of its treatment. The formal title was *Extrapolation, Interpolation, and Smoothing of Stationary Time Series*. In it Wiener developed a statistical method for predicting the future from noisy, uncertain, and corrupted data about the past. It was too ambitious for the existing gun machinery, but he tested it on Vannevar Bush\u2019s Differential Analyzer. Both the antiaircraft gun, with its operator, and the target airplane, with its pilot, were hybrids of machine and human. One had to predict the behavior of the other.\n\nWiener was as worldly as Shannon was reticent. He was well traveled and polyglot, ambitious and socially aware; he took science personally and passionately. His expression of the second law of thermodynamics, for example, was a cry of the heart:\n\n> We are swimming upstream against a great torrent of disorganization, which tends to reduce everything to the heat death of equilibrium and sameness\u2026. This heat death in physics has a counterpart in the ethics of Kierkegaard, who pointed out that we live in a chaotic moral universe. In this, our main obligation is to establish arbitrary enclaves of order and system\u2026. Like the Red Queen, we cannot stay where we are without running as fast as we can.\n\nHe was concerned for his place in intellectual history, and he aimed high. Cybernetics, he wrote in his memoirs, amounted to \u201ca new interpretation of man, of man\u2019s knowledge of the universe, and of society.\u201d Where Shannon saw himself as a mathematician and an engineer, Wiener considered himself foremost a philosopher, and from his fire-control work he drew philosophical lessons about purpose and behavior. If one defines behavior cleverly\u2014\u201cany change of an entity with respect to its surroundings\u201d\u2014then the word can apply to machines as well as animals. Behavior directed toward a goal is purposeful, and the purpose can sometimes be imputed to the machine rather than a human operator: for example, in the case of a target-seeking mechanism. \u201cThe term servomechanisms has been coined precisely to designate machines with an intrinsic purposeful behavior.\u201d The key was control, or self-regulation.\n\nTo analyze it properly he borrowed an obscure term from electrical engineering: \u201cfeed-back,\u201d the return of energy from a circuit\u2019s output back to its input. When feedback is positive, as when the sound from loudspeakers is re-amplified through a microphone, it grows wildly out of control. But when feedback is negative\u2014as in the original mechanical governor of steam engines, first analyzed by James Clerk Maxwell\u2014it can guide a system toward equilibrium; it serves as an agent of stability. Feedback can be mechanical: the faster Maxwell\u2019s governor spins, the wider its arms extend, and the wider its arms extend, the slower it must spin. Or it can be electrical. Either way, the key to the process is information.\nWhat governs the antiaircraft gun, for example, is information about the plane\u2019s coordinates and about the previous position of the gun itself. Wiener\u2019s friend Bigelow emphasized this: \u201cthat it was not some particular physical thing such as energy or length or voltage, but only information (conveyed by any means).\u201d\n\nNegative feedback must be ubiquitous, Wiener felt. He could see it at work in the coordination of eye and hand, guiding the nervous system of a person performing an action as ordinary as picking up a pencil. He focused especially on neurological disorders, maladies that disrupted physical coordination or language. He saw them quite specifically as cases of information feedback gone awry: varieties of ataxia, for example, where sense messages are either interrupted in the spinal cord or misinterpreted in the cerebellum. His analysis was detailed and mathematical, with equations\u2014almost unheard of in neurology. Meanwhile, feedback control systems were creeping into factory assembly lines, because a mechanical system, too, can modify its own behavior. Feedback is the governor, the steersman.\n\nSo *Cybernetics* became the title of Wiener\u2019s first book, published in the fall of 1948 in both the United States and France. Subtitle: *Control and Communication in the Animal and the Machine*. The book is a hodgepodge of notions and analysis, and, to the astonishment of its publishers, it became the year\u2019s unexpected bestseller. The popular American news magazines, *Time* and *Newsweek*, both featured it. Wiener and cybernetics were identified with a phenomenon that was bursting into public consciousness just at that moment: computing machines. With the end of the war, a veil had been lifted from the first urgent projects in electronic calculation, particularly the ENIAC, a thirty-ton monster of vacuum tubes, relays, and hand-soldered wires stretching across eighty feet at the University of Pennsylvania\u2019s electrical engineering school. It could store and multiply up to twenty numbers of ten decimal digits; the army used it to calculate artillery firing tables. The International Business Machines company, IBM, which provided punched card machines for the army projects, also built a giant calculating machine at Harvard, the Mark I. In Britain, still secret, the code breakers at Bletchley Park had gone on to build a vacuum-tube computing machine called the Colossus. Alan Turing was beginning work on another, at the University of Manchester. When the public learned about these machines, they were naturally thought of as \u201cbrains.\u201d Everyone asked the same question: Can machines think?\n\n\u201cThey are growing with fearful speed,\u201d declared *Time* in its year-end issue. \u201cThey started by solving mathematical equations with flash-of-lightning rapidity. Now they are beginning to act like genuine mechanical brains.\u201d Wiener encouraged the speculation, if not the wild imagery:\n\nDr. Wiener sees no reason why they can\u2019t learn from experience, like monstrous and\nprecocious children racing through grammar school. One such mechanical brain, ripe with stored experience, might run a whole industry, replacing not only mechanics and clerks but many of the executives too....\n\nAs men construct better calculating machines, explains Wiener, and as they explore their own brains, the two seem more & more alike. Man, he thinks, is recreating himself, monstrously magnified, in his own image.\n\nMuch of the success of his book, abstruse and ungainly as it was, lay in Wiener\u2019s always returning his focus to the human, not the machine. He was not as interested in shedding light on the rise of computing\u2014to which, in any case, his connections were peripheral\u2014as in how computing might shed light on humanity. He cared profoundly, it turned out, about understanding mental disorders; about mechanical prostheses; and about the social dislocations that might follow the rise of smart machinery. He worried that it would devalue the human brain as factory machinery had devalued the human hand.\n\nHe developed the human-machine parallels in a chapter titled \u201cComputing Machines and the Nervous System.\u201d First he laid out a distinction between two types of computing machines: analog and digital, though he did not yet use those words. The first type, like the Bush Differential Analyzer, represented numbers as measurements on a continuous scale; they were analogy machines. The other kind, which he called numerical machines, represented numbers directly and exactly, as desk calculators did. Ideally, these devices would use the binary number system for simplicity. For advanced calculations they would need to employ a form of logic. What form? Shannon had answered that question in his master\u2019s thesis of 1937, and Wiener offered the same answer:\n\nthe algebra of logic \\textit{par excellence}, or the Boolean algebra. This algorithm, like the binary arithmetic, is based on the dichotomy, the choice between yes and no, the choice between being in a class and outside.\n\nThe brain, too, he argued, is at least partly a logical machine. Where computers employ relays\u2014mechanical, or electromechanical, or purely electrical\u2014the brain has neurons. These cells tend to be in one of two states at any given moment: active (firing) or at rest (in repose). So they may be considered relays with two states. They are connected to one another in vast arrays, at points of contact known as synapses. They transmit messages. To store the messages, brains have memory; computing machines, too, need physical storage that can be called memory. (He knew well that this was a simplified picture of a complex system, that other sorts of messages, more analog than digital, seemed to be carried chemically by hormones.) Wiener suggested, too, that functional disorders such as \u201cnervous breakdowns\u201d might have cousins in electronics. Designers of computing machines might need to plan for untimely floods of data\u2014perhaps the equivalent of \u201ctraffic problems and overloading in the nervous system.\u201d\nBrains and electronic computers both use quantities of energy in performing their work of logic\u2014\"all of which is wasted and dissipated in heat,\" to be carried away by the blood or by ventilating and cooling apparatus. But this is really beside the point, Wiener said. \"Information is information, not matter or energy. No materialism which does not admit this can survive at the present day.\"\n\nNow came a time of excitement.\n\n\"We are again in one of those prodigious periods of scientific progress\u2014in its own way like the pre-Socratic period,\" declared the gnomic, white-bearded neurophysiologist Warren McCulloch to a meeting of British philosophers. He told them that listening to Wiener and von Neumann put him in mind of the debates of the ancients. A new physics of communication had been born, he said, and metaphysics would never be the same: \"For the first time in the history of science we know how we know and hence are able to state it clearly.\" He offered them heresy: that the knower was a computing machine, the brain composed of relays, perhaps ten billion of them, each receiving signals from other relays and sending them onward. The signals are quantized: they either happen or do not happen. So once again the stuff of the world, he said, turns out to be the atoms of Democritus\u2014\"indivisibles\u2014leasts\u2014which go batting about in the void.\"\n\nIt is a world for Heraclitus, always \"on the move.\" I do not mean merely that every relay is itself being momentarily destroyed and re-created like a flame, but I mean that its business is with information which pours into it over many channels, passes through it, eddies within it and emerges again to the world.\n\nThat these ideas were spilling across disciplinary borders was due in large part to McCulloch, a dynamo of eclecticism and cross-fertilization. Soon after the war he began organizing a series of conferences at the Beekman Hotel on Park Avenue in New York City, with money from the Josiah Macy Jr. Foundation, endowed in the nineteenth century by heirs of Nantucket whalers. A host of sciences were coming of age all at once\u2014so-called social sciences, like anthropology and psychology, looking for new mathematical footing; medical offshoots with hybrid names, like neurophysiology; not-quite-sciences like psychoanalysis\u2014and McCulloch invited experts in all these fields, as well as mathematics and electrical engineering. He instituted a Noah's Ark rule, inviting two of each species so that speakers would always have someone present who could see through their jargon. Among the core group were the already famous anthropologist Margaret Mead and her then-husband Gregory Bateson, the psychologists Lawrence K. Frank and Heinrich Kl\u00fcver, and that formidable, sometimes rivalrous pair of mathematicians, Wiener and von Neumann.\n\nMead, recording the proceedings in a shorthand no one else could read, said she broke a tooth in the excitement of the first meeting and did not realize it till\nafterward. Wiener told them that all these sciences, the social sciences especially, were fundamentally the study of communication, and that their unifying idea was the message. The meetings began with the unwieldy name of Conferences for Circular Causal and Feedback Mechanisms in Biological and Social Systems and then, in deference to Wiener, whose new fame they enjoyed, changed that to Conference on Cybernetics. Throughout the conferences, it became habitual to use the new, awkward, and slightly suspect term information theory. Some of the disciplines were more comfortable than others. It was far from clear where information belonged in their respective worldviews.\n\nThe meeting in 1950, on March 22 and 23, began self-consciously. \u201cThe subject and the group have provoked a tremendous amount of external interest,\u201d said Ralph Gerard, a neuroscientist from the University of Chicago\u2019s medical school, \u201calmost to the extent of a national fad. They have prompted extensive articles in such well known scientific magazines as Time, News-Week, and Life.\u201d He was referring, among others, to Time\u2019s cover story earlier that winter titled \u201cThe Thinking Machine\u201d and featuring Wiener:\n\nProfessor Wiener is a stormy petrel (he looks more like a stormy puffin) of mathematics and adjacent territory\u2026. The great new computers, cried Wiener with mingled alarm and triumph, are \u2026 harbingers of a whole new science of communication and control, which he promptly named \u201ccybernetics.\u201d The newest machines, Wiener pointed out, already have an extraordinary resemblance to the human brain, both in structure and function. So far, they have no senses or \u201ceffectors\u201d (arms and legs), but why shouldn\u2019t they have?\n\nIt was true, Gerard said, that his field was being profoundly affected by new ways of thought from communications engineering\u2014helping them think of a nerve impulse not just as a \u201cphysical-chemical event\u201d but as a sign or a signal. So it was helpful to take lessons from \u201ccalculating machines and communications systems,\u201d but it was dangerous, too.\n\nTo say, as the public press says, that therefore these machines are brains, and that our brains are nothing but calculating machines, is presumptuous. One might as well say that the telescope is an eye or that a bulldozer is a muscle.\n\nWiener felt he had to respond. \u201cI have not been able to prevent these reports,\u201d he said, \u201cbut I have tried to make the publications exercise restraint. I still do not believe that the use of the word \u2018thinking\u2019 in them is entirely to be reprehended.\u201d\n\nGerard\u2019s main purpose was to talk about whether the brain, with its mysterious architecture of neurons, branching dendrite trees, and complex interconnections alive within a chemical soup, could properly be described as analog or digital. Gregory Bateson instantly interrupted: he still found this distinction confusing. It was a basic question. Gerard owed his own understanding to \u201cthe expert tutelage that I have received here, primarily from John von Neumann\u201d\u2014who was sitting right there\u2014but Gerard took a stab at it anyway. Analog is a slide rule, where\nnumber is represented as distance; digital is an abacus, where you either count a bead or you do not; there\u2019s nothing in between. A rheostat\u2014light dimmer\u2014is analog; a wall switch that snaps on or off, digital. Brain waves and neural chemistry, said Gerard, are analog.\n\nDiscussion ensued. Von Neumann had plenty to say. He had lately been developing a \u201cgame theory,\u201d which he viewed effectively as a mathematics of incomplete information. And he was taking the lead in designing an architecture for the new electronic computers. He wanted the more analog-minded of the group to think more abstractly\u2014to recognize that digital processes take place in a messy, continuous world but are digital nonetheless. When a neuron snaps between two possible states\u2014\u201cthe state of the nerve cell with no message in it and the state of the cell with a message in it\u201d\u2014the chemistry of this transition may have intermediate shadings, but for theoretical purposes the shadings may be ignored. In the brain, he suggested, just as in a computer made of vacuum tubes, \u201cthese discrete actions are in reality simulated on the background of continuous processes.\u201d McCulloch had just put this neatly in a new paper called \u201cOf Digital Computers Called Brains\u201d: \u201cIn this world it seems best to handle even apparent continuities as some numbers of some little steps.\u201d Remaining quiet in the audience was the new man in the group, Claude Shannon.\n\nThe next speaker was J. C. R. Licklider, an expert on speech and sound from the new Psycho-Acoustic Laboratory at Harvard, known to everyone as Lick. He was another young scientist with his feet in two different worlds\u2014part psychologist and part electrical engineer. Later that year he moved to MIT, where he established a new psychology department within the department of electrical engineering. He was working on an idea for quantizing speech\u2014taking speech waves and reducing them to the smallest quantities that could be reproduced by a \u201cflip-flop circuit,\u201d a homemade gadget made from twenty-five dollars of vacuum tubes, resistors, and capacitors. It was surprising\u2014even to people used to the crackling and hissing of telephones\u2014how far speech could be reduced and still remain intelligible. Shannon listened closely, not just because he knew about the relevant telephone engineering but because he had dealt with the issues in his secret war work on audio scrambling. Wiener perked up, too, in part because of a special interest in prosthetic hearing aids.\n\nWhen Licklider described some distortion as neither linear nor logarithmic but \u201chalfway between,\u201d Wiener interrupted.\n\n\u201cWhat does \u2018halfway\u2019 mean? $X$ plus $S$ over $N$?\u201d\n\nLicklider sighed. \u201cMathematicians are always doing that, taking me up on inexact statements.\u201d But he had no problem with the math and later offered an estimate for how much information\u2014using Shannon\u2019s new terminology\u2014could be sent down a transmission line, given a certain bandwidth (5,000 cycles) and a\ncertain signal-to-noise ratio (33 decibels), numbers that were realistic for commercial radio. \u201cI think it appears that 100,000 bits of information can be transmitted through such a communication channel\u201d\u2014bits per second, he meant. That was a staggering number; by comparison, he calculated the rate of ordinary human speech this way: 10 phonemes per second, chosen from a vocabulary of 64 phonemes ($2^6$, \u201cto make it easy\u201d\u2014the logarithm of the number of choices is 6), so a rate of 60 bits per second. \u201cThis assumes that the phonemes are all equally probable\u2014\u201d\n\n\u201cYes!\u201d interrupted Wiener.\n\n\u201c\u2014and of course they are not.\u201d\n\nWiener wondered whether anyone had tried a similar calculation for \u201ccompression for the eye,\u201d for television. How much \u201creal information\u201d is necessary for intelligibility? Though he added, by the way: \u201cI often wonder why people try to look at television.\u201d\n\nMargaret Mead had a different issue to raise. She did not want the group to forget that meaning can exist quite apart from phonemes and dictionary definitions. \u201cIf you talk about another kind of information,\u201d she said, \u201cif you are trying to communicate the fact that somebody is angry, what order of distortion might be introduced to take the anger out of a message that otherwise will carry exactly the same words?\u201d\n\nThat evening Shannon took the floor. Never mind meaning, he said. He announced that, even though his topic was the redundancy of written English, he was not going to be interested in meaning at all.\n\nHe was talking about information as something transmitted from one point to another: \u201cIt might, for example, be a random sequence of digits, or it might be information for a guided missile or a television signal.\u201d What mattered was that he was going to represent the information source as a statistical process, generating messages with varying probabilities. He showed them the sample text strings he had used in *The Mathematical Theory of Communication*\u2014which few of them had read\u2014and described his \u201cprediction experiment,\u201d in which the subject guesses text letter by letter. He told them that English has a specific entropy, a quantity correlated with redundancy, and that he could use these experiments to compute the number. His listeners were fascinated\u2014Wiener, in particular, thinking of his own \u201cprediction theory.\u201d\n\n\u201cMy method has some parallelisms to this,\u201d Wiener interrupted. \u201cExcuse me for interrupting.\u201d\n\nThere was a difference in emphasis between Shannon and Wiener. For Wiener, entropy was a measure of disorder; for Shannon, of uncertainty. Fundamentally,\nas they were realizing, these were the same. The more inherent order exists in a sample of English text\u2014order in the form of statistical patterns, known consciously or unconsciously to speakers of the language\u2014the more predictability there is, and in Shannon\u2019s terms, the less information is conveyed by each subsequent letter. When the subject guesses the next letter with confidence, it is redundant, and the arrival of the letter contributes no new information. Information is surprise.\n\nThe others brimmed with questions about different languages, different prose styles, ideographic writing, and phonemes. One psychologist asked whether newspaper writing would look different, statistically, from the work of James Joyce. Leonard Savage, a statistician who worked with von Neumann, asked how Shannon chose a book for his test: at random?\n\n\u201cI just walked over to the shelf and chose one.\u201d\n\n\u201cI wouldn\u2019t call that random, would you?\u201d said Savage. \u201cThere is a danger that the book might be about engineering.\u201d Shannon did not tell them that in point of fact it had been a detective novel.\n\nSomeone else wanted to know if Shannon could say whether baby talk would be more or less predictable than the speech of an adult.\n\n\u201cI think more predictable,\u201d he replied, \u201cif you are familiar with the baby.\u201d\n\nEnglish is actually many different languages\u2014as many, perhaps, as there are English speakers\u2014each with different statistics. It also spawns artificial dialects: the language of symbolic logic, with its restricted and precise alphabet, and the language one questioner called \u201cAirplanese,\u201d employed by control towers and pilots. And language is in constant flux. Heinz von Foerster, a young physicist from Vienna and an early acolyte of Wittgenstein, wondered how the degree of redundancy in a language might change as the language evolved, and especially in the transition from oral to written culture.\n\nVon Foerster, like Margaret Mead and others, felt uncomfortable with the notion of information without meaning. \u201cI wanted to call the whole of what they called information theory signal theory,\u201d he said later, \u201cbecause information was not yet there. There were \u2018beep beeps\u2019 but that was all, no information. The moment one transforms that set of signals into other signals our brain can make an understanding of, then information is born\u2014it\u2019s not in the beeps.\u201d But he found himself thinking of the essence of language, its history in the mind and in the culture, in a new way. At first, he pointed out, no one is conscious of letters, or phonemes, as basic units of a language.\n\nI\u2019m thinking of the old Maya texts, the hieroglyphics of the Egyptians or the Sumerian tables of the first period. During the development of writing it takes some considerable time\u2014or an accident\u2014to recognize that a language can be split into smaller units than words, e.g., syllables or letters. I have the feeling that there is a\nThe discussion changed his mind about the centrality of information. He added an epigrammatic note to his transcript of the eighth conference: \u201cInformation can be considered as order wrenched from disorder.\u201d\n\nHard as Shannon tried to keep his listeners focused on his pure, meaning-free definition of information, this was a group that would not steer clear of semantic entanglements. They quickly grasped Shannon\u2019s essential ideas, and they speculated far afield. \u201cIf we could agree to define as information anything which changes probabilities or reduces uncertainties,\u201d remarked Alex Bavelas, a social psychologist, \u201cchanges in emotional security could be seen quite easily in this light.\u201d What about gestures or facial expressions, pats on the back or winks across the table? As the psychologists absorbed this artificial way of thinking about signals and the brain, their whole discipline stood on the brink of a radical transformation.\n\nRalph Gerard, the neuroscientist, was reminded of a story. A stranger is at a party of people who know one another well. One says, \u201c72,\u201d and everyone laughs. Another says, \u201c29,\u201d and the party roars. The stranger asks what is going on.\n\nHis neighbor said, \u201cWe have many jokes and we have told them so often that now we just use a number.\u201d The guest thought he\u2019d try it, and after a few words said, \u201c63.\u201d The response was feeble. \u201cWhat\u2019s the matter, isn\u2019t this a joke?\u201d\n\n\u201cOh, yes, that is one of our very best jokes, but you did not tell it well.\u201d\n\nThe next year Shannon returned with a robot. It was not a very clever robot, nor lifelike in appearance, but it impressed the cybernetics group. It solved mazes. They called it Shannon\u2019s rat.\n\nHe wheeled out a cabinet with a five-by-five grid on its top panel. Partitions could be placed around and between any of the twenty-five squares to make mazes in different configurations. A pin could be placed in any square to serve as the goal, and moving around the maze was a sensing rod driven by a pair of little motors, one for east-west and one for north-south. Under the hood lay an array of electrical relays, about seventy-five of them, interconnected, switching on and off to form the robot\u2019s \u201cmemory.\u201d Shannon flipped the switch to power it up.\n\n\u201cWhen the machine was turned off,\u201d he said, \u201cthe relays essentially forgot everything they knew, so that they are now starting afresh, with no knowledge of the maze.\u201d His listeners were rapt. \u201cYou see the finger now exploring the maze, hunting for the goal. When it reaches the center of a square, the machine makes a new decision as to the next direction to try.\u201d When the rod hit a partition, the motors reversed and the relays recorded the event. The machine made each \u201cdecision\u201d based on its previous \u201cknowledge\u201d\u2014it was impossible to avoid these\npsychological words\u2014according to a strategy Shannon had designed. It wandered about the space by trial and error, turning down blind alleys and bumping into walls. Finally, as they all watched, the rat found the goal, a bell rang, a lightbulb flashed on, and the motors stopped.\n\nThen Shannon put the rat back at the starting point for a new run. This time it went directly to the goal without making any wrong turns or hitting any partitions. It had \u201clearned.\u201d Placed in other, unexplored parts of the maze, it would revert to trial and error until, eventually, \u201cit builds up a complete pattern of information and is able to reach the goal directly from any point.\u201d\n\nTo carry out the exploring and goal-seeking strategy, the machine had to store one piece of information for each square it visited: namely, the direction by which it last left the square. There were only four possibilities\u2014north, west, south, east\u2014so, as Shannon carefully explained, two relays were assigned as memory for each square. Two relays meant two bits of information, enough for a choice among four alternatives, because there were four possible states: off-off, off-on, on-off, and on-on.\n\nNext Shannon rearranged the partitions so that the old solution would no longer work. The machine would then \u201cfumble around\u201d till it found a new solution. Sometimes, however, a particularly awkward combination of previous memory and a new maze would put the machine in an endless loop. He showed them: \u201cWhen it arrives at A, it remembers that the old solution said to go to B, and so it goes around the circle, A, B, C, D, A, B, C, D. It has established a vicious circle, or a singing condition.\u201d\n\n\u201cA neurosis!\u201d said Ralph Gerard.\n\nShannon added \u201can antineurotic circuit\u201d: a counter, set to break out of the loop when the machine repeated the same sequence six times. Leonard Savage saw that this was a bit of a cheat. \u201cIt doesn\u2019t have any way to recognize that it is \u2018psycho\u2019\u2014it just recognizes that it has been going too long?\u201d he asked. Shannon agreed.\n\u201cIt is all too human,\u201d remarked Lawrence K. Frank.\n\n\u201cGeorge Orwell should have seen this,\u201d said Henry Brosin, a psychiatrist.\n\nA peculiarity of the way Shannon had organized the machine\u2019s memory\u2014associating a single direction with each square\u2014was that the path could not be reversed. Having reached the goal, the machine did not \u201cknow\u201d how to return to its origin. The knowledge, such as it was, emerged from what Shannon called the vector field, the totality of the twenty-five directional vectors. \u201cYou can\u2019t say where the sensing finger came from by studying the memory,\u201d he explained.\n\n\u201cLike a man who knows the town,\u201d said McCulloch, \u201cso he can go from any place to any other place, but doesn\u2019t always remember how he went.\u201d\n\nShannon\u2019s rat was kin to Babbage\u2019s silver dancer and the metal swans and fishes of Merlin\u2019s Mechanical Museum: automata performing a simulation of life. They never failed to amaze and entertain. The dawn of the information age brought a whole new generation of synthetic mice, beetles, and turtles, made with vacuum tubes and then transistors. They were crude, almost trivial, by the standards of just a few years later. In the case of the rat, the creature\u2019s total memory amounted to seventy-five bits. Yet Shannon could fairly claim that it solved a problem by trial and error; retained the solution and repeated it without the errors; integrated new information from further experience; and \u201cforgot\u201d the solution when circumstances changed. The machine was not only imitating lifelike behavior; it was performing functions previously reserved for brains.\n\nOne critic, Dennis Gabor, a Hungarian electrical engineer who later won the Nobel Prize for inventing holography, complained, \u201cIn reality it is the maze which remembers, not the mouse.\u201d This was true up to a point. After all, there was no mouse. The electrical relays could have been placed anywhere, and they held the memory. They became, in effect, a mental model of a maze\u2014a theory of a maze.\n\nThe postwar United States was hardly the only place where biologists and neuroscientists were suddenly making common cause with mathematicians and electrical engineers\u2014though Americans sometimes talked as though it was. Wiener, who recounted his travels to other countries at some length in his introduction to *Cybernetics*, wrote dismissively that in England he had found researchers to be \u201cwell-informed\u201d but that not much progress had been made \u201cin unifying the subject and in pulling the various threads of research together.\u201d New cadres of British scientists began coalescing in response to information theory and cybernetics in 1949\u2014mostly young, with fresh experience in code breaking, radar, and gun control. One of their ideas was to form a dining club in the English\nfashion\u2014\u201climited membership and a post-prandial situation,\u201d proposed John Bates, a pioneer in electroencephalography. This required considerable discussion of names, membership rules, venues, and emblems. Bates wanted electrically inclined biologists and biologically oriented engineers and suggested \u201cabout fifteen people who had Wiener\u2019s ideas before Wiener\u2019s book appeared.\u201d They met for the first time in the basement of the National Hospital for Nervous Diseases, in Bloomsbury, and decided to call themselves the Ratio Club\u2014a name meaning whatever anyone wanted. (Their chroniclers Philip Husbands and Owen Holland, who interviewed many of the surviving members, report that half pronounced it RAY-she-oh and half RAT-ee-oh.) For their first meeting they invited Warren McCulloch.\n\nThey talked not just about understanding brains but \u201cdesigning\u201d them. A psychiatrist, W. Ross Ashby, announced that he was working on the idea that \u201ca brain consisting of randomly connected impressional synapses would assume the required degree of orderliness as a result of experience\u201d\u2014in other words, that the mind is a self-organizing dynamical system. Others wanted to talk about pattern recognition, about noise in the nervous system, about robot chess and the possibility of mechanical self-awareness. McCulloch put it this way: \u201cThink of the brain as a telegraphic relay, which, tripped by a signal, emits another signal.\u201d Relays had come a long way since Morse\u2019s time. \u201cOf the molecular events of brains these signals are the atoms. Each goes or does not go.\u201d The fundamental unit is a choice, and it is binary. \u201cIt is the least event that can be true or false.\u201d\n\nThey also managed to attract Alan Turing, who published his own manifesto with a provocative opening statement\u2014\u201cI propose to consider the question, \u2018Can machines think?\u2019 \u201d\u2014followed by a sly admission that he would do so without even trying to define the terms machine and think. His idea was to replace the question with a test called the Imitation Game, destined to become famous as the \u201cTuring Test.\u201d In its initial form the Imitation Game involves three people: a man, a woman, and an interrogator. The interrogator sits in a room apart and poses questions (ideally, Turing suggests, by way of a \u201cteleprinter communicating between the two rooms\u201d). The interrogator aims to determine which is the man and which is the woman. One of the two\u2014say, the man\u2014aims to trick the interrogator, while the other aims to help reveal the truth. \u201cThe best strategy for her is probably to give truthful answers,\u201d Turing suggests. \u201cShe can add such things as \u2018I am the woman, don\u2019t listen to him!\u2019 but it will avail nothing as the man can make similar remarks.\u201d\n\nBut what if the question is not which gender but which genus: human or machine?\n\nIt is understood that the essence of being human lies in one\u2019s \u201cintellectual capacities\u201d; hence this game of disembodied messages transmitted blindly\nbetween rooms. \u201cWe do not wish to penalise the machine for its inability to shine in beauty competitions,\u201d says Turing dryly, \u201cnor to penalise a man for losing in a race against an aeroplane.\u201d Nor, for that matter, for slowness in arithmetic. Turing offers up some imagined questions and answers:\n\nQ: Please write me a sonnet on the subject of the Forth Bridge.\n\nA: Count me out on this one. I never could write poetry.\n\nBefore proceeding further, however, he finds it necessary to explain just what sort of machine he has in mind. \u201cThe present interest in \u2018thinking machines,\u2019 \u201d he notes, \u201chas been aroused by a particular kind of machine, usually called an \u2018electronic computer\u2019 or \u2018digital computer.\u2019 \u201d These devices do the work of human computers, faster and more reliably. Turing spells out, as Shannon had not, the nature and properties of the digital computer. John von Neumann had done this, too, in constructing a successor machine to ENIAC. The digital computer comprises three parts: a \u201cstore of information,\u201d corresponding to the human computer\u2019s memory or paper; an \u201cexecutive unit,\u201d which carries out individual operations; and a \u201ccontrol,\u201d which manages a list of instructions, making sure they are carried out in the right order. These instructions are encoded as numbers. They are sometimes called a \u201cprogramme,\u201d Turing explains, and constructing such a list may be called \u201cprogramming.\u201d\n\nThe idea is an old one, Turing says, and he cites Charles Babbage, whom he identifies as Lucasian Professor of Mathematics at Cambridge from 1828 to 1839\u2014once so famous, now almost forgotten. Turing explains that Babbage \u201chad all the essential ideas\u201d and \u201cplanned such a machine, called the Analytical Engine, but it was never completed.\u201d It would have used wheels and cards\u2014nothing to do with electricity. The existence (or nonexistence, but at least near existence) of Babbage\u2019s engine allows Turing to rebut a superstition he senses forming in the zeitgeist of 1950. People seem to feel that the magic of digital computers is essentially electrical; meanwhile, the nervous system is also electrical. But Turing is at pains to think of computation in a universal way, which means in an abstract way. He knows it is not about electricity at all:\n\nSince Babbage\u2019s machine was not electrical, and since all digital computers are in a sense equivalent, we see that this use of electricity cannot be of theoretical importance\u2026. The feature of using electricity is thus seen to be only a very superficial similarity.\n\nTuring\u2019s famous computer was a machine made of logic: imaginary tape, arbitrary symbols. It had all the time in the world and unbounded memory, and it could do anything expressible in steps and operations. It could even judge the validity of a proof in the system of *Principia Mathematica*. \u201cIn the case that the formula is neither provable nor disprovable such a machine certainly does not behave in a very satisfactory manner, for it continues to work indefinitely without\nproducing any result at all, but this cannot be regarded as very different from the reaction of the mathematicians.\u201d So Turing supposed it could play the Imitation Game.\n\nHe could not pretend to prove that, of course. He was mainly trying to change the terms of a debate he considered largely fatuous. He offered a few predictions for the half century to come: that computers would have a storage capacity of $10^9$ bits (he imagined a few very large computers; he did not foresee our future of ubiquitous tiny computing devices with storage many magnitudes greater than that); and that they might be programmed to play the Imitation Game well enough to fool some interrogators for at least a few minutes (true, as far as it goes).\n\nThe original question, \u201cCan machines think?\u201d I believe to be too meaningless to deserve discussion. Nevertheless I believe that at the end of the century the use of words and general educated opinion will have altered so much that one will be able to speak of machines thinking without expecting to be contradicted.\n\nHe did not live to see how apt his prophecy was. In 1952 he was arrested for the crime of homosexuality, tried, convicted, stripped of his security clearance, and subjected by the British authorities to a humiliating, emasculating program of estrogen injections. In 1954 he took his own life.\n\nUntil years later, few knew of Turing\u2019s crucial secret work for his country on the Enigma project at Bletchley Park. His ideas of thinking machines did attract attention, on both sides of the Atlantic. Some of the people who found the notion absurd or even frightening appealed to Shannon for his opinion; he stood squarely with Turing. \u201cThe idea of a machine thinking is by no means repugnant to all of us,\u201d Shannon told one engineer. \u201cIn fact, I find the converse idea, that the human brain may itself be a machine which could be duplicated functionally with inanimate objects, quite attractive.\u201d More useful, anyway, than \u201chypothesating intangible and unreachable \u2018vital forces,\u2019 \u2018souls\u2019 and the like.\u201d\n\nComputer scientists wanted to know what their machines could do. Psychologists wanted to know whether brains are computers\u2014or perhaps whether brains are merely computers. At midcentury computer scientists were new; but so, in their way, were psychologists.\n\nPsychology at midcentury had grown moribund. Of all the sciences, it always had the most difficulty in saying what exactly it studied. Originally its object was the soul, as opposed to the body (somatology) and the blood (hematology). \u201cPsychologie is a doctrine which searches out man\u2019s Soul, and the effects of it; this is the part without which a man cannot consist,\u201d wrote James de Back in the seventeenth century. Almost by definition, though, the soul was ineffable\u2014hardly a thing to be known. Complicating matters further was the entanglement (in psychology as in no other field) of the observer with the observed. In 1854, when\nit was still more likely to be called \u201cmental philosophy,\u201d David Brewster lamented that no other department of knowledge had made so little progress as \u201cthe science of mind, if it can be called a science.\u201d\n\nViewed as material by one inquirer, as spiritual by another, and by others as mysteriously compounded as both, the human mind escapes from the cognisance of sense and reason, and lies, a waste field with a northern exposure, upon which every passing speculator casts his mental tares.\n\nThe passing speculators were still looking mainly inward, and the limits of introspection were apparent. Looking for rigor, verifiability, and perhaps even mathematicization, students of the mind veered in radically different directions by the turn of the twentieth century. Sigmund Freud\u2019s path was only one. In the United States, William James constructed a discipline of psychology almost single-handed\u2014professor of the first university courses, author of the first comprehensive textbook\u2014and when he was done, he threw up his hands. His own *Principles of Psychology*, he wrote, was \u201ca loathsome, distended, tumefied, bloated, dropsical mass, testifying to but two facts: 1st, that there is no such thing as a *science* of psychology, and 2nd, that WJ is an incapable.\u201d\n\nIn Russia, a new strain of psychology began with a physiologist, Ivan Petrovich Pavlov, known for his Nobel Prize\u2013winning study of digestion, who scorned the word *psychology* and all its associated terminology. James, in his better moods, considered psychology the science of mental life, but for Pavlov there was no mind, only behavior. Mental states, thoughts, emotions, goals, and purpose\u2014all these were intangible, subjective, and out of reach. They bore the taint of religion and superstition. What James had identified as central topics\u2014\u201cthe stream of thought,\u201d \u201cthe consciousness of self,\u201d the perception of time and space, imagination, reasoning, and will\u2014had no place in Pavlov\u2019s laboratory. All a scientist could observe was behavior, and this, at least, could be recorded and measured. The behaviorists, particularly John B. Watson in the United States and then, most famously, B. F. Skinner, made a science based on stimulus and response: food pellets, bells, electric shocks; salivation, lever pressing, maze running. Watson said that the whole purpose of psychology was to predict what responses would follow a given stimulus and what stimuli could produce a given behavior. Between stimulus and response lay a black box, known to be composed of sense organs, neural pathways, and motor functions, but fundamentally off limits. In effect, the behaviorists were saying yet again that the soul is ineffable. For a half century, their research program thrived because it produced results about conditioning reflexes and controlling behavior.\n\nBehaviorists said, as the psychologist George Miller put it afterward: \u201cYou talk about memory; you talk about anticipation; you talk about your feelings; you talk about all these mentalistic things. That\u2019s moonshine. Show me one, point to one.\u201d\nThey could teach pigeons to play ping-pong and rats to run mazes. But by midcentury, frustration had set in. The behaviorists\u2019 purity had become a dogma; their refusal to consider mental states became a cage, and psychologists still wanted to understand what the mind was.\n\nInformation theory gave them a way in. Scientists analyzed the processing of information and built machines to do it. The machines had memory. They simulated learning and goal seeking. A behaviorist running a rat through a maze would discuss the association between stimulus and response but would refuse to speculate in any way about the mind of the rat; now engineers were building mental models of rats out of a few electrical relays. They were not just prying open the black box; they were making their own. Signals were being transmitted, encoded, stored, and retrieved. Internal models of the external world were created and updated. Psychologists took note. From information theory and cybernetics, they received a set of useful metaphors and even a productive conceptual framework. Shannon\u2019s rat could be seen not only as a very crude model of the brain but also as a theory of behavior. Suddenly psychologists were free to talk about plans, algorithms, syntactic rules. They could investigate not just how living creatures react to the outside world but how they represent it to themselves.\n\nShannon\u2019s formulation of information theory seemed to invite researchers to look in a direction that he himself had not intended. He had declared, \u201cThe fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point.\u201d A psychologist could hardly fail to consider the case where the source of the message is the outside world and the receiver is the mind.\n\nEars and eyes were to be understood as message channels, so why not test and measure them like microphones and cameras? \u201cNew concepts of the nature and measure of information,\u201d wrote Homer Jacobson, a chemist at Hunter College in New York, \u201chave made it possible to specify quantitatively the informational capacity of the human ear,\u201d and he proceeded to do so. Then he did the same for the eye, arriving at an estimate four hundred times greater, in bits per second. Many more subtle kinds of experiments were suddenly fair game, some of them directly suggested by Shannon\u2019s work on noise and redundancy. A group in 1951 tested the likelihood that listeners would hear a word correctly when they knew it was one of just a few alternatives, as opposed to many alternatives. It seemed obvious but had never been done. Experimenters explored the effect of trying to understand two conversations at once. They began considering how much information an ensemble of items contained\u2014digits or letters or words\u2014and how much could be understood or remembered. In standard experiments, with speech and buzzers and key pressing and foot tapping, the language of stimulus and response began to give way to transmission and reception of information.\nFor a brief period, researchers discussed the transition explicitly; later it became invisible. Donald Broadbent, an English experimental psychologist exploring issues of attention and short-term memory, wrote of one experiment in 1958: \u201cThe difference between a description of the results in terms of stimulus and response, and a description in information theory terms, becomes most marked\u2026. One could no doubt develop an adequate description of the results in S-R terms \u2026 but such a description is clumsy compared to the information theory description.\u201d Broadbent founded an applied psychology division at Cambridge University, and a flood of research followed, there and elsewhere, in the general realm of how people handle information: effects of noise on performance; selective attention and filtering of perception; short-term and long-term memory; pattern recognition; problem solving. And where did logic belong? To psychology or to computer science? Surely not just to philosophy.\n\nAn influential counterpart of Broadbent\u2019s in the United States was George Miller, who helped found the Center for Cognitive Studies at Harvard in 1960. He was already famous for a paper published in 1956 under the slightly whimsical title \u201cThe Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information.\u201d Seven seemed to be the number of items that most people could hold in working memory at any one time: seven digits (the typical American telephone number of the time), seven words, or seven objects displayed by an experimental psychologist. The number also kept popping up, Miller claimed, in other sorts of experiments. Laboratory subjects were fed sips of water with different amounts of salt, to see how many different levels of saltiness they could discriminate. They were asked to detect differences between tones of varying pitch or loudness. They were shown random patterns of dots, flashed on a screen, and asked how many (below seven, they almost always knew; above seven, they almost always estimated). In one way and another, the number seven kept recurring as a threshold. \u201cThis number assumes a variety of disguises,\u201d he wrote, \u201cbeing sometimes a little larger and sometimes a little smaller than usual, but never changing so much as to be unrecognizable.\u201d\n\nClearly this was a crude simplification of some kind; as Miller noted, people can identify any of thousands of faces or words and can memorize long sequences of symbols. To see what kind of simplification, he turned to information theory, and especially to Shannon\u2019s understanding of information as a selection among possible alternatives. \u201cThe observer is considered to be a communication channel,\u201d he announced\u2014a formulation sure to appall the behaviorists who dominated the profession. Information is being transmitted and stored\u2014information about loudness, or saltiness, or number. He explained about bits:\n\nOne bit of information is the amount of information that we need to make a decision between two equally likely alternatives. If we must decide whether a man is less than six feet tall or more than six feet tall and if we know that the chances are 50-50, then\nwe need one bit of information\u2026.\n\nTwo bits of information enable us to decide among four equally likely alternatives. Three bits of information enable us to decide among eight equally likely alternatives \u2026 and so on. That is to say, if there are 32 equally likely alternatives, we must make five successive binary decisions, worth one bit each, before we know which alternative is correct. So the general rule is simple: every time the number of alternatives is increased by a factor of two, one bit of information is added.\n\nThe magical number seven is really just under three bits. Simple experiments measured discrimination, or channel capacity, in a single dimension; more complex measures arise from combinations of variables in multiple dimensions\u2014for example, size, brightness, and hue. And people perform acts of what information theorists call \u201crecoding,\u201d grouping information into larger and larger chunks\u2014for example, organizing telegraph dots and dashes into letters, letters into words, and words into phrases. By now Miller\u2019s argument had become something in the nature of a manifesto. Recoding, he declared, \u201cseems to me to be the very lifeblood of the thought processes.\u201d\n\nThe concepts and measures provided by the theory of information provide a quantitative way of getting at some of these questions. The theory provides us with a yardstick for calibrating our stimulus materials and for measuring the performance of our subjects\u2026. Informational concepts have already proved valuable in the study of discrimination and of language; they promise a great deal in the study of learning and memory; and it has even been proposed that they can be useful in the study of concept formation. A lot of questions that seemed fruitless twenty or thirty years ago may now be worth another look.\n\nThis was the beginning of the movement called the cognitive revolution in psychology, and it laid the foundation for the discipline called cognitive science, combining psychology, computer science, and philosophy. Looking back, some philosophers have called this moment the informational turn. \u201cThose who take the informational turn see information as the basic ingredient in building a mind,\u201d writes Frederick Adams. \u201cInformation has to contribute to the origin of the mental.\u201d As Miller himself liked to say, the mind came in on the back of the machine.\n\nShannon was hardly a household name\u2014he never did become famous to the general public\u2014but he had gained an iconic stature in his own academic communities, and sometimes he gave popular talks about \u201cinformation\u201d at universities and museums. He would explain the basic ideas; puckishly quote Matthew 5:37, \u201cLet your communication be, Yea, yea; Nay, nay: for whatsoever is more than these cometh of evil\u201d as a template for the notions of bits and of redundant encoding; and speculate about the future of computers and automata. \u201cWell, to conclude,\u201d he said at the University of Pennsylvania, \u201cI think that this present century in a sense will see a great upsurge and development of this whole\nThe Information\n\ninformation business; the business of collecting information and the business of transmitting it from one point to another, and perhaps most important of all, the business of processing it.\u201d\n\nWith psychologists, anthropologists, linguists, economists, and all sorts of social scientists climbing aboard the bandwagon of information theory, some mathematicians and engineers were uncomfortable. Shannon himself called it a bandwagon. In 1956 he wrote a short warning notice\u2014four paragraphs: \u201cOur fellow scientists in many different fields, attracted by the fanfare and by the new avenues opened to scientific analysis, are using these ideas in their own problems\u2026. Although this wave of popularity is certainly pleasant and exciting for those of us working in the field, it carries at the same time an element of danger.\u201d Information theory was in its hard core a branch of mathematics, he reminded them. He, personally, did believe that its concepts would prove useful in other fields, but not everywhere, and not easily: \u201cThe establishing of such applications is not a trivial matter of translating words to a new domain, but rather the slow tedious process of hypothesis and experimental verification.\u201d Furthermore, he felt the hard slogging had barely begun in \u201cour own house.\u201d He urged more research and less exposition.\n\nAs for cybernetics, the word began to fade. The Macy cyberneticians held their last meeting in 1953, at the Nassau Inn in Princeton; Wiener had fallen out with several of the group, who were barely speaking to him. Given the task of summing up, McCulloch sounded wistful. \u201cOur consensus has never been unanimous,\u201d he said. \u201cEven had it been so, I see no reason why God should have agreed with us.\u201d\n\nThroughout the 1950s, Shannon remained the intellectual leader of the field he had founded. His research produced dense, theorem-packed papers, pregnant with possibilities for development, laying foundations for broad fields of study. What Marshall McLuhan later called the \u201cmedium\u201d was for Shannon the channel, and the channel was subject to rigorous mathematical treatment. The applications were immediate and the results fertile: broadcast channels and wiretap channels, noisy and noiseless channels, Gaussian channels, channels with input constraints and cost constraints, channels with feedback and channels with memory, multiuser channels and multiaccess channels. (When McLuhan announced that the medium was the message, he was being arch. The medium is both opposite to, and entwined with, the message.)\n\nOne of Shannon\u2019s essential results, the noisy coding theorem, grew in importance, showing that error correction can effectively counter noise and corruption. At first this was just a tantalizing theoretical nicety; error correction requires computation, which was not yet cheap. But during the 1950s, work on\nerror-correcting methods began to fulfill Shannon\u2019s promise, and the need for them became apparent. One application was exploration of space with rockets and satellites; they needed to send messages very long distances with limited power. Coding theory became a crucial part of computer science, with error correction and data compression advancing side by side. Without it, modems, CDs, and digital television would not exist. For mathematicians interested in random processes, coding theorems are also measures of entropy.\n\nShannon, meanwhile, made other theoretical advances that planted seeds for future computer design. One discovery showed how to maximize flow through a network of many branches, where the network could be a communication channel or a railroad or a power grid or water pipes. Another was aptly titled \u201cReliable Circuits Using Crummy Relays\u201d (though this was changed for publication to \u201c\u2026 Less Reliable Relays\u201d). He studied switching functions, rate-distortion theory, and differential entropy. All this was invisible to the public, but the seismic tremors that came with the dawn of computing were felt widely, and Shannon was part of that, too.\n\nAs early as 1948 he completed the first paper on a problem that he said, \u201cof course, is of no importance in itself\u201d: how to program a machine to play chess. People had tried this before, beginning in the eighteenth and nineteenth centuries, when various chess automata toured Europe and were revealed every so often to\nhave small humans hiding inside. In 1910 the Spanish mathematician and tinkerer Leonardo Torres y Quevedo built a real chess machine, entirely mechanical, called El Ajedrecista, that could play a simple three-piece endgame, king and rook against king.\n\nShannon now showed that computers performing numerical calculations could be made to play a full chess game. As he explained, these devices, \u201ccontaining several thousand vacuum tubes, relays, and other elements,\u201d retained numbers in \u201cmemory,\u201d and a clever process of translation could make these numbers represent the squares and pieces of a chessboard. The principles he laid out have been employed in every chess program since. In these salad days of computing, many people immediately assumed that chess would be solved: fully known, in all its pathways and combinations. They thought a fast electronic computer would play perfect chess, just as they thought it would make reliable long-term weather forecasts. Shannon made a rough calculation, however, and suggested that the number of possible chess games was more than $10^{120}$\u2014a number that dwarfs the age of the universe in nanoseconds. So computers cannot play chess by brute force; they must reason, as Shannon saw, along something like human lines.\n\nHe visited the American champion Edward Lasker in his apartment on East Twenty-third Street in New York, and Lasker offered suggestions for improvement. When *Scientific American* published a simplified version of his paper in 1950, Shannon could not resist raising the question on everyone\u2019s minds: \u201cDoes a chess-playing machine of this type \u2018think\u2019?\u201d\n\nFrom a behavioristic point of view, the machine acts as though it were thinking. It has always been considered that skillful chess play requires the reasoning faculty. If we regard thinking as a property of external actions rather than internal method the machine is surely thinking.\n\nNonetheless, as of 1952 he estimated that it would take three programmers working six months to enable a large-scale computer to play even a tolerable amateur game. \u201cThe problem of a learning chess player is even farther in the future than a preprogrammed type. The methods which have been suggested are obviously extravagantly slow. The machine would wear out before winning a single game.\u201d The point, though, was to look in as many directions as possible for what a general-purpose computer could do.\n\nHe was exercising his sense of whimsy, too. He designed and actually built a machine to do arithmetic with Roman numerals: for example, IV times XII equals XLVIII. He dubbed this THROBAC I, an acronym for Thrifty Roman-numeral Backward-looking Computer. He created a \u201cmind-reading machine\u201d meant to play the child\u2019s guessing game of odds and evens. What all these flights of fancy had in common was an extension of algorithmic processes into new realms\u2014the abstract mapping of ideas onto mathematical objects. Later, he wrote thousands\nof words on scientific aspects of juggling\u2014with theorems and corollaries\u2014and included from memory a quotation from E. E. Cummings: \u201cSome son-of-a-bitch will invent a machine to measure Spring with.\u201d\n\nIn the 1950s Shannon was also trying to design a machine that would repair itself. If a relay failed, the machine would locate and replace it. He speculated on the possibility of a machine that could reproduce itself, collecting parts from the environment and assembling them. Bell Labs was happy for him to travel and give talks on such things, often demonstrating his maze-learning machine, but audiences were not universally delighted. The word \u201cFrankenstein\u201d was heard. \u201cI wonder if you boys realize what you\u2019re toying around with there,\u201d wrote a newspaper columnist in Wyoming.\n\nWhat happens if you switch on one of these mechanical computers but forget to turn it off before you leave for lunch? Well, I\u2019ll tell you. The same thing would happen in the way of computers in America that happened to Australia with jack rabbits. Before you could multiply $701,945,240$ by $879,030,546$, every family in the country would have a little computer of their own\u2026.\n\nMr. Shannon, I don\u2019t mean to knock your experiments, but frankly I\u2019m not remotely interested in even one computer, and I\u2019m going to be pretty sore if a gang of them crowd in on me to multiply or divide or whatever they do best.\n\nTwo years after Shannon raised his warning flag about the bandwagon, a younger information theorist, Peter Elias, published a notice complaining about a paper titled \u201cInformation Theory, Photosynthesis, and Religion.\u201d There was, of course, no such paper. But there had been papers on information theory, life, and topology; information theory and the physics of tissue damage; and clerical systems; and psychopharmacology; and geophysical data interpretation; and crystal structure; and melody. Elias, whose father had worked for Edison as an engineer, was himself a serious specialist\u2014a major contributor to coding theory. He mistrusted the softer, easier, platitudinous work flooding across disciplinary boundaries. The typical paper, he said, \u201cdiscusses the surprisingly close relationship between the vocabulary and conceptual framework of information theory and that of psychology (or genetics, or linguistics, or psychiatry, or business organization)\u2026. The concepts of structure, pattern, entropy, noise, transmitter, receiver, and code are (when properly interpreted) central to both.\u201d He declared this to be larceny. \u201cHaving placed the discipline of psychology for the first time on a sound scientific basis, the author modestly leaves the filling in of the outline to the psychologists.\u201d He suggested his colleagues give up larceny for a life of honest toil.\n\nThese warnings from Shannon and Elias appeared in one of the growing number of new journals entirely devoted to information theory.\n\nIn these circles a notorious buzzword was *entropy*. Another researcher, Colin\nCherry, complained, \u201cWe have heard of \u2018entropies\u2019 of languages, social systems, and economic systems and of its use in various method-starved studies. It is the kind of sweeping generality which people will clutch like a straw.\u201d He did not say, because it was not yet apparent, that information theory was beginning to change the course of theoretical physics and of the life sciences and that entropy was one of the reasons.\n\nIn the social sciences, the direct influence of information theorists had passed its peak. The specialized mathematics had less and less to contribute to psychology and more and more to computer science. But their contributions had been real. They had catalyzed the social sciences and prepared them for the new age under way. The work had begun; the informational turn could not be undone.\n\n* As Jean-Pierre Dupuy remarks: \u201cIt was, at bottom, a perfectly ordinary situation, in which scientists blamed nonscientists for taking them at their word. Having planted the idea in the public mind that thinking machines were just around the corner, the cyberneticians hastened to dissociate themselves from anyone gullible enough to believe such a thing.\u201d\nThought interferes with the probability of events, and, in the long run therefore, with entropy.\n\n\u2014David L. Watson (1930)\n\nIT WOULD BE AN EXAGGERATION TO SAY that no one knew what *entropy* meant. Still, it was one of those words. The rumor at Bell Labs was that Shannon had gotten it from John von Neumann, who advised him he would win every argument because no one would understand it. Untrue, but plausible. The word began by meaning the opposite of itself. It remains excruciatingly difficult to define. The *Oxford English Dictionary*, uncharacteristically, punts:\n\n1. The name given to one of the quantitative elements which determine the thermodynamic condition of a portion of matter.\n\nRudolf Clausius coined the word in 1865, in the course of creating a science of thermodynamics. He needed to name a certain quantity that he had discovered\u2014a quantity related to energy, but not energy.\n\nThermodynamics arose hand in hand with steam engines; it was at first nothing more than \u201cthe theoretical study of the steam engine.\u201d It concerned itself with the conversion of heat, or energy, into work. As this occurs\u2014heat drives an engine\u2014Clausius observed that the heat does not actually get lost; it merely passes from a hotter body into a cooler body. On its way, it accomplishes something. This is like a waterwheel, as Nicolas Sadi Carnot kept pointing out in France: water begins at the top and ends at the bottom, and no water is gained or lost, but the water performs work on the way down. Carnot imagined heat as just such a substance. The ability of a thermodynamic system to produce work depends not on the heat itself, but on the contrast between hot and cold. A hot stone plunged into cold water can generate work\u2014for example, by creating steam that drives a turbine\u2014but the total heat in the system (stone plus water) remains constant. Eventually, the stone and the water reach the same temperature. No matter how much energy a closed system contains, when everything is the same temperature, no work can be done.\n\nIt is the unavailability of this energy\u2014its uselessness for work\u2014that Clausius wanted to measure. He came up with the word *entropy*, formed from Greek to mean \u201ctransformation content.\u201d His English counterparts immediately saw the\npoint but decided Clausius had it backward in focusing on the negative. James Clerk Maxwell suggested in his *Theory of Heat* that it would be \u201cmore convenient\u201d to make entropy mean the opposite: \u201cthe part which can be converted into mechanical work.\u201d Thus:\n\nWhen the pressure and temperature of the system have become uniform the entropy is exhausted.\n\nWithin a few years, though, Maxwell turned about-face and decided to follow Clausius. He rewrote his book and added an abashed footnote:\n\nIn former editions of this book the meaning of the term Entropy, as introduced by Clausius, was erroneously stated to be that part of the energy which cannot be converted into work. The book then proceeded to use the term as equivalent to the available energy; thus introducing great confusion into the language of thermodynamics. In this edition I have endeavoured to use the word Entropy according to its original definition by Clausius.\n\nThe problem was not just in choosing between positive and negative. It was subtler than that. Maxwell had first considered entropy as a subtype of energy: the energy available for work. On reconsideration, he recognized that thermodynamics needed an entirely different measure. Entropy was not a kind of energy or an amount of energy; it was, as Clausius had said, the unavailability of energy. Abstract though this was, it turned out to be a quantity as measurable as temperature, volume, or pressure.\n\nIt became a totemic concept. With entropy, the \u201claws\u201d of thermodynamics could be neatly expressed:\n\nFirst law: The energy of the universe is constant.\n\nSecond law: The entropy of the universe always increases.\n\nThere are many other formulations of these laws, from the mathematical to the whimsical, e.g., \u201c1. You can\u2019t win; 2. You can\u2019t break even either.\u201d But this is the cosmic, fateful one. The universe is running down. It is a degenerative one-way street. The final state of maximum entropy is our destiny.\n\nWilliam Thomson, Lord Kelvin, imprinted the second law on the popular imagination by reveling in its bleakness: \u201cAlthough mechanical energy is indestructible,\u201d he declared in 1862, \u201cthere is a universal tendency to its dissipation, which produces gradual augmentation and diffusion of heat, cessation of motion, and exhaustion of potential energy through the material universe. The result of this would be a state of universal rest and death.\u201d Thus entropy dictated the universe\u2019s fate in H. G. Wells\u2019s novel *The Time Machine*: the life ebbing away, the dying sun, the \u201cabominable desolation that hung over the world.\u201d Heat death is not cold; it is lukewarm and dull. Freud thought he saw something useful there in 1918, though he muddled it: \u201cIn considering the conversion of psychical\nenergy no less than of physical, we must make use of the concept of an entropy, which opposes the undoing of what has already occurred.\u201d\n\nThomson liked the word *dissipation* for this. Energy is not lost, but it dissipates. Dissipated energy is present but useless. It was Maxwell, though, who began to focus on the confusion itself\u2014the disorder\u2014as entropy\u2019s essential quality. Disorder seemed strangely unphysical. It implied that a piece of the equation must be something like knowledge, or intelligence, or judgment. \u201cThe idea of dissipation of energy depends on the extent of our knowledge,\u201d Maxwell said. \u201cAvailable energy is energy which we can direct into any desired channel. Dissipated energy is energy which we cannot lay hold of and direct at pleasure, such as the energy of the confused agitation of molecules which we call heat.\u201d What *we* can do, or know, became part of the definition. It seemed impossible to talk about order and disorder without involving an agent or an observer\u2014without talking about the mind:\n\nConfusion, like the correlative term order, is not a property of material things in themselves, but only in relation to the mind which perceives them. A memorandum-book does not, provided it is neatly written, appear confused to an illiterate person, or to the owner who understands it thoroughly, but to any other person able to read it appears to be inextricably confused. Similarly the notion of dissipated energy could not occur to a being who could not turn any of the energies of nature to his own account, or to one who could trace the motion of every molecule and seize it at the right moment.\n\nOrder is subjective\u2014in the eye of the beholder. Order and confusion are not the sorts of things a mathematician would try to define or measure. Or are they? If disorder corresponded to entropy, maybe it was ready for scientific treatment after all.\n\nAs an ideal case, the pioneers of thermodynamics considered a box of gas. Being made of atoms, it is far from simple or calm. It is a vast ensemble of agitating particles. Atoms were unseen and hypothetical, but these theorists\u2014Clausius, Kelvin, Maxwell, Ludwig Boltzmann, Willard Gibbs\u2014accepted the atomic nature of a fluid and tried to work out the consequences: mixing, violence, continuous motion. This motion constitutes heat, they now understood. Heat is no substance, no fluid, no \u201cphlogiston\u201d\u2014just the motion of molecules.\n\nIndividually the molecules must be obeying Newton\u2019s laws\u2014every action, every collision, measurable and calculable, in theory. But there were too many to measure and calculate individually. Probability entered the picture. The new science of statistical mechanics made a bridge between the microscopic details and the macroscopic behavior. Suppose the box of gas is divided by a diaphragm. The gas on side A is hotter than the gas on side B\u2014that is, the A molecules are moving faster, with greater energy. As soon as the divider is removed, the\nmolecules begin to mix; the fast collide with the slow; energy is exchanged; and after some time the gas reaches a uniform temperature. The mystery is this: Why can the process not be reversed? In Newton\u2019s equations of motion, time can have a plus sign or a minus sign; the mathematics works either way. In the real world past and future cannot be interchanged so easily.\n\n\u201cTime flows on, never comes back,\u201d said L\u00e9on Brillouin in 1949. \u201cWhen the physicist is confronted with this fact he is greatly disturbed.\u201d Maxwell had been mildly disturbed. He wrote to Lord Rayleigh:\n\nIf this world is a purely dynamical system, and if you accurately reverse the motion of every particle of it at the same instant, then all things will happen backwards to the beginning of things, the raindrops will collect themselves from the ground and fly up to the clouds, etc, etc, and men will see their friends passing from the grave to the cradle till we ourselves become the reverse of born, whatever that is.\n\nHis point was that in the microscopic details, if we watch the motions of individual molecules, their behavior is the same forward and backward in time. We can run the film backward. But pan out, watch the box of gas as an ensemble, and statistically the mixing process becomes a one-way street. We can watch the fluid for all eternity, and it will never divide itself into hot molecules on one side and cool on the other. The clever young Thomasina says in Tom Stoppard\u2019s Arcadia, \u201cYou cannot stir things apart,\u201d and this is precisely the same as \u201cTime flows on, never comes back.\u201d Such processes run in one direction only. Probability is the reason. What is remarkable\u2014physicists took a long time to accept it\u2014is that every irreversible process must be explained the same way. Time itself depends on chance, or \u201cthe accidents of life,\u201d as Richard Feynman liked to say: \u201cWell, you see that all there is to it is that the irreversibility is caused by the general accidents of life.\u201d For the box of gas to come unmixed is not physically impossible; it is just improbable in the extreme. So the second law is merely probabilistic. Statistically, everything tends toward maximum entropy.\n\nYet probability is enough: enough for the second law to stand as a pillar of science. As Maxwell put it:\n\nMoral. The 2nd law of Thermodynamics has the same degree of truth as the statement that if you throw a tumblerful of water into the sea, you cannot get the same tumblerful of water out again.\n\nThe improbability of heat passing from a colder to a warmer body (without help from elsewhere) is identical to the improbability of order arranging itself from disorder (without help from elsewhere). Both, fundamentally, are due only to statistics. Counting all the possible ways a system can be arranged, the disorderly ones far outnumber the orderly ones. There are many arrangements, or \u201cstates,\u201d in which molecules are all jumbled, and few in which they are neatly sorted. The orderly states have low probability and low entropy. For impressive degrees of\norderliness, the probabilities may be very low. Alan Turing once whimsically proposed a number $N$, defined as \u201cthe odds against a piece of chalk leaping across the room and writing a line of Shakespeare on the board.\u201d\n\nEventually physicists began speaking of microstates and macrostates. A macrostate might be: all the gas in the top half of the box. The corresponding microstates would be all the possible arrangements of all particles\u2014positions and velocities. Entropy thus became a physical equivalent of probability: the entropy of a given macrostate is the logarithm of the number of its possible microstates. The second law, then, is the tendency of the universe to flow from less likely (orderly) to more likely (disorderly) macrostates.\n\nIt was still puzzling, though, to hang so much of physics on a matter of mere probability. Can it be right to say that nothing in physics is stopping a gas from dividing itself into hot and cold\u2014that it is only a matter of chance and statistics? Maxwell illustrated this conundrum with a thought experiment. Imagine, he suggested, \u201ca finite being\u201d who stands watch over a tiny hole in the diaphragm dividing the box of gas. This creature can see molecules coming, can tell whether they are fast or slow, and can choose whether or not to let them pass. Thus he could tilt the odds. By sorting fast from slow, he could make side A hotter and side B colder\u2014and yet no work has been done, only the intelligence of a very observant and neat-fingered being has been employed.\u201d The being defies ordinary probabilities. The chances are, things get mixed together. To sort them out requires information.\n\nThomson loved this idea. He dubbed the notional creature a demon:\n\u201cMaxwell\u2019s intelligent demon,\u201d \u201cMaxwell\u2019s sorting demon,\u201d and soon just \u201cMaxwell\u2019s demon.\u201d Thomson waxed eloquent about the little fellow: \u201cHe differs from real living animals only [only!] in extreme smallness and agility.\u201d Lecturing to an evening crowd at the Royal Institution of Great Britain, with the help of tubes of liquid dyed two different colors, Thomson demonstrated the apparently irreversible process of diffusion and declared that only the demon can counteract it:\n\nHe can cause one-half of a closed jar of air, or of a bar of iron, to become glowingly hot and the other ice cold; can direct the energy of the moving molecules of a basin of water to throw the water up to a height and leave it there proportionately cooled; can \u201csort\u201d the molecules in a solution of salt or in a mixture of two gases, so as to reverse the natural process of diffusion, and produce concentration of the solution in one portion of the water, leaving pure water in the remainder of the space occupied; or, in the other case, separate the gases into different parts of the containing vessel.\n\nThe reporter for *The Popular Science Monthly* thought this was ridiculous. \u201cAll nature is supposed to be filled with infinite swarms of absurd little microscopic imps,\u201d he sniffed. \u201cWhen men like Maxwell, of Cambridge, and Thomson, of Glasgow, lend their sanction to such a crude hypothetical fancy as that of little devils knocking and kicking the atoms this way and that \u2026, we may well ask, What next?\u201d He missed the point. Maxwell had not meant his demon to exist, except as a teaching device.\n\nThe demon sees what we cannot\u2014because we are so gross and slow\u2014namely, that the second law is statistical, not mechanical. At the level of molecules, it is violated all the time, here and there, purely by chance. The demon replaces chance with purpose. It uses information to reduce entropy. Maxwell never imagined how popular his demon would become, nor how long-lived. Henry Adams, who wanted to work some version of entropy into his theory of history, wrote to his brother Brooks in 1903, \u201cClerk Maxwell\u2019s demon who runs the second law of Thermo-dynamics ought to be made President.\u201d The demon presided over a gateway\u2014at first, a magical gateway\u2014from the world of physics to the world of information.\n\nScientists envied the demon\u2019s powers. It became a familiar character in cartoons enlivening physics journals. To be sure, the creature was a fantasy, but the atom itself had seemed fantastic, and the demon had helped tame it. Implacable as the laws of nature now seemed, the demon defied these laws. It was a burglar, picking the lock one molecule at a time. It had \u201cinfinitely subtile senses,\u201d wrote Henri Poincar\u00e9, and \u201ccould turn back the course of the universe.\u201d Was this not just what humans dreamed of doing?\nThrough their ever better microscopes, scientists of the early twentieth century examined the active, sorting processes of biological membranes. They discovered that living cells act as pumps, filters, and factories. Purposeful processes seemed to operate at tiny scales. Who or what was in control? Life itself seemed an organizing force. \u201cNow we must not introduce demonology into science,\u201d wrote the British biologist James Johnstone in 1914. In physics, he said, individual molecules must remain beyond our control. \u201cThese motions and paths are un-co-ordinated\u2014\u2018helter-skelter\u2019\u2014if we like so to term them. Physics considers only the statistical mean velocities.\u201d That is why the phenomena of physics are irreversible, \u201cso that for the latter science Maxwell\u2019s demons do not exist.\u201d But what of life? What of physiology? The processes of terrestrial life are reversible, he argued. \u201cWe must therefore seek for evidence that the organism can control the, otherwise, un-co-ordinated motions of the individual molecules.\u201d\n\nIs it not strange that while we see that most of our human effort is that of directing natural agencies and energies into paths which they would not otherwise take, we should yet have failed to think of primitive organisms, or even of the tissue elements in the bodies of the higher organisms, as possessing also the power of directing physico-chemical processes?\n\nWhen life remained so mysterious, maybe Maxwell\u2019s demon was not just a cartoon.\nThen the demon began to haunt Le\u00f3 Szil\u00e1rd, a very young Hungarian physicist with a productive imagination who would later conceive the electron microscope and, not incidentally, the nuclear chain reaction. One of his more famous teachers, Albert Einstein, advised him out of avuncular protectiveness to take a paying job with the patent office, but Szil\u00e1rd ignored the advice. He was thinking in the 1920s about how thermodynamics should deal with incessant molecular fluctuations. By definition, fluctuations ran counter to averages, like fish swimming momentarily upstream, and people naturally wondered: what if you could harness them? This irresistible idea led to a version of the perpetual motion machine, *perpetuum mobile*, holy grail of cranks and hucksters. It was another way of saying, \u201cAll that heat\u2014why can\u2019t we use it?\u201d\n\nIt was also another of the paradoxes engendered by Maxwell\u2019s demon. In a closed system, a demon who could catch the fast molecules and let the slow molecules pass would have a source of useful energy, continually refreshed. Or, if not the chimerical imp, what about some other \u201cintelligent being\u201d? An experimental physicist, perhaps? A perpetual motion machine should be possible, declared Szil\u00e1rd, \u201cif we view the experimenting man as a sort of *deus ex machina*, one who is continuously informed of the existing state of nature.\u201d For his version of the thought experiment, Szil\u00e1rd made clear that he did not wish to invoke a living demon, with, say, a brain\u2014biology brought troubles of its own. \u201cThe very existence of a nervous system,\u201d he noted, \u201cis dependent on continual dissipation of energy.\u201d (His friend Carl Eckart pithily rephrased this: \u201cThinking generates entropy.\u201d) Instead he proposed a \u201cnonliving device,\u201d intervening in a model thermodynamic system, operating a piston in a cylinder of fluid. He pointed out that this device would need, in effect, \u201ca sort of memory faculty.\u201d (Alan Turing was now, in 1929, a teenager. In Turing\u2019s terms, Szil\u00e1rd was treating the mind of the demon as a computer with a two-state memory.)\n\nSzil\u00e1rd showed that even this perpetual motion machine would have to fail. What was the catch? Simply put: information is not free. Maxwell, Thomson, and the rest had implicitly talked as though knowledge was there for the taking\u2014knowledge of the velocities and trajectories of molecules coming and going before the demon\u2019s eyes. They did not consider the cost of this information. They could not; for them, in a simpler time, it was as if the information belonged to a parallel universe, an astral plane, not linked to the universe of matter and energy, particles and forces, whose behavior they were learning to calculate.\n\nBut information is physical. Maxwell\u2019s demon makes the link. The demon performs a conversion between information and energy, one particle at a time. Szil\u00e1rd\u2014who did not yet use the word *information*\u2014found that, if he accounted exactly for each measurement and memory, then the conversion could be computed exactly. So he computed it. He calculated that each unit of information\nbrings a corresponding increase in entropy\u2014specifically, by $k \\log 2$ units. Every time the demon makes a choice between one particle and another, it costs one bit of information. The payback comes at the end of the cycle, when it has to clear its memory (Szil\u00e1rd did not specify this last detail in words, but in mathematics). Accounting for this properly is the only way to eliminate the paradox of perpetual motion, to bring the universe back into harmony, to \u201crestore concordance with the Second Law.\u201d\n\nSzil\u00e1rd had thus closed a loop leading to Shannon\u2019s conception of entropy as information. For his part, Shannon did not read German and did not follow *Zeitschrift f\u00fcr Physik*. \u201cI think actually Szil\u00e1rd was thinking of this,\u201d he said much later, \u201cand he talked to von Neumann about it, and von Neumann may have talked to Wiener about it. But none of these people actually talked to me about it.\u201d Shannon reinvented the mathematics of entropy nonetheless.\n\nTo the physicist, entropy is a measure of uncertainty about the state of a physical system: one state among all the possible states it can be in. These microstates may not be equally likely, so the physicist writes $S = -\\sum p_i \\log p_i$.\n\nTo the information theorist, entropy is a measure of uncertainty about a message: one message among all the possible messages that a communications source can produce. The possible messages may not be equally likely, so Shannon wrote $H = -\\sum p_i \\log p_i$.\n\nIt is not just a coincidence of formalism: nature providing similar answers to similar problems. It is all one problem. To reduce entropy in a box of gas, to perform useful work, one pays a price in information. Likewise, a particular message reduces the entropy in the ensemble of possible messages\u2014in terms of dynamical systems, a phase space.\n\nThat was how Shannon saw it. Wiener\u2019s version was slightly different. It was fitting\u2014for a word that began by meaning the opposite of itself\u2014that these colleagues and rivals placed opposite signs on their formulations of entropy. Where Shannon identified information with entropy, Wiener said it was negative entropy. Wiener was saying that information meant order, but an orderly thing does not necessarily embody much information. Shannon himself pointed out their difference and minimized it, calling it a sort of \u201cmathematical pun.\u201d They get the same numerical answers, he noted:\n\nI consider how much information is *produced* when a choice is made from a set\u2014the larger the set the *more* information. You consider the larger uncertainty in the case of a larger set to mean less knowledge of the situation and hence *less* information.\n\nPut another way, $H$ is a measure of surprise. Put yet another way, $H$ is the average number of yes-no questions needed to guess the unknown message. Shannon had\nit right\u2014at least, his approach proved fertile for mathematicians and physicists a generation later\u2014but the confusion lingered for some years. Order and disorder still needed some sorting.\n\nWe all behave like Maxwell\u2019s demon. Organisms organize. In everyday experience lies the reason sober physicists across two centuries kept this cartoon fantasy alive. We sort the mail, build sand castles, solve jigsaw puzzles, separate wheat from chaff, rearrange chess pieces, collect stamps, alphabetize books, create symmetry, compose sonnets and sonatas, and put our rooms in order, and to do all this requires no great energy, as long as we can apply intelligence. We propagate structure (not just we humans but we who are alive). We disturb the tendency toward equilibrium. It would be absurd to attempt a thermodynamic accounting for such processes, but it is not absurd to say we are reducing entropy, piece by piece. Bit by bit. The original demon, discerning one molecule at a time, distinguishing fast from slow, and operating his little gateway, is sometimes described as \u201csuperintelligent,\u201d but compared to a real organism it is an idiot savant. Not only do living things lessen the disorder in their environments; they are in themselves, their skeletons and their flesh, vesicles and membranes, shells and carapaces, leaves and blossoms, circulatory systems and metabolic pathways\u2014miracles of pattern and structure. It sometimes seems as if curbing entropy is our quixotic purpose in this universe.\n\nIn 1943 Erwin Schr\u00f6dinger, the chain-smoking, bow-tied pioneer of quantum physics, asked to deliver the Statutory Public Lectures at Trinity College, Dublin, decided the time had come to answer one of the greatest of unanswerable questions: What is life? The equation bearing his name was the essential formulation of quantum mechanics. In looking beyond his field, as middle-aged Nobel laureates so often do, Schr\u00f6dinger traded rigor for speculation and began by apologizing \u201cthat some of us should venture to embark on a synthesis of facts and theories, albeit with second-hand and incomplete knowledge of some of them\u2014and at the risk of making fools of ourselves.\u201d Nonetheless, the little book he made from these lectures became influential. Without discovering or even stating anything new, it laid a foundation for a nascent science, as yet unnamed, combining genetics and biochemistry. \u201cSchr\u00f6dinger\u2019s book became a kind of Uncle Tom\u2019s Cabin of the revolution in biology that, when the dust had cleared, left molecular biology as its legacy,\u201d one of the discipline\u2019s founders wrote later. Biologists had not read anything like it before, and physicists took it as a signal that the next great problems might lie in biology.\n\nSchr\u00f6dinger began with what he called the enigma of biological stability. In notable contrast to a box of gas, with its vagaries of probability and fluctuation, and in seeming disregard of Schr\u00f6dinger\u2019s own wave mechanics, where\nuncertainty is the rule, the structures of a living creature exhibit remarkable permanence. They persist, both in the life of the organism and across generations, through heredity. This struck Schr\u00f6dinger as requiring explanation.\n\n\u201cWhen is a piece of matter said to be alive?\u201d he asked. He skipped past the usual suggestions\u2014growth, feeding, reproduction\u2014and answered as simply as possible: \u201cWhen it goes on \u2018doing something,\u2019 moving, exchanging material with its environment, and so forth, for a much longer period than we would expect an inanimate piece of matter to \u2018keep going\u2019 under similar circumstances.\u201d Ordinarily, a piece of matter comes to a standstill; a box of gas reaches a uniform temperature; a chemical system \u201cfades away into a dead, inert lump of matter\u201d\u2014one way or another, the second law is obeyed and maximum entropy is reached. Living things manage to remain unstable. Norbert Wiener pursued this thought in *Cybernetics*: enzymes, he wrote, may be \u201cmetastable\u201d Maxwell\u2019s demons\u2014meaning not quite stable, or precariously stable. \u201cThe stable state of an enzyme is to be deconditioned,\u201d he noted, \u201cand the stable state of a living organism is to be dead.\u201d\n\nSchr\u00f6dinger felt that evading the second law for a while, or seeming to, is exactly why a living creature \u201cappears so enigmatic.\u201d The organism\u2019s ability to feign perpetual motion leads so many people to believe in a special, supernatural *life force*. He mocked this idea\u2014*vis viva* or entelechy\u2014and he also mocked the popular notion that organisms \u201cfeed upon energy.\u201d Energy and matter were just two sides of a coin, and anyway one calorie is as good as another. No, he said: the organism feeds upon negative entropy.\n\n\u201cTo put it less paradoxically,\u201d he added paradoxically, \u201cthe essential thing in metabolism is that the organism succeeds in freeing itself from all the entropy it cannot help producing while alive.\u201d\n\nIn other words, the organism sucks orderliness from its surroundings. Herbivores and carnivores dine on a smorgasbord of structure; they feed on organic compounds, matter in a well-ordered state, and return it \u201cin a very much degraded form\u2014not entirely degraded, however, for plants can make use of it.\u201d Plants meanwhile draw not just energy but negative entropy from sunlight. In terms of energy, the accounting can be more or less rigorously performed. In terms of order, calculations are not so simple. The mathematical reckoning of order and chaos remains more ticklish, the relevant definitions being subject to feedback loops of their own.\n\nMuch more remained to be learned, Schr\u00f6dinger said, about how life stores and perpetuates the orderliness it draws from nature. Biologists with their microscopes had learned a great deal about cells. They could see gametes\u2014sperm cells and egg cells. Inside them were the rodlike fibers called chromosomes, arranged in pairs, with consistent numbers from species to species, and known to\nbe carriers of hereditary features. As Schr\u00f6dinger put it now, they hold within them, somehow, the \u201cpattern\u201d of the organism: \u201cIt is these chromosomes, or probably only an axial skeleton fibre of what we actually see under the microscope as the chromosome, that contain in some kind of code-script the entire pattern of the individual\u2019s future development.\u201d He considered it amazing\u2014mysterious, but surely crucial in some way as yet unknown\u2014that every single cell of an organism \u201cshould be in possession of a complete (double) copy of the code-script.\u201d He compared this to an army in which every soldier knows every detail of the general\u2019s plans.\n\nThese details were the many discrete \u201cproperties\u201d of an organism, though it remained far from clear what a property entailed. (\u201cIt seems neither adequate nor possible to dissect into discrete \u2018properties\u2019 the pattern of an organism which is essentially a unity, a \u2018whole,\u2019 \u201d Schr\u00f6dinger mused.) The color of an animal\u2019s eyes, blue or brown, might be a property, but it is more useful to focus on the difference from one individual to another, and this difference was understood to be controlled by something conveyed in the chromosomes. He used the term gene: \u201cthe hypothetical material carrier of a definite hereditary feature.\u201d No one could yet see these hypothetical genes, but surely the time was not far off. Microscopic observations made it possible to estimate their size: perhaps 100 or 150 atomic distances; perhaps one thousand atoms or fewer. Yet somehow these tiny entities must encapsulate the entire pattern of a living creature\u2014a fly or a rhododendron, a mouse or a human. And we must understand this pattern as a four-dimensional object: the structure of the organism through the whole of its ontogenetic development, every stage from embryo to adult.\n\nIn seeking a clue to the gene\u2019s molecular structure, it seemed natural to look to the most organized forms of matter, crystals. Solids in crystalline form have a relative permanence; they can begin with a tiny germ and build up larger and larger structures; and quantum mechanics was beginning to give deep insight into the forces involved in their bonding. But Schr\u00f6dinger felt something was missing. Crystals are too orderly\u2014built up in \u201cthe comparatively dull way of repeating the same structure in three directions again and again.\u201d Elaborate though they seem, crystalline solids contain just a few types of atoms. Life must depend on a higher level of complexity, structure without predictable repetition, he argued. He invented a term: aperiodic crystals. This was his hypothesis: We believe a gene\u2014or perhaps the whole chromosome fiber\u2014to be an aperiodic solid. He could hardly emphasize enough the glory of this difference, between periodic and aperiodic:\n\nThe difference in structure is of the same kind as that between an ordinary wallpaper in which the same pattern is repeated again and again in regular periodicity and a masterpiece of embroidery, say a Raphael tapestry, which shows no dull repetition, but an elaborate, coherent, meaningful design.\nSome of his most admiring readers, such as L\u00e9on Brillouin, the French physicist recently decamped to the United States, said that Schr\u00f6dinger was too clever to be completely convincing, even as they demonstrated in their own work just how convinced they were. Brillouin was particularly taken with the comparison to crystals, with their elaborate but inanimate structures. Crystals have some capacity for self-repair, he noted; under stress, their atoms may shift to new positions for the sake of equilibrium. That may be understood in terms of thermodynamics and now quantum mechanics. How much more exalted, then, is self-repair in the organism: \u201cThe living organism heals its own wounds, cures its sicknesses, and may rebuild large portions of its structure when they have been destroyed by some accident. This is the most striking and unexpected behavior.\u201d He followed Schr\u00f6dinger, too, in using entropy to connect the smallest and largest scales.\n\nThe earth is not a closed system, and life feeds upon energy and negative entropy leaking into the earth system\u2026. The cycle reads: first, creation of unstable equilibriums (fuels, food, waterfalls, etc.); then use of these reserves by all living creatures.\n\nLiving creatures confound the usual computation of entropy. More generally, so does information. \u201cTake an issue of *The New York Times*, the book on cybernetics, and an equal weight of scrap paper,\u201d suggested Brillouin. \u201cDo they have the same entropy?\u201d If you are feeding the furnace, yes. But not if you are a reader. There is entropy in the arrangement of the ink spots.\n\nFor that matter, physicists themselves go around transforming negative entropy into information, said Brillouin. From observations and measurements, the physicist derives scientific laws; with these laws, people create machines never seen in nature, with the most improbable structures. He wrote this in 1950, as he was leaving Harvard to join the IBM Corporation in Poughkeepsie.\n\nThat was not the end for Maxwell\u2019s demon\u2014far from it. The problem could not truly be solved, the demon effectively banished without a deeper understanding of a realm far removed from thermodynamics: mechanical computing. Later, Peter Landsberg wrote its obituary this way: \u201cMaxwell\u2019s demon died at the age of 62 (when a paper by Le\u00f3 Szil\u00e1rd appeared), but it continues to haunt the castles of physics as a restless and lovable poltergeist.\u201d\nWhat lies at the heart of every living thing is not a fire, not warm breath, not a \u201cspark of life.\u201d It is information, words, instructions. If you want a metaphor, don\u2019t think of fires and sparks and breath. Think, instead, of a billion discrete, digital characters carved in tablets of crystal.\n\n\u2014Richard Dawkins (1986)\n\nSCIENTISTS LOVE THEIR FUNDAMENTAL PARTICLES. If traits are handed down from one generation to the next, these traits must take some primal form or have some carrier. Hence the putative particle of protoplasm. \u201cThe biologist must be allowed as much scientific use of the imagination as the physicist,\u201d The Popular Science Monthly explained in 1875. \u201cIf the one must have his atoms and molecules, the other must have his physiological units, his plastic molecules, his \u2018plasticules.\u2019\u201d\n\nPlasticule did not catch on, and almost everyone had the wrong idea about heredity anyway. So in 1910 a Danish botanist, Wilhelm Johannsen, self-consciously invented the word gene. He was at pains to correct the common mythology and thought a word might help. The myth was this: that \u201cpersonal qualities\u201d are transmitted from parent to progeny. This is \u201cthe most na\u00efve and oldest conception of heredity,\u201d Johannsen said in a speech to the American Society of Naturalists. It was understandable. If father and daughter are fat, people might be tempted to think that his fatness caused hers, or that he passed it on to her. But that is wrong. As Johannsen declared, \u201cThe personal qualities of any individual organism do not at all cause the qualities of its offspring; but the qualities of both ancestor and descendent are in quite the same manner determined by the nature of the \u2018sexual substances\u2019\u2014i.e., the gametes\u2014from which they have developed.\u201d What is inherited is more abstract, more in the nature of potentiality.\n\nTo banish the fallacious thinking, he proposed a new terminology, beginning with gene: \u201cnothing but a very applicable little word, easily combined with others.\u201d* It hardly mattered that neither he nor anyone else knew what a gene actually was; \u201cit may be useful as an expression for the \u2018unit-factors,\u2019 \u2018elements,\u2019 or \u2018allelomorphs.\u2019... As to the nature of the \u2018genes\u2019 it is as yet of no value to propose a hypothesis.\u201d Gregor Mendel\u2019s years of research with green and yellow\npeas showed that such a thing must exist. Colors and other traits vary depending on many factors, such as temperature and soil content, but something is preserved whole; it does not blend or diffuse; it must be quantized. Mendel had discovered the gene, though he did not name it. For him it was more an algebraic convenience than a physical entity.\n\nWhen Schr\u00f6dinger contemplated the gene, he faced a problem. How could such a \u201ctiny speck of material\u201d contain the entire complex code-script that determines the elaborate development of the organism? To resolve the difficulty Schr\u00f6dinger summoned an example not from wave mechanics or theoretical physics but from telegraphy: Morse code. He noted that two signs, dot and dash, could be combined in well-ordered groups to generate all human language. Genes, too, he suggested, must employ a code: \u201cThe miniature code should precisely correspond with a highly complicated and specified plan of development and should somehow contain the means to put it into action.\u201d\n\nCodes, instructions, signals\u2014all this language, redolent of machinery and engineering, pressed in on biologists like Norman French invading medieval English. In the 1940s the jargon had a precious, artificial feeling, but that soon passed. The new molecular biology began to examine information storage and information transfer. Biologists could count in terms of \u201cbits.\u201d Some of the physicists now turning to biology saw information as exactly the concept needed to discuss and measure biological qualities for which tools had not been available: complexity and order, organization and specificity. Henry Quastler, an early radiologist from Vienna, then at the University of Illinois, was applying information theory to both biology and psychology; he estimated that an amino acid has the information content of a written word and a protein molecule the information content of a paragraph. His colleague Sidney Dancoff suggested to him in 1950 that a chromosomal thread is \u201ca linear coded tape of information\u201d:\n\nThe entire thread constitutes a \u201cmessage.\u201d This message can be broken down into sub-units which may be called \u201cparagraphs,\u201d \u201cwords,\u201d etc. The smallest message unit is perhaps some flip-flop which can make a yes-no decision.\n\nIn 1952 Quastler organized a symposium on information theory in biology, with no purpose but to deploy these new ideas\u2014entropy, noise, messaging, differentiating\u2014in areas from cell structure and enzyme catalysis to large-scale \u201cbiosystems.\u201d One researcher constructed an estimate of the number of bits represented by a single bacterium: as much as $10^{13}$. (But that was the number needed to describe its entire molecular structure in three dimensions\u2014perhaps there was a more economical description.) The growth of the bacterium could be analyzed as a reduction in the entropy of its part of the universe. Quastler himself wanted to take the measure of higher organisms in terms of information content: not in terms of atoms (\u201cthis would be extremely wasteful\u201d) but in terms of\n\u201chypothetical instructions to build an organism.\u201d This brought him, of course, to genes.\n\nThe whole set of instructions\u2014situated \u201csomewhere in the chromosomes\u201d\u2014is the genome. This is a \u201ccatalogue,\u201d he said, containing, if not all, then at least \u201ca substantial fraction of all information about an adult organism.\u201d He emphasized, though, how little was known about genes. Were they discrete physical entities, or did they overlap? Were they \u201cindependent sources of information\u201d or did they affect one another? How many were there? Multiplying all these unknowns, he arrived at a result:\n\nthat the essential complexity of a single cell and of a whole man are both not more than $10^{12}$ nor less than $10^7$ bits; this is an extremely coarse estimate, but is better than no estimate at all.\n\nThese crude efforts led to nothing, directly. Shannon\u2019s information theory could not be grafted onto biology whole. It hardly mattered. A seismic shift was already under way: from thinking about energy to thinking about information.\n\nAcross the Atlantic, an odd little letter arrived at the offices of the journal *Nature* in London in the spring of 1953, with a list of signatories from Paris, Zurich, Cambridge, and Geneva, most notably Boris Ephrussi, France\u2019s first professor of genetics. The scientists complained of \u201cwhat seems to us a rather chaotic growth in technical vocabulary.\u201d In particular, they had seen genetic recombination in bacteria described as \u201ctransformation,\u201d \u201cinduction,\u201d \u201ctransduction,\u201d and even \u201cinfection.\u201d They proposed to simplify matters:\n\nAs a solution to this confusing situation, we would like to suggest the use of the term \u201cinterbacterial information\u201d to replace those above. It does not imply necessarily the transfer of material substances, and recognizes the possible future importance of cybernetics at the bacterial level.\n\nThis was the product of a wine-flushed lakeside lunch at Locarno, Switzerland\u2014meant as a joke, but entirely plausible to the editors of *Nature*, who published it forthwith. The youngest of the lunchers and signers was a twenty-five-year-old American named James Watson.\n\nThe very next issue of *Nature* carried another letter from Watson, along with his collaborator, Francis Crick. It made them famous. They had found the gene.\n\nA consensus had emerged that whatever genes were, however they functioned, they would probably be proteins: giant organic molecules made of long chains of amino acids. Alternatively, a few geneticists in the 1940s focused instead on simple viruses\u2014phages. Then again, experiments on heredity in bacteria had persuaded a few researchers, Watson and Crick among them, that genes might lie in a different substance, which, for no known reason, was found within the\nnucleus of every cell, plant and animal, phages included. This substance was a nucleic acid, particularly deoxyribonucleic acid, or DNA. The people working with nucleic acids, mainly chemists, had not been able to learn much about it, except that the molecules were built up from smaller units, called nucleotides. Watson and Crick thought this must be the secret, and they raced to figure out its structure at the Cavendish Laboratory in Cambridge. They could not see these molecules; they could only seek clues in the shadows cast by X-ray diffraction. But they knew a great deal about the subunits. Each nucleotide contained a \u201cbase,\u201d and there were just four different bases, designated as A, C, G, and T. They came in strictly predictable proportions. They must be the letters of the code. The rest was trial and error, fired by imagination.\n\nWhat they discovered became an icon: the double helix, heralded on magazine covers, emulated in sculpture. DNA is formed of two long sequences of bases, like ciphers coded in a four-letter alphabet, each sequence complementary to the other, coiled together. Unzipped, each strand may serve as a template for replication. (Was it Schr\u00f6dinger\u2019s \u201caperiodic crystal\u201d? In terms of physical structure, X-ray diffraction showed DNA to be entirely regular. The aperiodicity lies at the abstract level of language\u2014the sequence of \u201cletters.\u201d) In the local pub, Crick, ebullient, announced to anyone who would listen that they had discovered \u201cthe secret of life\u201d; in their one-page note in *Nature* they were more circumspect. They ended with a remark that has been called \u201cone of the most coy statements in the literature of science\u201d:\n\n> It has not escaped our notice that the specific pairing we have postulated immediately suggests a possible copying mechanism for the genetic material.\n\nThey dispensed with the timidity in another paper a few weeks later. In each chain the sequence of bases appeared to be irregular\u2014any sequence was possible, they observed. \u201cIt follows that in a long molecule many different permutations are possible.\u201d Many permutations\u2014many possible messages. Their next remark set alarms sounding on both sides of the Atlantic: \u201cIt therefore seems likely that the precise sequence of the bases is the code which carries the genetical information.\u201d In using these terms, *code* and *information*, they were no longer speaking figuratively.\n\nThe macromolecules of organic life embody information in an intricate structure. A single hemoglobin molecule comprises four chains of polypeptides, two with 141 amino acids and two with 146, in strict linear sequence, bonded and folded together. Atoms of hydrogen, oxygen, carbon, and iron could mingle randomly for the lifetime of the universe and be no more likely to form hemoglobin than the proverbial chimpanzees to type the works of Shakespeare. Their genesis requires energy; they are built up from simpler, less patterned parts, and the law of entropy\napplies. For earthly life, the energy comes as photons from the sun. The information comes via evolution.\n\nThe DNA molecule was special: the information it bears is its only function. Having recognized this, microbiologists turned to the problem of deciphering the code. Crick, who had been inspired to leave physics for biology when he read Schr\u00f6dinger\u2019s *What Is Life?*, sent Schr\u00f6dinger a copy of the paper but did not receive a reply.\n\nOn the other hand, George Gamow saw the Watson-Crick report when he was visiting the Radiation Laboratory at Berkeley. Gamow was a Ukrainian-born cosmologist\u2014an originator of the Big Bang theory\u2014and he knew a big idea when he saw one. He sent off a letter:\n\nDear Drs. Watson & Crick,\n\nI am a physicist, not a biologist\u2026. But I am very much excited by your article in May 30th *Nature*, and think that brings Biology over into the group of \u201cexact\u201d sciences\u2026. If your point of view is correct each organism will be characterized by a long number written in quadrucal (?) system with figures 1, 2, 3, 4 standing for different bases\u2026. This would open a very exciting possibility of theoretical research based on combinatorix and the theory of numbers!\u2026 I have a feeling this can be done. What do you think?\n\nFor the next decade, the struggle to understand the genetic code consumed a motley assortment of the world\u2019s great minds, many of them, like Gamow, lacking any useful knowledge of biochemistry. For Watson and Crick, the initial problem had depended on a morass of specialized particulars: hydrogen bonds, salt linkages, phosphate-sugar chains with deoxyribofuranose residues. They had to learn how inorganic ions could be organized in three dimensions; they had to calculate exact angles of chemical bonds. They made models out of cardboard and tin plates. But now the problem was being transformed into an abstract game of symbol manipulation. Closely linked to DNA, its single-stranded cousin, RNA, appeared to play the role of messenger or translator. Gamow said explicitly that the underlying chemistry hardly mattered. He and others who followed him understood this as a puzzle in mathematics\u2014a mapping between messages in different alphabets. If this was a coding problem, the tools they needed came from combinatorics and information theory. Along with physicists, they consulted cryptanalysts.\n\nGamow himself began impulsively by designing a combinatorial code. As he saw it, the problem was to get from the four bases in DNA to the twenty known amino acids in proteins\u2014a code, therefore, with four letters and twenty words.* Pure combinatorics made him think of nucleotide triplets: three-letter words. He had a detailed solution\u2014soon known as his \u201cdiamond code\u201d\u2014published in *Nature* within a few months. A few months after that, Crick showed this to be\nutterly wrong: experimental data on protein sequences ruled out the diamond code. But Gamow was not giving up. The triplet idea was seductive. An unexpected cast of scientists joined the hunt: Max Delbr\u00fcck, an ex-physicist now at Caltech in biology; his friend Richard Feynman, the quantum theorist; Edward Teller, the famous bomb maker; another Los Alamos alumnus, the mathematician Nicholas Metropolis; and Sydney Brenner, who joined Crick at the Cavendish.\n\nThey all had different coding ideas. Mathematically the problem seemed daunting even to Gamow. \u201cAs in the breaking of enemy messages during the war,\u201d he wrote in 1954, \u201cthe success depends on the available length of the coded text. As every intelligence officer will tell you, the work is very hard, and the success depends mostly on luck\u2026. I am afraid that the problem cannot be solved without the help of electronic computer.\u201d Gamow and Watson decided to make it a club: the RNA Tie Club, with exactly twenty members. Each member received a woolen tie in black and green, made to Gamow\u2019s design by a haberdasher in Los Angeles. The game playing aside, Gamow wanted to create a communication channel to bypass journal publication. News in science had never moved so fast. \u201cMany of the essential concepts were first proposed in informal discussions on both sides of the Atlantic and were then quickly broadcast to the cognoscenti,\u201d said another member, Gunther Stent, \u201cby private international bush telegraph.\u201d There were false starts, wild guesses, and dead ends, and the established biochemistry community did not always go along willingly.\n\n\u201cPeople didn\u2019t necessarily believe in the code,\u201d Crick said later. \u201cThe majority of biochemists simply weren\u2019t thinking along those lines. It was a completely novel idea, and moreover they were inclined to think it was oversimplified.\u201d They thought the way to understand proteins would be to study enzyme systems and the coupling of peptide units. Which was reasonable enough.\n\nThey thought protein synthesis couldn\u2019t be a simple matter of coding from one thing to another; that sounded too much like something a physicist had invented. It didn\u2019t sound like biochemistry to them\u2026. So there was a certain resistance to simple ideas like three nucleotides\u2019 coding an amino acid; people thought it was rather like cheating.\n\nGamow, at the other extreme, was bypassing the biochemical details to put forward an idea of shocking simplicity: that any living organism is determined by \u201ca long number written in a four-digital system.\u201d He called this \u201cthe number of the beast\u201d (from Revelation). If two beasts have the same number, they are identical twins.\n\nBy now the word code was so deeply embedded in the conversation that people seldom paused to notice how extraordinary it was to find such a thing\u2014abstract symbols representing arbitrarily different abstract symbols\u2014at work in chemistry, at the level of molecules. The genetic code performed a function with uncanny\nsimilarities to the metamathematical code invented by G\u00f6del for his philosophical purposes. G\u00f6del\u2019s code substitutes plain numbers for mathematical expressions and operations; the genetic code uses triplets of nucleotides to represent amino acids. Douglas Hofstadter was the first to make this connection explicitly, in the 1980s: \u201cbetween the complex machinery in a living cell that enables a DNA molecule to replicate itself and the clever machinery in a mathematical system that enables a formula to say things about itself.\u201d In both cases he saw a twisty feedback loop. \u201cNobody had ever in the least suspected that one set of chemicals could code for another set,\u201d Hofstadter wrote.\n\nIndeed, the very idea is somewhat baffling: If there is a code, then who invented it? What kinds of messages are written in it? Who writes them? Who reads them?\n\nThe Tie Club recognized that the problem was not just information storage but information transfer. DNA serves two different functions. First, it preserves information. It does this by copying itself, from generation to generation, spanning eons\u2014a Library of Alexandria that keeps its data safe by copying itself billions of times. Notwithstanding the beautiful double helix, this information store is essentially one-dimensional: a string of elements arrayed in a line. In human DNA, the nucleotide units number more than a billion, and this detailed gigabit message must be conserved perfectly, or almost perfectly. Second, however, DNA also sends that information outward for use in the making of the organism. The data stored in a one-dimensional strand has to flower forth in three dimensions. This information transfer occurs via messages passing from the nucleic acids to proteins. So DNA not only replicates itself; separately, it dictates the manufacture of something entirely different. These proteins, with their own enormous complexity, serve as the material of a body, the mortar and bricks, and also as the control system, the plumbing and wiring and the chemical signals that control growth.\n\nThe replication of DNA is a copying of information. The manufacture of proteins is a transfer of information: the sending of a message. Biologists could see this clearly now, because the message was now well defined and abstracted from any particular substrate. If messages could be borne upon sound waves or electrical pulses, why not by chemical processes?\n\nGamow framed the issue simply: \u201cThe nucleus of a living cell is a storehouse of information.\u201d Furthermore, he said, it is a transmitter of information. The continuity of all life stems from this \u201cinformation system\u201d; the proper study of genetics is \u201cthe language of the cells.\u201d\n\nWhen Gamow\u2019s diamond code proved wrong, he tried a \u201ctriangle code,\u201d and more variations followed\u2014also wrong. Triplet codons remained central, and a solution seemed tantalizingly close but out of reach. A problem was how nature punctuated the seemingly unbroken DNA and RNA strands. No one could see a\nbiological equivalent for the pauses that separate letters in Morse code, or the spaces that separate words. Perhaps every fourth base was a comma. Or maybe (Crick suggested) commas would be unnecessary if some triplets made \u201csense\u201d and others made \u201cnonsense.\u201d Then again, maybe a sort of tape reader just needed to start at a certain point and count off the nucleotides three by three. Among the mathematicians drawn to this problem were a group at the new Jet Propulsion Laboratory in Pasadena, California, meant to be working on aerospace research. To them it looked like a classic problem in Shannon coding theory: \u201cthe sequence of nucleotides as an infinite message, written without punctuation, from which any finite portion must be decodable into a sequence of amino acids by suitable insertion of commas.\u201d They constructed a dictionary of codes. They considered the problem of misprints.\n\nBiochemistry did matter. All the world\u2019s cryptanalysts, lacking petri dishes and laboratory kitchens, would not have been able to guess from among the universe of possible answers. When the genetic code was solved, in the early 1960s, it turned out to be full of redundancy. Much of the mapping from nucleotides to amino acids seemed arbitrary\u2014not as neatly patterned as any of Gamow\u2019s proposals. Some amino acids correspond to just one codon, others to two, four, or six. Particles called ribosomes ratchet along the RNA strand and translate it, three bases at a time. Some codons are redundant; some actually serve as start signals and stop signals. The redundancy serves exactly the purpose that an information theorist would expect. It provides tolerance for errors. Noise affects biological messages like any other. Errors in DNA\u2014misprints\u2014are mutations.\n\nEven before the exact answer was reached, Crick crystallized its fundamental principles in a statement that he called (and is called to this day) the Central Dogma. It is a hypothesis about the direction of evolution and the origin of life; it is provable in terms of Shannon entropy in the possible chemical alphabets:\n\nOnce \u201cinformation\u201d has passed into protein it cannot get out again. In more detail, the transfer of information from nucleic acid to nucleic acid, or from nucleic acid to protein may be possible, but transfer from protein to protein, or from protein to nucleic acid is impossible. Information means here the precise determination of sequence.\n\nThe genetic message is independent and impenetrable: no information from events outside can change it.\n\nInformation had never been writ so small. Here is scripture at angstrom scale, published where no one can see, the Book of Life in the eye of a needle.\n\n*Omne vivum ex ovo.* \u201cThe complete description of the organism is already written in the egg,\u201d said Sydney Brenner to Horace Freeland Judson, molecular biology\u2019s great chronicler, at Cambridge in the winter of 1971. \u201cInside every animal there is\nan internal description of that animal\u2026. What is going to be difficult is the immense amount of detail that will have to be subsumed. The most economical language of description is the molecular, genetic description that is already there. We do not yet know, in that language, what the names are. What does the organism name to itself? We cannot say that an organism has, for example, a name for a finger. There\u2019s no guarantee that in making a hand, the explanation can be couched in the terms we use for making a glove.\u201d\n\nBrenner was in a thoughtful mood, drinking sherry before dinner at King\u2019s College. When he began working with Crick, less than two decades before, molecular biology did not even have a name. Two decades later, in the 1990s, scientists worldwide would undertake the mapping of the entire human genome: perhaps 20,000 genes, 3 billion base pairs. What was the most fundamental change? It was a shift of the frame, from energy and matter to information.\n\n\u201cAll of biochemistry up to the fifties was concerned with where you get the energy and the materials for cell function,\u201d Brenner said. \u201cBiochemists only thought about the flux of energy and the flow of matter. Molecular biologists started to talk about the flux of information. Looking back, one can see that the double helix brought the realization that information in biological systems could be studied in much the same way as energy and matter\u2026.\n\n\u201cLook,\u201d he told Judson, \u201clet me give you an example. If you went to a biologist twenty years ago and asked him, How do you make a protein, he would have said, Well, that\u2019s a horrible problem, I don\u2019t know \u2026 but the important question is where do you get the energy to make the peptide bond. Whereas the molecular biologist would have said, That\u2019s not the problem, the important problem is where do you get the instructions to assemble the sequence of amino acids, and to hell with the energy; the energy will look after itself.\u201d\n\nBy this time, the technical jargon of biologists included the words alphabet, library, editing, proofreading, transcription, translation, nonsense, synonym, and redundancy. Genetics and DNA had drawn the attention not just of cryptographers but of classical linguists. Certain proteins, capable of flipping from one relatively stable state to another, were found to act as relays, accepting ciphered commands and passing them to their neighbors\u2014switching stations in three-dimensional communications networks. Brenner, looking forward, thought the focus would turn to computer science as well. He envisioned a science\u2014though it did not yet have a name\u2014of chaos and complexity. \u201cI think in the next twenty-five years we are going to have to teach biologists another language still,\u201d he said. \u201cI don\u2019t know what it\u2019s called yet; nobody knows. But what one is aiming at, I think, is the fundamental problem of the theory of elaborate systems.\u201d He recalled John von Neumann, at the dawn of information theory and cybernetics, proposing to understand biological processes and mental processes in\nterms of how a computing machine might operate. \u201cIn other words,\u201d said Brenner, \u201cwhere a science like physics works in terms of laws, or a science like molecular biology, to now, is stated in terms of mechanisms, maybe now what one has to begin to think of is algorithms. Recipes. Procedures.\u201d\n\nIf you want to know what a mouse is, ask instead how you could build a mouse. How does the mouse build itself? The mouse\u2019s genes switch one another on and off and perform computation, in steps. \u201cI feel that this new molecular biology has to go in this direction\u2014to explore the high-level logical computers, the programs, the algorithms of development\u2026.\n\n\u201cOne would like to be able to fuse the two\u2014to be able to move between the molecular hardware and the logical software of how it\u2019s all organized, without feeling they are different sciences.\u201d\n\nEven now\u2014or especially now\u2014the gene was not what it seemed. Having begun as a botanist\u2019s hunch and an algebraic convenience, it had been tracked down to the chromosome and revealed as molecular coiled strands. It was decoded, enumerated, and catalogued. And then, in the heyday of molecular biology, the idea of the gene broke free of its moorings once again.\n\nThe more was known, the harder it was to define. Is a gene nothing more or less than DNA? Is it made of DNA, or is it something carried in DNA? Is it properly pinned down as a material thing at all?\n\nNot everyone agreed there was a problem. Gunther Stent declared in 1977 that one of the field\u2019s great triumphs was the \u201cunambiguous identification\u201d of the Mendelian gene as a particular length of DNA. \u201cIt is in this sense that all working geneticists now employ the term \u2018gene,\u2019 \u201d he wrote. To put it technically but succinctly: \u201cThe gene is, in fact, a linear array of DNA nucleotides which determines a linear array of protein amino acids.\u201d It was Seymour Benzer, said Stent, who established that definitively.\n\nYet Benzer himself had not been quite so sanguine. He argued as early as 1957 that the classical gene was dead. It was a concept trying to serve three purposes at once\u2014as a unit of recombination, of mutation, and of function\u2014and already he had strong reason to suspect that these were incompatible. A strand of DNA carries many base pairs, like beads on a string or letters in a sentence; as a physical object it could not be called an elementary unit. Benzer offered a batch of new particle names: \u201crecon,\u201d for the smallest unit that can be interchanged by recombination; \u201cmuton,\u201d for the smallest unit of mutational change (a single base pair); and \u201ccistron\u201d for the unit of function\u2014which in turn, he admitted, was difficult to define. \u201cIt depends upon what level of function is meant,\u201d he wrote\u2014perhaps just the specification of an amino acid, or perhaps a whole ensemble of\nsteps \u201cleading to one particular physiological end-effect.\u201d *Gene* was not going away, but that was a lot of weight for one little word to bear.\n\nPart of what was happening was a collision between molecular biology and evolutionary biology, as studied in fields from botany to paleontology. It was as fruitful a collision as any in the history of science\u2014before long, neither side could move forward without the other\u2014but on the way some sparks flared. Quite a few of them were set off by a young zoologist at Oxford, Richard Dawkins. It seemed to Dawkins that many of his colleagues were looking at life the wrong way round.\n\nAs molecular biology perfected its knowledge of the details of DNA and grew more skillful in manipulating these molecular prodigies, it was natural to see them as the answer to the great question of life: how do organisms reproduce themselves? We use DNA, just as we use lungs to breathe and eyes to see. We *use* it. \u201cThis attitude is an error of great profundity,\u201d Dawkins wrote. \u201cIt is the truth turned crashingly on its head.\u201d DNA came first\u2014by billions of years\u2014and DNA *comes* first, he argued, when life is viewed from the proper perspective. From that perspective, genes are the focus, the sine qua non, the star of the show. In his first book\u2014published in 1976, meant for a broad audience, provocatively titled *The Selfish Gene*\u2014he set off decades of debate by declaring: \u201cWe are survival machines\u2014robot vehicles blindly programmed to preserve the selfish molecules known as genes.\u201d He said this was a truth he had known for years.\n\nGenes, not organisms, are the true units of natural selection. They began as \u201creplicators\u201d\u2014molecules formed accidentally in the primordial soup, with the unusual property of making copies of themselves.\n\nThey are past masters of the survival arts. But do not look for them floating loose in the sea; they gave up that cavalier freedom long ago. Now they swarm in huge colonies, safe inside gigantic lumbering robots, sealed off from the outside world, communicating with it by tortuous indirect routes, manipulating it by remote control. They are in you and in me; they created us, body and mind; and their preservation is the ultimate rationale for our existence. They have come a long way, those replicators. Now they go by the name of genes, and we are their survival machines.\n\nThis was guaranteed to raise the hackles of organisms who thought of themselves as more than robots. \u201cEnglish biologist Richard Dawkins has recently raised my hackles,\u201d wrote Stephen Jay Gould in 1977, \u201cwith his claim that genes themselves are units of selection, and individuals merely their temporary receptacles.\u201d Gould had plenty of company. Speaking for many molecular biologists, Gunther Stent dismissed Dawkins as \u201ca thirty-six-year-old student of animal behavior\u201d and filed him under \u201cthe old prescientific tradition of animism, under which natural objects are endowed with souls.\u201d\n\nYet Dawkins\u2019s book was brilliant and transformative. It established a new,\nmultilayered understanding of the gene. At first, the idea of the selfish gene seemed like a trick of perspective, or a joke. Samuel Butler had said a century earlier\u2014and did not claim to be the first\u2014that a hen is only an egg\u2019s way of making another egg. Butler was quite serious, in his way:\n\nEvery creature must be allowed to \u201crun\u201d its own development in its own way; the egg\u2019s way may seem a very roundabout manner of doing things; but it is its way, and it is one of which man, upon the whole, has no great reason to complain. Why the fowl should be considered more alive than the egg, and why it should be said that the hen lays the egg, and not that the egg lays the hen, these are questions which lie beyond the power of philosophic explanation, but are perhaps most answerable by considering the conceit of man, and his habit, persisted in during many ages, of ignoring all that does not remind him of himself.\n\nHe added, \u201cBut, perhaps, after all, the real reason is, that the egg does not cackle when it has laid the hen.\u201d Some time later, Butler\u2019s template, $X$ is just a $Y$\u2019s way of making another $Y$, began reappearing in many forms. \u201cA scholar,\u201d said Daniel Dennett in 1995, \u201cis just a library\u2019s way of making another library.\u201d Dennett, too, was not entirely joking.\n\nIt was prescient of Butler in 1878 to mock a man-centered view of life, but he had read Darwin and could see that all creation had not been designed in behalf of Homo sapiens. \u201cAnthropocentrism is a disabling vice of the intellect,\u201d Edward O. Wilson said a century later, but Dawkins was purveying an even more radical shift of perspective. He was not just nudging aside the human (and the hen) but the organism, in all its multifarious glory. How could biology not be the study of organisms? If anything, he understated the difficulty when he wrote, \u201cIt requires a deliberate mental effort to turn biology the right way up again, and remind ourselves that the replicators come first, in importance as well as in history.\u201d\n\nA part of Dawkins\u2019s purpose was to explain altruism: behavior in individuals that goes against their own best interests. Nature is full of examples of animals risking their own lives in behalf of their progeny, their cousins, or just fellow members of their genetic club. Furthermore, they share food; they cooperate in building hives and dams; they doggedly protect their eggs. To explain such behavior\u2014to explain any adaptation, for that matter\u2014one asks the forensic detective\u2019s question, cui bono? Who benefits when a bird spots a predator and cries out, warning the flock but also calling attention to itself? It is tempting to think in terms of the good of the group\u2014the family, tribe, or species\u2014but most theorists agree that evolution does not work that way. Natural selection can seldom operate at the level of groups. It turns out, however, that many explanations fall neatly into place if one thinks of the individual as trying to propagate its particular assortment of genes down through the future. Its species shares most of those genes, of course, and its kin share even more. Of course, the individual does not know about its genes. It is not consciously trying to do any\nsuch thing. Nor, of course, would anyone impute intention to the gene itself\u2014tiny brainless entity. But it works quite well, as Dawkins showed, to flip perspectives and say that the gene works to maximize its own replication. For example, a gene \u201cmight ensure its survival by tending to endow the successive bodies with long legs, which help those bodies escape from predators.\u201d A gene might maximize its own numbers by giving an organism the instinctive impulse to sacrifice its life to save its offspring: the gene itself, the particular clump of DNA, dies with its creature, but copies of the gene live on. The process is blind. It has no foresight, no intention, no knowledge. The genes, too, are blind: \u201cThey do not plan ahead,\u201d says Dawkins. \u201cGenes just are, some genes more so than others, and that is all there is to it.\u201d\n\nThe history of life begins with the accidental appearance of molecules complex enough to serve as building blocks\u2014replicators. The replicator is an information carrier. It survives and spreads by copying itself. The copies must be coherent and reliable but need not be perfect; on the contrary, for evolution to proceed, errors must appear. Replicators could exist long before DNA, even before proteins. In one scenario, proposed by the Scots biologist Alexander Cairns-Smith, replicators appeared in sticky layers of clay crystals: complex molecules of silicate minerals. In other models the evolutionary playground is the more traditional \u201cprimordial soup.\u201d Either way, some of these information-bearing macromolecules disintegrate more quickly than others; some make more or better copies; some have the chemical effect of breaking up competing molecules. Absorbing photon energy like the miniature Maxwell\u2019s demons they are, molecules of ribonucleic acid, RNA, catalyze the formation of bigger and more information-rich molecules. DNA, ever so slightly more stable, possesses the dual capability of copying itself while also manufacturing another sort of molecule, and this provides a special advantage. It can protect itself by building a shell of proteins around it. This is Dawkins\u2019s \u201csurvival machine\u201d\u2014first cells, then larger and larger bodies, with growing inventories of membranes and tissues and limbs and organs and skills. They are the genes\u2019 fancy vehicles, racing against other vehicles, converting energy, and even processing information. In the game of survival some vehicles outplay, outmaneuver, and outpropagate others.\n\nIt took some time, but the gene-centered, information-based perspective led to a new kind of detective work in tracing the history of life. Where paleontologists look back through the fossil record for skeletal precursors of wings and tails, molecular biologists and biophysicists look for telltale relics of DNA in hemoglobin, oncogenes, and all the rest of the library of proteins and enzymes. \u201cThere is a molecular archeology in the making,\u201d says Werner Loewenstein. The history of life is written in terms of negative entropy. \u201cWhat actually evolves is information in all its forms or transforms. If there were something like a\nguidebook for living creatures, I think, the first line would read like a biblical commandment, *Make thy information larger.*\n\nNo one gene makes an organism. Insects and plants and animals are collectives, communal vehicles, cooperative assemblies of a multitude of genes, each playing its part in the organism\u2019s development. It is a complex ensemble in which each gene interacts with thousands of others in a hierarchy of effects extending through both space and time. The body is a colony of genes. Of course, it acts and moves and procreates as a unit, and furthermore, in the case of at least one species, it feels itself, with impressive certainty, to be a unit. The gene-centered perspective has helped biologists appreciate that the genes composing the human genome are only a fraction of the genes carried around in any one person, because humans (like other species) host an entire ecosystem of microbes\u2014bacteria, especially, from our skin to our digestive systems. Our \u201cmicrobiomes\u201d help us digest food and fight disease, all the while evolving fast and flexibly in service of their own interests. All these genes engage in a grand process of mutual co-evolution\u2014competing with one another, and with their alternative alleles, in nature\u2019s vast gene pool, but no longer competing on their own. Their success or failure comes through interaction. \u201cSelection favors those genes which succeed in the presence of other genes,\u201d says Dawkins, \u201cwhich in turn succeed in the presence of them.\u201d\n\nThe effect of any one gene depends on these interactions with the ensemble and depends, too, on effects of the environment and on raw chance. Indeed, just to speak of a gene\u2019s *effect* became a complex business. It was not enough simply to say that the effect of a gene is the protein it synthesizes. One might want to say that a sheep or a crow has a gene for blackness. This might be a gene that manufactures a protein for black pigment in wool or feathers. But sheep and crows and all the other creatures capable of blackness exhibit it in varying circumstances and degrees; even so simple-seeming a quality seldom has a biological on-off switch. Dawkins suggests the case of a gene that synthesizes a protein that acts as an enzyme with many indirect and distant effects, one of which is to facilitate the synthesis of black pigment. Even more remotely, suppose a gene encourages an organism to seek sunlight, which is in turn necessary for the black pigment. Such a gene serves as a mere co-conspirator but its role may be indispensable. To call it a gene *for* blackness, however, becomes difficult. And it is harder still to specify genes for more complex qualities\u2014genes for obesity or aggression or nest building or braininess or homosexuality.\n\nAre there genes for such things? Not if a gene is a particular strand of DNA that expresses a protein. Strictly speaking, one cannot say there are genes *for* almost anything\u2014not even eye color. Instead, one should say that differences in genes tend to cause differences in phenotype (the actualized organism). But from\nThe Information\n\nthe earliest days of the study of heredity, scientists have spoken of genes more broadly. If a population varies in some trait\u2014say, tallness\u2014and if the variation is subject to natural selection, then by definition it is at least partly genetic. There is a genetic component to the variation in tallness. There is no gene for long legs; there is no gene for a leg at all. To build a leg requires many genes, each issuing instructions in the form of proteins, some making raw materials, some making timers and on-off switches. Some of these genes surely have the effect of making legs longer than they would otherwise be, and it is those genes that we may call, for short, genes for long legs\u2014as long as we remember that long-leggedness is not directly represented or encoded directly in the gene.\n\nSo geneticists and zoologists and ethologists and paleontologists all got into the habit of saying \u201ca gene for X\u201d instead of \u201ca genetic contribution to the variation in X.\u201d Dawkins was forcing them to face the logical consequences. If there is any genetic variation in a trait\u2014eye color or obesity\u2014then there must be a gene or genes for that trait. It doesn\u2019t matter that the actual appearance of the trait may depend on an unfathomable array of other factors, which may be environmental or even accidental. By way of illustration, he offered a deliberately extreme example: a gene for reading.\n\nThe idea seems absurd, for several reasons. Reading is learned behavior. No one is born able to read. If ever a skill depends on environmental factors, such as education, it is reading. Until a few millennia ago, the behavior did not exist, so it could not have been subject to natural selection. You might as well say (as the geneticist John Maynard Smith did, mockingly) that there is a gene for tying shoelaces. But Dawkins was undaunted. He pointed out that genes are about differences, after all. So he began with a simple counterpoint: might there not be a gene for dyslexia?\n\nAll we would need in order to establish the existence of a gene for reading is to discover a gene for not reading, say a gene which induced a brain lesion causing specific dyslexia. Such a dyslexic person might be normal and intelligent in all respects except that he could not read. No geneticist would be particularly surprised if this type of dyslexia turned out to breed true in some Mendelian fashion. Obviously, in this event the gene would only exhibit its effect in an environment which included normal education. In a prehistoric environment it might have had no detectable effect, or it might have had some different effect and have been known to cave-dwelling geneticists as, say, a gene for inability to read animal footprints\u2026.\n\nIt follows from the ordinary conventions of genetic terminology that the wild-type gene at the same locus, the gene that the rest of the population has in double dose, would properly be called a gene \u201cfor reading.\u201d If you object to that, you must also object to our speaking of a gene for tallness in Mendel\u2019s peas\u2026. In both cases the character of interest is a difference, and in both cases the difference only shows itself in some specified environment. The reason why something so simple as a one gene difference can have such a complex effect \u2026 is basically as follows. However complex a given state of the world may be, the difference between that state of the world and some alternative state of the world may be caused by something extremely\nCan there be a gene for altruism? Yes, says Dawkins, if this means \u201cany gene that influences the development of nervous systems in such a way as to make them likely to behave altruistically.\u201d Such genes\u2014these replicators, these survivors\u2014know nothing about altruism and nothing about reading, of course. Whatever and wherever they are, their phenotypic effects matter only insofar as they help the genes propagate.\n\nMolecular biology, in its signal achievement, had pinpointed the gene in a protein-encoding piece of DNA. This was the hardware definition. The software definition was older and fuzzier: the unit of heredity; the bearer of a phenotypic difference. With the two definitions uneasily coexisting, Dawkins looked past them both.\n\nIf genes are meant to be masters of survival, they can hardly be fragments of nucleic acid. Such things are fleeting. To say that a replicator manages to survive for eons is to define the replicator as all the copies considered as one. Thus the gene does not \u201cgrow senile,\u201d Dawkins declared.\n\nIt is no more likely to die when it is a million years old than when it is only a hundred. It leaps from body to body down the generations, manipulating body after body in its own way and for its own ends, abandoning a succession of mortal bodies before they sink in senility and death.\n\n\u201cWhat I am doing,\u201d he says, \u201cis emphasizing the potential near-immortality of a gene, in the form of copies, as its defining property.\u201d This is where life breaks free from its material moorings. (Unless you already believed in the immortal soul.) The gene is not an information-carrying macromolecule. The gene is the information. The physicist Max Delbr\u00fcck wrote in 1949, \u201cToday the tendency is to say \u2018genes are just molecules, or hereditary particles,\u2019 and thus to do away with the abstractions.\u201d Now the abstractions returned.\n\nWhere, then, is any particular gene\u2014say, the gene for long legs in humans? This is a little like asking where is Beethoven\u2019s Piano Sonata in E minor. Is it in the original handwritten score? The printed sheet music? Any one performance\u2014or perhaps the sum of all performances, historical and potential, real and imagined?\n\nThe quavers and crotchets inked on paper are not the music. Music is not a series of pressure waves sounding through the air; nor grooves etched in vinyl or pits burned in CDs; nor even the neuronal symphonies stirred up in the brain of the listener. The music is the information. Likewise, the base pairs of DNA are not genes. They encode genes. Genes themselves are made of bits.\n\n* He added: \u201cOld terms are mostly compromised by their application in antiquated or erroneous\ntheories and systems, from which they carry splinters of inadequate ideas, not always harmless to the developing insight.\u201d\n\n* In listing twenty amino acids, Gamow was getting ahead of what was actually known. The number twenty turned out to be correct, though Gamow\u2019s list was not.\nWhen I muse about memes, I often find myself picturing an ephemeral flickering pattern of sparks leaping from brain to brain, screaming \u201cMe, me!\u201d\n\n\u2014Douglas Hofstadter (1983)\n\n\u201cNOW THROUGH THE VERY UNIVERSALITY of its structures, starting with the code, the biosphere looks like the product of a unique event,\u201d Jacques Monod wrote in 1970. \u201cThe universe was not pregnant with life, nor the biosphere with man. Our number came up in the Monte Carlo game. Is it any wonder if, like a person who has just made a million at the casino, we feel a little strange and a little unreal?\u201d\n\nMonod, the Parisian biologist who shared the Nobel Prize for working out the role of messenger RNA in the transfer of genetic information, was not alone in thinking of the biosphere as more than a notional place: an entity, composed of all the earth\u2019s life-forms, simple and complex, teeming with information, replicating and evolving, coding from one level of abstraction to the next. This view of life was more abstract\u2014more mathematical\u2014than anything Darwin had imagined, but he would have recognized its basic principles. Natural selection directs the whole show. Now biologists, having absorbed the methods and vocabulary of communications science, went further to make their own contributions to the understanding of information itself. Monod proposed an analogy: Just as the biosphere stands above the world of nonliving matter, so an \u201cabstract kingdom\u201d rises above the biosphere. The denizens of this kingdom? Ideas.\n\nIdeas have retained some of the properties of organisms. Like them, they tend to perpetuate their structure and to breed; they too can fuse, recombine, segregate their content; indeed they too can evolve, and in this evolution selection must surely play an important role.\n\nIdeas have \u201cspreading power,\u201d he noted\u2014\u201cinfectivity, as it were\u201d\u2014and some more than others. An example of an infectious idea might be a religious ideology that gains sway over a large group of people. The American neurophysiologist Roger Sperry had put forward a similar notion several years earlier, arguing that ideas are \u201cjust as real\u201d as the neurons they inhabit. Ideas have power, he said.\n\nIdeas cause ideas and help evolve new ideas. They interact with each other and with other mental forces in the same brain, in neighboring brains, and thanks to global\ncommunication, in far distant, foreign brains. And they also interact with the external surroundings to produce in toto a burstwise advance in evolution that is far beyond anything to hit the evolutionary scene yet....\n\nMonod added, \u201cI shall not hazard a theory of the selection of ideas.\u201d No need. Others were willing.\n\nRichard Dawkins made his own connection between the evolution of genes and the evolution of ideas. His essential actor was the replicator, and it scarcely mattered whether replicators were made of nucleic acid. His rule is \u201cAll life evolves by the differential survival of replicating entities.\u201d Wherever there is life, there must be replicators. Perhaps on other worlds replicators could arise in a silicon-based chemistry\u2014or in no chemistry at all.\n\nWhat would it mean for a replicator to exist without chemistry? \u201cI think that a new kind of replicator has recently emerged on this planet,\u201d he proclaimed at the end of his first book, in 1976. \u201cIt is staring us in the face. It is still in its infancy, still drifting clumsily about in its primeval soup, but already it is achieving evolutionary change at a rate that leaves the old gene panting far behind.\u201d That \u201csoup\u201d is human culture; the vector of transmission is language; and the spawning ground is the brain.\n\nFor this bodiless replicator itself, Dawkins proposed a name. He called it the meme, and it became his most memorable invention, far more influential than his selfish genes or his later proselytizing against religiosity. \u201cMemes propagate themselves in the meme pool by leaping from brain to brain via a process which, in the broad sense, can be called imitation,\u201d he wrote. They compete with one another for limited resources: brain time or bandwidth. They compete most of all for attention. For example:\n\nIdeas. Whether an idea arises uniquely or reappears many times, it may thrive in the meme pool or it may dwindle and vanish. The belief in God is an example Dawkins offers\u2014an ancient idea, replicating itself not just in words but in music and art. The belief that the earth orbits the sun is no less a meme, competing with others for survival. (Truth may be a helpful quality for a meme, but it is only one among many.)\n\nTunes. This tune\n\nhas spread for centuries across several continents. This one\na notorious though shorter-lived invader of brains, overran an immense population many times faster.\n\n**Catchphrases.** One text snippet, \u201cWhat hath God wrought?\u201d appeared early and spread rapidly in more than one medium. Another, \u201cRead my lips,\u201d charted a peculiar path through late twentieth-century America. \u201cSurvival of the fittest\u201d is a meme that, like other memes, mutates wildly (\u201csurvival of the fattest\u201d; \u201csurvival of the sickest\u201d; \u201csurvival of the fakest\u201d; \u201csurvival of the twittest\u201d,\u2026).\n\n**Images.** In Isaac Newton\u2019s lifetime, no more than a few thousand people had any idea what he looked like, though he was one of England\u2019s most famous men, yet now millions of people have quite a clear idea\u2014based on replicas of copies of rather poorly painted portraits. Even more pervasive and indelible are the smile of *Mona Lisa*, *The Scream* of Edvard Munch, and the silhouettes of various fictional extraterrestrials. These are memes, living a life of their own, independent of any physical reality. \u201cThis may not be what George Washington looked like then,\u201d a tour guide was overheard saying of the Gilbert Stuart painting at the Metropolitan Museum of Art, \u201cbut this is what he looks like now.\u201d Exactly.\n\nMemes emerge in brains and travel outward, establishing beachheads on paper and celluloid and silicon and anywhere else information can go. They are not to be thought of as elementary particles but as organisms. The number three is not a meme; nor is the color blue, nor any simple thought, any more than a single nucleotide can be a gene. Memes are complex units, distinct and memorable\u2014units with staying power. Also, an object is not a meme. The hula hoop is not a meme; it is made of plastic, not of bits. When this species of toy spread worldwide in a mad epidemic in 1958, it was the product, the physical manifestation of a meme, or memes: the craving for hula hoops; the swaying, swinging, twirling skill set of hula-hooping. The hula hoop itself is a meme vehicle. So, for that matter, is each human hula hooper\u2014a strikingly effective meme vehicle, in the sense neatly explained by the philosopher Daniel Dennett: \u201cA wagon with spoked wheels carries not only grain or freight from place to place; it carries the brilliant idea of a wagon with spoked wheels from mind to mind.\u201d Hula hoopers did that for the hula hoop\u2019s memes\u2014and in 1958 they found a new transmission vector, broadcast television, sending its messages immeasurably faster and farther than any wagon. The moving image of the hula hooper seduced new minds by hundreds, and then by thousands, and then by millions. The meme is not the dancer but the dance.\n\nWe are their vehicles and their enablers. For most of our biological history they existed fleetingly; their main mode of transmission was the one called \u201cword of mouth.\u201d Lately, however, they have managed to adhere in solid substance: clay tablets, cave walls, paper sheets. They achieve longevity through our pens and\nprinting presses, magnetic tapes and optical disks. They spread via broadcast towers and digital networks. Memes may be stories, recipes, skills, legends, and fashions. We copy them, one person at a time. Alternatively, in Dawkins\u2019s meme-centered perspective, they copy themselves. At first some of Dawkins\u2019s readers wondered how literally to take that. Did he mean to give memes anthropomorphic desires, intentions, and goals? It was the selfish gene all over again. (Typical salvo: \u201cGenes cannot be selfish or unselfish, any more than atoms can be jealous, elephants abstract or biscuits teleological.\u201d Typical rebuttal: a reminder that selfishness is defined by the geneticist as the tendency to increase one\u2019s chances of survival relative to its competitors.)\n\nDawkins\u2019s way of speaking was not meant to suggest that memes are conscious actors, only that they are entities with interests that can be furthered by natural selection. Their interests are not our interests. \u201cA meme,\u201d Dennett says, \u201cis an information packet with attitude.\u201d When we speak of fighting for a principle or dying for an idea, we may be more literal than we know. \u201cTo die for an idea; it is unquestionably noble,\u201d H. L. Mencken wrote. \u201cBut how much nobler it would be if men died for ideas that were true!\u201d\n\nTinker, tailor, soldier, sailor \u2026 Rhyme and rhythm help people remember bits of text. Or: rhyme and rhythm help bits of text get remembered. Rhyme and rhythm are qualities that aid a meme\u2019s survival, just as strength and speed aid an animal\u2019s. Patterned language has an evolutionary advantage. Rhyme, rhythm, and reason\u2014for reason, too, is a form of pattern. I was promised on a time to have reason for my rhyme; from that time unto this season, I received nor rhyme nor reason.\n\nLike genes, memes have effects on the wide world beyond themselves: phenotypic effects. In some cases (the meme for making fire; for wearing clothes; for the resurrection of Jesus) the effects can be powerful indeed. As they broadcast their influence on the world, memes thus influence the conditions affecting their own chances of survival. The meme or memes composing Morse code had strong positive feedback effects. \u201cI believe that, given the right conditions, replicators automatically band together to create systems, or machines, that carry them around and work to favour their continued replication,\u201d wrote Dawkins. Some memes have evident benefits for their human hosts (\u201clook before you leap,\u201d knowledge of CPR, belief in hand washing before cooking), but memetic success and genetic success are not the same. Memes can replicate with impressive virulence while leaving swaths of collateral damage\u2014patent medicines and psychic surgery, astrology and satanism, racist myths, superstitions, and (a special case) computer viruses. In a way, these are the most interesting\u2014the memes that thrive to their hosts\u2019 detriment, such as the idea that suicide bombers will find their reward in heaven.\nWhen Dawkins first floated the *meme* meme, Nicholas Humphrey, an evolutionary psychologist, said immediately that these entities should be considered \u201cliving structures, not just metaphorically but technically\u201d:\n\n> When you plant a fertile meme in my mind you literally parasitize my brain, turning it into a vehicle for the meme\u2019s propagation in just the way that a virus may parasitize the genetic mechanism of a host cell. And this isn\u2019t just a way of talking\u2014the meme for, say, \u201cbelief in life after death\u201d is actually realized physically, millions of times over, as a structure in the nervous systems of individual men the world over.\n\nMost early readers of *The Selfish Gene* passed over memes as a fanciful afterthought, but the pioneering ethologist W. D. Hamilton, reviewing the book for *Science*, ventured this prediction:\n\n> Hard as this term may be to delimit\u2014it surely must be harder than gene, which is bad enough\u2014I suspect that it will soon be in common use by biologists and, one hopes, by philosophers, linguists, and others as well and that it may become absorbed as far as the word \u201cgene\u201d has been into everyday speech.\n\nMemes could travel wordlessly even before language was born. Plain mimicry is enough to replicate knowledge\u2014how to chip an arrowhead or start a fire. Among animals, chimpanzees and gorillas are known to acquire behaviors by imitation. Some species of songbirds *learn* their songs, or at least song variants, after hearing them from neighboring birds (or, more recently, from ornithologists with audio players). Birds develop song repertoires and song dialects\u2014in short, they exhibit a birdsong *culture* that predates human culture by eons. These special cases notwithstanding, for most of human history memes and language have gone hand in glove. (Clich\u00e9s are memes.) Language serves as culture\u2019s first catalyst. It supersedes mere imitation, spreading knowledge by abstraction and encoding.\n\nPerhaps the analogy with disease was inevitable. Before anyone understood anything of epidemiology, its language was applied to species of information. An emotion can be *infectious*, a tune *catchy*, a habit *contagious*. \u201cFrom look to look, contagious through the crowd / The panic runs,\u201d wrote the poet James Thomson in 1730. Lust, likewise, according to Milton: \u201cEve, whose eye darted contagious fire.\u201d But only in the new millennium, in the time of global electronic transmission, has the identification become second nature. Ours is the age of virality: viral education, viral marketing, viral e-mail and video and networking. Researchers studying the Internet itself as a medium\u2014crowdsourcing, collective attention, social networking, and resource allocation\u2014employ not only the language but also the mathematical principles of epidemiology.\n\nOne of the first to use the terms *viral text* and *viral sentences* seems to have been a reader of Dawkins named Stephen Walton of New York City, corresponding in 1981 with Douglas Hofstadter. Thinking logically\u2014perhaps in the mode of a computer\u2014Walton proposed simple self-replicating sentences\nalong the lines of \u201cSay me!\u201d \u201cCopy me!\u201d and \u201cIf you copy me, I\u2019ll grant you three wishes!\u201d Hofstadter, then a columnist for *Scientific American*, found the term *viral text* itself to be even catchier.\n\nWell, now, Walton\u2019s own viral text, as you can see here before your eyes, has managed to commandeer the facilities of a very powerful host\u2014an entire magazine and printing press and distribution service. It has leapt aboard and is now\u2014even as you read this viral sentence\u2014propagating itself madly throughout the ideosphere!\n\n(In the early 1980s, a magazine with a print circulation of 700,000 still seemed like a powerful communications platform.) Hofstadter gaily declared himself infected by the *meme* meme.\n\nOne source of resistance\u2014or at least unease\u2014was the shoving of us humans toward the wings. It was bad enough to say that a person is merely a gene\u2019s way of making more genes. Now humans are to be considered as vehicles for the propagation of memes, too. No one likes to be called a puppet. Dennett summed up the problem this way: \u201cI don\u2019t know about you, but I am not initially attracted by the idea of my brain as a sort of dung heap in which the larvae of other people\u2019s ideas renew themselves, before sending out copies of themselves in an informational diaspora\u2026. Who\u2019s in charge, according to this vision\u2014we or our memes?\u201d\n\nHe answered his own question by reminding us that, like it or not, we are seldom \u201cin charge\u201d of our own minds. He might have quoted Freud; instead he quoted Mozart (or so he thought):\n\n> In the night when I cannot sleep, thoughts crowd into my mind\u2026. Whence and how do they come? I do not know and I have nothing to do with it. Those which please me I keep in my head and hum them.\n\nLater Dennett was informed that this well-known quotation was not Mozart\u2019s after all. It had taken on a life of its own; it was a fairly successful meme.\n\nFor anyone taken with the idea of memes, the landscape was changing faster than Dawkins had imagined possible in 1976, when he wrote, \u201cThe computers in which memes live are human brains.\u201d By 1989, the time of the second edition of *The Selfish Gene*, having become an adept programmer himself, he had to amend that: \u201cIt was obviously predictable that manufactured electronic computers, too, would eventually play host to self-replicating patterns of information.\u201d Information was passing from one computer to another \u201cwhen their owners pass floppy discs around,\u201d and he could see another phenomenon on the near horizon: computers connected in networks. \u201cMany of them,\u201d he wrote, \u201care literally wired up together in electronic mail exchange\u2026. It is a perfect milieu for self-replicating programs to flourish.\u201d Indeed, the Internet was in its birth throes. Not only did it provide memes with a nutrient-rich culture medium; it also gave wings to the *idea* of memes. *Meme* itself quickly became an Internet buzzword.\nAwareness of memes fostered their spread.\n\nA notorious example of a meme that could not have emerged in pre-Internet culture was the phrase \u201cjumped the shark.\u201d Loopy self-reference characterized every phase of its existence. To jump the shark means to pass a peak of quality or popularity and begin an irreversible decline. The phrase was thought to have been used first in 1985 by a college student named Sean J. Connolly, in reference to a certain television series. The origin of the phrase requires a certain amount of explanation without which it could not have been initially understood. Perhaps for that reason, there is no recorded usage until 1997, when Connolly\u2019s roommate, Jon Hein, registered the domain name jumptheshark.com and created a web site devoted to its promotion. The web site soon featured a list of frequently asked questions:\n\nQ. Did \u201cjump the shark\u201d originate from this web site, or did you create the site to capitalize on the phrase?\n\nA. This site went up December 24, 1997 and gave birth to the phrase \u201cjump the shark.\u201d As the site continues to grow in popularity, the term has become more commonplace. The site is the chicken, the egg, and now a Catch-22.\n\nIt spread to more traditional media in the next year; Maureen Dowd devoted a column to explaining it in The New York Times in 2001; in 2003 the same newspaper\u2019s \u201cOn Language\u201d columnist, William Safire, called it \u201cthe popular culture\u2019s phrase of the year\u201d; soon after that, people were using the phrase in speech and in print without self-consciousness\u2014no quotation marks or explanation\u2014and eventually, inevitably, various cultural observers asked, \u201cHas \u2018jump the shark\u2019 jumped the shark?\u201d (\u201cGranted, Jump the Shark is a brilliant cultural concept\u2026. But now the damn thing is everywhere.\u201d) Like any good meme, it spawned mutations. The \u201cjumping the shark\u201d entry in Wikipedia advised in 2009, \u201cSee also: jumping the couch; nuking the fridge.\u201d\n\nIs this science? In his 1983 column, Hofstadter proposed the obvious memetic label for such a discipline: memetics. The study of memes has attracted researchers from fields as far apart as computer science and microbiology. In bioinformatics, chain letters are an object of study. They are memes; they have evolutionary histories. The very purpose of a chain letter is replication; whatever else a chain letter may say, it embodies one message: Copy me. One student of chain-letter evolution, Daniel W. VanArsdale, listed many variants, in chain letters and even earlier texts: \u201cMake seven copies of it exactly as it is written\u201d [1902]; \u201cCopy this in full and send to nine friends\u201d [1923]; \u201cAnd if any man shall take away from the words of the book of this prophecy, God shall take away his part out of the book of life\u201d [Revelation 22:19]. Chain letters flourished with the help of a new nineteenth-century technology: \u201ccarbonic paper,\u201d sandwiched between sheets of writing paper in stacks. Then carbon paper made a symbiotic\npartnership with another technology, the typewriter. Viral outbreaks of chain letters occurred all through the early twentieth century.\n\n\u201cAn unusual chain-letter reached Quincy during the latter part of 1933,\u201d wrote a local Illinois historian. \u201cSo rapidly did the chain-letter fad develop symptoms of mass hysteria and spread throughout the United States, that by 1935\u20131936 the Post Office Department, as well as agencies of public opinion, had to take a hand in suppressing the movement.\u201d He provided a sample\u2014a meme motivating its human carriers with promises and threats:\n\nWe trust in God. He supplies our needs.\n\nMrs. F. Streuzel........Mich.\nMrs. A. Ford...........Chicago, Ill.\nMrs. K. Adkins.........Chicago, Ill.\netc.\n\nCopy the above names, omitting the first. Add your name last. Mail it to five persons who you wish prosperity to. The chain was started by an American Colonel and must be mailed 24 hours after receiving it. This will bring prosperity within 9 days after mailing it.\n\nMrs. Sanford won $3,000. Mrs. Andres won $1,000.\nMrs. Howe who broke the chain lost everything she possessed.\nThe chain grows a definite power over the expected word.\nDO NOT BREAK THE CHAIN.\n\nTwo subsequent technologies, when their use became widespread, provided orders-of-magnitude boosts in chain-letter fecundity: photocopying (c. 1950) and e-mail (c. 1995). One team of information scientists\u2014Charles H. Bennett from IBM in New York and Ming Li and Bin Ma from Ontario, Canada\u2014inspired by a chance conversation on a hike in the Hong Kong mountains, began an analysis of a set of chain letters collected during the photocopier era. They had thirty-three, all variants of a single letter, with mutations in the form of misspellings, omissions, and transposed words and phrases. \u201cThese letters have passed from host to host, mutating and evolving,\u201d they reported.\n\nLike a gene, their average length is about 2,000 characters. Like a potent virus, the letter threatens to kill you and induces you to pass it on to your \u201cfriends and associates\u201d\u2014some variation of this letter has probably reached millions of people. Like an inheritable trait, it promises benefits for you and the people you pass it on to. Like genomes, chain letters undergo natural selection and sometimes parts even get transferred between coexisting \u201cspecies.\u201d\n\nReaching beyond these appealing metaphors, they set out to use the letters as a \u201ctest bed\u201d for algorithms used in evolutionary biology. The algorithms were designed to take the genomes of various modern creatures and work backward, by inference and deduction, to reconstruct their phylogeny\u2014their evolutionary trees.\nIf these mathematical methods worked with genes, the scientists suggested, they should work with chain letters, too. In both cases the researchers were able to verify mutation rates and relatedness measures.\n\nStill, most of the elements of culture change and blur too easily to qualify as stable replicators. They are rarely as neatly fixed as a sequence of DNA. Dawkins himself emphasized that he had never imagined founding anything like a new science of memetics. A peer-reviewed *Journal of Memetics* came to life in 1997\u2014published online, naturally\u2014and then faded away after eight years partly spent in self-conscious debate over status, mission, and terminology. Even compared with genes, memes are hard to mathematize or even to define rigorously. So the gene-meme analogy causes uneasiness and the genetics-memetics analogy even more.\n\nGenes at least have a grounding in physical substance. Memes are abstract, intangible, and unmeasurable. Genes replicate with near-perfect fidelity, and evolution depends on that: some variation is essential, but mutations need to be rare. Memes are seldom copied exactly; their boundaries are always fuzzy, and they mutate with a wild flexibility that would be fatal in biology. The term *meme* could be applied to a suspicious cornucopia of entities, from small to large. For Dennett, the first four notes of Beethoven\u2019s Fifth Symphony were \u201cclearly\u201d a meme, along with Homer\u2019s *Odyssey* (or at least the *idea* of the *Odyssey*), the wheel, anti-Semitism, and writing. \u201cMemes have not yet found their Watson and Crick,\u201d said Dawkins; \u201cthey even lack their Mendel.\u201d\n\nYet here they are. As the arc of information flow bends toward ever greater connectivity, memes evolve faster and spread farther. Their presence is felt if not seen in herd behavior, bank runs, informational cascades, and financial bubbles. Diets rise and fall in popularity, their very names becoming catchphrases\u2014the South Beach Diet and the Atkins Diet, the Scarsdale Diet, the Cookie Diet and the Drinking Man\u2019s Diet all replicating according to a dynamic about which the science of nutrition has nothing to say. Medical practice, too, experiences \u201csurgical fads\u201d and \u201ciatroepidemics\u201d\u2014epidemics caused by fashions in treatment\u2014like the iatroepidemic of children\u2019s tonsillectomies that swept the United States and parts of Europe in the mid-twentieth century, with no more medical benefit than ritual circumcision. Memes were seen through car windows when yellow diamond-shaped *BABY ON BOARD* signs appeared as if in an instant of mass panic in 1984, in the United States and then Europe and Japan, followed an instant later by a spawn of ironic mutations (*BABY I\u2019M BOARD, EX IN TRUNK*). Memes were felt when global discourse was dominated in the last year of the millennium by the belief that the world\u2019s computers would stammer or choke when their internal clocks reached a special round number.\n\nIn the competition for space in our brains and in the culture, the effective\nThe Information\n\ncombatants are the messages. The new, oblique, looping views of genes and memes have enriched us. They give us paradoxes to write on M\u00f6bius strips. \u201cThe human world is made of stories, not people,\u201d writes David Mitchell. \u201cThe people the stories use to tell themselves are not to be blamed.\u201d Margaret Atwood writes: \u201cAs with all knowledge, once you knew it, you couldn\u2019t imagine how it was that you hadn\u2019t known it before. Like stage magic, knowledge before you knew it took place before your very eyes, but you were looking elsewhere.\u201d Nearing death, John Updike reflects on\n\nA life poured into words\u2014apparent waste\nintended to preserve the thing consumed.\n\nFred Dretske, a philosopher of mind and knowledge, wrote in 1981: \u201cIn the beginning there was information. The word came later.\u201d He added this explanation: \u201cThe transition was achieved by the development of organisms with the capacity for selectively exploiting this information in order to survive and perpetuate their kind.\u201d Now we might add, thanks to Dawkins, that the transition was achieved by the information itself, surviving and perpetuating its kind and selectively exploiting organisms.\n\nMost of the biosphere cannot see the infosphere; it is invisible, a parallel universe humming with ghostly inhabitants. But they are not ghosts to us\u2014not anymore. We humans, alone among the earth\u2019s organic creatures, live in both worlds at once. It is as though, having long coexisted with the unseen, we have begun to develop the needed extrasensory perception. We are aware of the many species of information. We name their types sardonically, as though to reassure ourselves that we understand: urban myths and zombie lies. We keep them alive in air-conditioned server farms. But we cannot own them. When a jingle lingers in our ears, or a fad turns fashion upside down, or a hoax dominates the global chatter for months and vanishes as swiftly as it came, who is master and who is slave?\n12 | THE SENSE OF RANDOMNESS\n\n(In a State of Sin)\n\n\u201cI wonder,\u201d she said. \u201cIt\u2019s getting harder to see the patterns, don\u2019t you think?\u201d\n\n\u2014Michael Cunningham (2005)\n\nIN 1958, GREGORY CHAITIN, a precocious eleven-year-old New Yorker, the son of Argentine \u00e9migr\u00e9s, found a magical little book in the library and carried it around with him for a while trying to explain it to other children\u2014and then, he had to admit, trying to understand it himself. It was G\u00f6del\u2019s Proof, by Ernest Nagel and James R. Newman. Expanded from an article in Scientific American, it reviewed the renaissance in logic that began with George Boole; the process of \u201cmapping,\u201d encoding statements about mathematics in the form of symbols and even integers; and the idea of metamathematics, systematized language about mathematics and therefore beyond mathematics. This was heady stuff for the boy, who followed the authors through their simplified but rigorous exposition of G\u00f6del\u2019s \u201castounding and melancholy\u201d demonstration that formal mathematics can never be free of self-contradiction.\n\nThe vast bulk of mathematics as practiced at this time cared not at all for G\u00f6del\u2019s proof. Startling though incompleteness surely was, it seemed incidental somehow\u2014contributing nothing to the useful work of mathematicians, who went on making discoveries and proving theorems. But philosophically minded souls remained deeply disturbed by it, and these were the sorts of people Chaitin liked to read. One was John von Neumann\u2014who had been there at the start, in K\u00f6nigsberg, 1930, and then in the United States took the central role in the development of computation and computing theory. For von Neumann, G\u00f6del\u2019s proof was a point of no return:\n\nIt was a very serious conceptual crisis, dealing with rigor and the proper way to carry out a correct mathematical proof. In view of the earlier notions of the absolute rigor of mathematics, it is surprising that such a thing could have happened, and even more surprising that it could have happened in these latter days when miracles are not supposed to take place. Yet it did happen.\n\nWhy? Chaitin asked. He wondered if at some level G\u00f6del\u2019s incompleteness could be connected to that new principle of quantum physics, uncertainty, which smelled similar somehow. Later, the adult Chaitin had a chance to put this question to the oracular John Archibald Wheeler. Was G\u00f6del incompleteness\nrelated to Heisenberg uncertainty? Wheeler answered by saying he had once posed that very question to G\u00f6del himself, in his office at the Institute for Advanced Study\u2014G\u00f6del with his legs wrapped in a blanket, an electric heater glowing warm against the wintry drafts. G\u00f6del refused to answer. In this way, Wheeler refused to answer Chaitin.\n\nWhen Chaitin came upon Turing\u2019s proof of uncomputability, he thought this must be the key. He also found Shannon and Weaver\u2019s book, *The Mathematical Theory of Communication*, and was struck by its upside-down seeming reformulation of entropy: an entropy of bits, measuring information on the one hand and disorder on the other. The common element was randomness, Chaitin suddenly thought. Shannon linked randomness, perversely, to information. Physicists had found randomness inside the atom\u2014the kind of randomness that Einstein deplored by complaining about God and dice. All these heroes of science were talking about or around randomness.\n\nIt is a simple word, *random*, and everyone knows what it means. Everyone, that is, and no one. Philosophers and mathematicians struggled endlessly. Wheeler said this much, at least: \u201cProbability, like time, is a concept invented by humans, and humans have to bear the responsibility for the obscurities that attend it.\u201d The toss of a fair coin is random, though every detail of the coin\u2019s trajectory may be determined \u00e0 la Newton. Whether the population of France is an even or odd number at any given instant is random, but the population of France itself is surely *not* random: it is a definite fact, even if not knowable. John Maynard Keynes tackled randomness in terms of its opposites, and he chose three: knowledge, causality, and design. What is known in advance, determined by a cause, or organized according to plan cannot be random.\n\n\u201cChance is only the measure of our ignorance,\u201d Henri Poincar\u00e9 famously said. \u201cFortuitous phenomena are by definition those whose laws we do not know.\u201d Immediately he recanted: \u201cIs this definition very satisfactory? When the first Chaldean shepherds watched the movements of the stars, they did not yet know the laws of astronomy, but would they have dreamed of saying that the stars move at random?\u201d For Poincar\u00e9, who understood chaos long before it became a science, examples of randomness included such phenomena as the scattering of raindrops, their causes physically determined but so numerous and complex as to be unpredictable. In physics\u2014or wherever natural processes seem unpredictable\u2014apparent randomness may be noise or may arise from deeply complex dynamics.\n\nIgnorance is subjective. It is a quality of the observer. Presumably randomness\u2014if it exists at all\u2014should be a quality of the thing itself. Leaving humans out of the picture, one would like to say that an event, a choice, a\ndistribution, a game, or, most simply, a number is random.\n\nThe notion of a random number is full of difficulties. Can there be such thing as a *particular* random number; a *certain* random number? This number is arguably random:\n\n10097325337652013586346735487680959091173929274945\u2026\n\nThen again, it is special. It begins a book published in 1955 with the title *A Million Random Digits*. The RAND Corporation generated the digits by means of what it described as an electronic roulette wheel: a pulse generator, emitting 100,000 pulses per second, gated through a five-place binary counter, then passed through a binary-to-decimal converter, fed into an IBM punch, and printed by an IBM model 856 Cardatype. The process took years. When the first batch of digits was tested, statisticians discovered significant biases: digits, or groups of digits, or patterns of digits that appeared too frequently or not frequently enough. Finally, however, the tables were published. \u201cBecause of the very nature of the tables,\u201d the editors said wryly, \u201cit did not seem necessary to proofread every page of the final manuscript in order to catch random errors of the Cardatype.\u201d\n\nThe book had a market because scientists had a working need for random numbers in bulk, to use in designing statistically fair experiments and building realistic models of complex systems. The new method of Monte Carlo simulation employed random sampling to model phenomena that could not be solved analytically; Monte Carlo simulation was invented and named by von Neumann\u2019s team at the atomic-bomb project, desperately trying to generate random numbers to help them calculate neutron diffusion. Von Neumann realized that a mechanical computer, with its deterministic algorithms and finite storage capacity, could never generate truly random numbers. He would have to settle for *pseudorandom* numbers: deterministically generated numbers that behaved as if random. They were random enough for practical purposes. \u201cAny one who considers arithmetical methods of producing random digits is, of course, in a state of sin,\u201d said von Neumann.\n\nRandomness might be defined in terms of order\u2014its absence, that is. This orderly little number sequence can hardly be called \u201crandom\u201d:\n\n00000\n\nYet it makes a cameo appearance in the middle of the famous million random digits. In terms of probability, that is to be expected: \u201c00000\u201d is as likely to occur as any of the other 99,999 possible five-digit strings. Elsewhere in the million random digits we find:\n\n010101\n\nThis, too, appears patterned.\nTo pick out fragments of pattern in this jungle of digits requires work by an intelligent observer. Given a long enough random string, every possible short-enough substring will appear somewhere. One of them will be the combination to the bank vault. Another will be the encoded complete works of Shakespeare. But they will not do any good, because no one can find them.\n\nPerhaps we may say that numbers like 00000 and 010101 can be random in a particular context. If a person flips a fair coin (one of the simplest mechanical random-number generators) long enough, at some point the coin is bound to come up heads ten times in a row. When that happens, the random-number seeker will typically discard the result and go for a coffee break. This is one of the ways humans do poorly at generating random numbers, even with mechanical assistance. Researchers have established that human intuition is useless both in predicting randomness and in recognizing it. Humans drift toward pattern willy-nilly. The New York Public Library bought *A Million Random Digits* and shelved it under Psychology. In 2010 it was still available from Amazon for eighty-one dollars.\n\nA number is (we now understand) information. When we modern people, Shannon\u2019s heirs, think about information in its purest form, we may imagine a string of 0s and 1s, a binary number. Here are two binary strings, fifty digits long:\n\nA: 0101010101010101010101010101010101010101010101010101010101010101\n\nB: 100010101111101011101001101000011000100111101111\n\nIf Alice (A) and Bob (B) both say they generated their strings by flipping a coin, no one will ever believe Alice. The strings are surely not equally random. Classical probability theory offers no solid reason for claiming that B is more random than A, because a random process could produce either string. Probability is about ensembles, not individual events. Probability theory treats events statistically. It does not like questions in the form \u201cHow likely was that to happen?\u201d If it happened, it happened.\n\nTo Claude Shannon, these strings would look like messages. He would ask, *How much information* does each string contain? On their face, they both contain fifty bits. A telegraph operator charging by the digit would measure the length of the messages and give Alice and Bob the same bill. Then again, the two messages seem to differ profoundly. Message A immediately becomes boring: once you see the pattern, further repetitions provide no new information. In message B, every bit is as valuable as every other. Shannon\u2019s first formulation of information theory treated messages statistically, as choices from the ensemble of all possible messages\u2014in the case of A and B, $2^{50}$ of them. But Shannon also considered redundancy within a message: the pattern, the regularity, the order that makes a\nmessage compressible. The more regularity in a message, the more predictable it is. The more predictable, the more redundant. The more redundant a message is, the less information it contains.\n\nThe telegraph operator sending message A has a shortcut: he can transmit something like \u201cRepeat \u201801\u2019 twenty-five times.\u201d For longer messages with easy patterns, the savings in keystrokes becomes enormous. Once the pattern is clear, the extra characters are free. The operator for message B must soldier on the hard way, sending every character, because every character is a complete surprise; every character costs one bit. This pair of questions\u2014how random and how much information\u2014turn out to be one and the same. They have a single answer.\n\nChaitin was not thinking about telegraphs. The device he could not get out of his head was the Turing machine\u2014that impossibly elegant abstraction, marching back and forth along its infinite paper tape, reading and writing symbols. Free from all the real world\u2019s messiness, free from creaking wheel-work and finical electricity, free from any need for speed, the Turing machine was the ideal computer. Von Neumann, too, had kept coming back to Turing machines. They were the ever-handy lab mice of computer theory. Turing\u2019s $U$ had a transcendent power: a universal Turing machine can simulate any other digital computer, so computer scientists can disregard the messy details of any particular make or model. This is liberating.\n\nClaude Shannon, having moved from Bell Labs to MIT, reanalyzed the Turing machine in 1956. He stripped it down to the smallest possible skeleton, proving that the universal computer could be constructed with just two internal states, or with just two symbols, 0 and 1, or blank and nonblank. He wrote his proof in words more pragmatic than mathematical: he described exactly how the two-state Turing machine would step left and right, \u201cbouncing\u201d back and forth to keep track of the larger numbers of states in a more complex computer. It was all very intricate and specific, redolent of Babbage. For example:\n\nWhen the reading head moves, the state information must be transferred to the next cell of the tape to be visited using only two internal states in machine B. If the next state in machine A is to be (say) state 17 (according to some arbitrary numbering system) this is transferred in machine B by \u201cbouncing\u201d the reading head back and forth between the old cell and the new one 17 times (actually 18 trips to the new cell and 17 back to the old one).\n\nThe \u201cbouncing operation\u201d carries the information from cell to cell, and the cells act as \u201ctransmitters\u201d and \u201ccontrollers.\u201d\n\nTuring had titled his great paper \u201cOn Computable Numbers,\u201d but of course the real focus was on uncomputable numbers. Could uncomputable numbers and random numbers be related? In 1965 Chaitin was an undergraduate at the City College of New York, writing up a discovery he hoped to submit to a journal; it\nwould be his first publication. He began, \u201cIn this paper the Turing machine is regarded as a general purpose computer and some practical questions are asked about programming it.\u201d Chaitin, as a high-school student in the Columbia Science Honors Program, had the opportunity to practice programming in machine language on giant IBM mainframes, using decks of punched cards\u2014one card for each line of a program. He would leave his card deck in the computer center and come back the next day for the program\u2019s output. He could run Turing machines in his head, too: write 0, write 1, write blank, shift tape left, shift tape right\u2026. The universal computer gave him a nice way to distinguish between numbers like Alice and Bob\u2019s A and B. He could write a program to make a Turing machine print out \u201c010101\u2026\u201d a million times, and he could write down the length of that program\u2014quite short. But given a million random digits\u2014no pattern, no regularity, nothing special at all\u2014there could be no shortcut. The computer program would have to incorporate the entire number. To make the IBM mainframe print out those million digits, he would have to put the whole million digits into the punched cards. To make the Turing machine do it, he would still need the million digits for input.\n\nHere is another number (in decimal this time):\n\n\\[ C: 3.1415926535897932384626433832795028841971693993751\u2026 \\]\n\nThis looks random. Statistically each digit appears with the expected frequency (one in ten); likewise each pair of digits (one in a hundred), each triplet, and so on. A statistician would say it appears to be \u201cnormal,\u201d as far as anyone can tell. The next digit is always a surprise. The works of Shakespeare will be in there, eventually. But someone might recognize this as a familiar number, \\( \\pi \\). So it is not random after all.\n\nBut why do we say \\( \\pi \\) is not random? Chaitin proposed a clear answer: a number is not random if it is computable\u2014if a definable computer program will generate it. Thus computability is a measure of randomness.\n\nFor Turing computability was a yes-or-no quality\u2014a given number either is or is not. But we would like to say that some numbers are more random than others\u2014they are less patterned, less orderly. Chaitin said the patterns and the order express computability. Algorithms generate patterns. So we can gauge computability by looking at the size of the algorithm. Given a number\u2014represented as a string of any length\u2014we ask, what is the length of the shortest program that will generate it? Using the language of a Turing machine, that question can have a definite answer, measured in bits.\n\nChaitin\u2019s algorithmic definition of randomness also provides an algorithmic definition of information: the size of the algorithm measures how much information a given string contains.\nLooking for patterns\u2014seeking the order amid chaos\u2014is what scientists do, too. The eighteen-year-old Chaitin felt this was no accident. He ended this first paper by applying algorithmic information theory to the process of science itself. \u201cConsider a scientist,\u201d he proposed, \u201cwho has been observing a closed system that once every second either emits a ray of light or does not.\u201d\n\nHe summarizes his observations in a sequence of 0s and 1s in which a 0 represents \u201cray not emitted\u201d and a 1 represents \u201cray emitted.\u201d The sequence may start\n\n\\[0110101110\\ldots\\]\n\nand continue for a few thousand more bits. The scientist then examines the sequence in the hope of observing some kind of pattern or law. What does he mean by this? It seems plausible that a sequence of 0s and 1s is patternless if there is no better way to calculate it than just by writing it all out at once from a table giving the whole sequence.\n\nBut if the scientist could discover a way to produce the same sequence with an algorithm, a computer program significantly shorter than the sequence, then he would surely know the events were not random. He would say that he had hit upon a theory. This is what science always seeks: a simple theory that accounts for a large set of facts and allows for prediction of events still to come. It is the famous Occam\u2019s razor. \u201cWe are to admit no more causes of natural things than such as are both true and sufficient to explain their appearances,\u201d said Newton, \u201cfor nature is pleased with simplicity.\u201d Newton quantified mass and force, but simplicity had to wait.\n\nChaitin sent his paper to the *Journal of the Association for Computing Machinery*. They were happy to publish it, but one referee mentioned that he had heard rumors of similar work coming from the Soviet Union. Sure enough, the first issue of a new journal arrived (after a journey of months) in early 1966: *\u041f\u0440\u043e\u0431\u043b\u0435\u043c\u044b \u041f\u0435\u0440\u0435\u0434\u0430\u0447\u0438 \u0418\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438*, *Problems of Information Transmission*. It contained a paper titled \u201cThree Approaches to the Definition of the Concept \u2018Amount of Information,\u2019 \u201d by A. N. Kolmogorov. Chaitin, who did not read Russian, had just time to add a footnote.\n\nAndrei Nikolaevich Kolmogorov was the outstanding mathematician of the Soviet era. He was born in Tambov, three hundred miles southeast of Moscow, in 1903; his unwed mother, one of three sisters Kolmogorova, died in childbirth, and his aunt Vera raised him in a village near the river Volga. In the waning years of tsarist Russia, this independent-minded woman ran a village school and operated a clandestine printing press in her home, sometimes hiding forbidden documents under baby Andrei\u2019s cradle.\n\nMoscow University accepted Andrei Nikolaevich as a student of mathematics soon after the revolution of 1917. Within ten years he was proving a collection of\ninfluential results that took form in what became the theory of probability. His *Foundations of the Theory of Probability*, published in Russian in 1933 and in English in 1950, remains the modern classic. But his interests ranged widely, to physics and linguistics as well as other fast-growing branches of mathematics. Once he made a foray into genetics but drew back after a dangerous run-in with Stalin\u2019s favorite pseudoscientist, Trofim Lysenko. During World War II Kolmogorov applied his efforts to statistical theory in artillery fire and devised a scheme of stochastic distribution of barrage balloons to protect Moscow from Nazi bombers. Apart from his war work, he studied turbulence and random processes. He was a Hero of Socialist Labor and seven times received the Order of Lenin.\n\nHe first saw Claude Shannon\u2019s *Mathematical Theory of Communication* rendered into Russian in 1953, purged of its most interesting features by a translator working in Stalin\u2019s heavy shadow. The title became *Statistical Theory of Electrical Signal Transmission*. The word *information*, \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f, was everywhere replaced with \u0434\u0430\u043d\u043d\u044b\u0435, data. The word *entropy* was placed in quotation marks to warn the reader against inferring a connection with entropy in physics. The section applying information theory to the statistics of natural language was omitted entirely. The result was technical, neutral, juiceless, and thus unlikely to attract interpretation in the terms of Marxist ideology. These were serious concerns; \u201ccybernetics\u201d was initially defined in the *Short Philosophical Dictionary* (standard reference of ideological orthodoxy) as a \u201creactionary pseudoscience\u201d and \u201can ideological weapon of imperialist reaction.\u201d Kolmogorov leapt upon Shannon\u2019s paper nonetheless; he, at least, was unafraid to use the word *information*. Working with his students in Moscow, he put forth a rigorous mathematical formulation of information theory, with definitions of the fundamental concepts, careful proofs, and new discoveries\u2014some of which, he soon learned to his sorrow, had appeared in Shannon\u2019s original paper but had been omitted from the Russian version.\n\nIn the Soviet Union, still moderately isolated from the rest of the world\u2019s science, Kolmogorov was well placed to carry the banner of information. He was in charge of all mathematics in the *Great Soviet Encyclopedia*, choosing the authors, editing the articles, and writing much of it himself. In 1956 he delivered a long plenary report on the theory of information transmission to the Soviet Academy of Sciences. His colleagues thought this was a bit \u201caddled\u201d\u2014that Shannon\u2019s work was \u201cmore technology than mathematics,\u201d as Kolmogorov recalled it afterward. \u201cIt is true,\u201d he said, \u201cthat Shannon left to his successors the rigorous \u2018justification\u2019 of his ideas in some difficult cases. However, his mathematical intuition was amazingly precise.\u201d Kolmogorov was not as enthusiastic about cybernetics. Norbert Wiener felt a kinship with him\u2014they had\nboth done early work on stochastic processes and Brownian motion. On a visit to Moscow, Wiener said, \u201cWhen I read the works of Academician Kolmogorov, I feel that these are my thoughts as well, this is what I wanted to say. And I know that Academician Kolmogorov has the same feeling when reading my works.\u201d But the feeling was evidently not shared. Kolmogorov steered his colleagues toward Shannon instead. \u201cIt is easy to understand that as a mathematical discipline cybernetics in Wiener\u2019s understanding lacks unity,\u201d he said, \u201cand it is difficult to imagine productive work in training a specialist, say a postgraduate student, in cybernetics in this sense.\u201d He already had real results to back up his instincts: a useful generalized formulation of Shannon entropy, and an extension of his information measure to processes in both discrete and continuous time.\n\nPrestige in Russia was finally beginning to flow toward any work that promised to aid electronic communication and computing. Such work began almost in a void. Pragmatic electrical engineering barely existed; Soviet telephony was notoriously dismal, a subject for eternally bitter Russian humor. As of 1965, there was still no such thing as direct long-distance dialing. The number of toll calls nationally had yet to surpass the number of telegrams, a milestone that had been reached in the United States before the end of the previous century. Moscow had fewer telephones per capita than any major world city. Nonetheless, Kolmogorov and his students generated enough activity to justify a new quarterly journal, *Problems of Information Transmission*, devoted to information theory, coding theory, theory of networks, and even information in living organisms. The inaugural issue opened with Kolmogorov\u2019s \u201cThree Approaches to the Definition of the Concept \u2018Amount of Information\u2019\u201d\u2014almost a manifesto\u2014which then began its slow journey toward the awareness of mathematicians in the West.\n\n\u201cAt each given moment there is only a fine layer between the \u2018trivial\u2019 and the impossible,\u201d Kolmogorov mused in his diary. \u201cMathematical discoveries are made in this layer.\u201d In the new, quantitative view of information he saw a way to attack a problem that had eluded probability theory, the problem of randomness. How much information is contained in a given \u201cfinite object\u201d? An object could be a number (a series of digits) or a message or a set of data.\n\nHe described three approaches: the combinatorial, the probabilistic, and the algorithmic. The first and second were Shannon\u2019s, with refinements. They focused on the probability of one object among an ensemble of objects\u2014one particular message, say, chosen from a set of possible messages. How would this work, Kolmogorov wondered, when the object was not just a symbol in an alphabet or a lantern in a church window but something big and complicated\u2014a genetic organism, or a work of art? How would one measure the amount of information in Tolstoy\u2019s *War and Peace*? \u201cIs it possible to include this novel in a\nreasonable way in the set of \u2018all possible novels\u2019 and further to postulate the existence of a certain probability distribution in this set?\u201d he asked. Or could one measure the amount of genetic information in, say, the cuckoo bird by considering a probability distribution in the set of all possible species?\n\nHis third approach to measuring information\u2014the algorithmic\u2014avoided the difficulties of starting with ensembles of possible objects. It focused on the object itself.* Kolmogorov introduced a new word for the thing he was trying to measure: complexity. As he defined this term, the complexity of a number, or message, or set of data is the inverse of simplicity and order and, once again, it corresponds to information. The simpler an object is, the less information it conveys. The more complexity, the more information. And, just as Gregory Chaitin did, Kolmogorov put this idea on a solid mathematical footing by calculating complexity in terms of algorithms. The complexity of an object is the size of the smallest computer program needed to generate it. An object that can be produced by a short algorithm has little complexity. On the other hand, an object needing an algorithm every bit as long as the object itself has maximal complexity.\n\nA simple object can be generated\u2014or computed, or described\u2014with just a few bits. A complex object requires an algorithm of many bits. Put this way, it seemed obvious. But until now it had not been understood mathematically. Kolmogorov put it this way:\n\nThe intuitive difference between \u201csimple\u201d and \u201ccomplicated\u201d objects has apparently been perceived a long time ago. On the way to its formalization, an obvious difficulty arises: something that can be described simply in one language may not have a simple description in another and it is not clear what method of description should be chosen.\n\nThat difficulty is solved by using computer language. It does not matter which computer language, because they are all equivalent, reducible to the language of a universal Turing machine. The Kolmogorov complexity of an object is the size, in bits, of the shortest algorithm needed to generate it. This is also the amount of information. And it is also the degree of randomness\u2014Kolmogorov declared \u201ca new conception of the notion \u2018random\u2019 corresponding to the natural assumption that randomness is the absence of regularity.\u201d The three are fundamentally equivalent: information, randomness, and complexity\u2014three powerful abstractions, bound all along like secret lovers.\n\nFor Kolmogorov, these ideas belonged not only to probability theory but also to physics. To measure the complexity of an orderly crystal or a helter-skelter box of gas, one could measure the shortest algorithm needed to describe the state of the crystal or gas. Once again entropy was the key. Kolmogorov had a useful background in difficult physical problems to which these new methods could be applied. In 1941 he had produced the first useful, though flawed, understanding of the local structure of turbulent flows\u2014equations to predict the distribution of\nwhorls and eddies. He had also worked on perturbations in planetary orbits, another problem surprisingly intractable for classical Newtonian physics. Now he began laying the groundwork for the renaissance in chaos theory to come in the 1970s: analyzing dynamical systems in terms of entropy and information dimension. It made sense now to say that a dynamical system produces information. If it is unpredictable, it produces a great deal of information.\n\nKolmogorov knew nothing of Gregory Chaitin, nor did either man know of an American probability theorist named Ray Solomonoff, who had developed some of the same ideas. The world was changing. Time, distance, and language still divided mathematicians in Russia from their Western counterparts, but the gulf narrowed every year. Kolmogorov often said that no one should do mathematics after the age of sixty. He dreamed of spending his last years as a buoy keeper on the Volga, making a watery circuit in a boat with oars and a small sail. When the time came, buoy keepers had switched to motorboats, and for Kolmogorov, this ruined the dream.\n\nNow the paradoxes returned.\n\nZero is an interesting number. Books have been written about it. One is certainly an interesting number\u2014it is the first and the foremost (not counting zero), the singular and unique. Two is interesting in all kinds of ways: the smallest prime, the definitive even number, the number needed for a successful marriage, the atomic number of helium, the number of candles to light on Finnish Independence Day. Interesting is an everyday word, not mathematicians\u2019 jargon. It seems safe to say that any small number is interesting. All the two-digit numbers and many of the three-digit numbers have their own Wikipedia entries.\n\nNumber theorists name entire classes of interesting numbers: prime numbers, perfect numbers, squares and cubes, Fibonacci numbers, factorials. The number 593 is more interesting than it looks; it happens to be the sum of nine squared and two to the ninth\u2014thus a \u201cLeyland number\u201d (any number that can be expressed as \\(x^y + y^x\\)). Wikipedia also devotes an article to the number 9,814,072,356. It is the largest holodigital square\u2014which is to say, the largest square number containing each decimal digit exactly once.\n\nWhat would be an uninteresting number? Presumably a random number. The English number theorist G. H. Hardy randomly rode in taxi No. 1729 on his way to visit the ailing Srinivasa Ramanujan in 1917 and remarked to his colleague that, as numbers go, 1,729 was \u201crather a dull one.\u201d On the contrary, replied Ramanujan (according to a standard anecdote of mathematicians), it is the smallest number expressible as the sum of two cubes in two different ways.* \u201cEvery positive integer is one of Ramanujan\u2019s personal friends,\u201d remarked J. E. Littlewood. Due to the anecdote, 1,729 is known nowadays as the Hardy-Ramanujan number. Nor\nis that all; 1,729 also happens to be a Carmichael number, an Euler pseudoprime, and a Zeisel number.\n\nBut even the mind of Ramanujan was finite, as is Wikipedia, as is the aggregate sum of human knowledge, so the list of interesting numbers must end somewhere. Surely there must be a number about which there is nothing special to say. Wherever it is, there stands a paradox: the number we may describe, interestingly, as \u201cthe smallest uninteresting number.\u201d\n\nThis is none other than Berry\u2019s paradox reborn, the one described by Bertrand Russell in *Principia Mathematica*. Berry and Russell had devilishly asked, What is the least integer not nameable in fewer than nineteen syllables? Whatever this number is, it can be named in eighteen syllables: *the least integer not nameable in fewer than nineteen syllables*. Explanations for why a number is interesting are ways of naming the number: \u201cthe square of eleven,\u201d for example, or \u201cthe number of stars in the American flag.\u201d Some of these names do not seem particularly helpful, and some are rather fuzzy. Some are pure mathematical facts: whether, for example, a number is expressible as the sum of two cubes in two different ways. But some are facts about the world, or about language, or about human beings, and they may be accidental and ephemeral\u2014for example, whether a number corresponds to a subway stop or a date in history.\n\nChaitin and Kolmogorov revived Berry\u2019s paradox in inventing algorithmic information theory. An algorithm names a number. \u201cThe paradox originally talks about English, but that\u2019s much too vague,\u201d Chaitin says. \u201cI pick a computer-programming language instead.\u201d Naturally he picks the language of a universal Turing machine.\n\nAnd then what does it mean, how do you name an integer? Well, you name an integer by giving a way to calculate it. A program names an integer if its output is that integer\u2014you know, it outputs that integer, just one, and then it stops.\n\nAsking whether a number is interesting is the inverse of asking whether it is random. If the number $n$ can be computed by an algorithm that is relatively short, then $n$ is interesting. If not, it is random. The algorithm PRINT 1 AND THEN PRINT 100 ZEROES generates an interesting number (a googol). Similarly, FIND THE FIRST PRIME NUMBER, ADD THE NEXT PRIME NUMBER, AND REPEAT A MILLION TIMES generates a number that is interesting: the sum of the first million primes. It would take a Turing machine a long time to compute that particular number, but a finite time nonetheless. The number is computable.\n\nBut if the most concise algorithm for $n$ is \u201cPRINT [n]\u201d\u2014an algorithm incorporating the entire number, with no shorthand\u2014then we may say that there is nothing interesting about $n$. In Kolmogorov\u2019s terms, this number is random\u2014maximally complex. It will have to be patternless, because any pattern would\nprovide a way to devise a shorthand algorithm. \u201cIf there is a small, concise computer program that calculates the number, that means it has some quality or characteristic that enables you to pick it out and to compress it into a smaller algorithmic description,\u201d Chaitin says. \u201cSo that\u2019s unusual; that\u2019s an interesting number.\u201d\n\nBut *is* it unusual? Looking generally at all the numbers, how can a mathematician know whether the interesting ones are rare or common? For that matter, looking at any one number, can a mathematician ever know for sure whether a smaller algorithm might be found? For Chaitin, these were the critical questions.\n\nHe answered the first with a counting argument. The vast majority of numbers have to be uninteresting because there cannot possibly be enough concise computer programs to go around. Count them. Given 1,000 bits (say), one has $2^{1000}$ numbers; but not nearly that many useful computer programs can be written in 1,000 bits. \u201cThere are a lot of positive integers,\u201d Chaitin says. \u201cIf the programs have to be smaller, then there just aren\u2019t enough of them to name all those different positive integers.\u201d So most $n$\u2019s of any given length are random.\n\nThe next question was far more troubling. Knowing that most numbers are random, and given any particular number $n$, can mathematicians prove it to be random? They cannot tell by looking at it. They can often prove the opposite, that $n$ is interesting: in that case they just have to find a short algorithm that generates $n$. (Technically, it must be shorter than $\\log_2 n$ bits, the number needed to write $n$ in binary.) Proving the negative is a different story. \u201cEven though most positive integers are uninteresting,\u201d Chaitin declared, \u201cyou can never be sure\u2026. You can only prove it in a small number of cases.\u201d One could imagine trying to do it by brute force, writing down every possible algorithm and testing them one by one. But a computer will have to perform the tests\u2014an algorithm testing other algorithms\u2014and soon, Chaitin demonstrated, a new version of Berry\u2019s paradox appears. Instead of \u201cthe smallest uninteresting number,\u201d one inevitably encounters a statement in the form of \u201cthe smallest number that we can prove cannot be named in fewer than $n$ syllables.\u201d (We are not really talking about syllables any more, of course, but Turing-machine states.)* It is another recursive, self-looping twist. This was Chaitin\u2019s version of G\u00f6del\u2019s incompleteness. Complexity, defined in terms of program size, is generally uncomputable. Given an arbitrary string of a million digits, a mathematician knows that it is almost certainly random, complex, and patternless\u2014but cannot be absolutely sure.\n\nChaitin did this work in Buenos Aires. When he was still a teenager, before he could graduate from City College, his parents moved back to their home in Argentina, and he got a job there with IBM World Trade. He continued to nurse his obsession with G\u00f6del and incompleteness and to send papers to the American\nMathematical Society and the Association for Computing Machinery. Eight years later, Chaitin returned to the United States to visit IBM\u2019s research center in Yorktown Heights, New York, and placed a telephone call to his hero, then nearing seventy at the Institute for Advanced Study in Princeton. G\u00f6del answered, and Chaitin introduced himself and said he had a new approach to incompleteness, based on Berry\u2019s paradox instead of the liar paradox.\n\n\u201cIt doesn\u2019t make any difference which paradox you use,\u201d said G\u00f6del.\n\n\u201cYes, but \u2026\u201d Chaitin said he was on the trail of a new \u201cinformation-theoretic\u201d view of incompleteness and asked if he could call on G\u00f6del in Princeton. He was staying in the YMCA in White Plains and would take the train, changing in New York City. G\u00f6del agreed, but when the day came, he canceled. It was snowing, and he was fearful for his health. Chaitin never did meet him. G\u00f6del, increasingly unstable, afraid of poisoning, died in the winter of 1978 of self-starvation.\n\nChaitin spent the rest of his career at the IBM Watson Research Center, one of the last great scientists to be so well supported in work of no plausible use to his corporate patron. He sometimes said he was \u201chiding\u201d in a physics department; he felt that more conventional mathematicians dismissed him as \u201ca closet physicist\u201d anyway. His work treated mathematics as a sort of empirical science\u2014not a Platonic pipeline to absolute truth, but a research program subject to the world\u2019s contingencies and uncertainties. \u201cIn spite of incompleteness and uncomputability and even algorithmic randomness,\u201d he said, \u201cmathematicians don\u2019t want to give up absolute certainty. Why? Well, absolute certainty is like God.\u201d\n\nIn quantum physics and later in chaos, scientists found the limits to their knowledge. They explored the fruitful uncertainty that at first so vexed Einstein, who did not want to believe that God plays dice with the universe. Algorithmic information theory applies the same limitations to the universe of whole numbers\u2014an ideal, mental universe. As Chaitin put it, \u201cGod not only plays dice in quantum mechanics and nonlinear dynamics, but even in elementary number theory.\u201d\n\nAmong its lessons were these:\n\n- Most numbers are random. Yet very few of them can be proved random.\n- A chaotic stream of information may yet hide a simple algorithm. Working backward from the chaos to the algorithm may be impossible.\n- Kolmogorov-Chaitin (KC) complexity is to mathematics what entropy is to thermodynamics: the antidote to perfection. Just as we can have no perpetual-motion machines, there can be no complete formal axiomatic systems.\n- Some mathematical facts are true for no reason. They are accidental, lacking a cause or deeper meaning.\nJoseph Ford, a physicist studying the behavior of unpredictable dynamical systems in the 1980s, said that Chaitin had \u201ccharmingly captured the essence of the matter\u201d by showing the path from G\u00f6del\u2019s incompleteness to chaos. This was the \u201cdeeper meaning of chaos,\u201d Ford declared:\n\nChaotic orbits exist but they are G\u00f6del\u2019s children, so complex, so overladen with information that humans can never comprehend them. But chaos is ubiquitous in nature; therefore the universe is filled with countless mysteries that man can never understand.\n\nYet one still tries to take their measure.\n\nHow much information \u2026?\n\nWhen an object (a number or a bitstream or a dynamical system) can be expressed a different way in fewer bits, it is compressible. A frugal telegraph operator prefers to send the compressed version. Because the spirit of frugal telegraph operators kept the lights on at Bell Labs, it was natural for Claude Shannon to explore data compression, both theory and practice. Compression was fundamental to his vision: his war work on cryptography analyzed the disguising of information at one end and the recovery of the information at the other; data compression likewise encodes the information, with a different motivation\u2014the efficient use of bandwidth. Satellite television channels, pocket music players, efficient cameras and telephones and countless other modern appurtenances depend on coding algorithms to compress numbers\u2014sequences of bits\u2014and those algorithms trace their lineage to Shannon\u2019s original 1948 paper.\n\nThe first of these, now called Shannon-Fano coding, came from his colleague Robert M. Fano. It began with the simple idea of assigning short codes to frequent symbols, as in Morse code. They knew their method was not optimal, however: it could not be relied on to produce the shortest possible messages. Within three years it was surpassed by work of a graduate student of Fano\u2019s at MIT, David Huffman. In the decades since, versions of the Huffman coding algorithm have squeezed many, many bytes.\n\nRay Solomonoff, a child of Russian immigrants who studied at the University of Chicago, encountered Shannon\u2019s work in the early 1950s and began thinking about what he called the Information Packing Problem: how much information could one \u201cpack\u201d into a given number of bits, or conversely, given some information, how could one pack it into the fewest possible bits. He had majored in physics, studied mathematical biology and probability and logic on the side, and gotten to know Marvin Minsky and John McCarthy, pioneers in what would soon be called artificial intelligence. Then he read Noam Chomsky\u2019s offbeat and original paper \u201cThree Models for the Description of Language,\u201d applying the new information-theoretic ideas to the formalization of structure in language. All this\nwas bouncing around in Solomonoff\u2019s mind; he was not sure where it led, but he found himself focusing on the problem of *induction*. How do people create theories to account for their experience of the world? They have to make generalizations, find patterns in data that are always influenced by randomness and noise. Could one enable a machine to do that? In other words, could a computer be made to learn from experience?\n\nHe worked out an elaborate answer and published it in 1964. It was idiosyncratic, and hardly anyone noticed until the 1970s, when both Chaitin and Kolmogorov discovered that Solomonoff had anticipated the essential features of what by then was called algorithmic information theory. In effect, Solomonoff, too, had been figuring out how a computer might look at sequences of data\u2014number sequences or bit strings\u2014and measure their randomness and their hidden patterns. When humans or computers learn from experience, they are using induction: recognizing regularities amid irregular streams of information. From this point of view, the laws of science represent data compression in action. A theoretical physicist acts like a very clever coding algorithm. \u201cThe laws of science that have been discovered can be viewed as summaries of large amounts of empirical data about the universe,\u201d wrote Solomonoff. \u201cIn the present context, each such law can be transformed into a method of compactly coding the empirical data that gave rise to that law.\u201d A good scientific theory is economical. This was yet another way of saying so.\n\nSolomonoff, Kolmogorov, and Chaitin tackled three different problems and came up with the same answer. Solomonoff was interested in inductive inference: given a sequence of observations, how can one make the best predictions about what will come next? Kolmogorov was looking for a mathematical definition of randomness: what does it mean to say that one sequence is more random than another, when they have the same probability of emerging from a series of coin flips? And Chaitin was trying to find a deep path into G\u00f6del incompleteness by way of Turing and Shannon\u2014as he said later, \u201cputting Shannon\u2019s information theory and Turing\u2019s computability theory into a cocktail shaker and shaking vigorously.\u201d They all arrived at minimal program size. And they all ended up talking about complexity.\n\nThe following bitstream (or number) is not very complex, because it is rational:\n\n\\[ D: 14285714285714285714285714285714285714285714285714285714285714... \\]\n\nIt may be rephrased concisely as \u201cPRINT 142857 AND REPEAT,\u201d or even more concisely as \u201c1/7.\u201d If it is a message, the compression saves keystrokes. If it is an incoming stream of data, the observer may recognize a pattern, grow more and more confident, and settle on *one-seventh* as a theory for the data.\n\nIn contrast, this sequence contains a late surprise:\nThe telegraph operator (or theorist, or compression algorithm) must pay attention to the whole message. Nonetheless, the extra information is minimal; the message can still be compressed, wherever pattern exists. We may say it contains a redundant part and an arbitrary part.\n\nIt was Shannon who first showed that anything nonrandom in a message allows compression:\n\n\\[ F: 10110101111011010111010111101001110100111101110 \\]\n\nHeavy on ones, light on zeroes, this might be emitted by the flip of a biased coin. Huffman coding and other such algorithms exploit statistical regularities to compress the data. Photographs are compressible because of their subjects\u2019 natural structure: light pixels and dark pixels come in clusters; statistically, nearby pixels are likely to be similar; distant pixels are not. Video is even more compressible, because the differences between one frame and the next are relatively slight, except when the subject is in fast and turbulent motion. Natural language is compressible because of redundancies and regularities of the kind Shannon analyzed. Only a wholly random sequence remains incompressible: nothing but one surprise after another.\n\nRandom sequences are \u201cnormal\u201d\u2014a term of art meaning that on average, in the long run, each digit appears exactly as often as the others, one time in ten; and each pair of digits, from 00 to 99, appears one time in a hundred; and each triplet likewise, and so on. No string of any particular length is more likely to appear than any other string of that length. Normality is one of those simple-seeming ideas that, when mathematicians look closely, turn out to be covered with thorns. Even though a truly random sequence must be normal, the reverse is not necessarily the case. A number can be statistically normal yet not random at all. David Champernowne, a young Cambridge friend of Turing\u2019s, invented (or discovered) such a creature in 1933\u2014a construction made of all the integers, chained together in order:\n\n\\[ G: 12345678910111213141516171819202122232425262728293\u2026 \\]\n\nIt is easy to see that each digit, and each combination of digits, occurs equally often in the long run. Yet the sequence could not be less random. It is rigidly structured and completely predictable. If you know where you are, you know what comes next.\n\nEven apart from freaks like Champernowne\u2019s, it turns out that normal numbers are difficult to recognize. In the universe of numbers, normality is the rule; mathematicians know for sure that almost all numbers are normal. The rational numbers are not normal, and there are infinitely many rational numbers, but they\nare infinitely outnumbered by normal numbers. Yet, having settled the great and general question, mathematicians can almost never prove that any particular number is normal. This in itself is one of the more remarkable oddities of mathematics.\n\nEven $\\pi$ retains some mysteries:\n\n$$C: 3.1415926535897932384626433832795028841971693993751...$$\n\nThe world\u2019s computers have spent many cycles analyzing the first trillion or so known decimal digits of this cosmic message, and as far as anyone can tell, they appear normal. No statistical features have been discovered\u2014no biases or correlations, local or remote. It is a quintessentially nonrandom number that seems to behave randomly. Given the $n$th digit, there is no shortcut for guessing the $n$th plus one. Once again, the next bit is always a surprise.\n\nHow much information, then, is represented by this string of digits? Is it information rich, like a random number? Or information poor, like an ordered sequence?\n\nThe telegraph operator could, of course, save many keystrokes\u2014infinately many, in the long run\u2014by simply sending the message \u201c$\\pi$.\u201d But this is a cheat. It presumes knowledge previously shared by the sender and the receiver. The sender has to recognize this special sequence to begin with, and then the receiver has to know what $\\pi$ is, and how to look up its decimal expansion, or else how to compute it. In effect, they need to share a code book.\n\nThis does not mean, however, that $\\pi$ contains a lot of information. The essential message can be sent in fewer keystrokes. The telegraph operator has several strategies available. For example, he could say, \u201cTake 4, subtract 4/3, add 4/5, subtract 4/7, and so on.\u201d The telegraph operator sends an algorithm, that is. This infinite series of fractions converges slowly upon $\\pi$, so the recipient has a lot of work to do, but the message itself is economical: the total information content is the same no matter how many decimal digits are required.\n\nThe issue of shared knowledge at the far ends of the line brings complications. Sometimes people like to frame this sort of problem\u2014the problem of information content in messages\u2014in terms of communicating with an alien life-form in a faraway galaxy. What could we tell them? What would we want to say? The laws of mathematics being universal, we tend to think that $\\pi$ would be one message any intelligent race would recognize. Only, they could hardly be expected to know the Greek letter. Nor would they be likely to recognize the decimal digits \u201c3.1415926535\u2026\u201d unless they happened to have ten fingers.\n\nThe sender of a message can never fully know his recipient\u2019s mental code book. Two lights in a window might mean nothing or might mean \u201cThe British come by sea.\u201d Every poem is a message, different for every reader. There is a way to make\nthe fuzziness of this line of thinking go away. Chaitin expressed it this way:\n\nIt is preferable to consider communication not with a distant friend but with a digital computer. The friend might have the wit to make inferences about numbers or to construct a series from partial information or from vague instructions. The computer does not have that capacity, and for our purposes that deficiency is an advantage. Instructions given the computer must be complete and explicit, and they must enable it to proceed step by step.\n\nIn other words: the message is an algorithm. The recipient is a machine; it has no creativity, no uncertainty, and no knowledge, except whatever \u201cknowledge\u201d is inherent in the machine\u2019s structure. By the 1960s, digital computers were already getting their instructions in a form measured in bits, so it was natural to think about how much information was contained in any algorithm.\n\nA different sort of message would be this:\n\nEven to the eye this sequence of notes seems nonrandom. It happens that the message they represent is already making its way through interstellar space, 10 billion miles from its origin, at a tiny fraction of light speed. The message is not encoded in this print-based notation, nor in any digital form, but as microscopic waves in a single long groove winding in a spiral engraved on a disc twelve inches in diameter and one-fiftieth of an inch in thickness. The disc might have been vinyl, but in this case it was copper, plated with gold. This analog means of capturing, preserving, and reproducing sound was invented in 1877 by Thomas Edison, who called it phonography. It remained the most popular audio technology a hundred years later\u2014though not for much longer\u2014and in 1977 a committee led by the astronomer Carl Sagan created a particular phonograph record and stowed copies in a pair of spacecraft named *Voyager 1* and *Voyager 2*, each the size of a small automobile, launched that summer from Cape Canaveral, Florida.\n\nSo it is a message in an interstellar bottle. The message has no meaning, apart from its patterns, which is to say that it is abstract art: the first prelude of Johann Sebastian Bach\u2019s *Well-Tempered Clavier*, as played on the piano by Glenn Gould. More generally, perhaps the meaning is \u201cThere is intelligent life here.\u201d Besides the Bach prelude, the record includes music samples from several different\ncultures and a selection of earthly sounds: wind, surf, and thunder; spoken greetings in fifty-five languages; the voices of crickets, frogs, and whales; a ship\u2019s horn, the clatter of a horse-drawn cart, and a tapping in Morse code. Along with the phonograph record are a cartridge and needle and a brief pictographic instruction manual. The committee did not bother with a phonograph player or a source of electrical power. Maybe the aliens will find a way to convert those analog metallic grooves into waves in whatever fluid serves as their atmosphere\u2014or into some other suitable input for their alien senses.\n\nTHE \u201cGOLDEN RECORD\u201d STOWED ABOARD THE VOYAGER SPACECRAFT\n\n(Illustration credit 12.1)\n\nWould they recognize the intricate patterned structure of the Bach prelude (say), as distinct from the less interesting, more random chatter of crickets? Would the sheet music convey a clearer message\u2014the written notes containing, after all, the essence of Bach\u2019s creation? And, more generally, what kind of knowledge would be needed at the far end of the line\u2014what kind of code book\u2014to decipher the message? An appreciation of counterpoint and voice leading? A sense of the tonal context and performance practices of the European Baroque? The sounds\u2014the notes\u2014come in groups; they form shapes, called melodies; they obey the rules of an implicit grammar. Does the music carry its own logic with it, independent of geography and history? On earth, meanwhile, within a few years, even before the Voyagers had sailed past the solar system\u2019s edge, music was seldom recorded in analog form anymore. Better to store the sounds of the Well-Tempered Clavier as bits: the waveforms discretized without loss as per the Shannon sampling theorem, and the information preserved in dozens of plausible media.\n\nIn terms of bits, a Bach prelude might not seem to have much information at all. As penned by Bach on two manuscript pages, this one amounts to six hundred\nnotes, characters in a small alphabet. As Glenn Gould played it on a piano in 1964\u2014adding the performer\u2019s layers of nuance and variation to the bare instructions\u2014it lasts a minute and thirty-six seconds. The sound of that performance, recorded onto a CD, microscopic pits burned by a laser onto a slim disc of polycarbonate plastic, comprises 135 million bits. But this bitstream can be compressed considerably with no loss of information. Alternatively, the prelude fits on a small player-piano roll (descendant of Jacquard\u2019s loom, predecessor of punched-card computing); encoded electronically with the MIDI protocol, it uses a few thousands bits. Even the basic six-hundred-character message has tremendous redundancy: unvarying tempo, uniform timbre, just a brief melodic pattern, a word, repeated over and over with slight variations till the final bars. It is famously, deceptively simple. The very repetition creates expectations and breaks them. Hardly anything happens, and everything is a surprise. \u201cImmortal broken chords of radiantly white harmonies,\u201d said Wanda Landowska. It is simple the way a Rembrandt drawing is simple. It does a lot with a little. Is it then rich in information? Certain music could be considered information poor. At one extreme John Cage\u2019s composition titled 4\u201933\u201d contains no \u201cnotes\u201d at all: just four minutes and thirty-three seconds of near silence, as the piece absorbs the ambient sounds around the still pianist\u2014the listeners\u2019 shifting in their seats, rustling clothes, breathing, sighing.\n\nHow much information in the Bach C-major Prelude? As a set of patterns, in time and frequency, it can be analyzed, traced, and understood, but only up to a point. In music, as in poetry, as in any art, perfect understanding is meant to remain elusive. If one could find the bottom it would be a bore.\n\nIn a way, then, the use of minimal program size to define complexity seems perfect\u2014a fitting apogee for Shannon information theory. In another way it remains deeply unsatisfying. This is particularly so when turning to the big\nquestions\u2014one might say, the human questions\u2014of art, of biology, of intelligence.\n\nAccording to this measure, a million zeroes and a million coin tosses lie at opposite ends of the spectrum. The empty string is as simple as can be; the random string is maximally complex. The zeroes convey no information; coin tosses produce the most information possible. Yet these extremes have something in common. They are dull. They have no value. If either one were a message from another galaxy, we would attribute no intelligence to the sender. If they were music, they would be equally worthless.\n\nEverything we care about lies somewhere in the middle, where pattern and randomness interlace.\n\nChaitin and a colleague, Charles H. Bennett, sometimes discussed these matters at IBM\u2019s research center in Yorktown Heights, New York. Over a period of years, Bennett developed a new measure of value, which he called \u201clogical depth.\u201d Bennett\u2019s idea of depth is connected to complexity but orthogonal to it. It is meant to capture the usefulness of a message, whatever usefulness might mean in any particular domain. \u201cFrom the earliest days of information theory it has been appreciated that information per se is not a good measure of message value,\u201d he wrote, finally publishing his scheme in 1988.\n\nA typical sequence of coin tosses has high information content but little value; an ephemeris, giving the positions of the moon and planets every day for a hundred years, has no more information than the equations of motion and initial conditions from which it was calculated, but saves its owner the effort of recalculating these positions.\n\nThe amount of work it takes to compute something had been mostly disregarded\u2014set aside\u2014in all the theorizing based on Turing machines, which work, after all, so ploddingly. Bennett brought it back. There is no logical depth in the parts of a message that are sheer randomness and unpredictability, nor is there logical depth in obvious redundancy\u2014plain repetition and copying. Rather, he proposed, the value of a message lies in \u201cwhat might be called its buried redundancy\u2014parts predictable only with difficulty, things the receiver could in principle have figured out without being told, but only at considerable cost in money, time, or computation.\u201d When we value an object\u2019s complexity, or its information content, we are sensing a lengthy hidden computation. This might be true of music or a poem or a scientific theory or a crossword puzzle, which gives its solver pleasure when it is neither too cryptic nor too shallow, but somewhere in between.\n\nMathematicians and logicians had developed a tendency to think of information processing as free\u2014not like pumping water or carrying stones. In our time, it certainly has gotten cheap. But it embodies work after all, and Bennett suggests that we recognize this work, reckon its expense in understanding\ncomplexity. \u201cThe more subtle something is, the harder it is to discover,\u201d Bennett says. He applied the idea of logical depth to the problem of self-organization: the question of how complex structures develop in nature. Evolution starts with simple initial conditions; complexity arises, apparently building on itself. Whatever the basic processes involved, physical or biological, something is under way that begins to resemble computation.\n\n* \u201cOur definition of the quantity of information has the advantage that it refers to individual objects and not to objects treated as members of a set of objects with a probability distribution given on it. The probabilistic definition can be convincingly applied to the information contained, for example, in a stream of congratulatory telegrams. But it would not be clear how to apply it, for example, to an estimate of the quantity of information contained in a novel or in the translation of a novel into another language relative to the original.\u201d\n\n* $1729 = 1^3 + 12^3 = 9^3 + 10^3$\n\n* More precisely, it looked like this: \u201cThe finite binary sequence S with the first proof that S cannot be described by a Turing machine with n states or less\u201d is a $(\\log_2 n+c_F)$\u2013state description of S.\nThe Information\n\n13 | INFORMATION IS PHYSICAL\n\n(It from Bit)\n\nThe more energy, the faster the bits flip. Earth, air, fire, and water in the end are all made of energy, but the different forms they take are determined by information. To do anything requires energy. To specify what is done requires information.\n\n\u2014Seth Lloyd (2006)\n\nQUANTUM MECHANICS HAS WEATHERED in its short history more crises, controversies, interpretations (the Copenhagen, the Bohm, the Many Worlds, the Many Minds), factional implosions, and general philosophical breast-beating than any other science. It is happily riddled with mysteries. It blithely disregards human intuition. Albert Einstein died unreconciled to its consequences, and Richard Feynman was not joking when he said no one understands it. Perhaps arguments about the nature of reality are to be expected; quantum physics, so uncannily successful in practice, deals in theory with the foundations of all things, and its own foundations are continually being rebuilt. Even so, the ferment sometimes seems more religious than scientific.\n\n\u201cHow did this come about?\u201d asks Christopher Fuchs, a quantum theorist at Bell Labs and then the Perimeter Institute in Canada.\n\nGo to any meeting, and it is like being in a holy city in great tumult. You will find all the religions with all their priests pitted in holy war\u2014the Bohmians, the Consistent Historians, the Transactionalists, the Spontaneous Collapseans, the Einselectionists, the Contextual Objectivists, the outright Everettics, and many more beyond that. They all declare to see the light, the ultimate light. Each tells us that if we will accept their solution as our savior, then we too will see the light.\n\nIt is time, he says, to start fresh. Throw away the existing quantum axioms, exquisite and mathematical as they are, and turn to deep physical principles. \u201cThose principles should be crisp; they should be compelling. They should stir the soul.\u201d And where should these physical principles be found? Fuchs answers his own question: in quantum information theory.\n\n\u201cThe reason is simple, and I think inescapable,\u201d he declares. \u201cQuantum mechanics has always been about information; it is just that the physics community has forgotten this.\u201d\n\nOne who did not forget\u2014or who rediscovered it\u2014was John Archibald Wheeler, pioneer of nuclear fission, student of Bohr and teacher of Feynman, namer of\nblack holes, the last giant of twentieth-century physics. Wheeler was given to epigrams and gnomic utterances. *A black hole has no hair* was his famous way of stating that nothing but mass, charge, and spin can be perceived from outside. \u201cIt teaches us,\u201d he wrote, \u201cthat space can be crumpled like a piece of paper into an infinitesimal dot, that time can be extinguished like a blown-out flame, and that the laws of physics that we regard as \u2018sacred,\u2019 as immutable, are anything but.\u201d In 1989 he offered his final catchphrase: *It from Bit*. His view was extreme. It was immaterialist: information first, everything else later. \u201cOtherwise put,\u201d he said, every it\u2014every particle, every field of force, even the space-time continuum itself\u2014derives its function, its meaning, its very existence \u2026 from *bits*.\n\nWhy does nature appear quantized? Because information is quantized. The bit is the ultimate unsplittable particle.\n\nAmong the physics phenomena that pushed information front and center, none were more spectacular than black holes. At first, of course, they had not seemed to involve information at all.\n\nBlack holes were the brainchild of Einstein, though he did not live to know about them. He established by 1915 that light must submit to the pull of gravity; that gravity curves the fabric of spacetime; and that a sufficient mass, compacted together, as in a dense star, would collapse utterly, intensifying its own gravity and contracting without limit. It took almost a half century more to face up to the consequences, because they are strange. Anything goes in, nothing comes out. At the center lies the singularity. Density becomes infinite; gravity becomes infinite; spacetime curves infinitely. Time and space are interchanged. Because no light,\nno signal of any kind, can escape the interior, such things are quintessentially invisible. Wheeler began calling them \u201cblack holes\u201d in 1967. Astronomers are sure they have found some, by gravitational inference, and no one can ever know what is inside.\n\nAt first astrophysicists focused on matter and energy falling in. Later they began to worry about the information. A problem arose when Stephen Hawking, adding quantum effects to the usual calculations of general relativity, argued in 1974 that black holes should, after all, radiate particles\u2014a consequence of quantum fluctuations near the event horizon. Black holes slowly evaporate, in other words. The problem was that Hawking radiation is featureless and dull. It is thermal radiation\u2014heat. But matter falling into the black hole carries information, in its very structure, its organization, its quantum states\u2014in terms of statistical mechanics, its accessible microstates. As long as the missing information stayed out of reach beyond the event horizon, physicists did not have to worry about it. They could say it was inaccessible but not obliterated. \u201cAll colours will agree in the dark,\u201d as Francis Bacon said in 1625.\n\nThe outbound Hawking radiation carries no information, however. If the black hole evaporates, where does the information go? According to quantum mechanics, information may never be destroyed. The deterministic laws of physics require the states of a physical system at one instant to determine the states at the next instant; in microscopic detail, the laws are reversible, and information must be preserved. Hawking was the first to state firmly\u2014even alarmingly\u2014that this was a problem challenging the very foundations of quantum mechanics. The loss of information would violate unitarity, the principle that probabilities must add up to one. \u201cGod not only plays dice, He sometimes throws the dice where they cannot be seen,\u201d Hawking said. In the summer of 1975, he submitted a paper to the Physical Review with a dramatic headline, \u201cThe Breakdown of Physics in Gravitational Collapse.\u201d The journal held it for more than a year before publishing it with a milder title.\n\nAs Hawking expected, other physicists objected vehemently. Among them was John Preskill at the California Institute of Technology, who continued to believe in the principle that information cannot be lost: even when a book goes up in flames, in physicists\u2019 terms, if you could track every photon and every fragment of ash, you should be able to integrate backward and reconstruct the book. \u201cInformation loss is highly infectious,\u201d warned Preskill at a Caltech Theory Seminar. \u201cIt is very hard to modify quantum theory so as to accommodate a little bit of information loss without it leaking into all processes.\u201d In 1997 he made a much-publicized wager with Hawking that the information must be escaping the black hole somehow. They bet an encyclopedia of the winner\u2019s choice. \u201cSome physicists feel the question of what happens in a black hole is academic or even\ntheological, like counting angels on pinheads,\u201d said Leonard Susskind of Stanford, siding with Preskill. \u201cBut it is not so at all: at stake are the future rules of physics.\u201d Over the next few years a cornucopia of solutions was proposed. Hawking himself said at one point: \u201cI think the information probably goes off into another universe. I have not been able to show it yet mathematically.\u201d\n\nIt was not until 2004 that Hawking, then sixty-two, reversed himself and conceded the bet. He announced that he had found a way to show that quantum gravity is unitary after all and that information is preserved. He applied a formalism of quantum indeterminacy\u2014the \u201csum over histories\u201d path integrals of Richard Feynman\u2014to the very topology of spacetime and declared, in effect, that black holes are never unambiguously black. \u201cThe confusion and paradox arose because people thought classically in terms of a single topology for space-time,\u201d he wrote.* His new formulation struck some physicists as cloudy and left many questions unanswered, but he was firm on one point. \u201cThere is no baby universe branching off, as I once thought,\u201d he wrote. \u201cThe information remains firmly in our universe. I\u2019m sorry to disappoint science fiction fans.\u201d He gave Preskill a copy of Total Baseball: The Ultimate Baseball Encyclopedia, weighing in at 2,688 pages\u2014\u201cfrom which information can be recovered with ease,\u201d he said. \u201cBut maybe I should have just given him the ashes.\u201d\n\nCharles Bennett came to quantum information theory by a very different route. Long before he developed his idea of logical depth, he was thinking about the \u201cthermodynamics of computation\u201d\u2014a peculiar topic, because information processing was mostly treated as disembodied. \u201cThe thermodynamics of computation, if anyone had stopped to wonder about it, would probably have seemed no more urgent as a topic of scientific inquiry than, say, the thermodynamics of love,\u201d says Bennett. It is like the energy of thought. Calories may be expended, but no one is counting.\n\nStranger still, Bennett tried investigating the thermodynamics of the least thermodynamic computer of all\u2014the nonexistent, abstract, idealized Turing machine. Turing himself never worried about his thought experiment consuming any energy or radiating any heat as it goes about its business of marching up and down imaginary paper tapes. Yet in the early 1980s Bennett was talking about using Turing-machine tapes for fuel, their caloric content to be measured in bits. Still a thought experiment, of course, meant to focus on a very real question: What is the physical cost of logical work? \u201cComputers,\u201d he wrote provocatively, \u201cmay be thought of as engines for transforming free energy into waste heat and mathematical work.\u201d Entropy surfaced again. A tape full of zeroes, or a tape encoding the works of Shakespeare, or a tape rehearsing the digits of $\\pi$, has \u201cfuel value.\u201d A random tape has none.\nBennett, the son of two music teachers, grew up in the Westchester suburbs of New York; he studied chemistry at Brandeis and then Harvard in the 1960s. James Watson was at Harvard then, teaching about the genetic code, and Bennett worked for him one year as a teaching assistant. He got his doctorate in molecular dynamics, doing computer simulations that ran overnight on a machine with a memory of about twenty thousand decimal digits and generated output on pages and pages of fan-fold paper. Looking for more computing power to continue his molecular-motion research, he went to the Lawrence Livermore Laboratory in Berkeley, California, and Argonne National Laboratory in Illinois, and then joined IBM Research in 1972.\n\nIBM did not manufacture Turing machines, of course. But at some point it dawned on Bennett that a special-purpose Turing machine had already been found in nature: namely RNA polymerase. He had learned about polymerase directly from Watson; it is the enzyme that crawls along a gene\u2014its \u201ctape\u201d\u2014transcribing the DNA. It steps left and right; its logical state changes according to the chemical information written in sequence; and its thermodynamic behavior can be measured.\n\nIn the real world of 1970s computing, hardware had rapidly grown thousands of times more energy-efficient than during the early vacuum-tube era. Nonetheless, electronic computers dissipate considerable energy in the form of waste heat. The closer they come to their theoretical minimum of energy use, the more urgently scientists want to know just what that theoretical minimum is. Von Neumann, working with his big computers, made a back-of-the-envelope calculation as early as 1949, proposing an amount of heat that must be dissipated \u201cper elementary act of information, that is per elementary decision of a two-way alternative and per elementary transmittal of one unit of information.\u201d He based it on the molecular work done in a model thermodynamic system by Maxwell\u2019s demon, as reimagined by Le\u00f3 Szil\u00e1rd.* Von Neumann said the price is paid by every elementary act of information processing, every choice between two alternatives. By the 1970s this was generally accepted. But it was wrong.\n\nVon Neumann\u2019s error was discovered by the scientist who became Bennett\u2019s mentor at IBM, Rolf Landauer, an exile from Nazi Germany. Landauer devoted his career to establishing the physical basis of information. \u201cInformation Is Physical\u201d was the title of one famous paper, meant to remind the community that computation requires physical objects and obeys the laws of physics. Lest anyone forget, he titled a later essay\u2014his last, it turned out\u2014\u201cInformation Is Inevitably Physical.\u201d Whether a bit is a mark on a stone tablet or a hole in a punched card or a particle with spin up or down, he insisted that it could not exist without some embodiment. Landauer tried in 1961 to prove von Neumann\u2019s formula for the cost of information processing and discovered that he could not. On the contrary,\nit seemed that most logical operations have no entropy cost at all. When a bit flips from zero to one, or vice-versa, the information is preserved. The process is reversible. Entropy is unchanged; no heat needs to be dissipated. Only an irreversible operation, he argued, increases entropy.\n\nLandauer and Bennett were a double act: a straight and narrow old IBM type and a scruffy hippie (in Bennett\u2019s view, anyway). The younger man pursued Landauer\u2019s principle by analyzing every kind of computer he could imagine, real and abstract, from Turing machines and messenger RNA to \u201cballistic\u201d computers, carrying signals via something like billiard balls. He confirmed that a great deal of computation can be done with no energy cost at all. In every case, Bennett found, heat dissipation occurs only when information is erased. Erasure is the irreversible logical operation. When the head on a Turing machine erases one square of the tape, or when an electronic computer clears a capacitor, a bit is lost, and then heat must be dissipated. In Szil\u00e1rd\u2019s thought experiment, the demon does not incur an entropy cost when it observes or chooses a molecule. The payback comes at the moment of clearing the record, when the demon erases one observation to make room for the next.\n\nForgetting takes work.\n\n\u201cYou might say this is the revenge of information theory on quantum mechanics,\u201d Bennett says. Sometimes a successful idea in one field can impede progress in another. In this case the successful idea was the uncertainty principle, which brought home the central role played by the measurement process itself. One can no longer talk simply about \u201clooking\u201d at a molecule; the observer needs to employ photons, and the photons must be more energetic than the thermal background, and complications ensue. In quantum mechanics the act of observation has consequences of its own, whether performed by a laboratory scientist or by Maxwell\u2019s demon. Nature is sensitive to our experiments.\n\n\u201cThe quantum theory of radiation helped people come to the incorrect conclusion that computing had an irreducible thermodynamic cost per step,\u201d Bennett says. \u201cIn the other case, the success of Shannon\u2019s theory of information processing led people to abstract away all of the physics from information processing and think of it as a totally mathematical thing.\u201d As communications engineers and chip designers came closer and closer to atomic levels, they worried increasingly about quantum limitations interfering with their clean, classical ability to distinguish zero and one states. But now they looked again\u2014and this, finally, is where quantum information science is born. Bennett and others began to think differently: that quantum effects, rather than being a nuisance, might be turned to advantage.\n\nWedged like a hope chest against a wall of his office at IBM\u2019s research\nlaboratory in the wooded hills of Westchester is a light-sealed device called Aunt Martha (short for Aunt Martha\u2019s coffin). Bennett and his research assistant John Smolin jury-rigged it in 1988 and 1989 with a little help from the machine shop: an aluminum box spray-painted dull black on the inside and further sealed with rubber stoppers and black velvet. With a helium-neon laser for alignment and high-voltage cells to polarize the photons, they sent the first message ever to be encoded by quantum cryptography. It was a demonstration of an information-processing task that could be effectively accomplished only via a quantum system. Quantum error correction, quantum teleportation, and quantum computers followed shortly behind.\n\nThe quantum message passed between Alice and Bob, a ubiquitous mythical pair. Alice and Bob got their start in cryptography, but the quantum people own them now. Occasionally they are joined by Charlie. They are constantly walking into different rooms and flipping quarters and sending each other sealed envelopes. They choose states and perform Pauli rotations. \u201cWe say things such as \u2018Alice sends Bob a qubit and forgets what she did,\u2019 \u2018Bob does a measurement and tells Alice,\u2019\u201d explains Barbara Terhal, a colleague of Bennett\u2019s and one of the next generation of quantum information theorists. Terhal herself has investigated whether Alice and Bob are monogamous\u2014another term of art, naturally.\n\nIn the Aunt Martha experiment, Alice sends information to Bob, encrypted so that it cannot be read by a malevolent third party (Eve the eavesdropper). If they both know their private key, Bob can decipher the message. But how is Alice to send Bob the key in the first place? Bennett and Gilles Brassard, a computer scientist in Montreal, began by encoding each bit of information as a single quantum object, such as a photon. The information resides in the photon\u2019s quantum states\u2014for example, its horizontal or vertical polarization. Whereas an object in classical physics, typically composed of billions of particles, can be intercepted, monitored, observed, and passed along, a quantum object cannot. Nor can it be copied or cloned. The act of observation inevitably disrupts the message. No matter how delicately eavesdroppers try to listen in, they can be detected. Following an intricate and complex protocol worked out by Bennett and Brassard, Alice generates a sequence of random bits to use as the key, and Bob is able to establish an identical sequence at his end of the line.\n\nThe first experiments with Aunt Martha\u2019s coffin managed to send quantum bits across thirty-two centimeters of free air. It was not Mr. Watson, come here, I want to see you, but it was a first in the history of cryptography: an absolutely unbreakable cryptographic key. Later experimenters moved on to optical fiber. Bennett, meanwhile, moved on to quantum teleportation.\n\nHe regretted that name soon enough, when the IBM marketing department featured his work in an advertisement with the line \u201cStand by: I\u2019ll teleport you\nsome goulash.\u201d But the name stuck, because teleportation worked. Alice does not send goulash; she sends qubits.*\n\nThe qubit is the smallest nontrivial quantum system. Like a classical bit, a qubit has two possible values, zero or one\u2014which is to say, two states that can be reliably distinguished. In a classical system, all states are distinguishable in principle. (If you cannot tell one color from another, you merely have an imperfect measuring device.) But in a quantum system, imperfect distinguishability is everywhere, thanks to Heisenberg\u2019s uncertainty principle. When you measure any property of a quantum object, you thereby lose the ability to measure a complementary property. You can discover a particle\u2019s momentum or its position but not both. Other complementary properties include directions of spin and, as in Aunt Martha\u2019s coffin, polarization. Physicists think of these quantum states in a geometrical way\u2014the states of a system corresponding to directions in space (a space of many possible dimensions), and their distinguishability depending on whether those directions are perpendicular (or \u201corthogonal\u201d).\n\nThis imperfect distinguishability is what gives quantum physics its dreamlike character: the inability to observe systems without disturbing them; the inability to clone quantum objects or broadcast them to many listeners. The qubit has this dreamlike character, too. It is not just either-or. Its 0 and 1 values are represented by quantum states that can be reliably distinguished\u2014for example, horizontal and vertical polarizations\u2014but coexisting with these are the whole continuum of intermediate states, such as diagonal polarizations, that lean toward 0 or 1 with different probabilities. So a physicist says that a qubit is a superposition of states; a combination of probability amplitudes. It is a determinate thing with a cloud of indeterminacy living inside. But the qubit is not a muddle; a superposition is not a hodgepodge but a combining of probabilistic elements according to clear and elegant mathematical rules.\n\n\u201cA nonrandom whole can have random parts,\u201d says Bennett. \u201cThis is the most counterintuitive part of quantum mechanics, yet it follows from the superposition principle and is the way nature works, as far as we know. People may not like it at first, but after a while you get used to it, and the alternatives are far worse.\u201d\n\nThe key to teleportation and to so much of the quantum information science that followed is the phenomenon known as entanglement. Entanglement takes the superposition principle and extends it across space, to a pair of qubits far apart from each other. They have a definite state as a pair even while neither has a measurable state on its own. Before entanglement could be discovered, it had to be invented, in this case by Einstein. Then it had to be named, not by Einstein but by Schr\u00f6dinger. Einstein invented it for a thought experiment designed to illuminate what he considered flaws in quantum mechanics as it stood in 1935.\nHe publicized it in a famous paper with Boris Podolsky and Nathan Rosen titled \u201cCan Quantum-Mechanical Description of Physical Reality Be Considered Complete?\u201d It was famous in part for provoking Wolfgang Pauli to write to Werner Heisenberg, \u201cEinstein has once again expressed himself publicly on quantum mechanics\u2026. As is well known, this is a catastrophe every time it happens.\u201d The thought experiment imagined a pair of particles correlated in a special way, as when, for example, a pair of photons are emitted by a single atom. Their polarization is random but identical\u2014now and as long as they last.\n\nEinstein, Podolsky, and Rosen investigated what would happen when the photons are far apart and a measurement is performed on one of them. In the case of entangled particles\u2014the pair of photons, created together and now light-years apart\u2014it seems that the measurement performed on one has an effect on the other. The instant Alice measures the vertical polarization of her photon, Bob\u2019s photon will also have a definite polarization state on that axis, whereas its diagonal polarization will be indefinite. The measurement thus creates an influence apparently traveling faster than light. It seemed a paradox, and Einstein abhorred it. \u201cThat which really exists in B should not depend on what kind of measurement is carried out in space A,\u201d he wrote. The paper concluded sternly, \u201cNo reasonable definition of reality could be expected to permit this.\u201d He gave it the indelible name *spukhafte Fernwirkung*, \u201cspooky action at a distance.\u201d\n\nIn 2003 the Israeli physicist Asher Peres proposed one answer to the Einstein-Podolsky-Rosen (EPR) puzzle. The paper was not exactly wrong, he said, but it had been written too soon: before Shannon published his theory of information, \u201cand it took many more years before the latter was included in the physicist\u2019s toolbox.\u201d Information is physical. It is no use talking about quantum states\nwithout considering the *information* about the quantum states.\n\nInformation is not just an abstract notion. It requires a physical carrier, and the latter is (approximately) localized. After all, it was the business of the Bell Telephone Company to transport information from one telephone to another telephone, in a different location.\n\n... When Alice measures her spin, the information she gets is localized at her position, and will remain so until she decides to broadcast it. Absolutely nothing happens at Bob\u2019s location.... It is only if and when Alice informs Bob of the result she got (by mail, telephone, radio, or by means of any other material carrier, which is naturally restricted to the speed of light) that Bob realizes that his particle has a definite pure state.\n\nFor that matter, Christopher Fuchs argues that it is no use talking about quantum states at all. The quantum state is a construct of the observer\u2014from which many troubles spring. Exit states; enter information. \u201cTerminology can say it all: A practitioner in this field, whether she has ever thought an ounce about quantum foundations, is just as likely to say \u2018quantum information\u2019 as \u2018quantum state\u2019...\u2018What does the quantum teleportation protocol do?\u2019 A now completely standard answer would be: \u2018It transfers quantum information from Alice\u2019s site to Bob\u2019s.\u2019 What we have here is a change of mind-set.\u201d\n\nThe puzzle of spooky action at a distance has not been altogether resolved. *Nonlocality* has been demonstrated in a variety of clever experiments all descended from the EPR thought experiment. Entanglement turns out to be not only real but ubiquitous. The atom pair in every hydrogen molecule, H$_2$, is quantumly entangled (\u201cverschr\u00e4nkt,\u201d as Schr\u00f6dinger said). Bennett put entanglement to work in quantum teleportation, presented publicly for the first time in 1993. Teleportation uses an entangled pair to project quantum information from a third particle across an arbitrary distance. Alice cannot measure this third particle directly; rather, she measures something about its relation to one of the entangled particles. Even though Alice herself remains ignorant about the original, because of the uncertainty principle, Bob is able to receive an exact replica. Alice\u2019s object is disembodied in the process. Communication is not faster than light, because Alice must also send Bob a classical (nonquantum) message on the side. \u201cThe net result of teleportation is completely prosaic: the removal of [the quantum object] from Alice\u2019s hands and its appearance in Bob\u2019s hands a suitable time later,\u201d wrote Bennett and his colleagues. \u201cThe only remarkable feature is that in the interim, the information has been cleanly separated into classical and nonclassical parts.\u201d\n\nResearchers quickly imagined many applications, such as transfer of volatile information into secure storage, or memory. With or without goulash, teleportation created excitement, because it opened up new possibilities for the very real but still elusive dream of quantum computing.\nThe idea of a quantum computer is strange. Richard Feynman chose the strangeness as his starting point in 1981, speaking at MIT, when he first explored the possibility of using a quantum system to compute hard quantum problems. He began with a supposedly naughty digression\u2014\u201cSecret! Secret! Close the doors \u2026\u201d\n\nWe have always had a great deal of difficulty in understanding the world view that quantum mechanics represents. At least I do, because I\u2019m an old enough man [he was sixty-two] that I haven\u2019t got to the point that this stuff is obvious to me. Okay, I still get nervous with it\u2026. It has not yet become obvious to me that there is no real problem. I cannot define the real problem, therefore I suspect there\u2019s no real problem, but I\u2019m not sure there\u2019s no real problem.\n\nHe knew very well what the problem was for computation\u2014for simulating quantum physics with a computer. The problem was probability. Every quantum variable involved probabilities, and that made the difficulty of computation grow exponentially. \u201cThe number of information bits is the same as the number of points in space, and therefore you\u2019d have to have something like $N^N$ configurations to be described to get the probability out, and that\u2019s too big for our computer to hold\u2026. It is therefore impossible, according to the rules stated, to simulate by calculating the probability.\u201d\n\nSo he proposed fighting fire with fire. \u201cThe other way to simulate a probabilistic Nature, which I\u2019ll call $N$ for the moment, might still be to simulate the probabilistic Nature by a computer $C$ which itself is probabilistic.\u201d A quantum computer would not be a Turing machine, he said. It would be something altogether new.\n\n\u201cFeynman\u2019s insight,\u201d says Bennett, \u201cwas that a quantum system is, in a sense, computing its own future all the time. You may say it\u2019s an analog computer of its own dynamics.\u201d Researchers quickly realized that if a quantum computer had special powers in cutting through problems in simulating physics, it might be able to solve other types of intractable problems as well.\n\nThe power comes from that shimmering, untouchable object the qubit. The probabilities are built in. Embodying a superposition of states gives the qubit more power than the classical bit, always in only one state or the other, zero or one, \u201ca pretty miserable specimen of a two-dimensional vector,\u201d as David Mermin says. \u201cWhen we learned to count on our sticky little classical fingers, we were misled,\u201d Rolf Landauer said dryly. \u201cWe thought that an integer had to have a particular and unique value.\u201d But no\u2014not in the real world, which is to say the quantum world.\n\nIn quantum computing, multiple qubits are entangled. Putting qubits at work together does not merely multiply their power; the power increases exponentially. In classical computing, where a bit is either-or, $n$ bits can encode any one of $2^n$\nvalues. Qubits can encode these Boolean values along with all their possible superpositions. This gives a quantum computer a potential for parallel processing that has no classical equivalent. So quantum computers\u2014in theory\u2014can solve certain classes of problems that had otherwise been considered computationally infeasible.\n\nAn example is finding the prime factors of very large numbers. This happens to be the key to cracking the most widespread cryptographic algorithms in use today, particularly RSA encryption. The world\u2019s Internet commerce depends on it. In effect, the very large number is a public key used to encrypt a message; if eavesdroppers can figure out its prime factors (also large), they can decipher the message. But whereas multiplying a pair of large prime numbers is easy, the inverse is exceedingly difficult. The procedure is an informational one-way street. So factoring RSA numbers has been an ongoing challenge for classical computing. In December 2009 a team distributed in Lausanne, Amsterdam, Tokyo, Paris, Bonn, and Redmond, Washington, used many hundreds of machines working almost two years to discover that\n\n12301866845301177551304949583849627207728535695953347921973224521\n51726400507263657518745202199786469389956474942774063845925192557\n32630345373154826850791702612214291346167042921431160222124047927\n4737794080665351419597459856902143413 is the product of\n33478071698956898786044169848212690817704794983713768568912431388\n982883793878002287614711652531743087737814467999489 and\n36746043666799590428244633799627952632279158164343087642676032283\n815739666511279233373417143396810270092798736308917. They estimated that the computation used more than $10^{20}$ operations.\n\nThis was one of the smaller RSA numbers, but, had the solution come earlier, the team could have won a $50,000 prize offered by RSA Laboratories. As far as classical computing is concerned, such encryption is considered quite secure. Larger numbers take exponentially longer time, and at some point the time exceeds the age of the universe.\n\nQuantum computing is another matter. The ability of a quantum computer to occupy many states at once opens new vistas. In 1994, before anyone knew how actually to build any sort of quantum computer, a mathematician at Bell Labs figured out how to program one to solve the factoring problem. He was Peter Shor, a problem-solving prodigy who made an early mark in math olympiads and prize competitions. His ingenious algorithm, which broke the field wide open, is known by him simply as the factoring algorithm, and by everyone else as Shor\u2019s algorithm. Two years later Lov Grover, also at Bell Labs, came up with a quantum algorithm for searching a vast unsorted database. That is the canonical hard problem for a world of limitless information\u2014needles and haystacks.\n\u201cQuantum computers were basically a revolution,\u201d Dorit Aharonov of Hebrew University told an audience in 2009. \u201cThe revolution was launched into the air by Shor\u2019s algorithm. But the reason for the revolution\u2014other than the amazing practical implications\u2014is that they redefine what is an easy and what is a hard problem.\u201d\n\nWhat gives quantum computers their power also makes them exceedingly difficult to work with. Extracting information from a system means observing it, and observing a system means interfering with the quantum magic. Qubits cannot be watched as they do their exponentially many operations in parallel; measuring that shadow-mesh of possibilities reduces it to a classical bit. Quantum information is fragile. The only way to learn the result of a computation is to wait until after the quantum work is done.\n\nQuantum information is like a dream\u2014evanescent, never quite existing as firmly as a word on a printed page. \u201cMany people can read a book and get the same message,\u201d Bennett says, \u201cbut trying to tell people about your dream changes your memory of it, so that eventually you forget the dream and remember only what you said about it.\u201d Quantum erasure, in turn, amounts to a true undoing: \u201cOne can fairly say that even God has forgotten.\u201d\n\nAs for Shannon himself, he was unable to witness this flowering of the seeds he had planted. \u201cIf Shannon were around now, I would say he would be very enthusiastic about the entanglement-assisted capacity of a channel,\u201d says Bennett. \u201cThe same form, a generalization of Shannon\u2019s formula, covers both classic and quantum channels in a very elegant way. So it\u2019s pretty well established that the quantum generalization of classical information has led to a cleaner and more powerful theory, both of computing and communication.\u201d Shannon lived till 2001, his last years dimmed and isolated by the disease of erasure, Alzheimer\u2019s. His life had spanned the twentieth century and helped to define it. As much as any one person, he was the progenitor of the information age. Cyberspace is in part his creation; he never knew it, though he told his last interviewer, in 1987, that he was investigating the idea of mirrored rooms: \u201cto work out all the possible mirrored rooms that make sense, in that if you looked everywhere from inside one, space would be divided into a bunch of rooms, and you would be in each room and this would go on to infinity without contradiction.\u201d He hoped to build a gallery of mirrors in his house near MIT, but he never did.\n\nIt was John Wheeler who left behind an agenda for quantum information science\u2014a modest to-do list for the next generation of physicists and computer scientists together:\n\n\u201cTranslate the quantum versions of string theory and of Einstein\u2019s geometrodynamics from the language of continuum to the language of bit,\u201d he\nexhorted his heirs.\n\n\u201cSurvey one by one with an imaginative eye the powerful tools that mathematics\u2014including mathematical logic\u2014has won \u2026 and for each such technique work out the transcription into the world of bits.\u201d\n\nAnd, \u201cFrom the wheels-upon-wheels-upon-wheels evolution of computer programming dig out, systematize and display every feature that illuminates the level-upon-level-upon-level structure of physics.\u201d\n\nAnd, \u201cFinally. Deplore? No, celebrate the absence of a clean clear definition of the term \u2018bit\u2019 as elementary unit in the establishment of meaning\u2026. If and when we learn how to combine bits in fantastically large numbers to obtain what we call existence, we will know better what we mean both by bit and by existence.\u201d\n\nThis is the challenge that remains, and not just for scientists: the establishment of meaning.\n\n* \u201cIt was either R\u2074 or a black hole. But the Feynman sum over histories allows it to be both at once.\u201d\n\n* Von Neumann\u2019s formula for the theoretical energy cost of every logical operation was $kT\\ln 2$ joules per bit, where $T$ is the computer\u2019s operating temperature and $k$ is the Boltzman constant. Szil\u00e1rd had proved that the demon in his engine can get $kT\\ln 2$ of work out of every molecule it selects, so that energy cost must be paid somewhere in the cycle.\n\n* This word is not universally accepted, though the OED recognized it as of December 2007. David Mermin wrote that same year: \u201cUnfortunately the preposterous spelling qubit currently holds sway\u2026. Although \u201cqubit\u201d honors the English (German, Italian,\u2026) rule that q should be followed by u, it ignores the equally powerful requirement that qu should be followed by a vowel. My guess is that \u201cqubit\u201d has gained acceptance because it visually resembles an obsolete English unit of distance, the homonymic cubit. To see its ungainliness with fresh eyes, it suffices to imagine \u2026 that one erased transparencies and cleaned ones ears with Qutips.\u201d\nSuppose within every book there is another book, and within every letter on every page another volume constantly unfolding; but these volumes take no space on the desk. Suppose knowledge could be reduced to a quintessence, held within a picture, a sign, held within a place which is no place.\n\n\u2014Hilary Mantel (2009)\n\n\u201cTHE UNIVERSE (which others call the Library)\u2026\u201d\n\nThus Jorge Luis Borges began his 1941 story \u201cThe Library of Babel,\u201d about the mythical library that contains all books, in all languages, books of apology and prophecy, the gospel and the commentary upon that gospel and the commentary upon the commentary upon the gospel, the minutely detailed history of the future, the interpolations of all books in all other books, the faithful catalogue of the library and the innumerable false catalogues. This library (which others call the universe) enshrines all the information. Yet no knowledge can be discovered there, precisely because all knowledge is there, shelved side by side with all falsehood. In the mirrored galleries, on the countless shelves, can be found everything and nothing. There can be no more perfect case of information glut.\n\nWe make our own storehouses. The persistence of information, the difficulty of forgetting, so characteristic of our time, accretes confusion. As the free, amateur, collaborative online encyclopedia called Wikipedia began to overtake all the world\u2019s printed encyclopedias in volume and comprehensiveness, the editors realized that too many names had multiple identities. They worked out a disambiguation policy, which led to the creation of disambiguation pages\u2014a hundred thousand and more. For example, a user foraging in Wikipedia\u2019s labyrinthine galleries for \u201cBabel\u201d finds \u201cBabel (disambiguation),\u201d which leads in turn to the Hebrew name for ancient Babylon, to the Tower of Babel, to an Iraqi newspaper, a book by Patti Smith, a Soviet journalist, an Australian language teachers\u2019 journal, a film, a record label, an island in Australia, two different mountains in Canada, and \u201ca neutrally aligned planet in the fictional Star Trek universe.\u201d And more. The paths of disambiguation fork again and again. For example, \u201cTower of Babel (disambiguation)\u201d lists, besides the story in the Old Testament, songs, games, books, a Brueghel painting, an Escher woodcut, and \u201cthe tarot card.\u201d We have made many towers of Babel.\nLong before Wikipedia, Borges also wrote about the encyclopedia \u201cfallaciously called *The Anglo-American Cyclopedia* (New York, 1917),\u201d a warren of fiction mingling with fact, another hall of mirrors and misprints, a compendium of pure and impure information that projects its own world. That world is called Tl\u00f6n. \u201cIt is conjectured that this brave new world is the work of a secret society of astronomers, biologists, engineers, metaphysicians, poets, chemists, algebraists, moralists, painters, geometers\u2026.\u201d writes Borges. \u201cThis plan is so vast that each writer\u2019s contribution is infinitesimal. At first it was believed that Tl\u00f6n was a mere chaos, an irresponsible license of the imagination; now it is known that it is a cosmos.\u201d With good reason, the Argentine master has been taken up as a prophet (\u201cour heresiarch uncle,\u201d William Gibson says) by another generation of writers in the age of information.\n\nLong before Borges, the imagination of Charles Babbage had conjured another library of Babel. He found it in the very air: a record, scrambled yet permanent, of every human utterance.\n\nWhat a strange chaos is this wide atmosphere we breathe!... The air itself is one vast library, on whose pages are for ever written all that man has ever said or woman whispered. There, in their mutable but unerring characters, mixed with the earliest, as well as the latest sighs of mortality, stand for ever recorded, vows unredeemed, promises unfulfilled, perpetuating in the united movements of each particle, the testimony of man\u2019s changeful will.\n\nEdgar Allan Poe, following Babbage\u2019s work eagerly, saw the point. \u201cNo thought can perish,\u201d he wrote in 1845, in a dialogue between two angels. \u201cDid there not cross your mind some thought of the *physical power of words*? Is not every word an impulse on the air?\u201d Further, every impulse vibrates outward indefinitely, \u201cupward and onward in their influences upon all particles of all matter,\u201d until it must, \u201c*in the end,* impress every individual thing that exists *within the universe.*\u201d Poe was also reading Newton\u2019s champion Pierre-Simon Laplace. \u201cA being of infinite understanding,\u201d wrote Poe, \u201c\u2014one to whom the *perfection* of the algebraic analysis lay unfolded\u201d could trace the undulations backward to their source.\n\nBabbage and Poe took an information-theoretic view of the new physics. Laplace had expounded a perfect Newtonian mechanical determinism; he went further than Newton himself, arguing for a clockwork universe in which nothing is left to chance. Since the laws of physics apply equally to the heavenly bodies and the tiniest particles, and since they operate with perfect reliability, then surely (said Laplace) the state of the universe at every instant follows inexorably from the past and must lead just as relentlessly to the future. It was too soon to conceive of quantum uncertainty, chaos theory, or the limits of computability. To dramatize his perfect determinism, Laplace asked us to imagine a being\u2014an \u201cintelligence\u201d\u2014capable of perfect knowledge:\nThe Information\n\nIt would embrace in the same formula the movements of the greatest bodies of the universe and those of the lightest atom; for it, nothing would be uncertain and the future, as the past, would be present to its eyes.\n\nNothing else Laplace wrote ever became as famous as this thought experiment. It rendered useless not only God\u2019s will but Man\u2019s. To scientists this extreme Newtonianism seemed cause for optimism. To Babbage, all nature suddenly resembled a vast calculating engine, a grand version of his own deterministic machine: \u201cIn turning our views from these simple consequences of the juxtaposition of a few wheels, it is impossible not to perceive the parallel reasoning, as applied to the mighty and far more complex phenomena of nature.\u201d Each atom, once disturbed, must communicate its motion to others, and they in turn influence waves of air, and no impulse is ever entirely lost. The track of every canoe remains somewhere in the oceans. Babbage, whose railroad pen recorder traced on a roll of paper the history of a journey, saw information, formerly evanescent, as a series of physical impressions that were, or could be preserved. The phonograph, impressing sound into foil or wax, had yet to be invented, but Babbage could view the atmosphere as an engine of motion with meaning: \u201cevery atom impressed with good and with ill \u2026 which philosophers and sages have imparted to it, mixed and combined in ten thousand ways with all that is worthless and base.\u201d Every word ever said, whether heard by a hundred listeners or none, far from having vanished into the air, leaves its indelible mark, the complete record of human utterance being encrypted by the laws of motion and capable, in theory, of being recovered\u2014given enough computing power.\n\nThis was overoptimistic. Still, the same year Babbage published his essay, the artist and chemist Louis Daguerre in Paris perfected his means of capturing visual images on silver-coated plates. His English competitor, William Fox Talbot, called this \u201cthe art of photogenic drawing, or of forming pictures and images of natural objects by means of solar light.\u201d Talbot saw something meme-like. \u201cBy means of this contrivance,\u201d he wrote, \u201cit is not the artist who makes the picture, but the picture which makes itself.\u201d Now the images that fly before our eyes could be frozen, impressed upon substance, made permanent.\n\nBy painting or drawing, an artist\u2014with skill, training, and long labor\u2014reconstructs what the eye might see. By contrast, a daguerreotype is in some sense the thing itself\u2014the information, stored, in an instant. It was unimaginable, but there it was. The possibilities made the mind reel. Once storage began, where would it stop? An American essayist immediately connected photography to Babbage\u2019s atmospheric library of sounds: Babbage said that every word was registered somewhere in the air, so perhaps every image, too, left its permanent mark\u2014somewhere.\n\nIn fact, there is a great album of Babel. But what too, if the great business of the sun\nbe to act registrar likewise, and to give out impressions of our looks, and pictures of our actions; and so \u2026 for all we know to the contrary, other worlds may be peopled and conducted with the images of persons and transactions thrown off from this and from each other; the whole universal nature being nothing more than phonetic and photogenic structures.\n\nThe universe, which others called a library or an album, then came to resemble a computer. Alan Turing may have noticed this first: observing that the computer, like the universe, is best seen as a collection of states, and the state of the machine at any instant leads to the state at the next instant, and thus all the future of the machine should be predictable from its initial state and its input signals.\n\nThe universe is computing its own destiny.\n\nTuring noticed that Laplace\u2019s dream of perfection might be possible in a machine but not in the universe, because of a phenomenon which, a generation later, would be discovered by chaos theorists and named the butterfly effect. Turing described it this way in 1950:\n\nThe system of the \u201cuniverse as a whole\u201d is such that quite small errors in initial conditions can have an overwhelming effect at a later time. The displacement of a single electron by a billionth of a centimetre at one moment might make the difference between a man being killed by an avalanche a year later, or escaping.\n\nIf the universe is a computer, we may still struggle to access its memory. If it is a library, it is a library without shelves. When all the world\u2019s sounds disperse through the atmosphere, no word is left attached to any particular bunch of atoms. The words are anywhere and everywhere. That was why Babbage called this information store a \u201cchaos.\u201d Once again he was ahead of his time.\n\nWhen the ancients listed the Seven Wonders of the World, they included the Lighthouse of Alexandria, a 400-foot stone tower built to aid sailors, but overlooked the library nearby. The library, amassing hundreds of thousands of papyrus rolls, maintained the greatest collection of knowledge on earth, then and for centuries to come. Beginning in the third century BCE, it served the Ptolemies\u2019 ambition to buy, steal, or copy all the writings of the known world. The library enabled Alexandria to surpass Athens as an intellectual center. Its racks and cloisters held the dramas of Sophocles, Aeschylus, and Euripides; the mathematics of Euclid, Archimedes, and Eratosthenes; poetry, medical texts, star charts, mystic writings\u2014\u201csuch a blaze of knowledge and discovery,\u201d H. G. Wells declared, \u201cas the world was not to see again until the sixteenth century\u2026. It is the true beginning of Modern History.\u201d The lighthouse loomed large, but the library was the real wonder. And then it burned.\n\nExactly when and how that happened, no one can ever know. Probably more than once. Vengeful conquerors burn books as if the enemy\u2019s souls reside there,\ntoo. \u201cThe Romans burnt the books of the Jews, of the Christians, and the philosophers,\u201d Isaac D\u2019Israeli noted in the nineteenth century; \u201cthe Jews burnt the books of the Christians and the Pagans; and the Christians burnt the books of the Pagans and the Jews.\u201d The Qin dynasty burned China\u2019s books in order to erase previous history. The erasure was effective, the written word being fragile. What we have of Sophocles is not even a tenth of his plays. What we have of Aristotle is mostly second- or thirdhand. For historians peering into the past, the destruction of the Great Library is an event horizon, a boundary across which information does not pass. Not even a partial catalogue survived the flames.\n\n\u201cAll the lost plays of the Athenians!\u201d wails Thomasina (a young mathematician who resembles Ada Byron) to her tutor, Septimus, in Tom Stoppard\u2019s drama Arcadia. \u201cThousands of poems\u2014Aristotle\u2019s own library \u2026 How can we sleep for grief?\u201d\n\n\u201cBy counting our stock,\u201d Septimus replies.\n\nYou should no more grieve for the rest than for a buckle lost from your first shoe, or for your lesson book which will be lost when you are old. We shed as we pick up, like travelers who must carry everything in their arms, and what we let fall will be picked up by those behind. The procession is very long and life is very short. We die on the march. But there is nothing outside the march so nothing can be lost to it. The missing plays of Sophocles will turn up piece by piece, or be written again in another language.\n\nAnyway, according to Borges, the missing plays can be found in the Library of Babel.\n\nIn honor of the lost library, Wikipedia drew hundreds of its editors to Alexandria in the eighth summer of its existence\u2014people called Shipmaster, Brassratgirl, Notafish, and Jimbo who ordinarily meet only online. More than 7 million such user names had been registered by then; the pilgrims came from forty-five countries, paying their own way, toting laptops, exchanging tradecraft, wearing their fervor on their T-shirts. By then, July 2008, Wikipedia comprised 2.5 million articles in English, more than all the world\u2019s paper encyclopedias combined, and a total of 11 million in 264 languages, including Wolof, Twi, and Dutch Low Saxon, but not including Choctaw, closed by community vote after achieving only fifteen articles, or Klingon, found to be a \u201cconstructed,\u201d if not precisely fictional, language. The Wikipedians consider themselves as the Great Library\u2019s heirs, their mission the gathering of all recorded knowledge. They do not, however, collect and preserve existing texts. They attempt to summarize shared knowledge, apart from and outside of the individuals who might have thought it was theirs.\n\nLike the imaginary library of Borges, Wikipedia begins to appear boundless. Several dozen of the non-English Wikipedias have, each, one article on Pok\u00e9mon, the trading-card game, manga series, and media franchise. The English Wikipedia\nbegan with one article and then a jungle grew. There is a page for \u201cPok\u00e9mon (disambiguation),\u201d needed, among other reasons, in case anyone is looking for the Zbtb7 oncogene, which was called Pokemon (for POK erythroid myeloid ontogenic factor), until Nintendo\u2019s trademark lawyers threatened to sue. There are at least five major articles about the popular-culture Pok\u00e9mons, and these spawn secondary and side articles, about the Pok\u00e9mon regions, items, television episodes, game tactics, and all 493 creatures, heroes, protagonists, rivals, companions, and clones, from Bulbasaur to Arceus. All are carefully researched and edited for accuracy, to ensure that they are reliable and true to the Pok\u00e9mon universe, which does not actually, in some senses of the word, exist. Back in the real world, Wikipedia has, or aspires to have, detailed entries describing the routes, intersections, and histories of every numbered highway and road in the United States. (\u201cRoute 273 [New York State, decommissioned in 1980] began at an intersection with U.S. Route 4 in Whitehall. After the intersection, the route passed the Our Lady of Angels Cemetery, where it turned to the southeast. Route 273 ran along the base of Ore Red Hill, outside of Whitehall. Near Ore Red Hill, the highway intersected with a local road, which connected to US 4.\u201d) There are pages for every known enzyme and human gene. The Encyclopaedia Britannica never aspired to such breadth. How could it, being made of paper?\n\nAlone among the great enterprises of the early Internet, Wikipedia was not a business; made no money, only lost money. It was supported by a nonprofit charity established for the purpose. By the time the encyclopedia had 50 million users daily, the foundation had a payroll of eighteen people, including one in Germany, one in the Netherlands, one in Australia, and one lawyer, and everyone else was a volunteer: the millions of contributors, the thousand or more designated \u201cadministrators,\u201d and, always a looming presence, the founder and self-described \u201cspiritual leader,\u201d Jimmy Wales. Wales did not plan initially the scrappy, chaotic, dilettantish, amateurish, upstart free-for-all that Wikipedia quickly became. The would-be encyclopedia began with a roster of experts, academic credentials, verification, and peer review. But the wiki idea took over, willy-nilly. A \u201cwiki,\u201d from a Hawaiian word for \u201cquick,\u201d was a web site that could be not just viewed but edited, by anyone. A wiki was therefore self-created, or at least self-sustaining.\n\nWikipedia first appeared to Internet users with a simple self-description:\n\nHomePage\n\nYou can edit this page right now! It\u2019s a free, community project\n\nWelcome to Wikipedia! We\u2019re writing a complete encyclopedia from scratch, collaboratively. We started work in January 2001. We\u2019ve got over 3,000 pages already. We want to make over 100,000. So, let\u2019s get to work! Write a little (or a lot) about what you know! Read our welcome message here: Welcome, newcomers!\nThe sparseness of the coverage that first year could be gauged by the list of requested articles. Under the heading of Religion: \u201cCatholicism?\u2014Satan?\u2014Zoroaster?\u2014Mythology?\u201d Under Technology: \u201cinternal combustion engine?\u2014dirigible?\u2014liquid crystal display?\u2014bandwidth?\u201d Under Folklore: \u201c(If you want to write about folklore, please come up with a list of folklore topics that are actually recognized as distinct, significant topics in folklore, a subject that you are not likely to know much about if all you\u2019ve done along these lines is play Dungeons and Dragons, q.v.).\u201d Dungeons and Dragons was already well covered. Wikipedia was not looking for flotsam and jetsam but did not scorn them. Years later, in Alexandria, Jimmy Wales said: \u201cAll those people who are obsessively writing about Britney Spears or the Simpsons or Pok\u00e9mon\u2014it\u2019s just not true that we should try to redirect them into writing about obscure concepts in physics. Wiki is not paper, and their time is not owned by us. We can\u2019t say, \u2018Why do we have these employees doing stuff that\u2019s so useless?\u2019 They\u2019re not hurting anything. Let them write it.\u201d\n\n\u201cWiki is not paper\u201d was the unofficial motto. Self-referentially, the phrase has its own encyclopedia page (see also \u201cWiki ist kein Papier\u201d and \u201cWikip\u00e9dia n\u2019est pas sur papier\u201d). It means there is no physical or economic limit on the number or the length of articles. Bits are free. \u201cAny kind of metaphor around paper or space is dead,\u201d as Wales said.\n\nWikipedia found itself a mainstay of the culture with unexpected speed, in part because of its unplanned synergistic relationship with Google. It became a test case for ideas of crowd intelligence: users endlessly debated the reliability\u2014in theory and in actuality\u2014of articles written in an authoritative tone by people with no credentials, no verifiable identity, and unknown prejudices. Wikipedia was notoriously subject to vandalism. It exposed the difficulties\u2014perhaps the impossibility\u2014of reaching a neutral, consensus view of disputed, tumultuous reality. The process was plagued by so-called edit wars, when battling contributors reversed one another\u2019s alterations without surcease. At the end of 2006, people concerned with the \u201cCat\u201d article could not agree on whether a human with a cat is its \u201cowner,\u201d \u201ccaregiver,\u201d or \u201chuman companion.\u201d Over a three-week period, the argument extended to the length of a small book. There were edit wars over commas and edit wars over gods, futile wars over spelling and pronunciation and geopolitical disputes. Other edit wars exposed the malleability of words. Was the Conch Republic (Key West, Florida) a \u201cmicronation\u201d? Was a particular photograph of a young polar bear \u201ccute\u201d? Experts differed, and everyone was an expert.\n\nAfter the occasional turmoil, articles tend to settle toward permanence; still, if the project seems to approach a kind of equilibrium, it is nonetheless dynamic and unstable. In the Wikipedia universe, reality cannot be pinned down with finality.\nThat idea was an illusion fostered in part by the solidity of a leather-and-paper encyclopedia. Denis Diderot aimed in the *Encyclop\u00e9die*, published in Paris beginning in 1751, \u201cto collect all the knowledge that now lies scattered over the face of the earth, to make known its general structure to the men with whom we live, and to transmit it to those who will come after us.\u201d The *Britannica*, first produced in Edinburgh in 1768 in one hundred weekly installments, sixpence apiece, wears the same halo of authority. It seemed finished\u2014in every edition. It has no equivalent in any other language. Even so, the experts responsible for the third edition (\u201cin Eighteen Volumes, Greatly Improved\u201d), a full century after Isaac Newton\u2019s *Principia*, could not bring themselves to endorse his, or any, theory of gravity, or gravitation. \u201cThere have been great disputes,\u201d the *Britannica* stated.\n\nMany eminent philosophers, and among the rest Sir Isaac Newton himself, have considered it as the first of all second causes; an incorporeal or spiritual substance, which never can be perceived any other way than by its effects; an universal property of matter, &c. Others have attempted to explain the phenomena of gravitation by the action of a very subtile etherial fluid; and to this explanation Sir Isaac, in the latter part of his life, seems not to have been averse. He hath even given a conjecture concerning the matter in which this fluid might occasion these phenomena. But for a full account of \u2026 the state of the dispute at present, see the articles, Newtonian Philosophy, Astronomy, Atmosphere, Earth, Electricity, Fire, Light, Attraction, Repulsion, Plenum, Vacuum, &c.\n\nAs the *Britannica* was authoritative, Newton\u2019s theory of gravitation was not yet knowledge.\n\nWikipedia disclaims this sort of authority. Academic institutions officially distrust it. Journalists are ordered not to rely upon it. Yet the authority comes. If one wants to know how many American states contain a county named Montgomery, who will disbelieve the tally of eighteen in Wikipedia? Where else could one look for a statistic so obscure\u2014generated by a summing of the knowledge of hundreds or thousands of people, each of whom may know of only one particular Montgomery County? Wikipedia features a popular article called \u201cErrors in the *Encyclopaedia Britannica* that have been corrected in Wikipedia.\u201d This article is, of course, always in flux. All Wikipedia is. At any moment the reader is catching a version of truth on the wing.\n\nWhen Wikipedia states, in the article \u201cAging,\u201d\n\nAfter a period of near perfect renewal (in humans, between 20 and 35 years of age [citation needed]), organismal senescence is characterized by the declining ability to respond to stress, increasing homeostatic imbalance and increased risk of disease. This irreversible series of changes inevitably ends in death,\n\na reader may trust this; yet for one minute in the early morning of December 20, 2007, the entire article comprised instead a single sentence: \u201cAging is what you\nget when you get freakin old old old.\u201d Such obvious vandalism lasts hardly any time at all. Detecting it and reversing it are automated vandalbots and legions of human vandal fighters, many of them proud members of the Counter-Vandalism Unit and Task Force. According to a popular saying that originated with a frustrated vandal, \u201cOn Wikipedia, there is a giant conspiracy attempting to have articles agree with reality.\u201d This is about right. A conspiracy is all the Wikipedians can hope for, and often it is enough.\n\nLewis Carroll, near the end of the nineteenth century, described in fiction the ultimate map, representing the world on a unitary scale, a mile to a mile: \u201cIt has never been spread out, yet. The farmers objected: they said it would cover the whole country, and shut out the sunlight.\u201d The point is not lost on Wikipedians. Some are familiar with a debate carried out by the German branch about the screw on the left rear brake pad of Ulrich Fuchs\u2019s bicycle. Fuchs, as a Wikipedia editor, proposed the question, Does this item in the universe of objects merit its own Wikipedia entry? The screw was agreed to be small but real and specifiable. \u201cThis is an object in space, and I\u2019ve seen it,\u201d said Jimmy Wales. Indeed, an article appeared in the German Meta-Wiki (that is, the Wikipedia about Wikipedia) titled \u201cDie Schraube an der hinteren linken Bremsbacke am Fahrrad von Ulrich Fuchs.\u201d As Wales noted, the very existence of this article was \u201ca meta-irony.\u201d It was written by the very people who were arguing against its suitability. The article was not really about the screw, however. It is about a controversy: whether Wikipedia should strive, in theory or in practice, to describe the whole world in all its detail.\n\nOpposing factions coalesced around the labels \u201cdeletionism\u201d and \u201cinclusionism.\u201d Inclusionists take the broadest view of what belongs in Wikipedia. Deletionists argue for, and often perform, the removal of trivia: articles too short or poorly written or unreliable, on topics lacking notability. All these criteria are understood to be variable and subjective. Deletionists want to raise the bar of quality. In 2008 they succeeded in removing an entry on the Port Macquarie Presbyterian Church, New South Wales, Australia, on grounds of non-notability. Jimmy Wales himself leaned toward inclusionism. In the late summer of 2007, he visited Cape Town, South Africa, ate lunch at a place called Mzoli\u2019s, and created a \u201cstub\u201d with a single sentence: \u201cMzoli\u2019s Meats is a butcher shop and restaurant located in Guguletu township near Cape Town, South Africa.\u201d It survived for twenty-two minutes before a nineteen-year-old administrator called ^demon deleted it on grounds of insignificance. An hour later, another user re-created the article and expanded it based on information from a local Cape Town blog and a radio interview transcribed online. Two minutes passed, and yet another user objected on grounds that \u201cthis article or section is written like an advertisement.\u201d And so on. The word \u201cfamous\u201d was inserted and deleted several times. The user\nThe Information\n\n^demon weighed in again, saying, \u201cWe are not the white pages and we are not a travel guide.\u201d The user EVula retorted, \u201cI think if we give this article a bit more than a couple of hours of existence, we might have something worthwhile.\u201d Soon the dispute attracted newspaper coverage in Australia and England. By the next year, the article had not only survived but had grown to include a photograph, an exact latitude and longitude, a list of fourteen references, and separate sections for History, Business, and Tourism. Some hard feelings evidently remained, for in March 2008 an anonymous user replaced the entire article with one sentence: \u201cMzoli\u2019s is an insignificant little restaurant whose article only exists here because Jimmy Wales is a bumbling egomaniac.\u201d That lasted less than a minute.\n\nWikipedia evolves dendritically, sending off new shoots in many directions. (In this it resembles the universe.) So deletionism and inclusionism spawn mergism and incrementalism. They lead to factionalism, and the factions fission into Associations of Deletionist Wikipedians and Inclusionist Wikipedians side by side with the Association of Wikipedians Who Dislike Making Broad Judgments About the Worthiness of a General Category of Article, and Who Are in Favor of the Deletion of Some Particularly Bad Articles, but That Doesn\u2019t Mean They Are Deletionists. Wales worried particularly about Biographies of Living Persons. In an ideal world, where Wikipedia could be freed from practical concerns of maintenance and reliability, Wales said he would be happy to see a biography of every human on the planet. It outdoes Borges.\n\nEven then, at the impossible extreme\u2014every person, every bicycle screw\u2014the collection would possess nothing like All Knowledge. For encyclopedias, information tends to come in the form of topics and categories. Britannica framed its organization in 1790 as \u201ca plan entirely new.\u201d It advertised \u201cthe different sciences and arts\u201d arranged as \u201cdistinct Treatises or Systems\u201d\u2014And full Explanations given of the Various Detached Parts of Knowledge, whether relating to Natural and Artificial Objects, or to Matters Ecclesiastical, Civil, Military, Commercial, &c.\n\nIn Wikipedia the detached parts of knowledge tend to keep splitting. The editors analyzed the logical dynamics as Aristotle or Boole might have:\n\nMany topics are based on the relationship of factor X to factor Y, resulting in one or more full articles. This could refer to, for example, situation X in location Y, or version X of item Y. This is perfectly valid when the two variables put together represent some culturally significant phenomenon or some otherwise notable interest. Often, separate articles are needed for a subject within a range of different countries due to its substantial differences across international borders. Articles like Slate industry in Wales and Island Fox are fitting examples. But writing about Oak trees in North Carolina or a Blue truck would likely constitute a POV fork, original research, or would otherwise be outright silly.\nCharles Dickens had earlier considered this very problem. In *The Pickwick Papers*, a man is said to have read up in the *Britannica* on Chinese metaphysics. There was, however, no such article: \u201cHe read for metaphysics under the letter M, and for China under the letter C, and combined his information.\u201d\n\nIn 2008 the novelist Nicholson Baker, calling himself Wageless, got sucked into Wikipedia like so many others, first seeking information and then tentatively supplying some, beginning one Friday evening with the article on bovine somatotropin and, the next day, *Sleepless in Seattle*, periodization, and hydraulic fluid. On Sunday it was pornochanchada (Brazilian sex films), a football player of the 1950s called Earl Blair, and back to hydraulic fluid. On Tuesday he discovered the Article Rescue Squadron, dedicated to finding articles in danger of deletion and saving them by making them better instead. Baker immediately signed up, typing a note: \u201cI want to be a part of this.\u201d His descent into obsession is documented in the archives, like everything else that happens on Wikipedia, and he wrote about it a few months later in a print publication, *The New York Review of Books*.\n\nI began standing with my computer open on the kitchen counter, staring at my growing watchlist, checking, peeking\u2026 I stopped hearing what my family was saying to me\u2014for about two weeks I all but disappeared into my screen, trying to salvage brief, sometimes overly promotional but nevertheless worthy biographies by recasting them in neutral language, and by hastily scouring newspaper databases and Google Books for references that would bulk up their notability quotient. I had become an \u201cinclusionist.\u201d\n\nHe concluded with a \u201csecret hope\u201d: that all the flotsam and jetsam could be saved, if not in Wikipedia than in \u201ca Wikimorgue\u2014a bin of broken dreams.\u201d He suggested calling it Deletopedia. \u201cIt would have much to tell us over time.\u201d On the principle that nothing online ever perishes, Deletionpedia was created shortly thereafter, and it has grown by degrees. The Port Macquarie Presbyterian Church lives on there, though it is not, strictly speaking, part of the encyclopedia. Which some call the universe.\n\nNames became a special problem: their disambiguation; their complexity; their collisions. The nearly limitless flow of information had the effect of throwing all the world\u2019s items into a single arena, where they seemed to play a frantic game of Bumper Car. Simpler times had allowed simpler naming: \u201cThe Lord God formed every beast of the field, and every fowl of the air; and brought them unto Adam to see what he would call them,\u201d says Genesis; \u201cand whatsoever Adam called every living creature, that was the name thereof.\u201d For each creature one name; for each name one creature. Soon, however, Adam had help.\n\nIn his novel *The Infinities*, John Banville imagines the god Hermes saying: \u201cA hamadryad is a wood-nymph, also a poisonous snake in India, and an Abyssinian\nbaboon. It takes a god to know a thing like that.\u201d Yet according to Wikipedia, *hamadryad* also names a butterfly, a natural history journal from India, and a Canadian progressive rock band. Are we all now as gods? The rock band and the wood nymph could coexist without friction, but more generally the breaking down of information barriers leads to conflict over names and naming rights. Impossible as it seems, the modern world is running out of names. The roster of possibilities seems infinite, but the demand is even greater.\n\nThe major telegraph companies, struggling in 1919 with the growing problem of misdirected messages, established a Central Bureau for Registered Addresses. Its central office in the financial district of New York filled an upstairs room on Broad Street with steel filing cabinets. Customers were invited to register code names for their addresses: single words of five to ten letters, required to be \u201cpronounceable\u201d\u2014that is, \u201cmade up of syllables that appear in one of eight European languages.\u201d Many customers complained about the yearly charge\u2014$2.50 per code name\u2014but by 1934 the bureau was managing a list of 28,000, including ILLUMINATE (the New York Edison Company), TOOTSWEETS (the Sweet Company of America), and CHERRYTREE (George Washington Hotel). The financier Bernard M. Baruch managed to get BARUCH all to himself. It was first come, first served, and it was a modest harbinger of things to come.\n\nCyberspace, of course, changes everything. A South Carolina company called Fox & Hound Realty, Billy Benton owner/broker, registered the domain name BARUCH.COM. A Canadian living in High Prairie, Alberta, registered JRRTOLKIEN.COM and held on to it for a decade, until a panel of the World Intellectual Property Organization in Geneva took it away from him. The name had value; others who claimed an interest in it, as a brand and a trademark, either registered or unregistered, included the late writer\u2019s heirs, publisher, and filmmakers, not to mention the several thousand people worldwide who happened to share his surname. The same High Prairie man was basing a business on his possession of famous names: C\u00e9line Dion, Albert Einstein, Michael Crichton, Pierce Brosnan, and about 1,500 more. Some of these people fought back. A select few names\u2014the pinnacles and hilltops\u2014have developed a tremendous concentration of economic value. The word *Nike* is thought by economists to be worth $7 billion; *Coca-Cola* is valued at ten times more.\n\nIn the study of onomastics it is axiomatic that growing social units lead to growing name systems. For life in tribes and villages, single names like Albin and Ava were enough, but tribes gave way to clans, cities to nations, and people had to do better: surnames and patronyms; names based on geography and occupation. More complex societies demand more complex names. The Internet represents not just a new opportunity for fights over names but a leap in scale causing a phase transition.\nAn Atlanta music writer known as Bill Wyman received a cease-and-desist letter from lawyers representing the former Rolling Stone bass player also known as Bill Wyman; demanding, that is, that he \u201ccease and desist\u201d using his name. In responding, the first Bill Wyman pointed out that the second Bill Wyman had been born William George Perks. The car company known in Germany as Dr. Ing. h.c. F. Porsche AG fought a series of battles to protect the name Carrera. Another contender was the Swiss village, postal code 7122. \u201cThe village Carrera existed prior to the Porsche trademark,\u201d Christoph Reuss of Switzerland wrote to Porsche\u2019s lawyers. \u201cPorsche\u2019s use of that name constitutes a misappropriation of the goodwill and reputation developed by the villagers of Carrera.\u201d He added for good measure, \u201cThe village emits much less noise and pollution than Porsche Carrera.\u201d He did not mention that Jos\u00e9 Carreras, the opera singer, was embroiled in a name dispute of his own. The car company, meanwhile, also claimed trademark ownership of the numerals 911.\n\nA useful term of art emerged from computer science: namespace, a realm within which all names are distinct and unique. The world has long had namespaces based on geography and other namespaces based on economic niche. You could be Bloomingdale\u2019s as long as you stayed out of New York; you could be Ford if you did not make automobiles. The world\u2019s rock bands constitute a namespace, where Pretty Boy Floyd and Pink Floyd and Pink coexist, along with the 13th Floor Elevators and the 99th Floor Elevators and Hamadryad. Finding new names in this space becomes a challenge. The singer and songwriter long called simply \u201cPrince\u201d was given that name at birth; when he tired of it, he found himself tagged with a meta-name, \u201cthe Artist Formerly Known as Prince.\u201d The Screen Actors Guild maintains a formal namespace of its own\u2014only one Julia Roberts allowed. Traditional namespaces are overlapping and melting together. And many grow overcrowded.\n\nPharmaceutical names are a special case: a subindustry has emerged to coin them, research them, and vet them. In the United States, the Food and Drug Administration reviews proposed drug names for possible collisions, and this process is complex and uncertain. Mistakes cause death. Methadone, for opiate dependence, has been administered in place of Metadate, for attention-deficit disorder, and Taxol, a cancer drug, for Taxotere, a different cancer drug, with fatal results. Doctors fear both look-alike errors and sound-alike errors: Zantac/Xanax; Verelan/Virilon. Linguists devise scientific measures of the \u201cdistance\u201d between names. But Lamictal and Lamisil and Ludiomil and Lomotil are all approved drug names.\n\nIn the corporate namespace, signs of overcrowding could be seen in the fading away of what might be called simple, meaningful names. No new company could be called anything like General Electric or First National Bank or International\nBusiness Machines. Similarly, A.1. Steak Sauce could only refer to a food product with a long history. Millions of company names exist, and vast sums of money go to professional consultants in the business of creating more. It is no coincidence that the spectacular naming triumphs of cyberspace verge on nonsense: Yahoo!, Google, Twitter.\n\nThe Internet is not just a churner of namespaces; it is also a namespace of its own. Navigation around the globe\u2019s computer networks relies on the special system of domain names, like COCA-COLA.COM. These names are actually addresses, in the modern sense of that word: \u201ca register, location, or a device where information is stored.\u201d The text encodes numbers; the numbers point to places in cyberspace, branching down networks, subnetworks, and devices. Although they are code, these brief text fragments also carry the great weight of meaning in the most vast of namespaces. They blend together features of trademarks, vanity license plates, postal codes, radio-station call letters, and graffiti. Like the telegraph code names, anyone could register a domain name, for a small fee, beginning in 1993. It was first come, first served. The demand exceeds the supply.\n\nToo much work for short words. Many entities own \u201capple\u201d trademarks, but there is only one APPLE.COM; when the domains of music and computing collided, so did the Beatles and the computer company. There is only one MCDONALDS.COM, and a journalist named Joshua Quittner registered it first. Much as the fashion empire of Giorgio Armani wanted ARMANI.COM, so did Anand Ramnath Mani of Vancouver, and he got there first. Naturally a secondary market emerged for trade in domain names. In 2006, one entrepreneur paid another entrepreneur $14 million for SEX.COM. By then nearly every word in every well-known language had been registered; so had uncountable combinations of words and variations of words\u2014more than 100 million. It is a new business for corporate lawyers. A team working for DaimlerChrysler in Stuttgart, Germany, managed to wrest back MERCEDESSHOP.COM, DRIVEAMERCEDES.COM, DODGEVIPER.COM, CRYSLER.COM, CHRISLER.COM, CHRYSTLER.COM, and CHRISTLER.COM.\n\nThe legal edifices of intellectual property were rattled. The response was a species of panic\u2014a land grab in trademarks. As recently as 1980, the United States registered about ten thousand a year. Three decades later, the number approached three hundred thousand, jumping every year. The vast majority of trademark applications used to be rejected; now the opposite is true. All the words of the language, in all possible combinations, seem eligible for protection by governments. A typical batch of early twenty-first century United States trademarks: GREEN CIRCLE, DESERT ISLAND, MY STUDENT BODY, ENJOY A PARTY IN EVERY BOWL!, TECHNOLIFT, MEETINGS IDEAS,\nTAMPER PROOF KEY RINGS, THE BEST FROM THE WEST, AWESOME ACTIVITIES.\n\nThe collision of names, the exhaustion of names\u2014it has happened before, if never on this scale. Ancient naturalists knew perhaps five hundred different plants and, of course, gave each a name. Through the fifteenth century, that is as many as anyone knew. Then, in Europe, as printed books began to spread with lists and drawings, an organized, collective knowledge came into being, and with it, as the historian Brian Ogilvie has shown, the discipline called natural history. The first botanists discovered a profusion of names. Caspar Ratzenberger, a student at Wittenberg in the 1550s, assembled a herbarium and tried to keep track: for one species he noted eleven names in Latin and German: *Scandix, Pecten veneris, Herba scanaria, Cerefolium aculeatum, Nadelkrautt, Hechelkam, NadelKoerffel, Venusstrahl, Nadel Moehren, Schnabel Moehren, Schnabelkoerffel*. In England it would have been called *shepherd\u2019s needle* or *shepherd\u2019s comb*. Soon enough the profusion of species overtook the profusion of names. Naturalists formed a community; they corresponded, and they traveled. By the end of the century a Swiss botanist had published a catalogue of 6,000 plants. Every naturalist who discovered a new one had the privilege and the responsibility of naming it; a proliferation of adjectives and compounds was inevitable, as were duplication and redundancy. To *shepherd\u2019s needle* and *shepherd\u2019s comb* were added, in English alone, *shepherd\u2019s bag, shepherd\u2019s purse, shepherd\u2019s beard, shepherd\u2019s bedstraw, shepherd\u2019s bodkin, shepherd\u2019s cress, shepherd\u2019s hour-glass, shepherd\u2019s rod, shepherd\u2019s gourd, shepherd\u2019s joy, shepherd\u2019s knot, shepherd\u2019s myrtle, shepherd\u2019s peddler, shepherd\u2019s pouche, shepherd\u2019s staff, shepherd\u2019s teasel, shepherd\u2019s scrip,* and *shepherd\u2019s delight*.\n\nCarl Linnaeus had yet to invent taxonomy; when he did, in the eighteenth century, he had 7,700 species of plants to name, along with 4,400 animals. Now there are about 300,000, not counting insects, which add millions more. Scientists still try to name them all: there are beetle species named after Barack Obama, Darth Vader, and Roy Orbison. Frank Zappa has lent his name to a spider, a fish, and a jellyfish.\n\n\u201cThe name of a man is like his shadow,\u201d said the Viennese onomatologist Ernst Pulgram in 1954. \u201cIt is not of his substance and not of his soul, but it lives with him and by him. Its presence is not vital, nor its absence fatal.\u201d Those were simpler times.\n\nWhen Claude Shannon took a sheet of paper and penciled his outline of the measures of information in 1949, the scale went from tens of bits to hundreds to thousands, millions, billions, and trillions. The transistor was one year old and Moore\u2019s law yet to be conceived. The top of the pyramid was Shannon\u2019s estimate\nfor the Library of Congress\u2014one hundred trillion bits, $10^{14}$. He was about right, but the pyramid was growing.\n\nAfter bits came kilobits, naturally enough. After all, engineers had coined the word *kilobuck*\u2014\u201ca scientist\u2019s idea of a short way to say \u2018a thousand dollars,\u2019\u201d *The New York Times* helpfully explained in 1951. The measures of information climbed up an exponential scale, as the realization dawned in the 1960s that everything to do with information would now grow exponentially. That idea was casually expressed by Gordon Moore, who had been an undergraduate studying chemistry when Shannon jotted his note and found his way to electronic engineering and the development of integrated circuits. In 1965, three years before he founded the Intel Corporation, Moore was merely, modestly suggesting that within a decade, by 1975, as many as 65,000 transistors could be combined on a single wafer of silicon. He predicted a doubling every year or two\u2014a doubling of the number of components that could be packed on a chip, but then also, as it turned out, the doubling of all kinds of memory capacity and processing speed, a halving of size and cost, seemingly without end.\n\nKilobits could be used to express speed of transmission as well as quantity of storage. As of 1972, businesses could lease high-speed lines carrying data as fast as 240 kilobits per second. Following the lead of IBM, whose hardware typically processed information in chunks of eight bits, engineers soon adopted the modern and slightly whimsical unit, the byte. Bits and bytes. A kilobyte, then, represented 8,000 bits; a megabyte (following hard upon), 8 million. In the order of things as worked out by international standards committees, *mega-* led to *giga-*, *tera-*, *peta-*, and *exa-*, drawn from Greek, though with less and less linguistic fidelity. That was enough, for everything measured, until 1991, when the need was seen for the zettabyte ($1,000,000,000,000,000,000$) and the inadvertently comic sounding yottabyte ($1,000,000,000,000,000,000,000,000$). In this climb up the exponential ladder information left other gauges behind. Money, for example, is scarce by comparison. After kilobucks, there were megabucks and gigabucks, and people can joke about inflation leading to terabucks, but all the money in the world, all the wealth amassed by all the generations of humanity, does not amount to a petabuck.\n\nThe 1970s were the decade of megabytes. In the summer of 1970, IBM introduced two new computer models with more memory than ever before: the Model 155, with 768,000 bytes of memory, and the larger Model 165, with a full megabyte, in a large cabinet. One of these room-filling mainframes could be purchased for $4,674,160. By 1982 Prime Computer was marketing a megabyte of memory on a single circuit board, for $36,000. When the publishers of the *Oxford English Dictionary* began digitizing its contents in 1987 (120 typists; an IBM mainframe), they estimated its size at a gigabyte. A gigabyte also\nencompasses the entire human genome. A thousand of those would fill a terabyte. A terabyte was the amount of disk storage Larry Page and Sergey Brin managed to patch together with the help of $15,000 spread across their personal credit cards in 1998, when they were Stanford graduate students building a search-engine prototype, which they first called BackRub and then renamed Google. A terabyte is how much data a typical analog television station broadcasts daily, and it was the size of the United States government\u2019s database of patent and trademark records when it went online in 1998. By 2010, one could buy a terabyte disc drive for a hundred dollars and hold it in the palm of one hand. The books in the Library of Congress represent about 10 terabytes (as Shannon guessed), and the number is many times more when images and recording music are counted. The library now archives web sites; by February 2010 it had collected 160 terabytes\u2019 worth.\n\nAs the train hurtled onward, its passengers sometimes felt the pace foreshortening their sense of their own history. Moore\u2019s law had looked simple on paper, but its consequences left people struggling to find metaphors with which to understand their experience. The computer scientist Jaron Lanier describes the feeling this way: \u201cIt\u2019s as if you kneel to plant the seed of a tree and it grows so fast that it swallows your whole town before you can even rise to your feet.\u201d\n\nA more familiar metaphor is the cloud. All that information\u2014all that information capacity\u2014looms over us, not quite visible, not quite tangible, but awfully real; amorphous, spectral; hovering nearby, yet not situated in any one place. Heaven must once have felt this way to the faithful. People talk about shifting their lives to the cloud\u2014their informational lives, at least. You may store photographs in the cloud; Google will manage your business in the cloud; Google is putting all the world\u2019s books into the cloud; e-mail passes to and from the cloud and never really leaves the cloud. All traditional ideas of privacy, based on doors and locks, physical remoteness and invisibility, are upended in the cloud.\n\nMoney lives in the cloud; the old forms are vestigial tokens of knowledge about who owns what, who owes what. To the twenty-first century these will be seen as anachronisms, quaint or even absurd: bullion carried from shore to shore in fragile ships, subject to the tariffs of pirates and the god Poseidon; metal coins tossed from moving cars into baskets at highway tollgates and thereafter trucked about (now the history of your automobile is in the cloud); paper checks torn from pads and signed in ink; tickets for trains, performances, air travel, or anything at all, printed on weighty perforated paper with watermarks, holograms, or fluorescent fibers; and, soon enough, all forms of cash. The economy of the world is transacted in the cloud.\n\nIts physical aspect could not be less cloudlike. Server farms proliferate in\nunmarked brick buildings and steel complexes, with smoked windows or no windows, miles of hollow floors, diesel generators, cooling towers, seven-foot intake fans, and aluminum chimney stacks. This hidden infrastructure grows in a symbiotic relationship with the electrical infrastructure it increasingly resembles. There are information switchers, control centers, and substations. They are clustered and distributed. These are the wheel-works; the cloud is their avatar.\n\nThe information produced and consumed by humankind used to vanish\u2014that was the norm, the default. The sights, the sounds, the songs, the spoken word just melted away. Marks on stone, parchment, and paper were the special case. It did not occur to Sophocles\u2019 audiences that it would be sad for his plays to be lost; they enjoyed the show. Now expectations have inverted. Everything may be recorded and preserved, at least potentially: every musical performance; every crime in a shop, elevator, or city street; every volcano or tsunami on the remotest shore; every card played or piece moved in an online game; every rugby scrum and cricket match. Having a camera at hand is normal, not exceptional; something like 500 billion images were captured in 2010. YouTube was streaming more than a billion videos a day. Most of this is haphazard and unorganized, but there are extreme cases. The computer pioneer Gordon Bell, at Microsoft Research in his seventies, began recording every moment of his day, every conversation, message, document, a megabyte per hour or a gigabyte per month, wearing around his neck what he called a \u201cSenseCam\u201d to create what he called a \u201cLifeLog.\u201d Where does it end? Not with the Library of Congress.\n\nIt is finally natural\u2014even inevitable\u2014to ask how much information is in the universe. It is the consequence of Charles Babbage and Edgar Allan Poe saying, \u201cNo thought can perish.\u201d Seth Lloyd does the math. He is a moon-faced, bespectacled quantum engineer at MIT, a theorist and designer of quantum computers. The universe, by existing, registers information, he says. By evolving in time, it processes information. How much? To figure that out, Lloyd takes into account how fast this \u201ccomputer\u201d works and how long it has been working. Considering the fundamental limit on speed, $2E/\\pi\\hbar$ operations per second (\u201cwhere $E$ is the system\u2019s average energy above the ground state and $\\hbar = 1.0545 \\times 10^{-34}$ joule-sec is Planck\u2019s reduced constant\u201d), and on memory space, limited by entropy to $S/k_B \\ln 2$ (\u201cwhere $S$ is the system\u2019s thermodynamic entropy and $k_B = 1.38 \\times 10^{-23}$ joules/K is Boltzmann\u2019s constant\u201d), along with the speed of light and the age of the universe since the Big Bang, Lloyd calculates that the universe can have performed something on the order of $10^{120}$ \u201cops\u201d in its entire history. Considering \u201cevery degree of freedom of every particle in the universe,\u201d it could now hold something like $10^{90}$ bits. And counting.\nSorry for all the ups and downs of the web site in recent days. The way I understand it, freakish accumulations of ice weigh down the branches of the Internet and trucks carrying packets of information skid all over the place.\n\n\u2014Andrew Tobias (2007)\n\nAS THE PRINTING PRESS, the telegraph, the typewriter, the telephone, the radio, the computer, and the Internet prospered, each in its turn, people said, as if for the first time, that a burden had been placed on human communication: new complexity, new detachment, and a frightening new excess. In 1962 the president of the American Historical Association, Carl Bridenbaugh, warned his colleagues that human existence was undergoing a \u201cGreat Mutation\u201d\u2014so sudden and so radical \u201cthat we are now suffering something like historical amnesia.\u201d He lamented the decline of reading; the distancing from nature (which he blamed in part on \u201cugly yellow Kodak boxes\u201d and \u201cthe transistor radio everywhere\u201d); and the loss of shared culture. Most of all, for the preservers and recorders of the past, he worried about the new tools and techniques available to scholars: \u201cthat Bitch-goddess, Quantification\u201d; \u201cthe data processing machines\u201d; as well as \u201cthose frightening projected scanning devices, which we are told will read documents and books for us.\u201d More was not better, he declared:\n\nNotwithstanding the incessant chatter about communication that we hear daily, it has not improved; actually it has become more difficult.\n\nThese remarks became well known in several iterations: first, the oral address, heard by about a thousand people in the ballroom of Conrad Hilton\u2019s hotel in Chicago on the last Saturday evening on 1962; next, the printed version in the society\u2019s journal in 1963; and then, a generation later, an online version, with its far greater reach and perhaps greater durability as well.\n\nElizabeth Eisenstein encountered the printed version in 1963, when she was teaching history as a part-time adjunct lecturer at American University in Washington (the best job she could get, as a woman with a Harvard Ph.D.). Later she identified that moment as the starting point of fifteen years of research that culminated in her landmark of scholarship, two volumes titled *The Printing Press as an Agent of Change*. Before Eisenstein\u2019s work appeared in 1979, no one had attempted a comprehensive study of printing as the communications revolution\nThe Information\n\nessential to the transition from medieval times to modernity. Textbooks, as she noted, tended to slot the printing press somewhere between the Black Death and the discovery of America. She placed Gutenberg\u2019s invention at center stage: the shift from script to print; the rise of printing shops in the cities of fifteenth-century Europe; the transformation in \u201cdata collection, storage and retrieval systems and communications networks.\u201d She emphasized modestly that she would treat printing only as an agent of change, but she left readers convinced of its indispensable part in the transformations of early modern Europe: the Renaissance, the Protestant Reformation, and the birth of science. It was \u201ca decisive point of no return in human history.\u201d It shaped the modern mind.\n\nIt shaped the minds of historians, too; she was interested in the unconscious mental habits of her profession. As she embarked on her project, she began to believe that scholars were too often blinded to the effects of the very medium in which they swam. She gave credit to Marshall McLuhan, whose Gutenberg Galaxy had appeared in 1962, for forcing them to refocus their gaze. In the age of scribes, the culture had only primitive reckonings of chronology: muddled timelines counted the generations from Adam, or Noah, or Romulus and Remus. \u201cAttitudes toward historical change,\u201d she wrote, \u201cwill be found only occasionally in writings ostensibly devoted to \u2018history\u2019 and often have to be read into such writings. They must also be read into sagas and epics, sacred scriptures, funerary inscriptions, glyphs and ciphers, vast stone monuments, documents locked in chests in muniment rooms, and marginal notations on manuscript.\u201d The sense of when we are\u2014the ability to see the past spread out before one; the internalization of mental time charts; the appreciation of anachronism\u2014came with the shift to print.\n\nAs a duplicating machine, the printing press not only made texts cheaper and more accessible; its real power was to make them stable. \u201cScribal culture,\u201d Eisenstein wrote, was \u201cconstantly enfeebled by erosion, corruption, and loss.\u201d Print was trustworthy, reliable, and permanent. When Tycho Brahe spent his countless hours poring over planetary and star tables, he could count on others checking the same tables, now and in the future. When Kepler computed his own far more accurate catalogue, he was leveraging the tables of logarithms published by Napier. Meanwhile, print shops were not only spreading Martin Luther\u2019s theses but, more important, the Bible itself. The revolution of Protestantism hinged more on Bible reading than on any point of doctrine\u2014print overcoming script; the codex supplanting the scroll; and the vernacular replacing the ancient languages. Before print, scripture was not truly fixed. All forms of knowledge achieved stability and permanence, not because paper was more durable than papyrus but simply because there were many copies.\n\nIn 1963, reading the warnings of the president of the American Historical\nAssociation, Eisenstein found herself agreeing that the profession faced a crisis, of sorts. But she felt Bridenbaugh had it exactly backward. He thought the problem was forgetfulness: \u201cAs I see it,\u201d he said dramatically, \u201cmankind is faced with nothing short of the loss of its memory, and this memory is history.\u201d Eisenstein, looking at the same new information technologies that so troubled older historians, drew the opposite lesson. The past is not receding from view but, on the contrary, becoming more accessible and more visible. \u201cIn an age that has seen the deciphering of Linear B and the discovery of the Dead Sea Scrolls,\u201d she wrote, \u201cthere appears to be little reason to be concerned about \u2018the loss of mankind\u2019s memory.\u2019 There are good reasons for being concerned about the overloading of its circuits.\u201d As for the amnesia lamented by Bridenbaugh and so many of his colleagues:\n\nThis is a misreading of the predicament confronting historians today. It is not the onset of amnesia that accounts for present difficulties but a more complete recall than any prior generation has ever experienced. Steady recovery, not obliteration, accumulation, rather than loss, have led to the present impasse.\n\nFrom her point of view, a five-centuries-old communications revolution was still gathering momentum. How could they not see this?\n\n\u201cOverloading of circuits\u201d was a fairly new metaphor to express a sensation\u2014too much information\u2014that felt new. It had always felt new. One hungers for books; rereads a cherished few; begs or borrows more; waits at the library door, and perhaps, in the blink of an eye, finds oneself in a state of surfeit: too much to read. In 1621 the Oxford scholar Robert Burton (who amassed one of the world\u2019s largest private libraries, 1,700 books, but never a thesaurus) gave voice to the feeling:\n\nI hear new news every day, and those ordinary rumours of war, plagues, fires, inundations, thefts, murders, massacres, meteors, comets, spectrums, prodigies, apparitions, of towns taken, cities besieged in France, Germany, Turkey, Persia, Poland, &c. daily musters and preparations, and such like, which these tempestuous times afford, battles fought, so many men slain, monomachies, shipwrecks, piracies, and sea-fights, peace, leagues, stratagems, and fresh alarms. A vast confusion of vows, wishes, actions, edicts, petitions, lawsuits, pleas, laws, proclamations, complaints, grievances are daily brought to our ears. New books every day, pamphlets, currantoes, stories, whole catalogues of volumes of all sorts, new paradoxes, opinions, schisms, heresies, controversies in philosophy, religion, &c. Now come tidings of weddings, maskings, mummeries, entertainments, jubilees, embassies, tilts and tournaments, trophies, triumphs, revels, sports, plays: then again, as in a new shifted scene, treasons, cheating tricks, robberies, enormous villanies in all kinds, funerals, burials, deaths of Princes, new discoveries, expeditions; now comical then tragical matters. To-day we hear of new Lords and officers created, to-morrow of some great men deposed, and then again of fresh honours conferred; one is let loose, another imprisoned; one purchaseth, another breaketh: he thrives, his neighbour turns bankrupt; now plenty, then again dearth and famine; one runs, another rides, wrangles, laughs, weeps &c.\nThus I daily hear, and such like.\n\nHe thought information glut was new then. He was not complaining; just amazed. Protests followed soon enough, however. Leibniz feared a return to barbarism\u2014\u201cto which result that horrible mass of books which keeps on growing might contribute very much. For in the end the disorder will become nearly insurmountable.\u201d Alexander Pope wrote satirically of \u201cthose days, when (after Providence had permitted the invention of Printing as a scourge for the sins of the learned) Paper also became so cheap, and printers so numerous, that a deluge of Authors covered the land.\u201d\n\nDeluge became a common metaphor for people describing information surfeit. There is a sensation of drowning: information as a rising, churning flood. Or it calls to mind bombardment, data impinging in a series of blows, from all sides, too fast. Fear of the cacophony of voices can have a religious motivation, a worry about secular noise overwhelming the truth. T. S. Eliot expressed that in 1934:\n\nKnowledge of speech, but not of silence;\nKnowledge of words, and ignorance of the Word.\nAll our knowledge brings us nearer to our ignorance,\nAll our ignorance brings us nearer to death,\nBut nearness to death no nearer to GOD.\n\nOr one may dread the breaching of walls that stand before what is unfamiliar, or horrible, or terrifying. Or one may lose the ability to impose order on the chaos of sensations. The truth seems harder to find amid the multitude of plausible fictions.\n\nAfter \u201cinformation theory\u201d came to be, so did \u201cinformation overload,\u201d \u201cinformation glut,\u201d \u201cinformation anxiety,\u201d and \u201cinformation fatigue,\u201d the last recognized by the OED in 2009 as a timely syndrome: \u201cApathy, indifference, or mental exhaustion arising from exposure to too much information, esp. (in later use) stress induced by the attempt to assimilate excessive amounts of information from the media, the Internet, or at work.\u201d Sometimes information anxiety can coexist with boredom, a particularly confusing combination. David Foster Wallace had a more ominous name for this modern condition: Total Noise. \u201cThe tsunami of available fact, context, and perspective\u201d\u2014that, he wrote in 2007, constitutes Total Noise. He talked about the sensation of drowning and also of a loss of autonomy, of personal responsibility for being informed. To keep up with all the information we need proxies and subcontractors.\n\nAnother way to speak of the anxiety is in terms of the gap between information and knowledge. A barrage of data so often fails to tell us what we need to know. Knowledge, in turn, does not guarantee enlightenment or wisdom. (Eliot said that, too: \u201cWhere is the wisdom we have lost in knowledge? / Where is the knowledge\nwe have lost in information?\u201d) It is an ancient observation, but one that seemed to bear restating when information became plentiful\u2014particularly in a world where all bits are created equal and information is divorced from meaning. The humanist and philosopher of technology Lewis Mumford, for example, restated it in 1970: \u201cUnfortunately, \u2018information retrieving,\u2019 however swift, is no substitute for discovering by direct personal inspection knowledge whose very existence one had possibly never been aware of, and following it at one\u2019s own pace through the further ramification of relevant literature.\u201d He begged for a return to \u201cmoral self-discipline.\u201d There is a whiff of nostalgia in this sort of warning, along with an undeniable truth: that in the pursuit of knowledge, slower can be better. Exploring the crowded stacks of musty libraries has its own rewards. Reading\u2014even browsing\u2014an old book can yield sustenance denied by a database search. Patience is a virtue, gluttony a sin.\n\nEven in 1970, however, Mumford was not thinking about databases or any of the electronic technologies that loomed. He complained about \u201cthe multiplication of microfilms.\u201d He also complained about too many books. Without \u201cself-imposed restraints,\u201d he warned, \u201cthe overproduction of books will bring about a state of intellectual enervation and depletion hardly to be distinguished from massive ignorance.\u201d Restraints were not imposed. Titles continue to multiply. Books about information glut join the cornucopia; no irony is intended when the online bookseller Amazon.com transmits messages like \u201cStart reading Data Smog on your Kindle in under a minute\u201d and \u201cSurprise me! See a random page in this book.\u201d\n\nThe electronic communication technologies arrived so quickly, almost without warning. The word e-mail appeared in print (so far as the OED can determine) in 1982, in Computerworld magazine, which had barely heard reports: \u201cADR/Email is reportedly easy to use and features simple, English verbs and prompt screens.\u201d Next year, the journal Infosystems declared, \u201cEmail promotes movement of information through space.\u201d And the year after that\u2014still a full decade before most people heard the word\u2014a Swedish computer scientist named Jacob Palme at the QZ Computer Center in Stockholm issued a prescient warning\u2014as simple, accurate, and thorough as any that followed in the next decades. Palme began:\n\nElectronic mail system can, if used by many people, cause severe information overload problems. The cause of this problem is that it is so easy to send a message to a large number of people, and that systems are often designed to give the sender too much control of the communication process, and the receiver too little control\u2026.\n\nPeople get too many messages, which they do not have time to read. This also means that the really important messages are difficult to find in a large flow of less important messages.\n\nIn the future, when we get larger and larger message systems, and these systems get more and more interconnected, this will be a problem for almost all users of these systems.\nHe had statistics from his local network: the average message took 2 minutes, 36 seconds to write and just 28 seconds to read. Which would have been fine, except that people could so easily send many copies of the same message.\n\nWhen psychologists or sociologists try to study information overload with the methods of their disciplines, they get mixed results. As early as 1963, a pair of psychologists set out to quantify the effect of extra information on the process of clinical diagnosis. As they expected, they found that \u201ctoo much information\u201d\u2014not easy to define, they admitted\u2014often contaminated judgment. They titled their paper \u201cDoes One Sometimes Know Too Much?\u201d and somewhat gleefully listed alternative titles, as a bonus: \u201cNever Have So Many Done So Little\u201d; \u201cAre You Getting More Now But Predicting It Less?\u201d; and \u201cToo Much Information Is a Dangerous Thing.\u201d Others tried to measure the effects of information load on blood pressure, heart rhythms, and respiration rates.\n\nOne worker in the area was Siegfried Streufert, who reported in a series of papers in the 1960s that the relation between information load and information handling typically looked like an \u201cinverted U\u201d: more information was helpful at first, then not so helpful, and then actually harmful. One of his studies took 185 university students (all male) and had them pretend to be commanders making decisions in a tactical game. They were told:\n\nThe information you are receiving is prepared for you in the same way it would be prepared for real commanders by a staff of intelligence officers\u2026. You may instruct these intelligence officers to increase or decrease the amount of information they present to you\u2026. Please check your preference: I would prefer to:\n\n- receive much more information\n- receive a little more information\n- receive about the same amount of information\n- receive a little less information\n- receive much less information.\n\nNo matter what they chose, their preferences were ignored. The experimenter, not the subjects, predetermined the amount of information. Streufert concluded from the data that \u201csuperoptimal\u201d information loads caused poor performance, \u201cyet it should be noted that even at highly superoptimal information loads (i.e., 25 messages per 30-minute period), the subjects are still asking for increased information levels.\u201d Later, he used similar methodology to study the effects of drinking too much coffee.\n\nBy the 1980s, researchers were speaking confidently about the \u201cinformation-load paradigm.\u201d This was a paradigm based on a truism: that people can only \u201cabsorb\u201d or \u201cprocess\u201d a limited amount of information. Various investigators found surfeits causing not only confusion and frustration, but also blurred vision and dishonesty. Experiments themselves had a broad menu of information to\nprocess: measurements of memory span; ideas of channel capacity drawn from Shannon; and variations on the theme of signal-to-noise ratio. A common, if dubious, approach to research was direct introspection. One small project in 1998 took as a \u201ccommunity or folk group\u201d graduate students in library and information science at the University of Illinois; all agreed, when asked, that they suffered from information overload, due to \u201ce-mail, meetings, listservs, and in-basket paper piles.\u201d Most felt that a surfeit of information tainted their leisure time as well as their work time. Some reported headaches. The tentative conclusion: information overload is real; also, it is both a \u201ccode phrase\u201d and a myth. The research can only press onward.\n\nHaving to think of information as a burden is confusing, as Charles Bennett says. \u201cWe pay to have newspapers delivered, not taken away.\u201d But the thermodynamics of computation shows that yesterday\u2019s newspaper takes up space that Maxwell\u2019s demon needs for today\u2019s work, and modern experience teaches the same. Forgetting used to be a failing, a waste, a sign of senility. Now it takes effort. It may be as important as remembering.\n\nFacts were once dear; now they are cheap. Once, people would turn to the pages of *Whitaker\u2019s Almanack*, published yearly in Britain, or the *World Almanac*, in the United States, to find the names and dates of monarchs and presidents, tables of holidays and high water, sizes and populations of faraway places, or the ships and chief officers of the navy. Lacking the almanac, or seeking an even more obscure fact, they might call on a man or woman of experience behind a desk at a public library. When George Bernard Shaw needed the whereabouts of the nearest crematorium\u2014his wife was dying\u2014he opened the almanac and was aggrieved. \u201cI have just found an astonishing omission in Whitaker,\u201d he wrote to the editor. \u201cAs the desired information is just what one goes to your invaluable almanack for, may I suggest that a list of the 58 crematoria now working in the country, and instructions what to do, would be a very desirable addition.\u201d His letter is poignant. He does not mention his wife\u2014only \u201ca case of serious illness\u201d\u2014and refers to himself as \u201cthe bereaved enquirer.\u201d Shaw had a telegraph address and a telephone but took it for granted that facts were to be found in print.\n\nFor many, the telephone had already begun to extend the reach of the inquisitive. Twentieth-century people realized that they could know instantly the scores of sporting events they had not witnessed; so many came up with the idea of telephoning the newspaper that *The New York Times* felt compelled to print a front-page notice in 1929 begging readers to desist: \u201cDon\u2019t Ask by Telephone for World\u2019s Series Scores.\u201d Now the information, in \u201creal time,\u201d is considered a birthright.\n\nWhat do you do when you have everything at last? Daniel Dennett imagined\u2014\nin 1990, just before the Internet made this dream possible\u2014that electronic networks could upend the economics of publishing poetry. Instead of slim books, elegant specialty items marketed to connoisseurs, what if poets could publish online, instantly reaching not hundreds but millions of readers, not for tens of dollars but for fractions of pennies? That same year, Sir Charles Chadwyck-Healey, a publisher, conceived of the English Poetry Full-Text Database as he walked one day through the British Library, and four years later he had produced it\u2014not the present or future of poetry, but the past, and not, at first, online but in four compact discs, 165,000 poems by 1,250 poets spanning thirteen centuries, priced at $51,000. Readers and critics had to figure out what to make of this. Not read it, surely, the way they would read a book. Read in it, perhaps. Search it, for a word or an epigraph or a fragment half remembered.\n\nAnthony Lane, reviewing the database for The New Yorker, found himself swinging from elation to dismay and back. \u201cYou hunch like a pianist over the keys,\u201d he wrote, \u201cknowing what awaits you, thinking, Ah, the untold wealth of English literature! What hidden jewels I shall excavate from the deepest mines of human fancy!\u201d Then come the macaronics, the clunkers, the flood of bombast and mediocrity. The sheer unordered mass begins to wear you down. Not that Lane sounds at all weary. \u201cWhat a steaming heap,\u201d he cries, and he revels in it. \u201cNever have I beheld such a magnificent tribute to the powers of human incompetence\u2014and also, by the same token, to the blessings of human forgetfulness.\u201d Where else would he have found the utterly forgotten Thomas Freeman (not in Wikipedia) and this lovely self-referential couplet:\n\nWhoop, whoop, me thinkes I heare my Reader cry,\nHere is rime doggrell: I confesse it I.\n\nThe CD-ROMs are already obsolete. All English poetry is in the network now\u2014or if not all, some approximation thereof, and if not now, then soon.\n\nThe past folds accordion-like into the present. Different media have different event horizons\u2014for the written word, three millennia; for recorded sound, a century and a half\u2014and within their time frames the old becomes as accessible as the new. Yellowed newspapers come back to life. Under headings of 50 Years Ago and 100 Years Ago, veteran publications recycle their archives: recipes, card-play techniques, science, gossip, once out of print and now ready for use. Record companies rummage through their attics to release, or re-release, every scrap of music, rarities, B-sides, and bootlegs. For a certain time, collectors, scholars, or fans possessed their books and their records. There was a line between what they had and what they did not. For some, the music they owned (or the books, or the videos) became part of who they were. That line fades away. Most of Sophocles\u2019 plays are lost, but those that survive are available at the touch of a button. Most of Bach\u2019s music was unknown to Beethoven; we have it all\u2014partitas, cantatas, and\nringtones. It comes to us instantly, or at light speed. It is a symptom of omniscience. It is what the critic Alex Ross calls the Infinite Playlist, and he sees how mixed is the blessing: \u201canxiety in place of fulfillment, an addictive cycle of craving and malaise. No sooner has one experience begun than the thought of what else is out there intrudes.\u201d The embarrassment of riches. Another reminder that information is not knowledge, and knowledge is not wisdom.\n\nStrategies emerge for coping. There are many, but in essence they all boil down to two: filter and search. The harassed consumer of information turns to filters to separate the metal from the dross; filters include blogs and aggregators\u2014the choice raises issues of trust and taste. The need for filters intrudes on any thought experiment about the wonders of abundant information. When Dennett imagined his Complete Poetry Network, he saw the problem. \u201cThe obvious counterhypothesis arises from population memetics,\u201d he said. \u201cIf such a network were established, no poetry lover would be willing to wade through thousands of electronic files filled with doggerel, looking for good poems.\u201d Filters would be needed\u2014editors and critics. \u201cThey flourish because of the short supply and limited capacity of minds, whatever the transmission media between minds.\u201d When information is cheap, attention becomes expensive.\n\nFor the same reason, mechanisms of search\u2014*engines*, in cyberspace\u2014find needles in haystacks. By now we\u2019ve learned that it is not enough for information to *exist*. A \u201cfile\u201d was originally\u2014in sixteenth-century England\u2014a wire on which slips and bills and notes and letters could be strung for preservation and reference. Then came file folders, file drawers, and file cabinets; then the electronic namesakes of all these; and the inevitable irony. Once a piece of information is *filed*, it is statistically unlikely ever to be seen again by human eyes. Even in 1847, Augustus De Morgan, Babbage\u2019s friend, knew this. For any random book, he said, a library was no better than a wastepaper warehouse. \u201cTake the library of the British Museum, for instance, valuable and useful and accessible as it is: what chance has a work of being known to be there, merely because it is there? If it be wanted, it can be asked for; but to be wanted it must be known. Nobody can rummage the library.\u201d\n\nToo much information, and so much of it lost. An unindexed Internet site is in the same limbo as a misshelved library book. This is why the successful and powerful business enterprises of the information economy are built on filtering and searching. Even Wikipedia is a combination of the two: powerful search, mainly driven by Google, and a vast, collaborative filter, striving to gather the true facts and screen out the false ones. Searching and filtering are all that stand between this world and the Library of Babel.\n\nIn their computer-driven incarnations these strategies seem new. But they are\nnot. In fact, a considerable part of the gear and tackle of print media\u2014now taken for granted, invisible as old wallpaper\u2014evolved in direct response to the sense of information surfeit. They are mechanisms of selection and sorting: alphabetical indexes, book reviews, library shelving schemes and card catalogues, encyclopedias, anthologies and digests, books of quotation and concordances and gazetteers. When Robert Burton held forth on all his \u201cnew news every day,\u201d his \u201cnew paradoxes, opinions, schisms, heresies, controversies in philosophy, religion, &c,\u201d it was by way of justifying his life\u2019s great project, *The Anatomy of Melancholy*, a rambling compendium of all previous knowledge. Four centuries earlier, the Dominican monk Vincent of Beauvais tried to set down his own version of everything that was known, creating one of the first medieval encyclopedias, *Speculum Maius*, \u201cThe Great Mirror\u201d\u2014his manuscripts organized into eighty books, 9,885 chapters. His justification: \u201cThe multitude of books, the shortness of time and the slipperiness of memory do not allow all things which are written to be equally retained in the mind.\u201d Ann Blair, a Harvard historian of early modern Europe, puts it simply: \u201cThe perception of an overabundance of books fueled the production of many more books.\u201d In their own way, too, the natural sciences such as botany arose in answer to information overload. The explosion of recognized species (and names) in the sixteenth century demanded new routines of standardized description. Botanical encyclopedias appeared, with glossaries and indexes. Brian Ogilvie sees the story of Renaissance botanists as \u201cdriven by the need to master the information overload that they had unwittingly produced.\u201d They created a \u201c*confusio rerum,*\u201d he says, \u201caccompanied by a *confusio verborum.*\u201d Confused mass of new things; confusion of words. Natural history was born to channel information.\n\nWhen new information technologies alter the existing landscape, they bring disruption: new channels and new dams rerouting the flow of irrigation and transport. The balance between creators and consumers is upset: writers and readers, speakers and listeners. Market forces are confused; information can seem too cheap and too expensive at the same time. The old ways of organizing knowledge no longer work. Who will search; who will filter? The disruption breeds hope mixed with fear. In the first days of radio Bertolt Brecht, hopeful, fearful, and quite obsessed, expressed this feeling aphoristically: \u201cA man who has something to say and finds no listeners is bad off. Even worse off are listeners who can\u2019t find anyone with something to say to them.\u201d The calculus always changes. Ask bloggers and tweeters: Which is worse, too many mouths or too many ears?\nEPILOGUE\n\n(The Return of Meaning)\n\nIt was inevitable that meaning would force its way back in.\n\n\u2014Jean-Pierre Dupuy (2000)\n\nTHE EXHAUSTION, the surfeit, the pressure of information have all been seen before. Credit Marshall McLuhan for this insight\u2014his most essential\u2014in 1962:\n\nWe are today as far into the electric age as the Elizabethans had advanced into the typographical and mechanical age. And we are experiencing the same confusions and indecisions which they had felt when living simultaneously in two contrasted forms of society and experience.\n\nBut as much as it is the same, this time it is different. We are a half century further along now and can begin to see how vast the scale and how strong the effects of connectedness.\n\nOnce again, as in the first days of the telegraph, we speak of the annihilation of space and time. For McLuhan this was prerequisite to the creation of global consciousness\u2014global knowing. \u201cToday,\u201d he wrote, \u201cwe have extended our central nervous systems in a global embrace, abolishing both space and time as far as our planet is concerned. Rapidly, we approach the final phase of the extensions of man\u2014the technological simulation of consciousness, when the creative process of knowing will be collectively and corporately extended to the whole of human society.\u201d Walt Whitman had said it better a century before:\n\nWhat whispers are these O lands, running ahead of you, passing under the seas?\nAre all nations communing? is there going to be but one heart to the globe?\n\nThe wiring of the world, followed hard upon by the spread of wireless communication, gave rise to romantic speculation about the birth of a new global organism. Even in the nineteenth century mystics and theologians began speaking of a shared mind or collective consciousness, formed through the collaboration of millions of people placed in communication with one another.\n\nSome went so far as to view this new creature as a natural product of continuing evolution\u2014a way for humans to fulfill their special destiny, after their egos had been bruised by Darwinism. \u201cIt becomes absolutely necessary,\u201d wrote the French philosopher \u00c9douard Le Roy in 1928, \u201cto place [man] above the lower plane of nature, in a position which enables him to dominate it.\u201d How? By creating the \u201cnoosphere\u201d\u2014the sphere of mind\u2014a climactic \u201cmutation\u201d in\nevolutionary history. His friend the Jesuit philosopher Pierre Teilhard de Chardin did even more to promote the noosphere, which he called a \u201cnew skin\u201d on the earth:\n\nDoes it not seem as though a great body is in the process of being born\u2014with its limbs, its nervous system, its centers of perception, its memory\u2014the very body of that great something to come which was to fulfill the aspirations that had been aroused in the reflective being by the freshly acquired consciousness of its interdependence with and responsibility for a whole in evolution?\n\nThat was a mouthful even in French, and less mystical spirits considered it bunkum (\u201cnonsense, tricked out with a variety of tedious metaphysical conceits,\u201d judged Peter Medawar), but many people were testing the same idea, not least among them the writers of science fiction. Internet pioneers a half century later liked it, too.\n\nH. G. Wells was known for his science fiction, but it was as a purposeful social critic that he published a little book in 1938, late in his life, with the title *World Brain*. There was nothing fanciful about what he wanted to promote: an improved educational system throughout the whole \u201cbody\u201d of humanity. Out with the hodgepodge of local fiefdoms: \u201cour multitude of unco-ordinated ganglia, our powerless miscellany of universities, research institutions, literatures with a purpose.\u201d In with \u201ca reconditioned and more powerful Public Opinion.\u201d His World Brain would rule the globe. \u201cWe do not want dictators, we do not want oligarchic parties or class rule, we want a widespread world intelligence conscious of itself.\u201d Wells believed that a new technology was poised to revolutionize the production and distribution of information: microfilm. Tiny pictures of printed materials could be made for less than a penny per page, and librarians from Europe and the United States met to discuss the possibilities in Paris in 1937 for a World Congress of Universal Documentation. New ways of indexing the literature would be needed, they realized. The British Museum embarked on a program of microfilming four thousand of its oldest books. Wells made this prediction: \u201cIn a few score years there will be thousands of workers at this business of ordering and digesting knowledge where now you have one.\u201d He admitted that he meant to be controversial and provocative. Attending the congress himself on behalf of England, he foresaw a \u201csort of cerebrum for humanity, a cerebral cortex which will constitute a memory and a perception of current reality for the whole human race.\u201d Yet he was imagining something mundane, as well as utopian: an encyclopedia. It would be a successor to the great national encyclopedias\u2014the French encyclopedia of Diderot, the *Britannica*, the German *Konversations-Lexikon* (he did not mention China\u2019s *Four Great Books of Song*)\u2014which had stabilized and equipped \u201cthe general intelligence.\u201d\n\nThis new world encyclopedia would transcend the static form of the book,\nprinted in volumes, said Wells. Under the direction of a wise professional staff (\"very important and distinguished men in the new world\"), it would be in a state of constant change\u2014\"a sort of mental clearinghouse for the mind, a depot where knowledge and ideas are received, sorted, summarized, digested, clarified and compared.\" Who knows whether Wells would recognize his vision in Wikipedia? The hurly-burly of competing ideas did not enter into it. His world brain was to be authoritative, but not centralized.\n\nIt need not be vulnerable as a human head or a human heart is vulnerable. It can be reproduced exactly and fully, in Peru, China, Iceland, Central Africa.... It can have at once the concentration of a craniate animal and the diffused vitality of an amoeba.\n\nFor that matter, he said, \"It might have the form of a network.\"\n\nIt is not the amount of knowledge that makes a brain. It is not even the distribution of knowledge. It is the interconnectedness. When Wells used the word network\u2014a word he liked very much\u2014it retained its original, physical meaning for him, as it would for anyone in his time. He visualized threads or wires interlacing: \"A network of marvellously gnarled and twisted stems bearing little leaves and blossoms\"; \"an intricate network of wires and cables.\" For us that sense is almost lost; a network is an abstract object, and its domain is information.\n\nThe birth of information theory came with its ruthless sacrifice of meaning\u2014the very quality that gives information its value and its purpose. Introducing *The Mathematical Theory of Communication*, Shannon had to be blunt. He simply declared meaning to be \"irrelevant to the engineering problem.\" Forget human psychology; abandon subjectivity.\n\nHe knew there would be resistance. He could hardly deny that messages can have meaning, \"that is, they refer to or are correlated according to some system with certain physical or conceptual entities.\" (Presumably a \"system with certain physical or conceptual entities\" would be the world and its inhabitants, the kingdom and the power and the glory, amen.) For some, this was just too cold. There was Heinz von Foerster at one of the early cybernetics conferences, complaining that information theory was merely about \"beep beeps,\" saying that only when understanding begins, in the human brain, \"then information is born\u2014it's not in the beeps.\" Others dreamed of extending information theory with a semantic counterpart. Meaning, as ever, remained hard to pin down. \"I know an uncouth region,\" wrote Borges of the Library of Babel, \"whose librarians repudiate the vain and superstitious custom of finding a meaning in books and equate it with that of finding a meaning in dreams or in the chaotic lines of one\u2019s palm.\"\n\nEpistemologists cared about knowledge, not beeps and signals. No one would have bothered to make a philosophy of dots and dashes or puffs of smoke or\nelectrical impulses. It takes a human\u2014or, let\u2019s say, a \u201ccognitive agent\u201d\u2014to take a signal and turn it into information. \u201cBeauty is in the eye of the beholder, and information is in the head of the receiver,\u201d says Fred Dretske. At any rate that is a common view, in epistemology\u2014that \u201cwe invest stimuli with meaning, and apart from such investment, they are informationally barren.\u201d But Dretske argues that distinguishing information and meaning can set a philosopher free. The engineers have provided an opportunity and a challenge: to understand how meaning can evolve; how life, handling and coding information, progresses to interpretation, belief, and knowledge.\n\nStill, who could love a theory that gives false statements as much value as true statements (at least, in terms of quantity of information)? It was mechanistic. It was desiccated. A pessimist, looking backward, might call it a harbinger of a soulless Internet at its worst. \u201cThe more we \u2018communicate\u2019 the way we do, the more we create a hellish world,\u201d wrote the Parisian philosopher\u2014also a historian of cybernetics\u2014Jean-Pierre Dupuy.\n\nI take \u201chell\u201d in its theological sense, i.e., a place which is void of grace\u2014the undeserved, unnecessary, surprising, unforeseen. A paradox is at work here: ours is a world about which we pretend to have more and more information but which seems to us increasingly devoid of meaning.\n\nThat hellish world, devoid of grace\u2014has it arrived? A world of information glut and gluttony; of bent mirrors and counterfeit texts; scurrilous blogs, anonymous bigotry, banal messaging. Incessant chatter. The false driving out the true.\n\nThat is not the world I see.\n\nIt was once thought that a perfect language should have an exact one-to-one correspondence between words and their meanings. There should be no ambiguity, no vagueness, no confusion. Our earthly Babel is a falling off from the lost speech of Eden: a catastrophe and a punishment. \u201cI imagine,\u201d writes the novelist Dexter Palmer, \u201cthat the entries of the dictionary that lies on the desk in God\u2019s study must have one-to-one correspondences between the words and their definitions, so that when God sends directives to his angels, they are completely free from ambiguity. Each sentence that He speaks or writes must be perfect, and therefore a miracle.\u201d We know better now. With or without God, there is no perfect language.\n\nLeibniz thought that if natural language could not be perfect, at least the calculus could: a language of symbols rigorously assigned. \u201cAll human thoughts might be entirely resolvable into a small number of thoughts considered as primitive.\u201d These could then be combined and dissected mechanically, as it were. \u201cOnce this had been done, whoever uses such characters would either never make an error, or, at least, would have the possibility of immediately recognizing his mistakes, by using the simplest of tests.\u201d G\u00f6del ended that dream.\nOn the contrary, the idea of perfection is contrary to the nature of language. Information theory has helped us understand that\u2014or, if you are a pessimist, forced us to understand it. \u201cWe are forced to see,\u201d Palmer continues, that words are not themselves ideas, but merely strings of ink marks; we see that sounds are nothing more than waves. In a modern age without an Author looking down on us from heaven, language is not a thing of definite certainty, but infinite possibility; without the comforting illusion of meaningful order we have no choice but to stare into the face of meaningless disorder; without the feeling that meaning can be certain, we find ourselves overwhelmed by all the things that words might mean.\n\nInfinite possibility is good, not bad. Meaningless disorder is to be challenged, not feared. Language maps a boundless world of objects and sensations and combinations onto a finite space. The world changes, always mixing the static with the ephemeral, and we know that language changes, not just from edition to edition of the *Oxford English Dictionary* but from one moment to the next, and from one person to the next. Everyone\u2019s language is different. We can be overwhelmed or we can be emboldened.\n\nMore and more, the lexicon is in the network now\u2014preserved, even as it changes; accessible and searchable. Likewise, human knowledge soaks into the network, into the cloud. The web sites, the blogs, the search engines and encyclopedias, the analysts of urban legends and the debunkers of the analysts. Everywhere, the true rubs shoulders with the false. No form of digital communication has earned more mockery than the service known as Twitter\u2014banality shrink-wrapped, enforcing triviality by limiting all messages to 140 characters. The cartoonist Garry Trudeau twittered satirically in the guise of an imaginary newsman who could hardly look up from his twittering to gather any news. But then, eyewitness Twitter messages provided emergency information and comfort during terrorist attacks in Mumbai in 2008, and it was Twitter feeds from Tehran that made the Iranian protests visible to the world in 2009. The aphorism is a form with an honorable history. I barely twitter myself, but even this odd medium, microblogging so quirky and confined, has its uses and its enchantment. By 2010 Margaret Atwood, a master of a longer form, said she had been \u201csucked into the Twittersphere like Alice down the rabbit hole.\u201d\n\nIs it signaling, like telegraphs? Is it Zen poetry? Is it jokes scribbled on the washroom wall? Is it John Hearts Mary carved on a tree? Let\u2019s just say it\u2019s communication, and communication is something human beings like to do.\n\nShortly thereafter, the Library of Congress, having been founded to collect every book, decided to preserve every tweet, too. Possibly undignified, and probably redundant, but you never know. It is human communication.\n\nAnd the network has learned a few things that no individual could ever know. It identifies CDs of recorded music by looking at the lengths of their individual\ntracks and consulting a vast database, formed by accretion over years, by the shared contributions of millions of anonymous users. In 2007 this database revealed something that had eluded distinguished critics and listeners: that more than one hundred recordings released by the late English pianist Joyce Hatto\u2014music by Chopin, Beethoven, Mozart, Liszt, and others\u2014were actually stolen performances by other pianists. MIT established a Center for Collective Intelligence, devoted to finding group wisdom and \u201charnessing\u201d it. It remains difficult to know when and how much to trust the *wisdom of crowds*\u2014the title of a 2004 book by James Surowiecki, to be distinguished from the *madness of crowds* as chronicled in 1841 by Charles Mackay, who declared that people \u201cgo mad in herds, while they recover their senses slowly, and one by one.\u201d Crowds turn all too quickly into mobs, with their time-honored manifestations: manias, bubbles, lynch mobs, flash mobs, crusades, mass hysteria, herd mentality, goose-stepping, conformity, groupthink\u2014all potentially magnified by network effects and studied under the rubric of information cascades. Collective judgment has appealing possibilities; collective self-deception and collective evil have already left a cataclysmic record. But knowledge in the network is different from group decision making based on copying and parroting. It seems to develop by accretion; it can give full weight to quirks and exceptions; the challenge is to recognize it and gain access to it. In 2008, Google created an early warning system for regional flu trends based on data no firmer than the incidence of Web searches for the word *flu*; the system apparently discovered outbreaks a week sooner than the Centers for Disease Control and Prevention. This was Google\u2019s way: it approached classic hard problems of artificial intelligence\u2014machine translation and voice recognition\u2014not with human experts, not with dictionaries and linguists, but with its voracious data mining of trillions of words in more than three hundred languages. For that matter, its initial approach to searching the Internet relied on the harnessing of collective knowledge.\n\nHere is how the state of search looked in 1994. Nicholson Baker\u2014in a later decade a Wikipedia obsessive; back then the world\u2019s leading advocate for the preservation of card catalogues, old newspapers, and other apparently obsolete paper\u2014sat at a terminal in a University of California library and typed, BROWSE SU[BJECT] CENSORSHIP. He received an error message,\n\nLONG SEARCH: Your search consists of one or more very common words, which will retrieve over 800 headings and take a long time to complete,\n\nand a knuckle rapping:\n\nLong searches slow the system down for everyone on the catalog and often do not produce useful results. Please type HELP or see a reference librarian for assistance.\n\nAll too typical. Baker mastered the syntax needed for Boolean searches with complexes of ANDs and ORs and NOTs, to little avail. He cited research on\nscreen fatigue and search failure and information overload and admired a theory that electronic catalogues were \u201cin effect, conducting a program of \u2018aversive operant conditioning\u2019\u201d against online search.\n\nHere is how the state of search looked two years later, in 1996. The volume of Internet traffic had grown by a factor of ten each year, from 20 terabytes a month worldwide in 1994 to 200 terabytes a month in 1995, to 2 petabytes in 1996. Software engineers at the Digital Equipment Corporation\u2019s research laboratory in Palo Alto, California, had just opened to the public a new kind of search engine, named AltaVista, continually building and revising an index to every page it could find on the Internet\u2014at that point, tens of millions of them. A search for the phrase truth universally acknowledged and the name Darcy produced four thousand matches. Among them:\n\n- The complete if not reliable text of Pride and Prejudice, in several versions, stored on computers in Japan, Sweden, and elsewhere, downloadable free or, in one case, for a fee of $2.25.\n- More than one hundred answers to the question, \u201cWhy did the chicken cross the road?\u201d including \u201cJane Austen: Because it is a truth universally acknowledged that a single chicken, being possessed of a good fortune and presented with a good road, must be desirous of crossing.\u201d\n- The statement of purpose of the Princeton Pacific Asia Review: \u201cThe strategic importance of the Asia Pacific is a truth universally acknowledged \u2026\u201d\n- An article about barbecue from the Vegetarian Society UK: \u201cIt is a truth universally acknowledged among meat-eaters that \u2026\u201d\n- The home page of Kevin Darcy, Ireland. The home page of Darcy Cremer, Wisconsin. The home page and boating pictures of Darcy Morse. The vital statistics of Tim Darcy, Australian footballer. The r\u00e9sum\u00e9 of Darcy Hughes, a fourteen-year-old yard worker and babysitter in British Columbia.\n\nTrivia did not daunt the compilers of this ever-evolving index. They were acutely aware of the difference between making a library catalogue\u2014its target fixed, known, and finite\u2014and searching a world of information without boundaries or limits. They thought they were onto something grand. \u201cWe have a lexicon of the current language of the world,\u201d said the project manager, Allan Jennings.\n\nThen came Google. Brin and Page moved their fledgling company from their Stanford dorm rooms into offices in 1998. Their idea was that cyberspace possessed a form of self-knowledge, inherent in the links from one page to another, and that a search engine could exploit this knowledge. As other scientists\nhad done before, they visualized the Internet as a graph, with nodes and links: by early 1998, 150 million nodes joined by almost 2 billion links. They considered each link as an expression of value\u2014a recommendation. And they recognized that all links are not equal. They invented a recursive way of reckoning value: the rank of a page depends on the value of its incoming links; the value of a link depends on the rank of its containing page. Not only did they invent it, they published it. Letting the Internet know how Google worked did not hurt Google\u2019s ability to leverage the Internet\u2019s knowledge.\n\nAt the same time, the rise of this network of all networks was inspiring new theoretical work on the topology of interconnectedness in very large systems. The science of networks had many origins and evolved along many paths, from pure mathematics to sociology, but it crystallized in the summer of 1998, with the publication of a letter to *Nature* from Duncan Watts and Steven Strogatz. The letter had three things that combined to make it a sensation: a vivid catchphrase, a nice result, and a surprising assortment of applications. It helped that one of the applications was All the World\u2019s People. The catchphrase was *small world*. When two strangers discover that they have a mutual friend\u2014an unexpected connection\u2014they may say, \u201cIt\u2019s a small world,\u201d and it was in this sense that Watts and Strogatz talked about small-world networks.\n\nThe defining quality of a small-world network is the one unforgettably captured by John Guare in his 1990 play, *Six Degrees of Separation*. The canonical explanation is this:\n\nI read somewhere that everybody on this planet is separated by only six other people. Six degrees of separation. Between us and everyone else on this planet. The President of the United States. A gondolier in Venice. Fill in the names.\n\nThe idea can be traced back to a 1967 social-networking experiment by the Harvard psychologist Stanley Milgram and, even further, to a 1929 short story by a Hungarian writer, Frigyes Karinthy, titled \u201cL\u00e1ncszemek\u201d\u2014*Chains*. Watts and Strogatz took it seriously: it seems to be true, and it is counterintuitive, because in the kinds of networks they studied, nodes tended to be highly clustered. They are cliquish. You may know many people, but they tend to be your neighbors\u2014in a social space, if not literally\u2014and they tend to know mostly the same people. In the real world, clustering is ubiquitous in complex networks: neurons in the brain, epidemics of infectious disease, electric power grids, fractures and channels in oil-bearing rock. Clustering alone means fragmentation: the oil does not flow, the epidemics sputter out. Faraway strangers remain estranged.\n\nBut some nodes may have distant links, and some nodes may have an exceptional degree of connectivity. What Watts and Strogatz discovered in their mathematical models is that it takes astonishingly few of these exceptions\u2014just a few distant links, even in a tightly clustered network\u2014to collapse the average\nseparation to almost nothing and create a small world. One of their test cases was a global epidemic: \u201cInfectious diseases are predicted to spread much more easily and quickly in a small world; the alarming and less obvious point is how few short cuts are needed to make the world small.\u201d A few sexually active flight attendants might be enough.\n\nIn cyberspace, almost everything lies in the shadows. Almost everything is connected, too, and the connectedness comes from a relatively few nodes, especially well linked or especially well trusted. However, it is one thing to prove that every node is close to every other node; that does not provide a way of finding the path between them. If the gondolier in Venice cannot find his way to the president of the United States, the mathematical existence of their connection may be small comfort. John Guare understood this, too; the next part of his *Six Degrees of Separation* explanation is less often quoted:\n\nI find that A) tremendously comforting that we\u2019re so close, and B) like Chinese water torture that we\u2019re so close. Because you have to find the right six people to make the connection.\n\nThere is not necessarily an algorithm for that.\n\nThe network has a structure, and that structure stands upon a paradox. Everything is close, and everything is far, at the same time. This is why cyberspace can feel not just crowded but lonely. You can drop a stone into a well and never hear a splash.\n\nNo *deus ex machina* waits in the wings; no man behind the curtain. We have no Maxwell\u2019s demon to help us filter and search. \u201cWe want the Demon, you see,\u201d wrote Stanislaw Lem, \u201cto extract from the dance of atoms only information that is genuine, like mathematical theorems, fashion magazines, blueprints, historical chronicles, or a recipe for ion crumpets, or how to clean and iron a suit of asbestos, and poetry too, and scientific advice, and almanacs, and calendars, and secret documents, and everything that ever appeared in any newspaper in the Universe, and telephone books of the future.\u201d As ever, it is the choice that *informs* us (in the original sense of that word). Selecting the genuine takes work; then forgetting takes even more work. This is the curse of omniscience: the answer to any question may arrive at the fingertips\u2014via Google or Wikipedia or IMDb or YouTube or Epicurious or the National DNA Database or any of their natural heirs and successors\u2014and still we wonder what we know.\n\nWe are all patrons of the Library of Babel now, and we are the librarians, too. We veer from elation to dismay and back. \u201cWhen it was proclaimed that the Library contained all books,\u201d Borges tells us, \u201cthe first impression was one of extravagant happiness. All men felt themselves to be the masters of an intact and secret treasure. There was no personal or world problem whose eloquent solution\ndid not exist in some hexagon. The universe was justified.\u201d Then come the lamentations. What good are the precious books that cannot be found? What good is complete knowledge, in its immobile perfection? Borges worries: \u201cThe certitude that everything has been written negates us or turns us into phantoms.\u201d To which, John Donne had replied long before, \u201cHe that desires to print a book, should much more desire, to be a book.\u201d\n\nThe library will endure; it is the universe. As for us, everything has not been written; we are not turning into phantoms. We walk the corridors, searching the shelves and rearranging them, looking for lines of meaning amid leagues of cacophony and incoherence, reading the history of the past and of the future, collecting our thoughts and collecting the thoughts of others, and every so often glimpsing mirrors, in which we may recognize creatures of the information.\nI am indebted and grateful to Charles H. Bennett, Gregory J. Chaitin, Neil J. A. Sloane, Susanna Cuyler, Betty Shannon, Norma Barzman, John Simpson, Peter Gilliver, Jimmy Wales, Joseph Straus, Craig Townsend, Janna Levin, Katherine Bouton, Dan Menaker, Esther Schor, Siobhan Roberts, Douglas Hofstadter, Martin Seligman, Christopher Fuchs, the late John Archibald Wheeler, Carol Hutchins, and Betty Alexandra Toole; also my agent, Michael Carlisle, and, as always, for his brilliance and his patience, my editor, Dan Frank.\nNotes\n\nPROLOGUE\n\n1 MY MIND WANDERS AROUND: Robert Price, \u201cA Conversation with Claude Shannon: One Man\u2019s Approach to Problem Solving,\u201d IEEE Communications Magazine 22 (1984): 126.\n\n2 TRANSISTOR \u2026 BIT: The committee got transistor from John R. Pierce; Shannon got bit from John W. Tukey.\n\n3 SHANNON SUPPOSEDLY BELONGED: Interview, Mary Elizabeth Shannon, 25 July 2006.\n\n4 BY 1948 MORE THAN 125 MILLION: Statistical Abstract of the United States 1950. More exactly: 3,186 radio and television broadcasting stations, 15,000 newspapers and periodicals, 500 million books and pamphlets, and 40 billion pieces of mail.\n\n5 CAMPBELL\u2019S SOLUTION: George A. Campbell, \u201cOn Loaded Lines in Telephonic Transmission,\u201d Philosophical Magazine 5 (1903): 313.\n\n6 \u201cTHEORIES PERMIT CONSCIOUSNESS TO \u2018JUMP OVER ITS OWN SHADOW\u2019 \u201d: Hermann Weyl, \u201cThe Current Epistemological Situation in Mathematics\u201d (1925), quoted in John L. Bell, \u201cHermann Weyl on Intuition and the Continuum,\u201d Philosophia Mathematica 8, no. 3 (2000): 261.\n\n7 \u201cSHANNON WANTS TO FEED NOT JUST DATA\u201d: Andrew Hodges, Alan Turing: The Enigma (London: Vintage, 1992), 251.\n\n8 \u201cOFF AND ON \u2026 I HAVE BEEN WORKING\u201d: Letter, Shannon to Vannevar Bush, 16 February 1939, in Claude Elwood Shannon, Collected Papers, ed. N. J. A. Sloane and Aaron D. Wyner (New York: IEEE Press, 1993), 455.\n\n9 \u201cNOWE USED FOR AN ELEGANT WORDE\u201d: Thomas Elyot, The Boke Named The Governour (1531), III: xxiv.\n\n10 \u201cMAN THE FOOD-GATHERER REAPPEARS\u201d: Marshall McLuhan, Understanding Media: The Extensions of Man (New York: McGraw-Hill, 1965), 302.\n\n11 \u201cWHAT LIES AT THE HEART OF EVERY LIVING THING\u201d: Richard Dawkins, The Blind Watchmaker (New York: Norton, 1986), 112.\n\n12 \u201cTHE INFORMATION CIRCLE BECOMES THE UNIT OF LIFE\u201d: Werner R. Loewenstein, The Touchstone of Life: Molecular Information, Cell Communication, and the Foundations of Life (New York: Oxford University Press, 1999), xvi.\n\n13 \u201cEVERY IT\u2014EVERY PARTICLE, EVERY FIELD OF FORCE\u201d: John Archibald Wheeler, \u201cIt from Bit,\u201d in At Home in the Universe (New York: American Institute of Physics, 1994), 296.\n14 \u201cTHE BIT COUNT OF THE COSMOS\u201d: John Archibald Wheeler, \u201cThe Search for Links,\u201d in Anthony J. G. Hey, ed., *Feynman and Computation* (Boulder, Colo.: Westview Press, 2002), 321.\n\n15 \u201cNO MORE THAN 10120 OPS\u201d: Seth Lloyd, \u201cComputational Capacity of the Universe,\u201d *Physical Review Letters* 88, no. 23 (2002).\n\n16 \u201cTOMORROW \u2026 WE WILL HAVE LEARNED TO UNDERSTAND\u201d: John Archibald Wheeler, \u201cIt from Bit,\u201d 298.\n\n17 \u201cIT IS HARD TO PICTURE THE WORLD BEFORE SHANNON\u201d: John R. Pierce, \u201cThe Early Days of Information Theory,\u201d *IEEE Transactions on Information Theory* 19, no. 1 (1973): 4.\n\n18 \u201cNUMBERS TOO, CHIEFEST OF SCIENCES\u201d: Aeschylus, *Prometheus Bound*, trans. H. Smyth, 460\u201361.\n\n19 \u201cTHE INVENTION OF PRINTING, THOUGH INGENIOUS\u201d: Thomas Hobbes, *Leviathan* (London: Andrew Crooke, 1660), ch. 4.\n\n1. DRUMS THAT TALK\n\n1 \u201cACROSS THE DARK CONTINENT SOUND\u201d: Irma Wassall, \u201cBlack Drums,\u201d *Phylon Quarterly* 4 (1943): 38.\n\n2 \u201cMAKE YOUR FEET COME BACK\u201d: Walter J. Ong, *Interfaces of the Word* (Ithaca, N.Y.: Cornell University Press, 1977), 105.\n\n3 IN 1730 FRANCIS MOORE SAILED EASTWARD: Francis Moore, *Travels into the Inland Parts of Africa* (London: J. Knox, 1767).\n\n4 \u201cSUDDENLY HE BECAME TOTALLY ABSTRACTED\u201d: William Allen and Thomas R. H. Thompson, *A Narrative of the Expedition to the River Niger in 1841*, vol. 2 (London: Richard Bentley, 1848), 393.\n\n5 A MISSIONARY, ROGER T. CLARKE: Roger T. Clarke, \u201cThe Drum Language of the Tumba People,\u201d *American Journal of Sociology* 40, no. 1 (1934): 34\u201348.\n\n6 \u201cVERY OFTEN ARRIVING BEFORE THE MESSENGERS\u201d: G. Suetonius Tranquillus, *The Lives of the Caesars*, trans. John C. Rolfe (Cambridge, Mass.: Harvard University Press, 1998), 87.\n\n7 \u201cYET WHO SO SWIFT COULD SPEED THE MESSAGE\u201d: Aeschylus, *Agamemnon*, trans. Charles W. Eliot, 335.\n\n8 A GERMAN HISTORIAN, RICHARD HENNIG: Gerard J. Holzmann and Bj\u00f6rn Pehrson, *The Early History of Data Networks* (Washington, D.C.: IEEE Computer Society, 1995), 17.\n\n9 A \u201cCONCEIT \u2026 WHISPERED THOROW THE WORLD\u201d: Thomas Browne, *Pseudoxia Epidemica: Or, Enquiries Into Very Many Received Tenents, and Commonly Presumed Truths*, 3rd ed. (London: Nath. Ekins, 1658), 59.\n\n10 IN ITALY A MAN TRIED TO SELL GALILEO: Galileo Galilei, *Dialogue Concerning the*\nTwo Chief World Systems: Ptolemaic and Copernican, trans. Stillman Drake (Berkeley, Calif.: University of California Press, 1967), 95.\n\n11 \u201cA SYSTEM OF SIGNS FOR LETTERS\u201d: Samuel F. B. Morse: His Letters and Journals, vol. 2, ed. Edward Lind Morse (Boston: Houghton Mifflin, 1914), 12.\n\n12 \u201cTHE DICTIONARY OR VOCABULARY CONSISTS OF WORDS\u201d: U. S. Patent 1647, 20 June 1840, 6.\n\n13 \u201cTHE SUPERIORITY OF THE ALPHABETIC MODE\u201d: Samuel F. B. Morse, letter to Leonard D. Gale, in Samuel F. B. Morse: His Letters and Journals, vol. 2, 65.\n\n14 \u201cWHEN THE CIRCUIT WAS CLOSED A LONGER TIME\u201d: Ibid., 64.\n\n15 \u201cTHE CLERKS WHO ATTEND AT THE RECORDING INSTRUMENT\u201d: \u201cThe Atlantic Telegraph,\u201d The New York Times, 7 August 1858.\n\n16 IN SEARCH OF DATA ON THE LETTERS\u2019 RELATIVE FREQUENCIES: Morse claimed that this was he, and their partisans differ. Cf. Samuel F. B. Morse: His Letters and Journals, vol. 2, 68; George P. Oslin, The Story of Telecommunications (Macon, Ga.: Mercer University Press, 1992), 24; Franklin Leonard Pope, \u201cThe American Inventors of the Telegraph,\u201d Century Illustrated Magazine (April 1888): 934; Kenneth Silverman, Lightning Man: The Accursed Life of Samuel F. B. Morse (New York: Knopf, 2003), 167.\n\n17 LONG AFTERWARD, INFORMATION THEORISTS CALCULATED: John R. Pierce, An Introduction to Information Theory: Symbols, Signals, and Noise, 2nd ed. (New York: Dover, 1980), 25.\n\n18 \u201cONLY A FEW DAYS AGO I READ IN THE TIMES\u201d: Robert Sutherland Rattray, \u201cThe Drum Language of West Africa: Part II,\u201d Journal of the Royal African Society 22, no. 88 (1923): 302.\n\n19 \u201cHE IS NOT REALLY A EUROPEAN\u201d: John F. Carrington, La Voix des tambours: comment comprendre le langage tambourin\u00e9 d\u2019Afrique (Kinshasa: Protestant d\u2019\u00c9dition et de Diffusion, 1974), 66, quoted in Walter J. Ong, Interfaces of the Word, 95.\n\n20 \u201cI MUST HAVE BEEN GUILTY MANY A TIME\u201d: John F. Carrington, The Talking Drums of Africa (London: Carey Kingsgate, 1949), 19.\n\n21 EVEN THE LIMITED DICTIONARY OF THE MISSIONARIES: Ibid., 33.\n\n22 \u201cAMONG PEOPLES WHO KNOW NOTHING OF WRITING\u201d: Robert Sutherland Rattray, \u201cThe Drum Language of West Africa: Part I,\u201d Journal of the Royal African Society 22, no. 87 (1923): 235.\n\n23 FOR THE YAUNDE, THE ELEPHANT: Theodore Stern, \u201cDrum and Whistle \u2018Languages\u2019: An Analysis of Speech Surrogates,\u201d American Anthropologist 59 (1957): 489.\n\n24 \u201cTHIS COUNTERSPELL MAY SAVE YOUR SOUL\u201d: James Merrill, \u201cEight Bits,\u201d in The Inner Room (New York: Knopf, 1988), 48.\n\n25 A PAPER BY A BELL LABS TELEPHONE ENGINEER: Ralph V. L. Hartley,\nThe Information\n\n\u201cTransmission of Information,\u201d *Bell System Technical Journal* 7 (1928): 535\u201363.\n\n26 HE SAW LOKELE YOUTH PRACTICING THE DRUMS LESS AND LESS: John F. Carrington, *The Talking Drums of Africa*, 83.\n\n27 A VISITOR FROM THE UNITED STATES FOUND HIM: Israel Shenker, \u201cBoomlay,\u201d *Time*, 22 November 1954.\n\n2. THE PERSISTENCE OF THE WORD\n\n1 \u201cODYSSEUS WEPT\u201d: Ward Just, *An Unfinished Season* (New York: Houghton Mifflin, 2004), 153.\n\n2 \u201cTRY TO IMAGINE\u201d: Walter J. Ong, *Orality and Literacy: The Technologizing of the Word* (London: Methuen, 1982), 31.\n\n3 THE PASTNESS OF THE PAST: Jack Goody and Ian Watt, \u201cThe Consequences of Literacy,\u201d *Comparative Studies in Society and History* 5, no. 3 (1963): 304\u201345.\n\n4 \u201cTHE OTHER EMINENT CATHOLIC-ELECTRONIC PROPHET\u201d: Frank Kermode, \u201cFree Fall,\u201d *New York Review of Books* 10, no. 5 (14 March 1968).\n\n5 \u201cHORSES AS AUTOMOBILES WITHOUT WHEELS\u201d: Walter J. Ong, *Orality and Literacy*, 12.\n\n6 \u201cLANGUAGE IN FACT BEARS THE SAME RELATIONSHIP\u201d: Jonathan Miller, *Marshall McLuhan* (New York: Viking, 1971), 100.\n\n7 \u201cFOR THIS INVENTION WILL PRODUCE FORGETFULNESS\u201d: Plato, *Phaedrus*, trans. Benjamin Jowett (Fairfield, Iowa: First World Library, 2008), 275a.\n\n8 \u201cTWO THOUSAND YEARS OF MANUSCRIPT CULTURE\u201d: Marshall McLuhan, \u201cCulture Without Literacy,\u201d in Eric McLuhan and Frank Zingrone, eds., *Essential McLuhan* (New York: Basic Books, 1996), 305.\n\n9 \u201cTHIS MIRACULOUS REBOUNDING OF THE VOICE\u201d: Pliny the Elder, *The Historie of the World*, vol. 2, trans. Philemon Holland (London: 1601), 581.\n\n10 \u201cTHE WRITTEN SYMBOL EXTENDS INFINITELY\u201d: Samuel Butler, *Essays on Life, Art, and Science* (Port Washington, N.Y.: Kennikat Press, 1970), 198.\n\n11 \u201cTHERE NEVER WAS A MAN\u201d: David Diringer and Reinhold Regensburger, *The Alphabet: A Key to the History of Mankind*, 3rd ed., vol. 1 (New York: Funk & Wagnalls, 1968), 166.\n\n12 \u201cIT WAS SOMETHING LIKE A THUNDER-CLAP\u201d: \u201cThe Alphabetization of Homer,\u201d in Eric Alfred Havelock and Jackson P. Hershbell, *Communication Arts in the Ancient World* (New York: Hastings House, 1978), 3.\n\n13 \u201cHAPPENS, UP TO THE PRESENT DAY\u201d: Aristotle, *Poetics*, trans. William Hamilton Fyfe (Cambridge, Mass.: Harvard University Press, 1953), 1447b.\n\n14 HAVELOCK DESCRIBED IT AS CULTURAL WARFARE: Eric A. Havelock, *Preface to*\nThe Information\n\nPlato (Cambridge, Mass.: Harvard University Press, 1963), 300\u2013301.\n\n15 \u201cA BEGINNING IS THAT WHICH ITSELF DOES NOT FOLLOW\u201d: Aristotle, Poetics, 1450b.\n\n16 \u201cTHE MULTITUDE CANNOT ACCEPT\u201d: Republic, 6.493e. Cf. in Eric A. Havelock, Preface to Plato, 282.\n\n17 \u201cLOSE THEMSELVES AND WANDER\u201d: Republic, 6.484b.\n\n18 \u201cTRYING FOR THE FIRST TIME IN HISTORY\u201d: Eric A. Havelock, Preface to Plato, 282.\n\n19 LOGIC DESCENDED FROM THE WRITTEN WORD: Not everyone agrees with all this. A counterargument: John Halverson, \u201cGoody and the Implosion of the Literacy Thesis,\u201d Man 27, no. 2 (1992): 301\u201317.\n\n20 IF IT IS POSSIBLE FOR NO MAN TO BE A HORSE: Aristotle, Prior Analytics, trans. A. J. Jenkinson, 1:3.\n\n21 \u201cWE KNOW THAT FORMAL LOGIC\u201d: Walter J. Ong, Orality and Literacy, 49.\n\n22 FIELDWORK OF THE RUSSIAN PSYCHOLOGIST: A. R. Luria, Cognitive Development, Its Cultural and Social Foundations (Cambridge, Mass.: Harvard University Press, 1976), 86.\n\n23 \u201cBASICALLY THE PEASANT WAS RIGHT\u201d: Walter J. Ong, Orality and Literacy, 53.\n\n24 \u201cIN THE INFANCY OF LOGIC\u201d: Benjamin Jowett, introduction to Plato\u2019s Theaetetus (Teddington, U.K.: Echo Library, 2006), 7.\n\n25 \u201cWHEN A WHITE HORSE IS NOT A HORSE\u201d: Gongsun Long, \u201cWhen a White Horse Is Not a Horse,\u201d trans. by A. C. Graham, in P. J. Ivanhoe et al., Readings in Classical Chinese Philosophy, 2nd ed. (Indianapolis, Ind.: Hackett Publishing, 2005), 363\u201366. Also A. C. Graham, Studies in Chinese Philosophy and Philosophical Literature, SUNY Series in Chinese Philosophy and Culture (Albany: State University of New York Press, 1990), 178.\n\n26 \u201cWRITING, LIKE A THEATER CURTAIN GOING UP\u201d: Julian Jaynes, The Origin of Consciousness in the Breakdown of the Bicameral Mind (Boston: Houghton Mifflin, 1977), 177.\n\n27 \u201cTO THE ASSYRIANS, THE CHALDEANS, AND EGYPTIANS\u201d: Thomas Sprat, The History of the Royal Society of London, for the Improving of Natural Knowledge, 3rd ed. (London: 1722), 5.\n\n28 \u201cTHIS PROCESS OF CONQUEST AND INFLUENCE\u201d: Julian Jaynes, The Origin of Consciousness in the Breakdown of the Bicameral Mind, 198.\n\n29 TO FORM LARGE NUMBERS, THE BABYLONIANS: Donald E. Knuth, \u201cAncient Babylonian Algorithms,\u201d Communications of the Association for Computing Machinery 15, no. 7 (1972): 671\u201377.\n\n30 \u201cIT WAS ASSUMED THAT THE BABYLONIANS\u201d: Asger Aaboe, Episodes from the Early History of Mathematics (New York: L. W. Singer, 1963), 5.\n\n31 \u201cOUR TASK CAN THEREFORE PROPERLY BE COMPARED\u201d: Otto Neugebauer, The Exact Sciences in Antiquity, 2nd ed. (Providence, R.I.: Brown University Press, 1957), 30 and 40\u2013\n32 \u201cA CISTERNS. THE HEIGHT IS 3,20\u201d: Donald E. Knuth, \u201cAncient Babylonian Algorithms,\u201d 672.\n\n33 \u201cFUNDAMENTALLY LETTERS ARE SHAPES\u201d: John of Salisbury, Metalogicon, I:13, quoted and translated by M. T. Clanchy, From Memory to Written Record, England, 1066-1307 (Cambridge, Mass.: Harvard University Press, 1979), 202.\n\n34 \u201cOH! ALL YE WHO SHALL HAVE HEARD\u201d: Ibid.\n\n35 \u201cI CANNOT HELP FEELING\u201d: Phaedrus, trans. Benjamin Jowett, 275d.\n\n36 \u201cWE ARE IN OUR CENTURY \u2018WINDING THE TAPE BACKWARD\u2019 \u201d: Marshall McLuhan, \u201cMedia and Cultural Change,\u201d in Essential McLuhan, 92.\n\n37 \u201cTHE LARGER THE NUMBER OF SENSES INVOLVED\u201d: Jonathan Miller, Marshall McLuhan, 3.\n\n38 \u201cACOUSTIC SPACE IS ORGANIC\u201d: Playboy interview, March 1969, in Essential McLuhan, 240.\n\n39 \u201cMEN LIVED UPON GROSS EXPERIENCE\u201d: Thomas Hobbes, Leviathan, or The Matter, Forme and Power of a Commonwealth, Ecclesiasticall, and Civill, (1651; repr., London: George Routledge and Sons, 1886), 299.\n\n40 \u201cMOST LITERATE PERSONS, WHEN YOU SAY\u201d: Walter J. Ong, \u201cThis Side of Oral Culture and of Print,\u201d Lincoln Lecture (1973), 2.\n\n41 \u201cIT IS DEMORALIZING TO REMIND ONESELF\u201d: Walter J. Ong, Orality and Literacy, 14.\n\n3. TWO WORDBOOKS\n\n1 \u201cIN SUCH BUSIE, AND ACTIVE TIMES\u201d: Thomas Sprat, The History of the Royal Society of London, for the Improving of Natural Knowledge, 3rd ed. (London: 1722), 42.\n\n2 A BOOK IN 1604 WITH A RAMBLING TITLE: Robert Cawdrey, A Table Alphabeticall (London: Edmund Weaver, 1604) may be found in the Bodleian Library; in a facsimile edition, Robert A. Peters, ed. (Gainesville, Fla.: Scholars\u2019 Facsimiles & Reprints, 1966); online via the University of Toronto Library; and, most satisfyingly, reprinted as John Simpson, ed., The First English Dictionary, 1604: Robert Cawdrey\u2019s A Table Alphabeticall (Oxford: Bodleian Library, 2007).\n\n3 A SINGLE 1591 PAMPHLET: Robert Greene, A Notable Discovery of Coosnage (1591; repr., Gloucester, U.K.: Dodo Press, 2008); Albert C. Baugh, A History of the English Language, 2nd ed. (New York: Appleton-Century-Crofts, 1957), 252.\n\n4 \u201cIT WERE A THING VERIE PRAISEWORTHIE\u201d: Richard Mulcaster, The First Part of the Elementarie Which Entreateth Chefelie of the Right Writing of Our English Tung (London: Thomas Vautroullier, 1582).\n5 \u201cSOME MEN SEEK SO FAR FOR OUTLANDISH ENGLISH\u201d: John Simpson, ed., *The First English Dictionary*, 41.\n\n6 \u201cNOT CONFORMING HIMSELF\u201d: John Strype, *Historical Collections of the Life and Acts of the Right Reverend Father in God, John Aylmer* (London: 1701), 129, quoted in John Simpson, ed., *The First English Dictionary*, 10.\n\n7 HE COPIED THE REMARKS ABOUT INKHORN TERMS: Gertrude E. Noyes, \u201cThe First English Dictionary, Cawdrey\u2019s *Table Alphabeticall*,\u201d *Modern Language Notes* 58, no. 8 (1943): 600.\n\n8 \u201cSO MORE KNOWLEDGE WILL BE BROUGHT INTO THIS LAND\u201d: Edmund Coote, *The English Schoole-maister* (London: Ralph Jackson & Robert Dexter, 1596), 2.\n\n9 \u201cFOR EXAMPLE I INTEND TO DISCUSS AMO\u201d: Lloyd W. Daly, *Contributions to a History of Alphabeticization in Antiquity and the Middle Ages* (Brussels: Latomus, 1967), 73.\n\n10 NOT UNTIL 1613 WAS THE FIRST ALPHABETICAL CATALOGUE: William Dunn Macray, *Annals of the Bodleian Library, Oxford, 1598\u20131867* (London: Rivingtons, 1868), 39.\n\n11 \u201cLET ME MENTION THAT THE WORDS OR NAMES\u201d: Gottfried Leibniz, *Unvorgreifliche Gedanken*, quoted and translated by Werner H\u00fcllen, *English Dictionaries 800\u20131700: The Topical Tradition* (Oxford: Clarendon Press, 1999), 16n.\n\n12 \u201cSAYWHAT, CORRUPTLY CALLED A DEFINITION\u201d: Ralph Lever, *The Arte of Reason* (London: H. Bynneman, 1573).\n\n13 \u201cDEFINITION \u2026 BEING NOTHING BUT MAKING ANOTHER UNDERSTAND\u201d: John Locke, *An Essay Concerning Human Understanding*, ch. 3, sect. 10.\n\n14 \u201cSO LONG AS MEN WERE IN FACT OBLIGED\u201d: Galileo, letter to Mark Welser, 4 May 1612, trans. Stillman Drake, in *Discoveries and Opinions of Galileo*, 92.\n\n15 \u201cI DO NOT DEFINE TIME, SPACE, PLACE, AND MOTION\u201d: Isaac Newton, *Philosophiae Naturalis Principia Mathematica*, trans. Andrew Motte (Scholium) 6.\n\n16 JOHN BULLOKAR, OTHERWISE LEFT AS FAINT A MARK: Jonathon Green, *Chasing the Sun: Dictionary Makers and the Dictionaries They Made* (New York: Holt, 1996), 181.\n\n17 \u201cWE REALLY DON\u2019T LIKE BEING PUSHED\u201d: Interview, John Simpson, 13 September 2006.\n\n18 \u201cDICTIONARY, A MALEVOLENT LITERARY DEVICE\u201d: Ambrose Bierce, *The Devil\u2019s Dictionary* (New York: Dover, 1993), 25.\n\n19 \u201cIN GIVING EXPLANATIONS I ALREADY HAVE TO USE LANGUAGE\u201d: Ludwig Wittgenstein, *Philosophical Investigations*, trans. G. E. M. Anscombe (New York: Macmillan, 1953), 47.\n\n20 \u201cTHE ENGLISH DICTIONARY, LIKE THE ENGLISH CONSTITUTION\u201d: James A. H. Murray, \u201cThe Evolution of English Lexicography,\u201d Romanes Lecture (1900).\n\n21 W. H. AUDEN DECLARED: Peter Gilliver et al., *The Ring of Words: Tolkien and the Oxford*\nThe Information\n\nEnglish Dictionary (Oxford: Oxford University Press, 2006), 82.\n\n22 ANTHONY BURGESS WHINGED: Anthony Burgess, \u201cOED +,\u201d in But Do Blondes Prefer Gentlemen? Homage to Qwert Yuiop and Other Writings (New York: McGraw-Hill, 1986), 139. He could not let go, either. In a later essay, \u201cAmeringlish,\u201d he complained again.\n\n23 \u201cEVERY FORM IN WHICH A WORD\u201d: \u201cWriting the OED: Spellings,\u201d Oxford English Dictionary, http://www.oed.com/about/writing/spellings.html (accessed 6 April 2007).\n\n24 \u201cWHICH, WHILE IT WAS EMPLOYED IN THE CULTIVATION\u201d: Samuel Johnson, preface to A Dictionary of the English Language (1755).\n\n25 WE POSSESS NOW A MORE COMPLETE DICTIONARY: John Simpson, ed., The First English Dictionary, 24.\n\n26 \u201cWHAT I SHALL HEREAFTER CALL MONDEGREENS\u201d: \u201cThe Death of Lady Mondegreen,\u201d Harper\u2019s Magazine, November 1954, 48.\n\n27 \u201cTHE INTERESTING THING ABOUT MONDEGREENS\u201d: Steven Pinker, The Language Instinct: How the Mind Creates Language (New York: William Morrow, 1994), 183.\n\n4. TO THROW THE POWERS OF THOUGHT INTO WHEEL-WORK\n\n1 The original writings of Charles Babbage and, to a lesser extent, Ada Lovelace are increasingly accessible. The comprehensive, thousand-dollar, eleven-volume edition, The Works of Charles Babbage, edited by Martin Campbell-Kelly, was published in 1989. Online, the full texts of Babbage\u2019s Passages from the Life of a Philosopher (1864), On the Economy of Machinery and Manufactures (1832), and The Ninth Bridgewater Treatise (1838) can now be found in editions scanned from libraries by Google\u2019s book program. Not yet available there (as of 2010), but also useful, is his son\u2019s volume, Babbage\u2019s Calculating Engines: Being a Collection of Papers Relating to Them (1889). As interest grew during the era of computing, much of the useful material in these books was reprinted in collections; most valuable are Charles Babbage and His Calculating Engines, edited by Philip Morrison and Emily Morrison (1961); and Anthony Hyman\u2019s Science and Reform: Selected Works of Charles Babbage (1989). Other manuscripts were published in J. M. Dubbey, The Mathematical Work of Charles Babbage (1978). The notes that follow refer to one or more of these sources, depending on what seems most useful for the reader. The translation and astounding \u201cnotes\u201d on L. F. Menabrea\u2019s \u201cSketch of the Analytical Engine\u201d by Ada Augusta, Countess of Lovelace, have been made available online at http://www.fourmilab.ch/babbage/sketch.html thanks to John Walker; they are also reproduced in the Morrisons\u2019 collection. As for the Lovelace letters and papers, they are in the British Library, the Bodleian, and elsewhere, but many have been published by Betty Alexandra Toole in Ada: The Enchantress of Numbers (1992 and 1998); where possible I try to cite the published versions.\n\n2 \u201cLIGHT ALMOST SOLAR HAS BEEN EXTRACTED\u201d: Charles Babbage, On the Economy of Machinery and Manufactures (1832), 300; reprinted in Science and Reform: Selected Works of Charles Babbage, ed. Anthony Hyman (Cambridge: Cambridge University Press, 1989), 200.\n3 THE TIMES OBITUARIST: \u201cThe Late Mr. Charles Babbage, F.R.S.,\u201d *The Times* (London), 23 October 1871. Babbage\u2019s crusade against organ-grinders and hurdy-gurdies was not in vain; a new law against street music in 1864 was known as Babbage\u2019s Act. Cf. Stephanie Pain, \u201cMr. Babbage and the Buskers,\u201d *New Scientist* 179, no. 2408 (2003): 42.\n\n4 \u201cHE SHOWED A GREAT DESIRE TO INQUIRE\u201d: N. S. Dodge, \u201cCharles Babbage,\u201d *Smithsonian Annual Report of 1873*, 162\u201397, reprinted in *Annals of the History of Computing* 22, no. 4 (October\u2013December 2000), 20.\n\n5 NOT \u201cTHE MANUAL LABOR OF ROWING\u201d: Charles Babbage, *Passages from the Life of a Philosopher* (London: Longman, Green, Longman, Roberts, & Green, 1864), 37.\n\n6 \u201c\u2018THE TALL GENTLEMAN IN THE CORNER\u2019 \u201d: Ibid., 385\u201386.\n\n7 \u201cTHOSE WHO ENJOY LEISURE\u201d: Charles Babbage, *On the Economy of Machinery and Manufactures*, 4th ed. (London: Charles Knight, 1835), v.\n\n8 HE COMPUTED THE COST OF EACH PHASE: Ibid., 146.\n\n9 \u201cAT THE EXPENSE OF THE NATION\u201d: Henry Prevost Babbage, ed., *Babbage\u2019s Calculating Engines: Being a Collection of Papers Relating to Them; Their History and Construction* (London: E. & F. N. Spon, 1889), 52.\n\n10 \u201cON TWO OCCASIONS I HAVE BEEN ASKED\u201d: Charles Babbage, *Passages from the Life of a Philosopher*, 67.\n\n11 TABLE OF CONSTANTS OF THE CLASS MAMMALIA: *Charles Babbage and His Calculating Engines: Selected Writings*, ed. Philip Morrison and Emily Morrison (New York: Dover Publications, 1961), xxiii.\n\n12 \u201cLO! THE RAPTURED ARITHMETICIAN!\u201d: \u00c9lie de Joncourt, *De Natura Et Praeclaro Usu Simplicissimae Speciei Numerorum Trigonalium* (Hagae Comitum: Husson, 1762), quoted in Charles Babbage, *Passages from the Life of a Philosopher*, 54.\n\n13 \u201cTO ASTROLOGERS, LAND-MEASURERS, MEASURERS OF TAPESTRY\u201d: Quoted in Elizabeth L. Eisenstein, *The Printing Press as an Agent of Change: Communications and Cultural Transformations in Early-Modern Europe* (Cambridge: Cambridge University Press, 1979), 468.\n\n14 THIRTY-FOUR MEN AND ONE WOMAN: Mary Croarken, \u201cMary Edwards: Computing for a Living in 18th-Century England,\u201d *IEEE Annals of the History of Computing* 25, no. 4 (2003): 9\u201315; and\u2014with fascinating detective work\u2014Mary Croarken, \u201cTabulating the Heavens: Computing the Nautical Almanac in 18th-Century England,\u201d *IEEE Annals of the History of Computing* 25, no. 3 (2003): 48\u201361.\n\n15 \u201cLOGARITHMES ARE NUMBERS INVENTED\u201d: Henry Briggs, *Logarithmicall Arithmetike: Or Tables of Logarithmes for Absolute Numbers from an Unite to 100000* (London: George Miller, 1631), 1.\n\n16 \u201cTAKE AWAY ALL THE DIFFICULTIE\u201d: John Napier, \u201cDedicatore,\u201d in *A Description of the Admirable Table of Logarithmes*, trans. Edward Wright (London: Nicholas Okes, 1616), 3.\n17 \u201cNAPER, LORD OF MARKINSTON, HATH SET\u201d: Henry Briggs to James Ussher, 10 March 1615, quoted by Graham Jagger in Martin Campbell-Kelly et al., eds., *The History of Mathematical Tables: From Sumer to Spreadsheets* (Oxford: Oxford University Press, 2003), 56.\n\n18 A QUARTER HOUR OF SILENCE: \u201cSPENT, EACH BEHOLDING OTHER\u201d: William Lilly, *Mr. William Lilly\u2019s History of His Life and Times, from the Year 1602 to 1681* (London: Charles Baldwyn, 1715), 236.\n\n19 *POLE STARRE, GIRDLE OF ANDROMEDA, WHALES BELLIE*: Henry Briggs, *Logarithmicall Arithmetike*, 52.\n\n20 \u201cIT MAY BE HERE ALSO NOTED THAT THE USE OF A 100 POUND\u201d: Ibid., 11.\n\n21 \u201cA SCOTTISH BARON HAS APPEARED ON THE SCENE\u201d: Ole I. Franksen, \u201cIntroducing \u2018Mr. Babbage\u2019s Secret,\u2019\u201d *APL Quote Quad* 15, no. 1 (1984): 14.\n\n22 THE MAJORITY OF HUMAN COMPUTATION: Michael Williams, *A History of Computing Technology* (Washington, D.C.: IEEE Computer Society, 1997), 105.\n\n23 \u201cIT IS NOT FITTING FOR A PROFESSOR\u201d: Michael M\u00e4stlin, quoted in Ole I. Franksen, \u201cIntroducing \u2018Mr. Babbage\u2019s Secret,\u2019\u201d 14.\n\n24 \u201cTHIS LADY ATTITUDINIZED\u201d: Charles Babbage, *Passages from the Life of a Philosopher*, 17.\n\n25 INSTALLED IT ON A PEDESTAL: Simon Schaffer, \u201cBabbage\u2019s Dancer,\u201d in Francis Spufford and Jenny Uglow, eds., *Cultural Babbage: Technology, Time and Invention* (London: Faber and Faber, 1996), 58.\n\n26 FROM A SPECIALTY BOOKSELLER: Charles Babbage, *Passages from the Life of a Philosopher*, 26\u201327.\n\n27 \u201cA SIN AGAINST THE MEMORY OF NEWTON\u201d: W. W. Rouse Ball, *A History of the Study of Mathematics at Cambridge* (Cambridge: Cambridge University Press, 1889), 117.\n\n28 \u201cTHE DOTS OF NEWTON, THE D\u2019S OF LEIBNITZ\u201d: *Charles Babbage and His Calculating Engines*, 23.\n\n29 \u201cTO THINK AND REASON IN A NEW LANGUAGE\u201d: Ibid., 31.\n\n30 \u201cA NEW KIND OF AN INSTRUMENT INCREASING THE POWERS OF REASON\u201d: C. Gerhardt, ed., *Die Philosophischen Schriften von Gottfried Wilhelm Leibniz*, vol. 7 (Berlin: Olms, 1890), 12, quoted by Kurt G\u00f6del in \u201cRussell\u2019s Mathematical Logic\u201d (1944), in *Kurt G\u00f6del: Collected Works*, vol. 2, ed. Solomon Feferman (New York: Oxford University Press, 1986), 140.\n\n31 \u201cBY THE APPARENT IMPOSSIBILITY OF ARRANGING SIGNS\u201d: Charles Babbage, *Passages from the Life of a Philosopher*, 25.\n\n32 \u201cTHE DOT-AGE OF THE UNIVERSITY\u201d: *Charles Babbage and His Calculating Engines*, 25.\n\n33 \u201cWE HAVE NOW TO RE-IMPORT THE EXOTIC\u201d: Charles Babbage, *Memoirs of the Analytical Society*, preface (1813), in Anthony Hyman, ed., *Science and Reform: Selected Works*\nof Charles Babbage (Cambridge: Cambridge University Press, 1989), 15\u201316.\n\n34 \u201cTHE BROWS OF MANY A CAMBRIDGE MODERATOR\u201d: Agnes M. Clerke, The Herschels and Modern Astronomy (New York: Macmillan, 1895), 144.\n\n35 \u201cEVERY MEMBER SHALL COMMUNICATE HIS ADDRESS\u201d: Charles Babbage, Passages from the Life of a Philosopher, 34.\n\n36 \u201cI AM THINKING THAT ALL THESE TABLES\u201d: Ibid., 42.\n\n37 \u201cWHETHER, WHEN THE NUMBERS\u201d: Ibid., 41.\n\n38 \u201cWE MAY GIVE FINAL PRAISE\u201d: \u201cMachina arithmetica in qua non additio tantum et subtractio sed et multipicatio nullo, divisio vero paene nullo animi labore peragantur,\u201d trans. M. Kormes, 1685, in D. E. Smith, A Source Book in Mathematics (New York: McGraw-Hill, 1929), 173.\n\n39 \u201cINTOLERABLE LABOUR AND FATIGUING MONOTONY\u201d: Charles Babbage, A Letter to Sir Humphry Davy on the Application of Machinery to the Purpose of Calculating and Printing Mathematical Tables (London: J. Booth & Baldwain, Cradock & Joy, 1822), 1.\n\n40 \u201cI WILL YET VENTURE TO PREDICT\u201d: Babbage to David Brewster, 6 November 1822, in Martin Campbell-Kelly, ed., The Works of Charles Babbage (New York: New York University Press, 1989) 2:43.\n\n41 \u201cCONFUSION IS WORSE CONFOUNDED\u201d: Dionysius Lardner, \u201cBabbage\u2019s Calculating Engine,\u201d Edinburgh Review 59, no. 120 (1834), 282; and Edward Everett, \u201cThe Uses of Astronomy,\u201d in Orations and Speeches on Various Occasions (Boston: Little, Brown, 1870), 447.\n\n42 250 SETS OF LOGARITHMIC TABLES: Martin Campbell-Kelly, \u201cCharles Babbage\u2019s Table of Logarithms (1827),\u201d Annals of the History of Computing 10 (1988): 159\u201369.\n\n43 \u201cWOULD AFFORD A CURIOUS SUBJECT OF METAPHYSICAL SPECULATION\u201d: Dionysius Lardner, \u201cBabbage\u2019s Calculating Engines,\u201d 282.\n\n44 \u201cIF PAPA FAIL TO INFORM HIM\u201d: Charles Babbage, Passages from the Life of a Philosopher, 52.\n\n45 \u201cIF THIS COULD BE ACCOMPLISHED\u201d: Ibid., 60\u201362.\n\n46 \u201cIT IS SCARCELY TOO MUCH TO ASSERT\u201d: Babbage to John Herschel, 10 August 1814, quoted in Anthony Hyman, Charles Babbage: Pioneer of the Computer (Princeton, N.J.: Princeton University Press, 1982), 31.\n\n47 \u201cIT IS WITH NO INCONSIDERABLE DEGREE OF RELUCTANCE\u201d: David Brewster to Charles Babbage, 3 July 1821, quoted in J. M. Dubbey, The Mathematical Work of Charles Babbage (Cambridge: Cambridge University Press, 1978), 94.\n\n48 \u201cLOGARITHMIC TABLES AS CHEAP AS POTATOES\u201d: Babbage to John Herschel, 27 June 1823, quoted in Anthony Hyman, Charles Babbage, 53.\n\n49 \u201cPROPOSITION TO REDUCE ARITHMETIC TO THE DOMINION OF MECHANISM\u201d: Dionysius Lardner, \u201cBabbage\u2019s Calculating Engines,\u201d 264.\n50 \u201cTHE QUESTION IS SET TO THE INSTRUMENT\u201d: \u201cAddress of Presenting the Gold Medal of the Astronomical Society to Charles Babbage,\u201d in *Charles Babbage and His Calculating Engines*, 219.\n\n51 LARDNER\u2019S OWN EXPLANATION OF \u201cCARRYING\u201d: Dionysius Lardner, \u201cBabbage\u2019s Calculating Engines,\u201d 288\u2013300.\n\n52 IN 1826 HE PROUDLY REPORTED TO THE ROYAL SOCIETY: Charles Babbage, \u201cOn a Method of Expressing by Signs the Action of Machinery,\u201d *Philosophical Transactions of the Royal Society of London* 116, no. 3 (1826): 250\u201365.\n\n53 \u201cI NEED HARDLY POINT OUT TO YOU THAT THIS CALCULATION\u201d: Quoted in *Charles Babbage and His Calculating Engines*, xxiii. The Morrisons point out that Tennyson apparently did change \u201cminute\u201d to \u201cmoment\u201d in editions after 1850.\n\n54 \u201cTHE PROS AND CONS IN PARALLEL COLUMNS\u201d: Harriet Martineau, *Autobiography* (1877), quoted in Anthony Hyman, *Charles Babbage*, 129.\n\n55 \u201cIF YOU SPEAK TO HIM OF A MACHINE FOR PEELING A POTATO\u201d: Quoted in Doron Swade, *The Difference Engine: Charles Babbage and the Quest to Build the First Computer* (New York: Viking, 2001), 132.\n\n56 \u201cI THINK IT LIKELY HE LIVES IN A SORT OF DREAM\u201d: Quoted in ibid., 38.\n\n57 FOR A GUINEA, SHE COULD SIT: Advertisement in *The Builder*, 31 December 1842, http://www.victorianlondon.org/photography/adverts.htm (accessed 7 March 2006).\n\n58 \u201cTHE CHILD OF LOVE,\u2026\u2014THOUGH BORN IN BITTERNESS\u201d: Lord Byron, \u201cChilde Harold\u2019s Pilgrimage,\u201d canto 3, 118.\n\n59 \u201cIS THE GIRL IMAGINATIVE?\u201d: Byron to Augusta Leigh, 12 October 1823, in Leslie A. Marchand, ed., *Byron\u2019s Letters and Journals*, vol. 9 (London: John Murray, 1973\u201394), 47.\n\n60 \u201cI AM GOING TO BEGIN MY PAPER WINGS\u201d: Ada to Lady Byron, 3 February 1828, in Betty Alexandra Toole, *Ada, the Enchantress of Numbers: Prophet of the Computer Age* (Mill Valley, Calif.: Strawberry Press, 1998), 25.\n\n61 \u201cMISS STAMP DESIRES ME TO SAY\u201d: Ada to Lady Byron, 2 April 1828, ibid., 27.\n\n62 \u201cWHEN I AM WEAK\u201d: Ada to Mary Somerville, 20 February 1835, ibid., 55.\n\n63 AN \u201cOLD MONKEY\u201d: Ibid., 33.\n\n64 \u201cWHILE OTHER VISITORS GAZED\u201d: Sophia Elizabeth De Morgan, *Memoir of Augustus De Morgan* (London: Longmans, Green, 1882), 89.\n\n65 \u201cI DO NOT CONSIDER THAT I KNOW\u201d: Ada to Dr. William King, 24 March 1834, in Betty Alexandra Toole, *Ada, the Enchantress of Numbers*, 45.\n\n66 \u201cGEM OF ALL MECHANISM\u201d: Ada to Mary Somerville, 8 July 1834, ibid., 46.\n\n67 \u201cPUNCHES HOLES IN A SET OF PASTEBOARD CARDS\u201d: \u201cOf the Analytical Engine,\u201d in *Charles Babbage and His Calculating Engines*, 55.\n68 \u201cHOW THE MACHINE COULD PERFORM THE ACT OF JUDGMENT\u201d: Ibid., 65.\n\n69 \u201cI AM AT PRESENT A CONDEMNED SLAVE\u201d: Ada to Mary Somerville, 22 June 1837, in Betty Alexandra Toole, *Ada, the Enchantress of Numbers*, 70.\n\n70 \u201cTHE ONLY OTHER PERSON WAS A MIDDLE-AGED GENTLEMAN\u201d: Ada to Lady Byron, 26 June 1838, ibid., 78.\n\n71 \u201cI HAVE A PECULIAR WAY OF LEARNING\u201d: Ada to Babbage, November 1839, ibid., 82.\n\n72 \u201cYOU KNOW I AM BY NATURE A BIT OF A PHILOSOPHER\u201d: Ada to Babbage, 16 February 1840, ibid., 83.\n\n73 \u201cAN ORIGINAL MATHEMATICAL INVESTIGATOR\u201d: Augustus De Morgan to Lady Byron, quoted in Betty Alexandra Toole, \u201cAda Byron, Lady Lovelace, an Analyst and Metaphysician,\u201d *IEEE Annals of the History of Computing* 18, no. 3 (1996), 7.\n\n74 \u201cI HAVE DONE IT BY TRYING\u201d: Ada to Babbage, 16 February 1840, in Betty Alexandra Toole, *Ada, the Enchantress of Numbers*, 83.\n\n75 \u201cOF CERTAIN SPRITES & FAIRIES\u201d: Ada to Augustus De Morgan, 3 February 1841, ibid., 99.\n\n76 \u201cWE TALK MUCH OF IMAGINATION\u201d: Untitled essay, 5 January 1841, ibid., 94.\n\n77 \u201cI HAVE ON MY MIND MOST STRONGLY\u201d: Ada to Woronzow Greig, 15 January 1841, ibid., 98.\n\n78 \u201cWHAT A MOUNTAIN I HAVE TO CLIMB\u201d: Ada to Lady Byron, 6 February 1841, ibid., 101.\n\n79 \u201cIT WILL ENABLE OUR CLERKS TO PLUNDER US\u201d: *Charles Babbage and His Calculating Engines*, 113. He added: \u201cpossibly we might send lightning to outstrip the culprit \u2026\u201d\n\n80 \u201cTHE DISCOVERY OF THE ANALYTICAL ENGINE\u201d: Quoted in Anthony Hyman, *Charles Babbage*, 185.\n\n81 \u201cNOTIONS SUR LA MACHINE ANALYTIQUE\u201d: Biblioth\u00e8que Universelle de Gen\u00e8ve, no. 82 (October 1842).\n\n82 NOT TO \u201cPROCLAIM WHO HAS WRITTEN IT\u201d: Ada to Babbage, 4 July 1843, in Betty Alexandra Toole, *Ada, the Enchantress of Numbers*, 145.\n\n83 \u201cANY PROCESS WHICH ALTERS THE MUTUAL RELATION\u201d: Note A (by the translator, Ada Lovelace) to L. F. Menabrea, \u201cSketch of the Analytical Engine Invented by Charles Babbage,\u201d in *Charles Babbage and His Calculating Engines*, 247.\n\n84 \u201cTHE ANALYTICAL ENGINE DOES NOT OCCUPY COMMON GROUND\u201d: Ibid., 252.\n\n85 \u201cTHE ENGINE EATING ITS OWN TAIL\u201d: H. Babbage, \u201cThe Analytical Engine,\u201d paper read at Bath, 12 September 1888, in *Charles Babbage and His Calculating Engines*, 331.\n\n86 \u201cWE EASILY PERCEIVE THAT SINCE EVERY SUCCESSIVE FUNCTION\u201d: Note D (by the translator, Ada Lovelace) to L. F. Menabrea, \u201cSketch of the Analytical Engine Invented by\nCharles Babbage.\u201d\n\n87 \u201cTHAT BRAIN OF MINE\u201d: Ada to Babbage, 5 July 1843, in Betty Alexandra Toole, *Ada, the Enchantress of Numbers*, 147.\n\n88 \u201cHOW MULTIFARIOUS AND HOW MUTUALLY COMPLICATED\u201d: Note D (by the translator, Ada Lovelace) to L. F. Menabrea, \u201cSketch of the Analytical Engine Invented by Charles Babbage.\u201d\n\n89 \u201cI AM IN MUCH DISMAY\u201d: Ada to Babbage, 13 July 1843, in Betty Alexandra Toole, *Ada, the Enchantress of Numbers*, 149.\n\n90 \u201cI FIND THAT MY PLANS & IDEAS\u201d: Ada to Babbage, 22 July 1843, ibid., 150.\n\n91 \u201cI DO NOT THINK YOU POSSESS HALF MY FORETHOUGHT\u201d: Ada to Babbage, 30 July 1843, ibid., 157.\n\n92 \u201cIT WOULD BE LIKE USING THE STEAM HAMMER\u201d: H. P. Babbage, \u201cThe Analytical Engine,\u201d 333.\n\n93 \u201cWHAT SHALL WE THINK OF THE CALCULATING MACHINE\u201d: \u201cMaelzel\u2019s Chess-Player,\u201d in *The Prose Tales of Edgar Allan Poe: Third Series* (New York: A. C. Armstrong & Son, 1889), 230.\n\n94 \u201cSTEAM IS AN APT SCHOLAR\u201d: Ralph Waldo Emerson, *Society and Solitude* (Boston: Fields, Osgood, 1870), 143.\n\n95 \u201cWHAT A SATIRE IS THAT MACHINE\u201d: Oliver Wendell Holmes, *The Autocrat of the Breakfast-Table* (New York: Houghton Mifflin, 1893), 11.\n\n96 \u201cONE OF THE MOST FASCINATING OF ARTS\u201d: Charles Babbage, *Passages from the Life of a Philosopher*, 235.\n\n97 \u201cEVERY SHOWER THAT FALLS\u201d: \u201cOn the Age of Strata, as Inferred from the Rings of Trees Embedded in Them,\u201d from Charles Babbage, *The Ninth Bridgewater Treatise: A Fragment* (London: John Murray, 1837), in *Charles Babbage and His Calculating Engines*, 368.\n\n98 \u201cADMITTING IT TO BE POSSIBLE BETWEEN LONDON AND LIVERPOOL\u201d: Charles Babbage, *On the Economy of Machinery*, 10.\n\n99 \u201cENCLOSED IN SMALL CYLINDERS ALONG WIRES\u201d: Charles Babbage, *Passages from the Life of a Philosopher*, 447.\n\n100 \u201cA COACH AND APPARATUS\u201d: Charles Babbage, *On the Economy of Machinery*, 273.\n\n101 \u201cZENITH-LIGHT SIGNALS\u201d: Charles Babbage, *Passages from the Life of a Philosopher*, 460.\n\n102 \u201cTHIS LED TO A NEW THEORY OF STORMS\u201d: Ibid., 301.\n\n103 \u201cA DIFFERENT SENSE OF ANACHRONISM\u201d: Jenny Uglow, \u201cPossibility,\u201d in Francis Spufford and Jenny Uglow, *Cultural Babbage*, 20.\n\n104 \u201cIF, UNWARNED BY MY EXAMPLE\u201d: Charles Babbage, *Passages from the Life of a\n5. A NERVOUS SYSTEM FOR THE EARTH\n\n1 \u201cIS IT A FACT\u2014OR HAVE I DREAMT IT\u201d: Nathaniel Hawthorne, *The House of the Seven Gables* (Boston: Ticknor, Reed, & Fields, 1851), 283.\n\n2 THREE CLERKS IN A SMALL ROOM: They managed the traffic \u201ceasily, and not very continuously.\u201d \u201cCentral Telegraph Stations,\u201d *Journal of the Society of Telegraph Engineers* 4 (1875): 106.\n\n3 \u201cWHO WOULD THINK THAT BEHIND THIS NARROW FOREHEAD\u201d: Andrew Wynter, \u201cThe Electric Telegraph,\u201d *Quarterly Review* 95 (1854): 118\u201364.\n\n4 HE WAS NEITHER THE FIRST NOR THE LAST: Iwan Rhys Morus, \u201c\u2018The Nervous System of Britain\u2019: Space, Time and the Electric Telegraph in the Victorian Age,\u201d *British Journal of the History of Science* 33 (2000): 455\u201375.\n\n5 ALFRED SMEE: Quoted in Iwan Rhys Morus, \u201c\u2018The Nervous System of Britain,\u2019\u201d 471.\n\n6 \u201cTHE DOCTOR CAME AND LOOKED\u201d: \u201cEdison\u2019s Baby,\u201d *The New York Times*, 27 October 1878, 5.\n\n7 \u201cTHE TIME IS CLOSE AT HAND\u201d: \u201cThe Future of the Telephone,\u201d *Scientific American*, 10 January 1880.\n\n8 \u201cELECTRICITY IS THE POETRY OF SCIENCE\u201d: Alexander Jones, *Historical Sketch of the Electric Telegraph: Including Its Rise and Progress in the United States* (New York: Putnam, 1852), v.\n\n9 \u201cAN INVISIBLE, INTANGIBLE, IMPONDERABLE AGENT\u201d: William Robert Grove, quoted in Iwan Rhys Morus, \u201c\u2018The Nervous System of Britain,\u2019\u201d 463.\n\n10 \u201cTHE WORLD OF SCIENCE IS NOT AGREED\u201d: Dionysus Lardner, *The Electric Telegraph*, revised and rewritten by Edward B. Bright (London: James Walton, 1867), 6.\n\n11 \u201cWE ARE NOT TO CONCEIVE OF THE ELECTRICITY\u201d: \u201cThe Telegraph,\u201d *Harper\u2019s New Monthly Magazine*, 47 (August 1873), 337.\n\n12 \u201cBOTH OF THEM ARE POWERFUL\u201d: \u201cThe Electric Telegraph,\u201d *The New York Times*, 11 November 1852.\n\n13 \u201cCANST THOU SEND LIGHTNINGS\u201d: Job 38:35; Dionysus Lardner, *The Electric Telegraph*.\n\n14 COUNT MIOT DE MELITO CLAIMED: *Memoirs of Count Miot de Melito*, vol. 1, trans. Cashel Hoey and John Lillie (London: Sampson Low, 1881), 44n.\nMEANWHILE THE CHAPPES MANAGED: Gerard J. Holzmann and Bj\u00f6rn Pehrson, *The Early History of Data Networks* (Washington, D.C.: IEEE Computer Society, 1995), 52 ff.\n\n\u201cTHE DAY WILL COME\u201d: \u201cLettre sur une nouveau t\u00e9l\u00e9graphe,\u201d quoted in Jacques Attali and Yves Stourdze, \u201cThe Birth of the Telephone and the Economic Crisis: The Slow Death of Monologue in French Society,\u201d in Ithiel de Sola Poolin, ed., *The Social Impact of the Telephone* (Cambridge, Mass.: MIT Press, 1977), 97.\n\n\u201cCITIZEN CHAPPE OFFERS AN INGENIOUS METHOD\u201d: Gerard J. Holzmann and Bj\u00f6rn Pehrson, *The Early History of Data Networks*, 59.\n\nONE DEPUTY NAMED A PANTHEON: Bertrand Bar\u00e8re de Vieuzac, 17 August 1794, quoted in ibid., 64.\n\nCHAPPE ONCE CLAIMED: Taliaferro P. Shaffner, *The Telegraph Manual: A Complete History and Description of the Semaphoric, Electric and Magnetic Telegraphs of Europe, Asia, Africa, and America, Ancient and Modern* (New York: Pudney & Russell, 1859), 42.\n\n\u201cTHEY HAVE PROBABLY NEVER PERFORMED EXPERIMENTS\u201d: Gerard J. Holzmann and Bj\u00f6rn Pehrson, *The Early History of Data Networks*, 81.\n\n\u201cIF YOU\u2019LL ONLY JUST PROMISE\u201d: Charles Dibdin, \u201cThe Telegraph,\u201d in *The Songs of Charles Dibdin, Chronologically Arranged*, vol. 2 (London: G. H. Davidson, 1863), 69.\n\n\u201cTHESE STATIONS ARE NOW SILENT\u201d: Taliaferro P. Shaffner, *The Telegraph Manual*, 31.\n\n\u201cANYTHING THAT COULD BE THE SUBJECT\u201d: Gerard J. Holzmann and Bj\u00f6rn Pehrson, *The Early History of Data Networks*, 56.\n\n\u201cANYONE PERFORMING UNAUTHORIZED TRANSMISSIONS\u201d: Ibid., 91.\n\n\u201cWHAT CAN ONE EXPECT\u201d: Ibid., 93.\n\n\u201cOTHER BODIES THAT CAN BE AS EASILY ATTRACTED\u201d: J. J. Fahie, *A History of Electric Telegraphy to the Year 1837* (London: E. & F. N. Spon, 1884), 90.\n\n\u201cTHIS SECONDARY OBJECT, THE ALARUM\u201d: E. A. Marland, *Early Electrical Communication* (London: Abelard-Schuman, 1964), 37.\n\nHARRISON GRAY DYER TRIED SENDING SIGNALS: \u201cAn attempt made by Dyer to introduce his telegraph to general use encountered intense prejudice, and, becoming frightened at some of the manifestations of this feeling, he left the country.\u201d Chauncey M. Depew, *One Hundred Years of American Commerce* (New York: D. O. Haynes, 1895), 126.\n\n\u201cIT MUST BE EVIDENT TO THE MOST COMMON OBSERVER\u201d: John Pickering, *Lecture on Telegraphic Language* (Boston: Hilliard, Gray, 1833), 11.\n\n\u201cTELEGRAPHY IS AN ELEMENT OF POWER AND ORDER\u201d: Quoted in Daniel R. Headrick, *When Information Came of Age: Technologies of Knowledge in the Age of Reason and Revolution, 1700\u20131850* (Oxford: Oxford University Press, 2000), 200.\n\n\u201cIf there are now essential advantages\u201d: John Pickering, *Lecture on Telegraphic Language*, 26.\n32 \u201cA SINGLE LETTER MAY BE INDICATED\u201d: Davy manuscript, quoted in J. J. Fahie, *A History of Electric Telegraphy to the Year 1837*, 351.\n\n33 \u201cI WORKED OUT EVERY POSSIBLE PERMUTATION\u201d: William Fothergill Cooke, *The Electric Telegraph: Was it Invented By Professor Wheatstone?* (London: W. H. Smith & Son, 1857), 27.\n\n34 \u201cSUPPOSE THE MESSAGE TO BE SENT\u201d: Alfred Vail, *The American Electro Magnetic Telegraph: With the Reports of Congress, and a Description of All Telegraphs Known, Employing Electricity Or Galvanism* (Philadelphia: Lea & Blanchard, 1847), 178.\n\n35 \u201cTHE WORDY BATTLES WAGED\u201d: Samuel F. B. Morse: *His Letters and Journals*, vol. 2 (Boston: Houghton Mifflin, 1914), 21.\n\n36 \u201cTHE MAILS IN OUR COUNTRY ARE TOO SLOW\u201d: Recalled by R. W. Habersham, *Samuel F. B. Morse: His Letters and Journals*.\n\n37 \u201cIT WOULD NOT BE DIFFICULT\u201d: Alfred Vail, *The American Electro Magnetic Telegraph*, 70.\n\n38 \u201cSEND A MESSENGER TO MR HARRIS\u201d: Andrew Wynter, \u201cThe Electric Telegraph,\u201d 128.\n\n39 AT THE STROKE OF THE NEW YEAR: Laurence Turnbull, *The Electro-Magnetic Telegraph, With an Historical Account of Its Rise, Progress, and Present Condition* (Philadelphia: A. Hart, 1853), 87.\n\n40 \u201cIN THE GARB OF A KWAKER\u201d: \u201cThe Trial of John Tawell for the Murder of Sarah Hart by Poison, at the Aylesbury Spring Assizes, before Mr. Baron Parks, on March 12th 1845,\u201d in William Otter Woodall, *A Collection of Reports of Celebrated Trials* (London: Shaw & Sons, 1873).\n\n41 \u201cIN CONVEYING THE MOVES, THE ELECTRICITY TRAVELLED\u201d: John Timbs, *Stories of Inventors and Discoverers in Science and the Useful Arts* (London: Kent, 1860), 335.\n\n42 \u201cWHEN YOU CONSIDER THAT BUSINESS IS EXTREMELY DULL\u201d: Quoted in Tom Standage, *The Victorian Internet: The Remarkable Story of the Telegraph and the Nineteenth Century\u2019s On-Line Pioneers* (New York: Berkley, 1998), 55.\n\n43 ALEXANDER JONES SENT HIS FIRST STORY: Alexander Jones, *Historical Sketch of the Electric Telegraph*, 121.\n\n44 \u201cTHE FIRST INSTALMENT OF THE INTELLIGENCE\u201d: Charles Maybury Archer, ed., *The London Anecdotes: The Electric Telegraph*, vol. 1 (London: David Bogue, 1848), 85.\n\n45 \u201cTHE RAPID AND INDISPENSABLE CARRIER\u201d: *Littell\u2019s Living Age* 6, no. 63 (26 July 1845): 194.\n\n46 \u201cSWIFTER THAN A ROCKET COULD FLY\u201d: Andrew Wynter, \u201cThe Electric Telegraph,\u201d 138.\n\n47 \u201cALL IDEA OF CONNECTING EUROPE WITH AMERICA\u201d: Alexander Jones, *Historical Sketch of the Electric Telegraph*, 6.\n48 \u201cA RESULT SO PRACTICAL, YET SO INCONCEIVABLE\u201d: \u201cThe Atlantic Telegraph,\u201d *The New York Times*, 6 August 1858, 1.\n\n49 *DERBY, VERY DULL*: Charles Maybury Archer, *The London Anecdotes*, 51.\n\n50 \u201cTHE PHENOMENA OF THE ATMOSPHERE\u201d: Ibid., 73.\n\n51 \u201cENABLES US TO SEND COMMUNICATIONS\u201d: George B. Prescott, *History, Theory, and Practice of the Electric Telegraph* (Boston: Ticknor and Fields, 1860), 5.\n\n52 \u201cFOR ALL PRACTICAL PURPOSES\u201d: *The New York Times*, 7 August 1858, 1.\n\n53 \u201cDISTANCE AND TIME HAVE BEEN SO CHANGED\u201d: Quoted in Iwan Rhys Morus, \u201c\u2018The Nervous System of Britain,\u2019\u201d 463.\n\n54 *LIEUTENANT CHARLES WILKES*: Charles Wilkes to S. F. B. Morse, 13 June 1844, in Alfred Vail, *The American Electro Magnetic Telegraph*, 60.\n\n55 \u201cPROFESSOR MORSE\u2019S TELEGRAPH IS NOT ONLY AN ERA\u201d: Quoted in Adam Frank, \u201cValdemar\u2019s Tongue, Poe\u2019s Telegraphy,\u201d *ELH* 72 (2005): 637.\n\n56 \u201cWHAT MIGHT NOT BE GATHERED SOME DAY\u201d: Andrew Wynter, \u201cThe Electric Telegraph,\u201d 133.\n\n57 \u201cMUCH IMPORTANT INFORMATION \u2026 CONSISTING OF MESSAGES\u201d: Alfred Vail, *The American Electro Magnetic Telegraph*, viii.\n\n58 *THE GIVING, PRINTING, STAMPING, OR OTHERWISE TRANSMITTING*: Agreement between Cooke and Wheatstone, 1843, in William Fothergill Cooke, *The Electric Telegraph*, 46.\n\n59 \u201cTHE DIFFICULTY OF FORMING A CLEAR CONCEPTION\u201d: \u201cThe Telegraph,\u201d *Harper\u2019s New Monthly Magazine*, 336.\n\n60 \u201cTELEGRAPHIC COMPANIES ARE RUNNING A RACE\u201d: Andrew Wynter, *Subtle Brains and Lissom Fingers: Being Some of the Chisel-Marks of Our Industrial and Scientific Progress* (London: Robert Hardwicke, 1863), 363.\n\n61 \u201cTHEY STRING AN INSTRUMENT AGAINST THE SKY\u201d: Robert Frost, \u201cThe Line-Gang,\u201d 1920.\n\n62 \u201cA NET-WORK OF NERVES OF IRON WIRE\u201d: *Littell\u2019s Living Age* 6, no. 63 (26 July 1845): 194.\n\n63 \u201cTHE WHOLE NET-WORK OF WIRES\u201d: \u201cThe Telegraph,\u201d *Harper\u2019s New Monthly Magazine*, 333.\n\n64 \u201cTHE TIME IS NOT DISTANT\u201d: Andrew Wynter, *Subtle Brains and Lissom Fingers*, 371.\n\n65 \u201cTHE TELEGRAPHIC STYLE BANISHES\u201d: Andrew Wynter, \u201cThe Electric Telegraph,\u201d 132.\n\n66 \u201cWE EARLY INVENTED A SHORT-HAND\u201d: Alexander Jones, *Historical Sketch of the Electric Telegraph*, 123.\n\n67 \u201cTHE GREAT ADVANTAGE\u201d: Alfred Vail, *The American Electro Magnetic Telegraph*, 46.\n\n68 *THE SECRET CORRESPONDING VOCABULARY*: Francis O. J. Smith, *THE SECRET*\nCORRESPONDING VOCABULARY; Adapted for Use to Morse\u2019s Electro-Magnetic Telegraph: And Also in Conducting Written Correspondence, Transmitted by the Mails, or Otherwise (Portland, Maine: Thurston, Ilsley, 1845).\n\n69 THE A B C UNIVERSAL COMMERCIAL ELECTRIC TELEGRAPH CODE: Examples from William Clauson-Thue, THE A B C UNIVERSAL COMMERCIAL ELECTRIC TELEGRAPH CODE, 4th ed. (London: Eden Fisher, 1880).\n\n70 \u201cIT HAS BEEN BROUGHT TO THE AUTHOR\u2019S KNOWLEDGE\u201d: Ibid., iv.\n\n71 \u201cTO GUARD AGAINST MISTAKES OR DELAYS\u201d: Primrose v. Western Union Tel. Co., 154 U.S. 1 (1894); \u201cNot Liable for Errors in Ciphers,\u201d The New York Times, 27 May 1894, 1.\n\n72 AN ANONYMOUS LITTLE BOOK: Later reprinted, with the author identified, as John Wilkins, Mercury: Or the Secret and Swift Messenger. Shewing, How a Man May With Privacy and Speed Communicate His Thoughts to a Friend At Any Distance, 3rd ed. (London: John Nicholson, 1708).\n\n73 \u201cHE WAS A VERY INGENIOUS MAN\u201d: John Aubrey, Brief Lives, ed. Richard Barber (Woodbridge, Suffolk: Boydell Press, 1982), 324.\n\n74 \u201cHOW A MAN MAY WITH THE GREATEST SWIFTNESS\u201d: John Wilkins, Mercury: Or the Secret and Swift Messenger, 62.\n\n75 \u201cWHATEVER IS CAPABLE OF A COMPETENT DIFFERENCE\u201d: Ibid., 69.\n\n76 THE CONTRIBUTION OF THE DILETTANTES: David Kahn, The Codebreakers: The Story of Secret Writing (London: Weidenfeld & Nicolson, 1968), 189.\n\n77 \u201cWE CAN SCARCELY IMAGINE A TIME\u201d: \u201cA Few Words on Secret Writing,\u201d Graham\u2019s Magazine, July 1841; Edgar Allan Poe, Essays and Reviews (New York: Library of America, 1984), 1277.\n\n78 \u201cTHE SOUL IS A CYPHER\u201d: The Literati of New York (1846), in Edgar Allan Poe, Essays and Reviews, 1172.\n\n79 A BRIDGE BETWEEN SCIENCE AND THE OCCULT: Cf. William F. Friedman, \u201cEdgar Allan Poe, Cryptographer,\u201d American Literature 8, no. 3 (1936): 266\u201380; Joseph Wood Krutch, Edgar Allan Poe: A Study in Genius (New York: Knopf, 1926).\n\n80 A \u201cKEY-ALPHABET\u201d AND A \u201cMESSAGE-ALPHABET\u201d: Lewis Carroll, \u201cThe Telegraph-Cipher,\u201d printed card 8 x 12 cm., Berol Collection, New York University Library.\n\n81 \u201cONE OF THE MOST SINGULAR CHARACTERISTICS\u201d: Charles Babbage, Passages from the Life of a Philosopher (London: Longman, Green, Longman, Roberts, & Green, 1864), 235.\n\n82 POLYALPHABETIC CIPHER KNOWN AS THE VIGEN\u00c8RE: Simon Singh, The Code Book: The Secret History of Codes and Code-breaking (London: Fourth Estate, 1999), 63 ff.\n\n83 \u201cTHE VARIOUS PARTS OF THE MACHINERY\u201d: Dionysius Lardner, \u201cBabbage\u2019s Calculating Engines,\u201d Edinburgh Review 59, no. 120 (1834): 315\u201317.\n\n84 \u201cNAME OF EVERYTHING WHICH IS BOTH X AND Y\u201d: De Morgan to Boole, 28\nNovember 1847, in G. C. Smith, ed., *The Boole\u2013De Morgan Correspondence 1842\u20131864* (Oxford: Clarendon Press, 1982), 25.\n\n85 \u201cNOW SOME ZS ARE NOT XS\u201d: De Morgan to Boole, draft, not sent, ibid., 27.\n\n86 \u201cIT IS SIMPLY A FACT\u201d: quoted by Samuel Neil, \u201cThe Late George Boole, LL.D., D.C.L.\u201d (1865), in James Gasser, ed., *A Boole Anthology: Recent and Classical Studies in the Logic of George Boole* (Dordrecht, Netherlands: Kluwer Academic, 2000), 16.\n\n87 \u201cTHE RESPECTIVE INTERPRETATION OF THE SYMBOLS 0 AND 1\u201d: George Boole, *An Investigation of the Laws of Thought, on Which Are Founded the Mathematical Theories of Logic and Probabilities* (London: Walton & Maberly, 1854), 34.\n\n88 \u201cTHAT LANGUAGE IS AN INSTRUMENT OF HUMAN REASON\u201d: Ibid., 24\u201325.\n\n89 \u201cUNCLEAN BEASTS ARE ALL\u201d: Ibid., 69.\n\n90 \u201cA WORD IS A TOOL FOR THINKING\u201d: \u201cThe Telegraph,\u201d *Harper\u2019s New Monthly Magazine*, 359.\n\n91 \u201cBABIES ARE ILLOGICAL\u201d: Lewis Carroll, *Symbolic Logic: Part I, Elementary* (London: Macmillan, 1896), 112 and 131. And cf. Steve Martin, *Born Standing Up: A Comic\u2019s Life* (New York: Simon & Schuster, 2007), 74.\n\n92 \u201cPURE MATHEMATICS WAS DISCOVERED BY BOOLE\u201d: Bertrand Russell, *Mysticism and Logic* (1918; reprinted Mineola, N.Y.: Dover, 2004), 57.\n\n6. NEW WIRES, NEW LOGIC\n\n1 \u201cTHE PERFECT SYMMETRY OF THE WHOLE APPARATUS\u201d: James Clerk Maxwell, \u201cThe Telephone,\u201d Rede Lecture, Cambridge 1878, \u201cillustrated with the aid of Mr. Gower\u2019s telephonic harp,\u201d in W. D. Niven, ed., *The Scientific Papers of James Clerk Maxwell*, vol. 2 (Cambridge: Cambridge University Press, 1890; repr. New York: Dover, 1965), 750.\n\n2 GAYLORD AMOUNTED TO LITTLE MORE: \u201cSmall enough that if you walked a couple of blocks, you\u2019d be in the countryside.\u201d Shannon interview with Anthony Liversidge, *Omni* (August 1987), in Claude Elwood Shannon, *Collected Papers*, ed. N. J. A. Sloane and Aaron D. Wyner (New York: IEEE Press, 1993), xx.\n\n3 \u201cTHERE CAN BE NO DOUBT\u201d: \u201cIn the World of Electricity,\u201d *The New York Times*, 14 July 1895, 28.\n\n4 THE MONTANA EAST LINE TELEPHONE ASSOCIATION: David B. Sicilia, \u201cHow the West Was Wired,\u201d *Inc.*, 15 June 1997.\n\n5 \u201cTHE GOLD-BUG\u201d: 1843; *Complete Stories and Poems of Edgar Allan Poe* (New York: Doubleday, 1966), 71.\n\n6 \u201cCIRCUMSTANCES, AND A CERTAIN BIAS OF MIND\u201d: Ibid., 90.\n\n7 \u201c\u2018THINKING MACHINE\u2019 DOES HIGHER MATHEMATICS\u201d: *The New York Times*, 21\nOctober 1927.\n\n8 \u201cA MATHEMATICIAN IS NOT A MAN\u201d: Vannevar Bush, \u201cAs We May Think,\u201d *The Atlantic* (July 1945).\n\n9 UTTERLY CAPTIVATED BY THIS \u201cCOMPUTER\u201d: Shannon to Rudolf E. Kalman, 12 June 1987, Manuscript Division, Library of Congress.\n\n10 \u201cAUTOMATICALLY ADD TWO NUMBERS\u201d: Claude Shannon, \u201cA Symbolic Analysis of Relay and Switching Circuits,\u201d *Transactions of the American Institute of Electrical Engineers* 57 (1938): 38\u201350.\n\n11 HIS \u201cQUEER ALGEBRA\u201d: Vannevar Bush to Barbara Burks, 5 January 1938, Manuscript Division, Library of Congress.\n\n12 \u201cAN ALGEBRA FOR THEORETICAL GENETICS\u201d: Claude Shannon, *Collected Papers*, 892.\n\n13 EVALUATION FORTY YEARS LATER: Ibid., 921.\n\n14 \u201cOFF AND ON I HAVE BEEN WORKING ON AN ANALYSIS\u201d: Claude Shannon to Vannevar Bush, 16 February 1939, in Claude Shannon, *Collected Papers*, 455.\n\n15 \u201cA CERTAIN SCRIPT OF LANGUAGE\u201d: Leibniz to Jean Galloys, December 1678, in Martin Davis, *The Universal Computer: The Road from Leibniz to Turing* (New York: Norton, 2000), 16.\n\n16 \u201cHIGHLY ABSTRACT PROCESSES AND IDEAS\u201d: Alfred North Whitehead and Bertrand Russell, *Principia Mathematica*, vol. 1 (Cambridge: Cambridge University Press, 1910), 2.\n\n17 \u201cEPIMENIDES THE CREtan SAID\u201d: Bertrand Russell, \u201cMathematical Logic Based on the Theory of Types,\u201d *American Journal of Mathematics* 30, no. 3 (July 1908): 222.\n\n18 \u201cIT WAS IN THE AIR\u201d: Douglas R. Hofstadter, *I Am a Strange Loop* (New York: Basic Books, 2007), 109.\n\n19 \u201cHENCE THE NAMES OF SOME INTEGERS\u201d: Alfred North Whitehead and Bertrand Russell, *Principia Mathematica*, vol. 1, 61.\n\n20 DOES THE BARBER SHAVE HIMSELF: \u201cThe Philosophy of Logical Atomism\u201d (1910), in Bertrand Russell, *Logic and Knowledge: Essays, 1901\u20131950* (London: Routledge, 1956), 261.\n\n21 \u201cLOOKED AT FROM THE OUTSIDE\u201d: Kurt G\u00f6del, \u201cOn Formally Undecidable Propositions of *Principia Mathematica* and Related Systems I\u201d (1931), in *Kurt G\u00f6del: Collected Works*, vol. 1, ed. Solomon Feferman (New York: Oxford University Press, 1986), 146.\n\n22 \u201cA SCIENCE PRIOR TO ALL OTHERS\u201d: Kurt G\u00f6del, \u201cRussell\u2019s Mathematical Logic\u201d (1944), in *Kurt G\u00f6del: Collected Works*, vol. 2, 119.\n\n23 \u201cONE CAN PROVE ANY THEOREM\u201d: Kurt G\u00f6del, \u201cOn Formally Undecidable Propositions of *Principia Mathematica* and Related Systems I\u201d (1931), 145.\n\n24 \u201cCONTRARY TO APPEARANCES, SUCH A PROPOSITION\u201d: Ibid., 151 n15.\n25 \u201cAMAZING FACT\u201d\u2014\u201cTHAT OUR LOGICAL INTUITIONS\u201d: Kurt G\u00f6del, \u201cRussell\u2019s Mathematical Logic\u201d (1944), 124.\n\n26 \u201cA SUDDEN THUNDERBOLT FROM THE BLUEST OF SKIES\u201d: Douglas R. Hofstadter, *I Am a Strange Loop*, 166.\n\n27 \u201cTHE IMPORTANT POINT\u201d: John von Neumann, \u201cTribute to Dr. G\u00f6del\u201d (1951), quoted in Steve J. Heims, *John von Neumann and Norbert Weiner* (Cambridge, Mass.: MIT Press, 1980), 133.\n\n28 \u201cIT MADE ME GLAD\u201d: Russell to Leon Henkin, 1 April 1963.\n\n29 \u201cMATHEMATICS CANNOT BE INCOMPLETE\u201d: Ludwig Wittgenstein, *Remarks on the Foundations of Mathematics* (Cambridge, Mass.: MIT Press, 1967), 158.\n\n30 \u201cRUSSELL EVIDENTLY MISINTERPRETS MY RESULT\u201d: G\u00f6del to Abraham Robinson, 2 July 1973, in *Kurt G\u00f6del: Collected Works*, vol. 5, 201.\n\n31 HIS NAME WAS RECODED BY THE TELEPHONE COMPANY: Rebecca Goldstein, *Incompleteness: The Proof and Paradox of Kurt G\u00f6del* (New York: Atlas, 2005), 207.\n\n32 \u201cYOUR BIO-MATHEMATICAL PROBLEMS\u201d: Hermann Weyl to Claude Shannon, 11 April 1940, Manuscript Division, Library of Congress.\n\n33 \u201cPROJECT 7\u201d: David A. Mindell, *Between Human and Machine: Feedback, Control, and Computing Before Cybernetics* (Baltimore: Johns Hopkins University Press, 2002), 289.\n\n34 \u201cAPPLYING CORRECTIONS TO THE GUN CONTROL\u201d: Vannevar Bush, \u201cReport of the National Defense Research Committee for the First Year of Operation, June 27, 1940, to June 28, 1941,\u201d Franklin D. Roosevelt Presidential Library and Museum, 19.\n\n35 \u201cTHERE IS AN OBVIOUS ANALOGY\u201d: R. B. Blackman, H. W. Bode, and Claude E. Shannon, \u201cData Smoothing and Prediction in Fire-Control Systems,\u201d Summary Technical Report of Division 7, National Defense Research Committee, vol. 1, *Gunfire Control* (Washington D.C.: 1946), 71\u2013159 and 166\u201367; David A. Mindell, \u201cAutomation\u2019s Finest Hour: Bell Labs and Automatic Control in World War II,\u201d *IEEE Control Systems* 15 (December 1995): 72\u201380.\n\n36 \u201cBELL SEEMS TO BE SPENDING ALL HIS ENERGIES\u201d: Elisha Gray to A. L. Hayes, October 1875, quoted in Michael E. Gorman, *Transforming Nature: Ethics, Invention and Discovery* (Boston: Kluwer Academic, 1998), 165.\n\n37 \u201cI CAN SCARCE BELIEVE THAT A MAN\u201d: Albert Bigelow Paine, *In One Man\u2019s Life: Being Chapters from the Personal & Business Career of Theodore N. Vail* (New York: Harper & Brothers, 1921), 114.\n\n38 \u201cI FANCY THE DESCRIPTIONS WE GET\u201d: Marion May Dilts, *The Telephone in a Changing World* (New York: Longmans, Green, 1941), 11.\n\n39 \u201cNO MATTER TO WHAT EXTENT A MAN\u201d: \u201cThe Telephone Unmasked,\u201d *The New York Times*, 13 October 1877, 4.\n\n40 \u201cTHE SPEAKER TALKS TO THE TRANSMITTER\u201d: *The Scientific Papers of James Clerk*\nThe Information\n\nMaxwell, ed. W. D. Niven, vol. 2 (Cambridge: Cambridge University Press, 1890; repr. New York: Dover, 1965), 744.\n\n41 \u201cWHAT THE TELEGRAPH ACCOMPLISHED IN YEARS\u201d: Scientific American, 10 January 1880.\n\n42 \u201cINSTANTANEOUS COMMUNICATION ACROSS SPACE\u201d: Telephones: 1907, Special Reports, Bureau of the Census, 74.\n\n43 \u201cIT MAY SOUND RIDICULOUS TO SAY THAT BELL\u201d: Quoted in Ithiel de Sola Pool, ed., The Social Impact of the Telephone (Cambridge, Mass.: MIT Press, 1977), 140.\n\n44 \u201cAFFECTATIONS OF THE SAME SUBSTANCE\u201d: J. Clerk Maxwell, \u201cA Dynamical Theory of the Electromagnetic Field,\u201d Philosophical Transactions of the Royal Society 155 (1865): 459.\n\n45 THE FIRST TELEPHONE OPERATORS: Mich\u00e8le Martin, \u201cHello, Central?\u201d: Gender, Technology, and Culture in the Formation of Telephone Systems (Montreal: McGill\u2013Queen\u2019s University Press, 1991), 55.\n\n46 \u201cTHEY ARE STEADIER, DO NOT DRINK BEER\u201d: Proceedings of the National Telephone Exchange Association, 1881, in Frederick Leland Rhodes, Beginnings of Telephony (New York: Harper & Brothers, 1929), 154.\n\n47 \u201cTHE ACTION OF STRETCHING HER ARMS\u201d: Quoted in Peter Young, Person to Person: The International Impact of the Telephone (Cambridge: Granta, 1991), 65.\n\n48 \u201cTHE TELEPHONE REMAINS THE ACME\u201d: Herbert N. Casson, The History of the Telephone (Chicago: A. C. McClurg, 1910), 296.\n\n49 \u201cANY TWO OF THAT LARGE NUMBER\u201d: John Vaughn, \u201cThe Thirtieth Anniversary of a Great Invention,\u201d Scribner\u2019s 40 (1906): 371.\n\n50 A MONSTER OF 2 MILLION SOLDERED PARTS: G. E. Schindler, Jr., ed., A History of Engineering and Science in the Bell System: Switching Technology 1925\u20131975 (Bell Telephone Laboratories, 1982).\n\n51 \u201cFOR THE MATHEMATICIAN, AN ARGUMENT\u201d: T. C. Fry, \u201cIndustrial Mathematics,\u201d Bell System Technical Journal 20 (July 1941): 255.\n\n52 \u201cTHERE WAS SPUTTERING AND BUBBLING\u201d: Bell Canada Archives, quoted in Mich\u00e8le Martin, \u201cHello, Central?\u201d 23.\n\n53 \u201cSPEED OF TRANSMISSION OF INTELLIGENCE\u201d: H. Nyquist, \u201cCertain Factors Affecting Telegraph Speed,\u201d Bell System Technical Journal 3 (April 1924): 332.\n\n54 \u201cINFORMATION IS A VERY ELASTIC TERM\u201d: R. V. L. Hartley, \u201cTransmission of Information,\u201d Bell System Technical Journal 7 (July 1928): 536.\n\n55 \u201cFOR EXAMPLE, IN THE SENTENCE, \u2018APPLES ARE RED\u2019 \u201d: Ibid.\n\n56 \u201cBY THE SPEED OF TRANSMISSION OF INTELLIGENCE IS MEANT\u201d: H. Nyquist, \u201cCertain Factors Affecting Telegraph Speed,\u201d 333.\n\n57 \u201cTHE CAPACITY OF A SYSTEM TO TRANSMIT\u201d: R. V. L. Hartley, \u201cTransmission of\n7. INFORMATION THEORY\n\n1 \u201cPERHAPS COMING UP WITH A THEORY\u201d: Jon Barwise, \u201cInformation and Circumstance,\u201d Notre Dame Journal of Formal Logic 27, no. 3 (1986): 324.\n\n2 SAID NOTHING TO EACH OTHER ABOUT THEIR WORK: Shannon interview with Robert Price: \u201cA Conversation with Claude Shannon: One Man\u2019s Approach to Problem Solving,\u201d IEEE Communications Magazine 22 (1984): 125; cf. Alan Turing to Claude Shannon, 3 June 1953, Manuscript Division, Library of Congress.\n\n3 \u201cNO, I\u2019M NOT INTERESTED IN DEVELOPING A POWERFUL BRAIN\u201d: Andrew Hodges, Alan Turing: The Enigma (London: Vintage, 1992), 251.\n\n4 \u201cA CONFIRMED SOLITARY\u201d: Max H. A. Newman to Alonzo Church, 31 May 1936, quoted in Andrew Hodges, Alan Turing, 113.\n\n5 \u201cTHE JUSTIFICATION \u2026 LIES IN THE FACT\u201d: Alan M. Turing, \u201cOn Computable Numbers, with an Application to the Entscheidungsproblem,\u201d Proceedings of the London Mathematical Society 42 (1936): 230\u201365.\n\n6 \u201cIT WAS ONLY BY TURING\u2019S WORK\u201d: Kurt G\u00f6del to Ernest Nagel, 1957, in Kurt G\u00f6del: Collected Works, vol. 5, ed. Solomon Feferman (New York: Oxford University Press, 1986), 147.\n\n7 \u201cYOU SEE \u2026 THE FUNNY LITTLE ROUNDS\u201d: letter from Alan Turing to his mother and father, summer 1923, AMT/K/1/3, Turing Digital Archive, http://www.turingarchive.org.\n\n8 \u201cIN ELEMENTARY ARITHMETIC THE TWO-DIMENSIONAL CHARACTER\u201d: Alan M. Turing, \u201cOn Computable Numbers,\u201d 230\u201365.\n\n9 \u201cTHE THING HINGES ON GETTING THIS HALTING INSPECTOR\u201d: \u201cOn the Seeming Paradox of Mechanizing Creativity,\u201d in Douglas R. Hofstadter, Metamagical Themas: Questing for the Essence of Mind and Pattern (New York: Basic Books, 1985), 535.\n\n10 \u201cIT USED TO BE SUPPOSED IN SCIENCE\u201d: \u201cThe Nature of Spirit,\u201d unpublished essay, 1932, in Andrew Hodges, Alan Turing, 63.\n\n11 \u201cONE CAN PICTURE AN INDUSTRIOUS AND DILIGENT CLERK\u201d: Herbert B. Enderton, \u201cElements of Recursion Theory,\u201d in Jon Barwise, Handbook of Mathematical Logic (Amsterdam: North Holland, 1977), 529.\n\n12 \u201cA LOT OF PARTICULAR AND INTERESTING CODES\u201d: Alan Turing to Sara Turing, 14 October 1936, quoted in Andrew Hodges, Alan Turing, 120.\n\n13 \u201cTHE ENEMY KNOWS THE SYSTEM BEING USED\u201d: \u201cCommunication Theory of Secrecy Systems\u201d (1948), in Claude Elwood Shannon, Collected Papers, ed. N. J. A. Sloane and Aaron D. Wyner (New York: IEEE Press, 1993), 90.\n\n14 \u201cFROM THE POINT OF VIEW OF THE CRYPTOANALYST\u201d: Ibid., 113.\n15 \u201cTHE MERE SOUNDS OF SPEECH\u201d: Edward Sapir, *Language: An Introduction to the Study of Speech* (New York: Harcourt, Brace, 1921), 21.\n\n16 \u201cD MEASURES, IN A SENSE, HOW MUCH A TEXT\u201d: \u201cCommunication Theory of Secrecy Systems,\u201d in Claude Shannon, *Collected Papers*, 85.\n\n17 \u201cTHE ENEMY IS NO BETTER OFF\u201d: Ibid., 97.\n\n18 \u201cTHE \u2018MEANING\u2019 OF A MESSAGE IS GENERALLY IRRELEVANT\u201d: \u201cCommunication Theory\u2014Exposition of Fundamentals,\u201d *IRE Transactions on Information Theory*, no. 1 (February 1950), in Claude Shannon, *Collected Papers*, 173.\n\n19 \u201cWHAT GIBBS DID FOR PHYSICAL CHEMISTRY\u201d: Warren Weaver letter to Claude Shannon, 27 January 1949, Manuscript Division, Library of Congress.\n\n20 \u201cSOMETHING OF A DELAYED ACTION BOMB\u201d: John R. Pierce, \u201cThe Early Days of Information Theory,\u201d *IEEE Transactions on Information Theory* 19, no. 1 (1973): 4.\n\n21 \u201cTHE FUNDAMENTAL PROBLEM OF COMMUNICATION\u201d: Claude Elwood Shannon and Warren Weaver, *The Mathematical Theory of Communication* (Urbana: University of Illinois Press, 1949), 31.\n\n22 \u201cTHIS IS ALREADY DONE TO A LIMITED EXTENT\u201d: Ibid., 11.\n\n23 LANDMARK 1943 PAPER: \u201cStochastic Problems in Physics and Astronomy,\u201d *Reviews of Modern Physics* 15, no. 1 (January 1943), 1.\n\n24 BOOK NEWLY PUBLISHED FOR SUCH PURPOSES: M. G. Kendall and B. Babington Smith, *Table of Random Sampling Numbers* (Cambridge: Cambridge University Press, 1939). Kendall and Smith used a \u201crandomizing machine\u201d\u2014a rotating disc with the ten digits illuminated at irregular intervals by a neon light. An earlier effort, by L. H. C. Tippett in 1927, drew 41,000 digits from population census reports, also noting only the last digit of any number. A slightly na\u00efve article in the *Mathematical Gazette* argued in 1944 that machines were unnecessary: \u201cIn a modern community, there is, it seems, no need to construct a randomising machine, for so many features of sociological life exhibit randomness\u2026. Thus a set of random numbers serviceable for all ordinary purposes can be constructed by reading the registration numbers of cars as they pass us in the street, for cars though numbered serially move about the streets in non-serial fashion, obvious errors, such as those of reading the numbers seen every morning on the way to the station along one\u2019s own road when Mr. Smith\u2019s car is always standing outside No. 49 being, of course, avoided.\u201d Frank Sandon, \u201cRandom Sampling Numbers,\u201d *The Mathematical Gazette* 28 (December 1944): 216.\n\n25 TABLES CONSTRUCTED FOR USE BY CODE BREAKERS: Fletcher Pratt, *Secret and Urgent: The Story of Codes and Ciphers* (Garden City, N.Y.: Blue Ribbon, 1939).\n\n26 \u201cHOW MUCH \u2018CHOICE\u2019 IS INVOLVED\u201d: Claude Elwood Shannon and Warren Weaver, *The Mathematical Theory of Communication*, 18.\n\n27 \u201cBINARY DIGITS, OR MORE BRIEFLY, BITS\u201d: \u201cA word suggested by J. W. Tukey,\u201d he added. John Tukey, the statistician, had been a roommate of Richard Feynman\u2019s at Princeton and\nspent some time working at Bell Labs after the war.\n\n28 \u201cMORE ERRATIC AND UNCERTAIN\u201d: Claude Shannon, \u201cPrediction and Entropy of Printed English,\u201d *Bell System Technical Journal* 30 (1951): 50, in Claude Shannon, *Collected Papers*, 94.\n\n29 \u201cTO MAKE THE CHANCE OF ERROR\u201d: quoted in M. Mitchell Waldrop, \u201cReluctant Father of the Digital Age,\u201d *Technology Review* (July\u2013August 2001): 64\u201371.\n\n30 \u201cIT\u2019S A SOLID-STATE AMPLIFIER\u201d: Shannon interview with Anthony Liversidge, *Omni* (August 1987), in Claude Shannon, *Collected Papers*, xxiii.\n\n31 \u201cBITS STORAGE CAPACITY\u201d: Handwritten note, 12 July 1949, Manuscript Division, Library of Congress.\n\n8. THE INFORMATIONAL TURN\n\n1 \u201cIT IS PROBABLY DANGEROUS TO USE THIS THEORY\u201d: Heinz von Foerster, ed., *Cybernetics: Circular Causal and Feedback Mechanisms in Biological and Social Systems: Transactions of the Seventh Conference, March 23\u201324, 1950* (New York: Josiah Macy, Jr. Foundation, 1951), 155.\n\n2 \u201cAND IT IS NOT ALWAYS CLEAR\u201d: J. J. Doob, review (untitled), *Mathematical Reviews* 10 (February 1949): 133.\n\n3 \u201cAT FIRST GLANCE, IT MIGHT APPEAR\u201d: A. Chapanis, review (untitled), *Quarterly Review of Biology* 26, no. 3 (September 1951): 321.\n\n4 \u201cSHANNON DEVELOPS A CONCEPT OF INFORMATION\u201d: Arthur W. Burks, review (untitled), *Philosophical Review* 60, no. 3 (July 1951): 398.\n\n5 SHORT REVIEW OF WIENER\u2019S BOOK: *Proceedings of the Institute of Radio Engineers* 37 (1949), in Claude Elwood Shannon, *Collected Papers*, ed. N. J. A. Sloane and Aaron D. Wyner (New York: IEEE Press, 1993), 872.\n\n6 \u201cWIENER\u2019S HEAD WAS FULL\u201d: John R. Pierce, \u201cThe Early Days of Information Theory,\u201d *IEEE Transactions on Information Theory* 19, no. 1 (1973): 5.\n\n7 THE WORD HE TOOK FROM THE GREEK: Andr\u00e9-Marie Amp\u00e8re had used the word, *cybern\u00e9tics*, in 1834 (*Essai sur la philosophie des sciences*).\n\n8 \u201cA LAD WHO HAS BEEN PROUDLY TERMED\u201d: \u201cBoy of 14 College Graduate,\u201d *The New York Times*, 9 May 1909, 1.\n\n9 \u201cAN INFANT PRODIGY NAMED WIENER\u201d: Bertrand Russell to Lucy Donnelly, 19 October 1913, quoted in Steve J. Heims, *John von Neumann and Norbert Wiener* (Cambridge, Mass.: MIT Press, 1980), 18.\n\n10 \u201cHE IS AN ICEBERG\u201d: Norbert Wiener to Leo Wiener, 15 October 1913, quoted in Flo Conway and Jim Siegelman, *Dark Hero of the Information Age: In Search of Norbert Weiner*, the\nFather of Cybernetics (New York: Basic Books, 2005), 30.\n\n11 \u201cWE ARE SWIMMING UPSTREAM AGAINST A GREAT TORRENT\u201d: Norbert Wiener, I Am a Mathematician: The Later Life of a Prodigy (Cambridge, Mass.: MIT Press, 1964), 324.\n\n12 \u201cA NEW INTERPRETATION OF MAN\u201d: Ibid., 375.\n\n13 \u201cANY CHANGE OF AN ENTITY\u201d: Arturo Rosenblueth et al., \u201cBehavior, Purpose and Teleology,\u201d Philosophy of Science 10 (1943): 18.\n\n14 \u201cTHAT IT WAS NOT SOME PARTICULAR PHYSICAL THING\u201d: Quoted in Warren S. McCulloch, \u201cRecollections of the Many Sources of Cybernetics,\u201d ASC Forum 6, no. 2 (1974).\n\n15 \u201cTHEY ARE GROWING WITH FEARFUL SPEED\u201d: \u201cIn Man\u2019s Image,\u201d Time, 27 December 1948.\n\n16 \u201cTHE ALGEBRA OF LOGIC PAR EXCELLENCE\u201d: Norbert Wiener, Cybernetics: Or Control and Communication in the Animal and the Machine, 2nd ed. (Cambridge, Mass.: MIT Press, 1961), 118.\n\n17 \u201cTRAFFIC PROBLEMS AND OVERLOADING\u201d: Ibid., 132.\n\n18 \u201cFOR THE FIRST TIME IN THE HISTORY OF SCIENCE\u201d: Warren S. McCulloch, \u201cThrough the Den of the Metaphysician,\u201d British Journal for the Philosophy of Science 5, no. 17 (1954): 18.\n\n19 A NOAH\u2019S ARK RULE: Warren S. McCulloch, \u201cRecollections of the Many Sources of Cybernetics,\u201d 11.\n\n20 WIENER TOLD THEM THAT ALL THESE SCIENCES: Steve J. Heims, The Cybernetics Group (Cambridge, Mass.: MIT Press, 1991), 22.\n\n21 \u201cTHE SUBJECT AND THE GROUP\u201d: Heinz von Foerster, ed., Transactions of the Seventh Conference, 11.\n\n22 \u201cTO SAY, AS THE PUBLIC PRESS SAYS\u201d: Ibid., 12.\n\n23 \u201cI HAVE NOT BEEN ABLE TO PREVENT THESE REPORTS\u201d: Ibid., 18.\n\n24 IT WAS, AT BOTTOM, A PERFECTLY ORDINARY SITUATION: Jean-Pierre Dupuy, The Mechanization of the Mind: On the Origins of Cognitive Science, trans. M. B. DeBevoise (Princeton, N.J.: Princeton University Press, 2000), 89.\n\n25 COULD PROPERLY BE DESCRIBED AS ANALOG OR DIGITAL: Heinz von Foerster, ed., Transactions of the Seventh Conference, 13.\n\n26 \u201cTHE STATE OF THE NERVE CELL WITH NO MESSAGE IN IT\u201d: Ibid., 20.\n\n27 \u201cIN THIS WORLD IT SEEMS BEST\u201d: Warren S. McCulloch and John Pfeiffer, \u201cOf Digital Computers Called Brains,\u201d Scientific Monthly 69, no. 6 (1949): 368.\n\n28 HE WAS WORKING ON AN IDEA FOR QUANTIZING SPEECH: J. C. R. Licklider, interview by William Aspray and Arthur Norberg, 28 October 1988, Charles Babbage Institute, University of Minnesota, http://special.lib.umn.edu/cbi/oh/pdf.phtml?id=180 (accessed 6\n29 \u201cMATHEMATICIANS ARE ALWAYS DOING THAT\u201d: Heinz von Foerster, ed., Transactions of the Seventh Conference, 66.\n\n30 \u201cYES!\u201d INTERRUPTED WIENER: Ibid., 92.\n\n31 \u201cIF YOU TALK ABOUT ANOTHER KIND OF INFORMATION\u201d: Ibid., 100.\n\n32 \u201cIT MIGHT, FOR EXAMPLE, BE A RANDOM SEQUENCE\u201d: Ibid., 123.\n\n33 \u201cI WOULDN\u2019T CALL THAT RANDOM, WOULD YOU? \u201d: Ibid., 135.\n\n34 \u201cI WANTED TO CALL THE WHOLE\u201d: quoted in Flo Conway and Jim Siegelman, Dark Hero of the Information Age, 189.\n\n35 \u201cT\u2019M THINKING OF THE OLD MAYA TEXTS\u201d: Heinz von Foerster, ed., Transactions of the Seventh Conference, 143.\n\n36 \u201cINFORMATION CAN BE CONSIDERED AS ORDER\u201d: Heinz von Foerster, ed., Cybernetics: Circular Causal and Feedback Mechanisms in Biological and Social Systems: Transactions of the Eighth Conference, March 15\u201316, 1951 (New York: Josiah Macy, Jr. Foundation, 1952), xiii.\n\n37 HIS NEIGHBOR SAID: Heinz von Foerster, ed., Transactions of the Seventh Conference, 151.\n\n38 \u201cWHEN THE MACHINE WAS TURNED OFF\u201d: Heinz von Foerster, ed., Transactions of the Eighth Conference, 173.\n\n39 \u201cIT BUILDS UP A COMPLETE PATTERN OF INFORMATION\u201d: \u201cComputers and Automata,\u201d in Claude Shannon, Collected Papers, 706.\n\n40 \u201cWHEN IT ARRIVES AT A, IT REMEMBERS\u201d: Heinz von Foerster, ed. Transactions of the Eighth Conference, 175.\n\n41 \u201cLIKE A MAN WHO KNOWS THE TOWN\u201d: Ibid., 180.\n\n42 \u201cIN REALITY IT IS THE MAZE WHICH REMEMBERS\u201d: Quoted in Roberto Cordeschi, The Discovery of the Artificial: Behavior, Mind, and Machines Before and Beyond Cybernetics (Dordrecht, Netherlands: Springer, 2002), 163.\n\n43 FOUND RESEARCHERS TO BE \u201cWELL-INFORMED\u201d: Norbert Wiener, Cybernetics, 23.\n\n44 \u201cABOUT FIFTEEN PEOPLE WHO HAD WIENER\u2019S IDEAS\u201d: John Bates to Grey Walter, quoted in Owen Holland, \u201cThe First Biologically Inspired Robots,\u201d Robotica 21 (2003): 354.\n\n45 HALF PRONOUNCED IT RAY-SHE-OH: Philip Husbands and Owen Holland, \u201cThe Ratio Club: A Hub of British Cybernetics,\u201d in The Mechanical Mind in History (Cambridge, Mass.: MIT Press, 2008), 103.\n\n46 \u201cA BRAIN CONSISTING OF RANDOMLY CONNECTED IMPRESSIONAL SYNAPSES\u201d: Ibid., 110.\n\n47 \u201cTHINK OF THE BRAIN AS A TELEGRAPHIC RELAY\u201d: \u201cBrain and Behavior,\u201d Comparative Psychology Monograph, Series 103 (1950), in Warren S. McCulloch, Embodiments\nof Mind (Cambridge, Mass.: MIT Press, 1965), 307.\n\n48 \u201cI PROPOSE TO CONSIDER THE QUESTION\u201d: Alan M. Turing, \u201cComputing Machinery and Intelligence,\u201d Minds and Machines 59, no. 236 (1950): 433\u201360.\n\n49 \u201cTHE PRESENT INTEREST IN \u2018THINKING MACHINES\u2019 \u201d: Ibid., 436.\n\n50 \u201cSINCE BABBAGE\u2019S MACHINE WAS NOT ELECTRICAL\u201d: Ibid., 439.\n\n51 \u201cIN THE CASE THAT THE FORMULA IS NEITHER PROVABLE NOR DISPROVABLE\u201d: Alan M. Turing, \u201cIntelligent Machinery, A Heretical Theory,\u201d unpublished lecture, c. 1951, in Stuart M. Shieber, ed., The Turing Test: Verbal Behavior as the Hallmark of Intelligence (Cambridge, Mass.: MIT Press, 2004), 105.\n\n52 THE ORIGINAL QUESTION, \u201cCAN MACHINES THINK?\u201d: Alan M. Turing, \u201cComputing Machinery and Intelligence,\u201d 442.\n\n53 \u201cTHE IDEA OF A MACHINE THINKING\u201d: Claude Shannon to C. Jones, 16 June 1952, Manuscript Div., Library of Congress, by permission of Mary E. Shannon.\n\n54 \u201cPSYCHOLOGIE IS A DOCTRINE WHICH SEARCHES OUT\u201d: Translated in William Harvey, Anatomical Exercises Concerning the Motion of the Heart and Blood (London, 1653), quoted in \u201cpsychology, n,\u201d draft revision Dec. 2009, OED Online, Oxford University Press, http://dictionary.oed.com/cgi/entry/50191636.\n\n55 \u201cTHE SCIENCE OF MIND, IF IT CAN BE CALLED A SCIENCE\u201d: North British Review 22 (November 1854), 181.\n\n56 \u201cA LOATHSOME, DISTENDED, TUMEFIED, BLOATED, DROPSICAL MASS\u201d: William James to Henry Holt, 9 May 1890, quoted in Robert D. Richardson, William James: In the Maelstrom of American Modernism (New York: Houghton Mifflin, 2006), 298.\n\n57 \u201cYOU TALK ABOUT MEMORY\u201d: George Miller, dialogue with Jonathan Miller, in Jonathan Miller, States of Mind (New York: Pantheon, 1983), 22.\n\n58 \u201cNEW CONCEPTS OF THE NATURE AND MEASURE\u201d: Homer Jacobson, \u201cThe Informational Capacity of the Human Ear,\u201d Science 112 (4 August 1950): 143\u201344; \u201cThe Informational Capacity of the Human Eye,\u201d Science 113 (16 March 1951): 292\u201393.\n\n59 A GROUP IN 1951 TESTED THE LIKELIHOOD: G. A. Miller, G. A. Heise, and W. Lichten, \u201cThe Intelligibility of Speech as a Function of the Context of the Test Materials,\u201d Journal of Experimental Psychology 41 (1951): 329\u201335.\n\n60 \u201cTHE DIFFERENCE BETWEEN A DESCRIPTION\u201d: Donald E. Broadbent, Perception and Communication (Oxford: Pergamon Press, 1958), 31.\n\n61 \u201cTHE MAGICAL NUMBER SEVEN\u201d: Psychological Review 63 (1956): 81\u201397.\n\n62 \u201cTHOSE WHO TAKE THE INFORMATIONAL TURN\u201d: Frederick Adams, \u201cThe Informational Turn in Philosophy,\u201d Minds and Machines 13 (2003): 495.\n\n63 THE MIND CAME IN ON THE BACK: Jonathan Miller, States of Mind, 26.\n\n64 \u201cI THINK THAT THIS PRESENT CENTURY\u201d: Claude Shannon, \u201cThe Transfer of\nInformation,\u201d talk presented at the 75th anniversary of the University of Pennsylvania Graduate School of Arts and Sciences, Manuscript Division, Library of Congress. Reprinted by permission of Mary E. Shannon.\n\n65 \u201cOUR FELLOW SCIENTISTS IN MANY DIFFERENT FIELDS\u201d: \u201cThe Bandwagon,\u201d in Claude Shannon, *Collected Papers*, 462.\n\n66 \u201cOUR CONSENSUS HAS NEVER BEEN UNANIMOUS\u201d: quoted in Steve J. Heims, *The Cybernetics Group*, 277.\n\n67 THIS WAS CHANGED FOR PUBLICATION: Notes by Neil J. A. Sloane and Aaron D. Wyner in Claude Shannon, *Collected Papers*, 882.\n\n68 \u201cOF COURSE, IS OF NO IMPORTANCE\u201d: Claude E. Shannon, \u201cProgramming a Computer for Playing Chess,\u201d first presented at National IRE Convention, 9 March 1949, in Claude Shannon, *Collected Papers*, 637; and \u201cA Chess-Playing Machine,\u201d *Scientific American* (February 1950), in Claude Shannon, *Collected Papers*, 657.\n\n69 VISITED THE AMERICAN CHAMPION: Edward Lasker to Claude Shannon, 7 February 1949, Manuscript Division, Library of Congress.\n\n70 \u201cLEARNING CHESS PLAYER\u201d: Claude Shannon to C. J. S. Purdy, 28 August 1952, Manuscript Div., Library of Congress, by permission of Mary E. Shannon.\n\n71 SCIENTIFIC ASPECTS OF JUGGLING: Unpublished, in Claude Shannon, *Collected Papers*, 861. The actual lines, from Cummings\u2019s poem \u201cvoices to voices, lip to lip,\u201d are: \u201cwho cares if some oneeyed son of a bitch / invents an instrument to measure Spring with?\u201d\n\n72 A MACHINE THAT WOULD REPAIR ITSELF: Claude Shannon to Irene Angus, 8 August 1952, Manuscript Division, Library of Congress.\n\n73 \u201cWHAT HAPPENS IF YOU SWITCH ON ONE OF THESE MECHANICAL COMPUTERS\u201d: Robert McCraken, \u201cThe Sinister Machines,\u201d *Wyoming Tribune*, March 1954.\n\n74 \u201cINFORMATION THEORY, PHOTOSYNTHESIS, AND RELIGION\u201d: Peter Elias, \u201cTwo Famous Papers,\u201d *IRE Transactions on Information Theory* 4, no. 3 (1958): 99.\n\n75 \u201cWE HAVE HEARD OF \u2018ENTROPIES\u2019 \u201d: E. Colin Cherry, *On Human Communication* (Cambridge, Mass.: MIT Press, 1957), 214.\n\n9. ENTROPY AND ITS DEMONS\n\n1 \u201cTHOUGHT INTERFERES WITH THE PROBABILITY OF EVENTS\u201d: David L. Watson, \u201cEntropy and Organization,\u201d *Science* 72 (1930): 222.\n\n2 THE RUMOR AT BELL LABS: Robert Price, \u201cA Conversation with Claude Shannon: One Man\u2019s Approach to Problem Solving,\u201d *IEEE Communications Magazine* 22 (1984): 124.\n\n3 \u201cTHE THEORETICAL STUDY OF THE STEAM ENGINE\u201d: For example, J. Johnstone, \u201cEntropy and Evolution,\u201d *Philosophy* 7 (July 1932): 287.\n4 MAXWELL TURNED ABOUT-FACE: James Clerk Maxwell, *Theory of Heat*, 2nd ed. (London: Longmans, Green, 1872), 186; 8th edition (London: Longmans, Green, 1891), 189 n.\n\n5 \u201cYOU CAN\u2019T WIN\u201d: Peter Nicholls and David Langford, eds., *The Science in Science Fiction* (New York: Knopf, 1983), 86.\n\n6 \u201cALTHOUGH MECHANICAL ENERGY IS INDESTRUCTIBLE\u201d: Lord Kelvin (William Thomson), \u201cPhysical Considerations Regarding the Possible Age of the Sun\u2019s Heat,\u201d lecture at the Meeting of the British Association at Manchester, September 1861, in *Philosophical Magazine* 152 (February 1862): 158.\n\n7 \u201cIN CONSIDERING THE CONVERSION OF PSYCHICAL ENERGY\u201d: Sigmund Freud, \u201cFrom the History of an Infantile Neurosis,\u201d 1918b, 116, in *The Standard Edition of the Complete Psychological Works of Sigmund Freud* (London: Hogarth Press, 1955).\n\n8 \u201cCONFUSION, LIKE THE CORRELATIVE TERM ORDER\u201d: James Clerk Maxwell, \u201cDiffusion,\u201d written for the ninth edition of *Encyclopaedia Britannica*, in *The Scientific Papers of James Clerk Maxwell*, ed. W. D. Niven, vol. 2 (Cambridge: Cambridge University Press, 1890; repr. New York: Dover, 1965), 646.\n\n9 \u201cTIME FLOWS ON, NEVER COMES BACK\u201d: L\u00e9on Brillouin, \u201cLife, Thermodynamics, and Cybernetics\u201d (1949), in Harvey S. Leff and Andrew F. Rex, eds., *Maxwell\u2019s Demon 2: Entropy, Classical and Quantum Information, Computing* (Bristol, U.K.: Institute of Physics, 2003), 77.\n\n10 \u201cTHE ACCIDENTS OF LIFE\u201d: Richard Feynman, *The Character of Physical Law* (New York: Modern Library, 1994), 106.\n\n11 \u201cMORAL. THE 2ND LAW OF THERMODYNAMICS\u201d: James Clerk Maxwell to John William Strutt, 6 December 1870, in Elizabeth Garber, Stephen G. Brush, and C. W. F. Everitt, eds., *Maxwell on Heat and Statistical Mechanics: On \u201cAvoiding All Personal Enquiries\u201d of Molecules* (London: Associated University Presses, 1995), 205.\n\n12 \u201cTHE ODDS AGAINST A PIECE OF CHALK\u201d: Quoted by Andrew Hodges, \u201cWhat Did Alan Turing Mean by \u2018Machine,\u2019?\u201d in Philip Husbands et al., *The Mechanical Mind in History* (Cambridge, Mass.: MIT Press, 2008), 81.\n\n13 \u201cAND YET NO WORK HAS BEEN DONE\u201d: James Clerk Maxwell to Peter Guthrie Tait, 11 December 1867, in *The Scientific Letters and Papers of James Clerk Maxwell*, ed. P. M. Harman, vol. 3 (Cambridge: Cambridge University Press, 2002), 332.\n\n14 \u201cHE DIFFERS FROM REAL LIVING ANIMALS\u201d: Royal Institution Lecture, 28 February 1879, *Proceedings of the Royal Institution* 9 (1880): 113, in William Thomson, *Mathematical and Physical Papers*, vol. 5 (Cambridge: Cambridge University Press, 1911), 21.\n\n15 \u201cINFINITE SWARMS OF ABSURD LITTLE MICROSCOPIC IMPS\u201d: \u201cEditor\u2019s Table,\u201d *Popular Science Monthly* 15 (1879): 412.\n\n16 \u201cCLERK MAXWELL\u2019S DEMON\u201d: Henry Adams to Brooks Adams, 2 May 1903, in *Henry Adams and His Friends: A Collection of His Unpublished Letters*, ed. Harold Cater (Boston: Houghton Mifflin, 1947), 545.\n17 \u201cINFINITELY SUBTILE SENSES\u201d: Henri Poincar\u00e9, *The Foundations of Science*, trans. George Bruce Halsted (New York: Science Press, 1913), 152.\n\n18 \u201cNOW WE MUST NOT INTRODUCE DEMONOLOGY\u201d: James Johnstone, *The Philosophy of Biology* (Cambridge: Cambridge University Press, 1914), 118.\n\n19 \u201cIF WE VIEW THE EXPERIMENTING MAN\u201d: Le\u00f3 Szil\u00e1rd, \u201cOn the Decrease of Entropy in a Thermodynamic System by the Intervention of Intelligent Beings,\u201d trans. Anatol Rapoport and Mechthilde Knoller, from Le\u00f3 Szil\u00e1rd, \u201c\u00dcber Die Entropieverminderung in Einem Thermodynamischen System Bei Eingriffen Intelligenter Wesen,\u201d *Zeitschrift f\u00fcr Physik* 53 (1929): 840\u201356, in Harvey S. Leff and Andrew F. Rex, eds., *Maxwell\u2019s Demon 2*, 111.\n\n20 \u201cTHINKING GENERATES ENTROPY\u201d: Quoted in William Lanouette, *Genius in the Shadows* (New York: Scribner\u2019s, 1992), 64.\n\n21 \u201cI THINK ACTUALLY SZILARD\u201d: Shannon interview with Friedrich-Wilhelm Hagemeyer, 1977, quoted in Erico Mariu Guizzo, \u201cThe Essential Message: Claude Shannon and the Making of Information Theory\u201d (Master\u2019s thesis, Massachusetts Institute of Technology, 2004).\n\n22 \u201cI CONSIDER HOW MUCH INFORMATION IS PRODUCED\u201d: Claude Shannon to Norbert Wiener, 13 October 1948, Massachusetts Institute of Technology Archives.\n\n23 \u201cTHAT SOME OF US SHOULD VENTURE TO EMBARK\u201d: Erwin Schr\u00f6dinger, *What Is Life?*, reprint ed. (Cambridge: Cambridge University Press, 1967), 1.\n\n24 \u201cSCHR\u00d6DINGER\u2019S BOOK BECAME A KIND OF UNCLE TOM\u2019S CABIN\u201d: Gunther S. Stent, \u201cThat Was the Molecular Biology That Was,\u201d *Science* 160, no. 3826 (1968): 392.\n\n25 \u201cWHEN IS A PIECE OF MATTER SAID TO BE ALIVE?\u201d: Erwin Schr\u00f6dinger, *What Is Life?*, 69.\n\n26 \u201cTHE STABLE STATE OF AN ENZYME\u201d: Norbert Wiener, *Cybernetics: Or Control and Communication in the Animal and the Machine*, 2nd ed. (Cambridge, Mass.: MIT Press, 1961), 58.\n\n27 \u201cTO PUT IT LESS PARADOXICALLY\u201d: Erwin Schr\u00f6dinger, *What Is Life?*, 71.\n\n28 \u201cA COMPLETE (DOUBLE) COPY OF THE CODE-SCRIPT\u201d: Ibid., 23.\n\n29 \u201cIT SEEMS NEITHER ADEQUATE NOR POSSIBLE\u201d: Ibid., 28.\n\n30 \u201cWE BELIEVE A GENE\u2014OR PERHAPS THE WHOLE CHROMOSOME FIBER\u201d: Ibid., 61.\n\n31 \u201cTHE DIFFERENCE IN STRUCTURE\u201d: Ibid., 5 (my emphasis).\n\n32 \u201cTHE LIVING ORGANISM HEALS ITS OWN WOUNDS\u201d: L\u00e9on Brillouin, \u201cLife, Thermodynamics, and Cybernetics,\u201d 84.\n\n33 HE WROTE THIS IN 1950: L\u00e9on Brillouin, \u201cMaxwell\u2019s Demon Cannot Operate: Information and Entropy,\u201d in Harvey S. Leff and Andrew F. Rex, eds., *Maxwell\u2019s Demon 2*, 123.\n\n34 \u201cMAXWELL\u2019S DEMON DIED AT THE AGE OF 62\u201d: Peter T. Landsberg, *The Enigma of Time* (Bristol: Adam Hilger, 1982), 15.\n10. LIFE\u2019S OWN CODE\n\n1 \u201cWHAT LIES AT THE HEART OF EVERY LIVING THING\u201d: Richard Dawkins, *The Blind Watchmaker* (New York: Norton, 1986), 112.\n\n2 \u201cTHE BIOLOGIST MUST BE ALLOWED\u201d: W. D. Gunning, \u201cProgression and Retrogression,\u201d *The Popular Science Monthly* 8 (December 1875): 189, n1.\n\n3 \u201cTHE MOST NA\u00cfVE AND OLDEST CONCEPTION\u201d: Wilhelm Johannsen, \u201cThe Genotype Conception of Heredity,\u201d *American Naturalist* 45, no. 531 (1911): 130.\n\n4 IT MUST BE QUANTIZED: \u201cDiscontinuity and constant differences between the \u2018genes\u2019 are the quotidian bread of Mendelism,\u201d *American Naturalist* 45, no. 531 (1911): 147.\n\n5 \u201cTHE MINIATURE CODE SHOULD PRECISELY CORRESPOND\u201d: Erwin Schr\u00f6dinger, *What Is Life?*, reprint ed. (Cambridge: Cambridge University Press, 1967), 62.\n\n6 SOME OF THE PHYSICISTS NOW TURNING TO BIOLOGY: Henry Quastler, ed., *Essays on the Use of Information Theory in Biology* (Urbana: University of Illinois Press, 1953).\n\n7 \u201cA LINEAR CODED TAPE OF INFORMATION\u201d: Sidney Dancoff to Henry Quastler, 31 July 1950, quoted in Lily E. Kay, *Who Wrote the Book of Life: A History of the Genetic Code* (Stanford, Calif.: Stanford University Press, 2000), 119.\n\n8 NUMBER OF BITS REPRESENTED BY A SINGLE BACTERIUM: Henry Linschitz, \u201cThe Information Content of a Bacterial Cell,\u201d in Henry Quastler, ed., *Essays on the Use of Information Theory in Biology*, 252.\n\n9 \u201cHYPOTHETICAL INSTRUCTIONS TO BUILD AN ORGANISM\u201d: Sidney Dancoff and Henry Quastler, \u201cThe Information Content and Error Rate of Living Things,\u201d in Henry Quastler, ed., *Essays on the Use of Information Theory in Biology*, 264.\n\n10 \u201cTHE ESSENTIAL COMPLEXITY OF A SINGLE CELL\u201d: Ibid., 270.\n\n11 AN ODD LITTLE LETTER: Boris Ephrussi, Urs Leopold, J. D. Watson, and J. J. Weigle, \u201cTerminology in Bacterial Genetics,\u201d *Nature* 171 (18 April 1953): 701.\n\n12 MEANT AS A JOKE: Cf. Sahotra Sarkar, *Molecular Models of Life* (Cambridge, Mass.: MIT Press, 2005); Lily E. Kay, *Who Wrote the Book of Life?*, 58; Harriett Ephrussi-Taylor to Joshua Lederberg, 3 September 1953, and Lederberg annotation 30 April 2004, in Lederberg papers, http://profiles.nlm.nih.gov/BB/A/J/R/R/ (accessed 22 January 2009); and James D. Watson, *Genes, Girls, and Gamow: After the Double Helix* (New York: Knopf, 2002), 12.\n\n13 GENES MIGHT LIE IN A DIFFERENT SUBSTANCE: In retrospect, everyone understood that this had been proven in 1944, by Oswald Avery at Rockefeller University. Not many researchers were convinced at the time, however.\n\n14 \u201cONE OF THE MOST COY STATEMENTS\u201d: Gunther S. Stent, \u201cDNA,\u201d *Daedalus* 99 (1970): 924.\n\n15 \u201cIT HAS NOT ESCAPED OUR NOTICE\u201d: James D. Watson and Francis Crick, \u201cA Structure for Deoxyribose Nucleic Acid,\u201d *Nature* 171 (1953): 737.\n16 \u201cIT FOLLOWS THAT IN A LONG MOLECULE\u201d: James D. Watson and Francis Crick, \u201cGenetical Implications of the Structure of Deoxyribonucleic Acid,\u201d *Nature* 171 (1953): 965.\n\n17 \u201cDEAR DRS. WATSON & CRICK\u201d: George Gamow to James D. Watson and Francis Crick, 8 July 1953, quoted in Lily E. Kay, *Who Wrote the Book of Life?*, 131. Reprinted by permission of R. Igor Gamow.\n\n18 \u201cAS IN THE BREAKING OF ENEMY MESSAGES\u201d: George Gamow to E. Chargaff, 6 May 1954, Ibid., 141.\n\n19 \u201cBY PRIVATE INTERNATIONAL BUSH TELEGRAPH\u201d: Gunther S. Stent, \u201cDNA,\u201d 924.\n\n20 \u201cPEOPLE DIDN\u2019T NECESSARILY BELIEVE IN THE CODE\u201d: Francis Crick, interview with Horace Freeland Judson, 20 November 1975, in Horace Freeland Judson, *The Eighth Day of Creation: Makers of the Revolution in Biology* (New York: Simon & Schuster, 1979), 233.\n\n21 \u201cA LONG NUMBER WRITTEN IN A FOUR-DIGITAL SYSTEM\u201d: George Gamow, \u201cPossible Relation Between Deoxyribonucleic Acid and Protein Structures,\u201d *Nature* 173 (1954): 318.\n\n22 \u201cBETWEEN THE COMPLEX MACHINERY IN A LIVING CELL\u201d: Douglas R. Hofstadter, \u201cThe Genetic Code: Arbitrary?\u201d (March 1982), in *Metamagical Themas: Questing for the Essence of Mind and Pattern* (New York: Basic Books, 1985), 671.\n\n23 \u201cTHE NUCLEUS OF A LIVING CELL IS A STOREHOUSE OF INFORMATION\u201d: George Gamow, \u201cInformation Transfer in the Living Cell,\u201d *Scientific American* 193, no. 10 (October 1955): 70.\n\n24 UNNECESSARY IF SOME TRIPLETS MADE \u201cSENSE\u201d: Francis Crick, \u201cGeneral Nature of the Genetic Code for Proteins,\u201d *Nature* 192 (30 December 1961): 1227.\n\n25 \u201cTHE SEQUENCE OF NUCLEOTIDES AS AN INFINITE MESSAGE\u201d: Solomon W. Golomb, Basil Gordon, and Lloyd R. Welch, \u201cComma-Free Codes,\u201d *Canadian Journal of Mathematics* 10 (1958): 202\u2013209, quoted in Lily E. Kay, *Who Wrote the Book of Life?*, 171.\n\n26 \u201cONCE \u2018INFORMATION\u2019 HAS PASSED INTO PROTEIN\u201d: Francis Crick, \u201cOn Protein Synthesis,\u201d *Symposium of the Society for Experimental Biology* 12 (1958): 152; Cf. Francis Crick, \u201cCentral Dogma of Molecular Biology,\u201d *Nature* 227 (1970): 561\u201363; and Hubert P. Yockey, *Information Theory, Evolution, and the Origin of Life* (Cambridge: Cambridge University Press, 2005), 20\u201321.\n\n27 \u201cTHE COMPLETE DESCRIPTION OF THE ORGANISM\u201d: Horace Freeland Judson, *The Eighth Day of Creation*, 219\u201321.\n\n28 \u201cIT IS IN THIS SENSE THAT ALL WORKING GENETICISTS\u201d: Gunther S. Stent, \u201cYou Can Take the Ethics Out of Altruism But You Can\u2019t Take the Altruism Out of Ethics,\u201d *Hastings Center Report* 7, no. 6 (1977): 34; and Gunther S. Stent, \u201cDNA,\u201d 925.\n\n29 \u201cIT DEPENDS UPON WHAT LEVEL\u201d: Seymour Benzer, \u201cThe Elementary Units of Heredity,\u201d in W. D. McElroy and B. Glass, eds., *The Chemical Basis of Heredity* (Baltimore: Johns Hopkins University Press, 1957), 70.\n30 \u201cTHIS ATTITUDE IS AN ERROR OF GREAT PROFUNDITY\u201d: Richard Dawkins, *The Selfish Gene*, 30th anniversary edition (Oxford: Oxford University Press, 2006), 237.\n\n31 \u201cWE ARE SURVIVAL MACHINES\u201d: Ibid., xxi.\n\n32 \u201cTHEY ARE PAST MASTERS OF THE SURVIVAL ARTS\u201d: Ibid., 19.\n\n33 \u201cENGLISH BIOLOGIST RICHARD DAWKINS HAS RECENTLY RAISED\u201d: Stephen Jay Gould, \u201cCaring Groups and Selfish Genes,\u201d in *The Panda\u2019s Thumb* (New York: Norton, 1980), 86.\n\n34 \u201cA THIRTY-SIX-YEAR-OLD STUDENT OF ANIMAL BEHAVIOR\u201d: Gunther S. Stent, \u201cYou Can Take the Ethics Out of Altruism But You Can\u2019t Take the Altruism Out of Ethics,\u201d 33.\n\n35 \u201cEVERY CREATURE MUST BE ALLOWED TO \u2018RUN\u2019 ITS OWN DEVELOPMENT\u201d: Samuel Butler, *Life and Habit* (London: Tr\u00fcbner & Co, 1878), 134.\n\n36 \u201cA SCHOLAR \u2026 IS JUST A LIBRARY\u2019S WAY\u201d: Daniel C. Dennett, *Darwin\u2019s Dangerous Idea: Evolution and the Meanings of Life* (New York: Simon & Schuster, 1995), 346.\n\n37 \u201cANTHROPOCENTRISM IS A DISABLING VICE OF THE INTELLECT\u201d: Edward O. Wilson, \u201cBiology and the Social Sciences,\u201d *Daedalus* 106, no. 4 (Fall 1977), 131.\n\n38 \u201cIT REQUIRES A DELIBERATE MENTAL EFFORT\u201d: Richard Dawkins, *The Selfish Gene*, 265.\n\n39 \u201cMIGHT ENSURE ITS SURVIVAL BY TENDING TO ENDOW\u201d: Ibid., 36.\n\n40 \u201cTHEY DO NOT PLAN AHEAD\u201d: Ibid., 25.\n\n41 \u201cTHERE IS A MOLECULAR ARCHEOLOGY IN THE MAKING\u201d: Werner R. Loewenstein, *The Touchstone of Life: Molecular Information, Cell Communication, and the Foundations of Life* (New York: Oxford University Press, 1999), 93\u201394.\n\n42 \u201cSELECTION FAVORS THOSE GENES WHICH SUCCEED\u201d: Richard Dawkins, *The Extended Phenotype*, rev. ed. (Oxford: Oxford University Press, 1999), 117.\n\n43 DAWKINS SUGGESTS THE CASE OF A GENE: Ibid., 196\u201397.\n\n44 THERE IS NO GENE FOR LONG LEGS: Richard Dawkins, *The Selfish Gene*, 37.\n\n45 HABIT OF SAYING \u201cA GENE FOR X\u201d: Richard Dawkins, *The Extended Phenotype*, 21.\n\n46 \u201cALL WE WOULD NEED IN ORDER\u201d: Ibid., 23.\n\n47 \u201cANY GENE THAT INFLUENCES THE DEVELOPMENT OF NERVOUS SYSTEMS\u201d: Richard Dawkins, *The Selfish Gene*, 60.\n\n48 \u201cIT IS NO MORE LIKELY TO DIE\u201d: Ibid., 34.\n\n49 \u201cTODAY THE TENDENCY IS TO SAY\u201d: Max Delbr\u00fcck, \u201cA Physicist Looks At Biology,\u201d *Transactions of the Connecticut Academy of Arts and Sciences* 38 (1949): 194.\n\n11. INTO THE MEME POOL\n\n1 \u201cWHEN I MUSE ABOUT MEMES\u201d: Douglas R. Hofstadter, \u201cOn Viral Sentences and Self-\nReplicating Structures,\u201d in *Metamagical Themas: Questing for the Essence of Mind and Pattern* (New York, Basic Books, 1985), 52.\n\n2 \u201cNOW THROUGH THE VERY UNIVERSALITY OF ITS STRUCTURES\u201d: Jacques Monod, *Chance and Necessity: An Essay on the Natural Philosophy of Modern Biology*, trans. Austryn Wainhouse (New York: Knopf, 1971), 145.\n\n3 \u201cIDEAS HAVE RETAINED SOME OF THE PROPERTIES\u201d: Ibid., 165.\n\n4 \u201cIDEAS CAUSE IDEAS\u201d: Roger Sperry, \u201cMind, Brain, and Humanist Values,\u201d in *New Views of the Nature of Man*, ed. John R. Platt (Chicago: University of Chicago Press, 1983), 82.\n\n5 \u201cI THINK THAT A NEW KIND\u201d: Richard Dawkins, *The Selfish Gene*, 30th anniversary edition (Oxford: Oxford University Press, 2006), 192.\n\n6 \u201cTHIS MAY NOT BE WHAT GEORGE WASHINGTON LOOKED LIKE THEN\u201d: Daniel C. Dennett, *Darwin\u2019s Dangerous Idea: Evolution and the Meanings of Life* (New York: Simon & Schuster, 1995), 347.\n\n7 \u201cA WAGON WITH SPOKED WHEELS\u201d: Daniel C. Dennett, *Consciousness Explained* (Boston: Little, Brown, 1991), 204.\n\n8 \u201cGENES CANNOT BE SELFISH\u201d: Mary Midgley, \u201cGene-Juggling,\u201d *Philosophy* 54 (October 1979).\n\n9 \u201cA MEME \u2026 IS AN INFORMATION PACKET\u201d: Daniel C. Dennett, \u201cMemes: Myths, Misunderstandings, and Misgivings,\u201d draft for Chapel Hill lecture, October 1998, http://ase.tufts.edu/cogstud/papers/MEMEMYTH.FIN.htm (accessed 7 June 2010).\n\n10 \u201cTO DIE FOR AN IDEA\u201d: George Jean Nathan and H. L. Mencken, \u201cClinical Notes,\u201d *American Mercury* 3, no. 9 (September 1924), 55.\n\n11 *I WAS PROMISED ON A TIME TO HAVE REASON FOR MY RHYME*: Edmund Spenser, quoted by Thomas Fuller, *The History of the Worthies of England* (London: 1662).\n\n12 \u201cI BELIEVE THAT, GIVEN THE RIGHT CONDITIONS\u201d: Richard Dawkins, *The Selfish Gene*, 322.\n\n13 \u201cWHEN YOU PLANT A FERTILE MEME\u201d: Quoted by Dawkins, Ibid., 192.\n\n14 \u201cHARD AS THIS TERM MAY BE TO DELIMIT\u201d: W. D. Hamilton, \u201cThe Play by Nature,\u201d *Science* 196 (13 May 1977): 759.\n\n15 BIRDSONG CULTURE: Juan D. Delius, \u201cOf Mind Memes and Brain Bugs, A Natural History of Culture,\u201d in *The Nature of Culture*, ed. Walter A. Koch (Bochum, Germany: Bochum, 1989), 40.\n\n16 \u201cFROM LOOK TO LOOK\u201d: James Thomson, \u201cAutumn\u201d (1730).\n\n17 \u201cEVE, WHOSE EYE\u201d: John Milton, *Paradise Lost*, IX:1036.\n\n18 WALTON PROPOSED SIMPLE SELF-REPLICATING SENTENCES: Douglas R. Hofstadter, \u201cOn Viral Sentences and Self-Replicating Structures,\u201d 52.\n19 \u201cI DON\u2019T KNOW ABOUT YOU\u201d: Daniel C. Dennett, *Darwin\u2019s Dangerous Idea*, 346.\n\n20 \u201cTHE COMPUTERS IN WHICH MEMES LIVE\u201d: Richard Dawkins, *The Selfish Gene*, 197.\n\n21 \u201cIT WAS OBVIOUSLY PREDICTABLE\u201d: Ibid., 329.\n\n22 \u201cMAKE SEVEN COPIES OF IT EXACTLY AS IT IS WRITTEN\u201d: Daniel W. VanArsdale, \u201cChain Letter Evolution,\u201d http://www.silcom.com/~barnowl/chain-letter/evolution.html (accessed 8 June 2010).\n\n23 \u201cAN UNUSUAL CHAIN-LETTER REACHED QUINCY\u201d: Harry Middleton Hyatt, *Folk-Lore from Adams County, Illinois*, 2nd and rev. ed. (Hannibal, Mo.: Alma Egan Hyatt Foundation, 1965), 581.\n\n24 \u201cTHESE LETTERS HAVE PASSED FROM HOST TO HOST\u201d: Charles H. Bennett, Ming Li, and Bin Ma, \u201cChain Letters and Evolutionary Histories,\u201d *Scientific American* 288, no. 6 (June 2003): 77.\n\n25 FOR DENNETT, THE FIRST FOUR NOTES: Daniel C. Dennett, *Darwin\u2019s Dangerous Idea*, 344.\n\n26 \u201cMEMES HAVE NOT YET FOUND\u201d: Richard Dawkins, foreword to Susan Blackmore, *The Meme Machine* (Oxford: Oxford University Press, 1999), xii.\n\n27 \u201cTHE HUMAN WORLD IS MADE OF STORIES\u201d: David Mitchell, *Ghostwritten* (New York: Random House, 1999), 378.\n\n28 \u201cAS WITH ALL KNOWLEDGE, ONCE YOU KNEW IT\u201d: Margaret Atwood, *The Year of the Flood* (New York: Doubleday, 2009), 170.\n\n29 \u201cA LIFE POURED INTO WORDS\u201d: John Updike, \u201cThe Author Observes His Birthday, 2005,\u201d *Endpoint and Other Poems* (New York: Knopf, 2009), 8.\n\n30 \u201cIN THE BEGINNING THERE WAS INFORMATION\u201d: Fred I. Dretske, *Knowledge and the Flow of Information* (Cambridge, Mass.: MIT Press, 1981), xii.\n\n12. THE SENSE OF RANDOMNESS\n\n1 \u201cI WONDER,\u201d SHE SAID: Michael Cunningham, *Specimen Days* (New York: Farrar Straus Giroux, 2005), 154.\n\n2 FOUND A MAGICAL LITTLE BOOK: Interviews, Gregory J. Chaitin, 27 October 2007 and 14 September 2009; Gregory J. Chaitin, \u201cThe Limits of Reason,\u201d *Scientific American* 294, no. 3 (March 2006): 74.\n\n3 \u201cASTOUNDING AND MELANCHOLY\u201d: Ernest Nagel and James R. Newman, *G\u00f6del\u2019s Proof* (New York: New York University Press, 1958), 6.\n\n4 \u201cIT WAS A VERY SERIOUS CONCEPTUAL CRISIS\u201d: quoted in Gregory J. Chaitin, *Information, Randomness & Incompleteness: Papers on Algorithmic Information Theory* (Singapore: World Scientific, 1987), 61.\nHE WONDERED IF AT SOME LEVEL: \u201cAlgorithmic Information Theory,\u201d in Gregory J. Chaitin, *Conversations with a Mathematician* (London: Springer, 2002), 80.\n\n\u201cPROBABILITY, LIKE TIME\u201d: John Archibald Wheeler, *At Home in the Universe, Masters of Modern Physics*, vol. 9 (New York: American Institute of Physics, 1994), 304.\n\nWHETHER THE POPULATION OF FRANCE: Cf. John Maynard Keynes, *A Treatise on Probability* (London: Macmillan, 1921), 291.\n\nHE CHOSE THREE: KNOWLEDGE, CAUSALITY, AND DESIGN: Ibid., 281.\n\n\u201cCHANCE IS ONLY THE MEASURE\u201d: Henri Poincar\u00e9, \u201cChance,\u201d in *Science and Method*, trans. Francis Maitland (Mineola, N.Y.: Dover, 2003), 65.\n\n1009732533765201358634673548: *A Million Random Digits with 100,000 Normal Deviates* (Glencoe, Ill.: Free Press, 1955).\n\nAN ELECTRONIC ROULETTE WHEEL: Ibid., ix\u2013x.\n\n\u201cSTATE OF SIN\u201d: Von Neumann quoted in Peter Galison, *Image and Logic: A Material Culture of Microphysics* (Chicago: University of Chicago Press, 1997), 703.\n\n\u201cWHEN THE READING HEAD MOVES\u201d: \u201cA Universal Turing Machine with Two Internal States,\u201d in Claude Elwood Shannon, *Collected Papers*, ed. N. J. A. Sloane and Aaron D. Wyner (New York: IEEE Press, 1993), 733\u201341.\n\n\u201cHE SUMMARIZES HIS OBSERVATIONS\u201d: Gregory J. Chaitin, \u201cOn the Length of Programs for Computing Finite Binary Sequences,\u201d *Journal of the Association for Computing Machinery* 13 (1966): 567.\n\n\u201cWE ARE TO ADMIT NO MORE CAUSES\u201d: Isaac Newton, \u201cRules of Reasoning in Philosophy; Rule I,\u201d *Philosophiae Naturalis Principia Mathematica*.\n\nIN THE WANING YEARS OF TSARIST RUSSIA: Obituary, *Bulletin of the London Mathematical Society* 22 (1990): 31; A. N. Shiryaev, \u201cKolmogorov: Life and Creative Activities,\u201d *Annals of Probability* 17, no. 3 (1989): 867.\n\nUNLIKELY TO ATTRACT INTERPRETATION: David A. Mindell et al., \u201cCybernetics and Information Theory in the United States, France, and the Soviet Union,\u201d in *Science and Ideology: A Comparative History*, ed. Mark Walker (London: Routledge, 2003), 66 and 81.\n\nHE SOON LEARNED TO HIS SORROW: Cf. \u201cAmount of Information and Entropy for Continuous Distributions,\u201d note 1, in *Selected Works of A. N. Kolmogorov*, vol. 3, *Information Theory and the Theory of Algorithms*, trans. A. B. Sossinsky (Dordrecht, Netherlands: Kluwer Academic Publishers, 1993), 33.\n\n\u201cMORE TECHNOLOGY THAN MATHEMATICS\u201d: A. N. Kolmogorov and A. N. Shiryayev, *Kolmogorov in Perspective*, trans. Harold H. McFaden, *History of Mathematics* vol. 20 (n.p.: American Mathematical Society, London Mathematical Society, 2000), 54.\n\n\u201cWHEN I READ THE WORKS OF ACADEMICIAN KOLMOGOROV\u201d: Quoted in Slava Gerovitch, *From Newspeak to Cyberspeak: A History of Soviet Cybernetics* (Cambridge, Mass.:\n21 \u201cCYBERNETICS IN WIENER\u2019S UNDERSTANDING\u201d: \u201cIntervention at the Session,\u201d in *Selected Works of A. N. Kolmogorov*, 31.\n\n22 \u201cAT EACH GIVEN MOMENT\u201d: Kolmogorov diary entry, 14 September 1943, in A. N. Kolmogorov and A. N. Shiryaev, *Kolmogorov in Perspective*, 50.\n\n23 \u201cIS IT POSSIBLE TO INCLUDE THIS NOVEL\u201d: \u201cThree Approaches to the Definition of the Concept \u2018Quantity of Information,\u2019 \u201d in *Selected Works of A. N. Kolmogorov*, 188.\n\n24 \u201cOUR DEFINITION OF THE QUANTITY\u201d: A. N. Kolmogorov, \u201cCombinatorial Foundations of Information Theory and the Calculus of Probabilities,\u201d *Russian Mathematical Surveys* 38, no. 4 (1983): 29\u201343.\n\n25 \u201cTHE INTUITIVE DIFFERENCE BETWEEN \u2018SIMPLE\u2019 AND \u2018COMPLICATED\u2019 \u201d: \u201cThree Approaches to the Definition of the Concept \u2018Quantity of Information,\u2019 \u201d *Selected Works of A. N. Kolmogorov*, 221.\n\n26 \u201cA NEW CONCEPTION OF THE NOTION \u2018RANDOM\u2019\u201d: \u201cOn the Logical Foundations of Information Theory and Probability Theory,\u201d *Problems of Information Transmission* 5, no. 3 (1969): 1\u20134.\n\n27 HE DREAMED OF SPENDING HIS LAST YEARS: V. I. Arnold, \u201cOn A. N. Kolmogorov,\u201d in A. N. Kolmogorov and A. N. Shiryaev, *Kolmogorov in Perspective*, 94.\n\n28 \u201cTHE PARADOX ORIGINALLY TALKS ABOUT ENGLISH\u201d: Gregory J. Chaitin, *Thinking About G\u00f6del and Turing: Essays on Complexity, 1970\u20132007* (Singapore: World Scientific, 2007), 176.\n\n29 \u201cIT DOESN\u2019T MAKE ANY DIFFERENCE WHICH PARADOX\u201d: Gregory J. Chaitin, \u201cThe Berry Paradox,\u201d *Complexity* 1, no. 1 (1995): 26; \u201cParadoxes of Randomness,\u201d *Complexity* 7, no. 5 (2002): 14\u201321.\n\n30 \u201cABSOLUTE CERTAINTY IS LIKE GOD\u201d: Interview, Gregory J. Chaitin, 14 September 2009.\n\n31 \u201cGOD NOT ONLY PLAYS DICE\u201d: Foreword to Cristian S. Calude, *Information and Randomness: An Algorithmic Perspective* (Berlin: Springer, 2002), viii.\n\n32 \u201cCHARMINGLY CAPTURED THE ESSENCE\u201d: Joseph Ford, \u201cDirections in Classical Chaos,\u201d in *Directions in Chaos*, ed. Hao Bai-lin (Singapore: World Scientific, 1987), 14.\n\n33 THE INFORMATION PACKING PROBLEM: Ray J. Solomonoff, \u201cThe Discovery of Algorithmic Probability,\u201d *Journal of Computer and System Sciences* 55, no. 1 (1997): 73\u201388.\n\n34 \u201cTHREE MODELS FOR THE DESCRIPTION OF LANGUAGE\u201d: Noam Chomsky, \u201cThree Models for the Description of Language,\u201d *IRE Transactions on Information Theory* 2, no. 3 (1956): 113\u201324.\n\n35 \u201cTHE LAWS OF SCIENCE THAT HAVE BEEN DISCOVERED\u201d: Ray J. Solomonoff, \u201cA Formal Theory of Inductive Inference,\u201d *Information and Control* 7, no. 1 (1964): 1\u201322.\n36 \u201cCOCKTAIL SHAKER AND SHAKING VIGOROUSLY\u201d: Foreword to Cristian S. Calude, *Information and Randomness*, vii.\n\n37 \u201cIT IS PREFERABLE TO CONSIDER COMMUNICATION\u201d: Gregory J. Chaitin, \u201cRandomness and Mathematical Proof,\u201d in *Information, Randomness & Incompleteness*, 4.\n\n38 \u201cFROM THE EARLIEST DAYS OF INFORMATION THEORY\u201d: Charles H. Bennett, \u201cLogical Depth and Physical Complexity,\u201d in *The Universal Turing Machine: A Half-Century Survey*, ed. Rolf Herken (Oxford: Oxford University Press, 1988), 209\u201310.\n\n13. INFORMATION IS PHYSICAL\n\n1 \u201cTHE MORE ENERGY, THE FASTER THE BITS FLIP\u201d: Seth Lloyd, *Programming the Universe* (New York: Knopf, 2006), 44.\n\n2 \u201cHOW DID THIS COME ABOUT?\u201d: Christopher A. Fuchs, \u201cQuantum Mechanics as Quantum Information (and Only a Little More),\u201d *arXiv:quant-ph/0205039v1*, 8 May 2002, 1.\n\n3 \u201cTHE REASON IS SIMPLE\u201d: Ibid., 4.\n\n4 \u201cIT TEACHES US \u2026 THAT SPACE CAN BE CRUMPLED\u201d: John Archibald Wheeler with Kenneth Ford, *Geons, Black Holes, and Quantum Foam: A Life in Physics* (New York: Norton, 1998), 298.\n\n5 \u201cOTHERWISE PUT \u2026 EVERY IT\u201d: \u201cIt from Bit\u201d in John Archibald Wheeler, *At Home in the Universe, Masters of Modern Physics*, vol. 9 (New York: American Institute of Physics, 1994), 296.\n\n6 A PROBLEM AROSE WHEN STEPHEN HAWKING: Stephen Hawking, \u201cBlack Hole Explosions?\u201d *Nature* 248 (1 March 1974), DOI:10.1038/248030a0, 30\u201331.\n\n7 PUBLISHING IT WITH A MILD TITLE: Stephen Hawking, \u201cThe Breakdown of Predictability in Gravitational Collapse,\u201d *Physical Review D* 14 (1976): 2460\u201373; Gordon Belot et al., \u201cThe Hawking Information Loss Paradox: The Anatomy of a Controversy,\u201d *British Journal for the Philosophy of Science* 50 (1999): 189\u2013229.\n\n8 \u201cINFORMATION LOSS IS HIGHLY INFECTIOUS\u201d: John Preskill, \u201cBlack Holes and Information: A Crisis in Quantum Physics,\u201d Caltech Theory Seminar, 21 October 1994, http://www.theory.caltech.edu/~preskill/talks/blackholes.pdf (accessed 20 March 2010).\n\n9 \u201cSOME PHYSICISTS FEEL THE QUESTION\u201d: John Preskill, \u201cBlack Holes and the Information Paradox,\u201d *Scientific American* (April 1997): 54.\n\n10 \u201cI THINK THE INFORMATION PROBABLY GOES OFF\u201d: Quoted in Tom Siegfried, *The Bit and the Pendulum: From Quantum Computing to M Theory\u2014The New Physics of Information* (New York: Wiley and Sons, 2000), 203.\n\n11 \u201cTHERE IS NO BABY UNIVERSE\u201d: Stephen Hawking, \u201cInformation Loss in Black Holes,\u201d *Physical Review D* 72 (2005): 4.\n12 THE \u201cTHERMODYNAMICS OF COMPUTATION\u201d: Charles H. Bennett, \u201cNotes on the History of Reversible Computation,\u201d *IBM Journal of Research and Development* 44 (2000): 270.\n\n13 \u201cCOMPUTERS \u2026 MAY BE THOUGHT OF AS ENGINES\u201d: Charles H. Bennett, \u201cThe Thermodynamics of Computation\u2014a Review,\u201d *International Journal of Theoretical Physics* 21, no. 12 (1982): 906.\n\n14 BACK-OF-THE-ENVELOPE CALCULATION: Ibid.\n\n15 ROLF LANDAUER: \u201cInformation Is Physical,\u201d *Physics Today* 23 (May 1991); \u201cInformation Is Inevitably Physical,\u201d in Anthony H. G. Hey, ed., *Feynman and Computation* (Boulder, Colo.: Westview Press, 2002), 77.\n\n16 STRAIGHT AND NARROW OLD IBM TYPE: Charles Bennett, quoted by George Johnson in \u201cRolf Landauer, Pioneer in Computer Theory, Dies at 72,\u201d *The New York Times*, 30 April 1999.\n\n17 \u201cYOU MIGHT SAY THIS IS THE REVENGE\u201d: Interview, Charles Bennett, 27 October 2009.\n\n18 BENNETT AND HIS RESEARCH ASSISTANT: J. A. Smolin, \u201cThe Early Days of Experimental Quantum Cryptography,\u201d *IBM Journal of Research and Development* 48 (2004): 47\u201352.\n\n19 \u201cWE SAY THINGS SUCH AS \u2018ALICE SENDS BOB\u2019 \u201d: Barbara M. Terhal, \u201cIs Entanglement Monogamous?\u201d *IBM Journal of Research and Development* 48, no. 1 (2004): 71\u201378.\n\n20 FOLLOWING AN INTRICATE AND COMPLEX PROTOCOL: A detailed explanation can be found in Simon Singh, *The Code Book: The Secret History of Codes and Codebreaking* (London: Fourth Estate, 1999); it takes ten pages of exquisite prose, beginning at 339.\n\n21 \u201cSTAND BY: I\u2019LL TELEPORT YOU SOME GOULASH\u201d: IBM advertisement, *Scientific American* (February 1996), 0\u20131; Anthony H. G. Hey, ed., *Feynman and Computation*, xiii; Tom Siegfried, *The Bit and the Pendulum*, 13.\n\n22 \u201cUNFORTUNATELY THE PREPOSTEROUS SPELLING QUBIT\u201d: N. David Mermin, *Quantum Computer Science: An Introduction* (Cambridge: Cambridge University Press, 2007), 4.\n\n23 \u201cCAN QUANTUM-MECHANICAL DESCRIPTION OF PHYSICAL REALITY\u201d: *Physical Review* 47 (1935): 777\u201380.\n\n24 \u201cEINSTEIN HAS ONCE AGAIN EXPRESSED HIMSELF\u201d: Wolfgang Pauli to Werner Heisenberg, 15 June 1935, quoted in Louisa Gilder, *The Age of Entanglement: When Quantum Physics Was Reborn* (New York: Knopf, 2008), 162.\n\n25 \u201cTHAT WHICH REALLY EXISTS IN B\u201d: Albert Einstein to Max Born, March 1948, in *The Born-Einstein Letters*, trans. Irene Born (New York: Walker, 1971), 164.\n\n26 IT TOOK MANY MORE YEARS BEFORE THE LATTER: Asher Peres, \u201cEinstein, Podolsky, Rosen, and Shannon,\u201d *arXiv:quant-ph/0310010 v1*, 2003.\n\n27 \u201cTERMINOLOGY CAN SAY IT ALL\u201d: Christopher A. Fuchs, \u201cQuantum Mechanics as Quantum Information (and Only a Little More)\u201d: *arXiv: quant-ph/1003.5209 v1*, 26 March 2010: 3.\n28 BENNETT PUT ENTANGLEMENT TO WORK: Charles H. Bennett et al., \u201cTeleporting an Unknown Quantum State Via Dual Classical and Einstein-Podolsky-Rosen Channels,\u201d *Physical Review Letters* 70 (1993): 1895.\n\n29 \u201cSECRET! SECRET! CLOSE THE DOORS\u201d: Richard Feynman, \u201cSimulating Physics with Computers,\u201d in Anthony H. G. Hey, ed., *Feynman and Computation*, 136.\n\n30 \u201cFEYNMAN\u2019S INSIGHT\u201d: Interview, Charles H. Bennett, 27 October 2009.\n\n31 \u201cA PRETTY MISERABLE SPECIMEN\u201d: N. David Mermin, *Quantum Computer Science*, 17.\n\n32 RSA ENCRYPTION: named after its inventors, Ron Rivest, Adi Shamir, and Len Adleman.\n\n33 THEY ESTIMATED THAT THE COMPUTATION: T. Kleinjung, K. Aoki, J. Franke, et al., \u201cFactorization of a 768-bit RSA modulus,\u201d Eprint archive no. 2010/006, 2010.\n\n34 \u201cQUANTUM COMPUTERS WERE BASICALLY A REVOLUTION\u201d: Dorit Aharonov, panel discussion \u201cHarnessing Quantum Physics,\u201d 18 October 2009, Perimeter Institute, Waterloo, Ontario; and e-mail message 10 February 2010.\n\n35 \u201cMANY PEOPLE CAN READ A BOOK\u201d: Charles H. Bennett, \u201cPublicity, Privacy, and Permanence of Information,\u201d in *Quantum Computing: Back Action*, AIP Conference Proceeding 864 (2006), ed. Debabrata Goswami (Melville, N.Y.: American Institute of Physics), 175\u201379.\n\n36 \u201cIF SHANNON WERE AROUND NOW\u201d: Charles H. Bennett, interview, 27 October 2009.\n\n37 \u201cTO WORK OUT ALL THE POSSIBLE MIRRORED ROOMS\u201d: Shannon interview with Anthony Liversidge, *Omni* (August 1987), in Claude Elwood Shannon, *Collected Papers*, ed. N. J. A. Sloane and Aaron D. Wyner (New York: IEEE Press, 1993), xxxii.\n\n38 A MODEST TO-DO LIST: John Archibald Wheeler, \u201cInformation, Physics, Quantum: The Search for Links,\u201d *Proceedings of the Third International Symposium on the Foundations of Quantum Mechanics* (1989), 368.\n\n14. AFTER THE FLOOD\n\n1 \u201cSUPPOSE WITHIN EVERY BOOK\u201d: Hilary Mantel, *Wolf Hall* (New York: Henry Holt, 2009), 394.\n\n2 \u201cTHE UNIVERSE (WHICH OTHERS CALL THE LIBRARY)\u201d: Jorge Luis Borges, \u201cThe Library of Babel,\u201d in *Labyrinths: Selected Stories and Other Writings* (New York: New Directions, 1962), 54.\n\n3 \u201cIT IS CONJECTURED THAT THIS BRAVE NEW WORLD\u201d: Jorge Luis Borges, \u201cTl\u00f6n, Uqbar, Orbis Tertius,\u201d in *Labyrinths*, 8.\n\n4 \u201cOUR HERESIARCH UNCLE\u201d: William Gibson, \u201cAn Invitation,\u201d introduction to *Labyrinths*, xii.\n\n5 \u201cWHAT A STRANGE CHAOS\u201d: Charles Babbage, *The Ninth Bridgewater Treatise: A Fragment*, 2nd ed. (London: John Murray, 1838), 111.\n6 \u201cNO THOUGHT CAN PERISH\u201d: Edgar Allan Poe, \u201cThe Power of Words\u201d (1845), in *Poetry and Tales* (New York: Library of America, 1984), 823\u201324.\n\n7 \u201cIT WOULD EMBRACE IN THE SAME FORMULA\u201d: Pierre-Simon Laplace, *A Philosophical Essay on Probabilities*, trans. Frederick Wilson Truscott and Frederick Lincoln Emory (New York: Dover, 1951).\n\n8 \u201cIN TURNING OUR VIEWS\u201d: Charles Babbage, *The Ninth Bridgewater Treatise*, 44.\n\n9 \u201cTHE ART OF PHOTGENIC DRAWING\u201d: Nathaniel Parker Willis, \u201cThe Pencil of Nature: A New Discovery,\u201d *The Corsair* 1, no. 5 (April 1839): 72.\n\n10 \u201cIN FACT, THERE IS A GREAT ALBUM OF BABEL\u201d: Ibid., 71.\n\n11 \u201cTHE SYSTEM OF THE \u2018UNIVERSE AS A WHOLE\u2019 \u201d: Alan M. Turing, \u201cComputing Machinery and Intelligence,\u201d *Minds and Machines* 59, no. 236 (1950): 440.\n\n12 \u201cSUCH A BLAZE OF KNOWLEDGE AND DISCOVERY\u201d: H. G. Wells, *A Short History of the World* (San Diego: Book Tree, 2000), 97.\n\n13 \u201cTHE ROMANS BURNT THE BOOKS OF THE JEWS\u201d: Isaac Disraeli, *Curiosities of Literature* (London: Routledge & Sons, 1893), 17.\n\n14 \u201cALL THE LOST PLAYS OF THE ATHENIANS!\u201d: Tom Stoppard, *Arcadia* (London: Samuel French, 1993), 38.\n\n15 \u201cIF YOU WANT TO WRITE ABOUT FOLKLORE\u201d: \u201cWikipedia: Requested Articles,\u201d http://web.archive.org/-/web/-20010406104800/-www.wikipedia.com/-wiki/-Requested_articles (accessed 4 April 2001).\n\n16 \u201cAGING IS WHAT YOU GET\u201d: Quoted by Nicholson Baker in \u201cThe Charms of Wikipedia,\u201d *New York Review of Books* 55, no. 4 (20 March 2008). The same anonymous user later struck again, vandalizing the entries on angioplasty and Sigmund Freud.\n\n17 \u201cIT HAS NEVER BEEN SPREAD OUT, YET\u201d: Lewis Carroll, *Sylvie and Bruno Concluded* (London: Macmillan, 1893), 169.\n\n18 \u201cTHIS IS AN OBJECT IN SPACE, AND I\u2019VE SEEN IT\u201d: Interview, Jimmy Wales, 24 July 2008.\n\n19 \u201cDIE SCHRAUBE AN DER HINTEREN LINKEN BREMSBACKE\u201d: http://meta.wikimedia.org/-wiki/-Die_Schraube_an_-der_hinteren_-linken_-Bremsbacke_am_-Fahrrad_von_-_Ulrich_Fuchs (accessed 25 July 2008).\n\n20 \u201cA PLAN ENTIRELY NEW\u201d: *Encyclopaedia Britannica*, 3rd edition, title page; cf. Richard Yeo, *Encyclopaedic Visions: Scientific Dictionaries and Enlightenment Culture* (Cambridge: Cambridge University Press, 2001), 181.\n\n21 \u201cMANY TOPICS ARE BASED ON THE RELATIONSHIP\u201d: \u201cWikipedia: What Wikipedia Is Not,\u201d http://en.wikipedia.org/wiki/Wikipedia:What_Wikipedia_is_not (accessed 3 August 2008).\n\n22 \u201cHE READ FOR METAPHYSICS\u201d: Charles Dickens, *The Pickwick Papers*, chapter 51.\n\n23 \u201cI BEGAN STANDING WITH MY COMPUTER OPEN\u201d: Nicholson Baker, \u201cThe Charms of\nWikipedia.\u201d\n\n24 \u201cA HAMADRYAD IS A WOOD-NYMPH\u201d: John Banville, *The Infinities* (London: Picador, 2009), 178.\n\n25 \u201cMADE UP OF SYLLABLES THAT APPEAR\u201d: Deming Seymour, \u201cA New Yorker at Large,\u201d *Sarasota Herald*, 25 August 1929.\n\n26 BY 1934 THE BUREAU WAS MANAGING A LIST: \u201cRegbureau,\u201d *The New Yorker* (26 May 1934), 16.\n\n27 AS THE HISTORIAN BRIAN OGILVIE HAS SHOWN: Brian W. Ogilvie, *The Science of Describing: Natural History in Renaissance Europe* (Chicago: University of Chicago Press, 2006).\n\n28 SCANDIX, PECTEN VENERIS, HERBA SCANARIA: Ibid., 173.\n\n29 CATALOGUE OF 6,000 PLANTS: Caspar Bauhin; Ibid., 208.\n\n30 \u201cTHE NAME OF A MAN IS LIKE HIS SHADOW\u201d: Ernst Pulgram, *Theory of Names* (Berkeley, Calif.: American Name Society, 1954), 3.\n\n31 \u201cA SCIENTIST\u2019S IDEA OF A SHORT WAY\u201d: Michael Amrine, \u201c\u2018Megabucks\u2019 for What\u2019s \u2018Hot,\u2019\u201d *The New York Times Magazine*, 22 April 1951.\n\n32 \u201cIT\u2019S AS IF YOU KNEEL TO PLANT THE SEED\u201d: Jaron Lanier, *You Are Not a Gadget* (New York: Knopf, 2010), 8.\n\n33 SERVER FARMS PROLIFERATE: Cf. Tom Vanderbilt, \u201cData Center Overload,\u201d *The New York Times Magazine*, 14 June 2009.\n\n34 LLOYD CALCULATES: Seth Lloyd, \u201cComputational Capacity of the Universe,\u201d *Physical Review Letters* 88, no. 23 (2002).\n\n15. NEW NEWS EVERY DAY\n\n1 \u201cSORRY FOR ALL THE UPS AND DOWNS\u201d: http://www.andrewtobias.com/bkoldcolumns/070118.html (accessed 18 January 2007).\n\n2 \u201cGREAT MUTATION\u201d: Carl Bridenbaugh, \u201cThe Great Mutation,\u201d *American Historical Review* 68, no. 2 (1963): 315\u201331.\n\n3 \u201cNOTWITHSTANDING THE INCESSANT CHATTER\u201d: Ibid., 322.\n\n4 A THOUSAND PEOPLE IN THE BALLROOM: \u201cHistorical News,\u201d *American Historical Review* 63, no. 3 (April 1963): 880.\n\n5 TENDED TO SLOT THE PRINTING PRESS: Elizabeth L. Eisenstein, *The Printing Press as an Agent of Change: Communications and Cultural Transformations in Early-Modern Europe* (Cambridge: Cambridge University Press, 1979), 25.\n\n6 \u201cDATA COLLECTION, STORAGE AND RETRIEVAL SYSTEMS\u201d: Ibid., xvi.\n\n7 \u201cA DECISIVE POINT OF NO RETURN\u201d: Elizabeth L. Eisenstein, \u201cClio and Chronos: An\nThe Information\n\nEssay on the Making and Breaking of History-Book Time,\u201d *History and Theory* 6, suppl. 6: History and the Concept of Time (1966), 64.\n\n8 \u201cATTITUDES TOWARD HISTORICAL CHANGE\u201d: Ibid., 42.\n\n9 \u201cSCRIBAL CULTURE\u201d: Ibid., 61.\n\n10 PRINT WAS TRUSTWORTHY, RELIABLE, AND PERMANENT: Elizabeth L. Eisenstein, *The Printing Press as an Agent of Change*, 624 ff.\n\n11 \u201cAS I SEE IT \u2026 MANKIND IS FACED WITH NOTHING SHORT OF\u201d: Carl Bridenbaugh, \u201cThe Great Mutation,\u201d 326.\n\n12 \u201cTHIS IS A MISREADING OF THE PREDICAMENT\u201d: Elizabeth L. Eisenstein, \u201cClio and Chronos,\u201d 39.\n\n13 \u201cI HEAR NEW NEWS EVERY DAY\u201d: Robert Burton, *The Anatomy of Melancholy*, ed. Floyd Dell and Paul Jordan-Smith (New York: Tudor, 1927), 14.\n\n14 \u201cTO WHICH RESULT THAT HORRIBLE MASS OF BOOKS\u201d: Gottfried Wilhelm Leibniz, *Leibniz Selections*, ed. Philip P. Wiener (New York: Scribner\u2019s, 1951), 29; cf. Marshall McLuhan, *The Gutenberg Galaxy* (Toronto: University of Toronto Press, 1962), 254.\n\n15 \u201cTHOSE DAYS, WHEN (AFTER PROVIDENCE\u201d: Alexander Pope, *The Dunciad* (1729) (London: Methuen, 1943), 41.\n\n16 \u201cKNOWLEDGE OF SPEECH, BUT NOT OF SILENCE\u201d: T. S. Eliot, \u201cThe Rock,\u201d in *Collected Poems: 1909\u20131962* (New York: Harcourt Brace, 1963), 147.\n\n17 \u201cTHE TSUNAMI OF AVAILABLE FACT\u201d: David Foster Wallace, Introduction to *The Best American Essays 2007* (New York: Mariner, 2007).\n\n18 \u201cUNFORTUNATELY, \u2018INFORMATION RETRIEVING,\u2019 HOWEVER SWIFT\u201d: Lewis Mumford, *The Myth of the Machine*, vol. 2, *The Pentagon of Power* (New York: Harcourt, Brace, 1970), 182.\n\n19 \u201cELECTRONIC MAIL SYSTEM\u201d: Jacob Palme, \u201cYou Have 134 Unread Mail! Do You Want to Read Them Now?\u201d in *Computer-Based Message Services*, ed. Hugh T. Smith (North Holland: Elsevier, 1984), 175\u201376.\n\n20 A PAIR OF PSYCHOLOGISTS: C. J. Bartlett and Calvin G. Green, \u201cClinical Prediction: Does One Sometimes Know Too Much,\u201d *Journal of Counseling Psychology* 13, no. 3 (1966): 267\u201370.\n\n21 \u201cTHE INFORMATION YOU ARE RECEIVING IS PREPARED FOR YOU\u201d: Siegfried Streufert et al., \u201cConceptual Structure, Information Search, and Information Utilization,\u201d *Journal of Personality and Social Psychology* 2, no. 5 (1965): 736\u201340.\n\n22 \u201cINFORMATION-LOAD PARADIGM\u201d: For example, Naresh K. Malhotra, \u201cInformation Load and Consumer Decision Making,\u201d *Journal of Consumer Research* 8 (March 1982): 419.\n\n23 \u201cE-MAIL, MEETINGS, LISTSERVS, AND IN-BASKET PAPER PILES\u201d: Tonyia J. Tidline, \u201cThe Mythology of Information Overload,\u201d *Library Trends* 47, no. 3 (Winter 1999): 502.\nThe Information\n\n24 \u201cWE PAY TO HAVE NEWSPAPERS DELIVERED\u201d: Charles H. Bennett, \u201cDemons, Engines, and the Second Law,\u201d *Scientific American* 257, no. 5 (1987): 116.\n\n25 \u201cAS THE DESIRED INFORMATION\u201d: G. Bernard Shaw to the Editor, *Whitaker\u2019s Almanack*, 31 May 1943.\n\n26 \u201cDON\u2019T ASK BY TELEPHONE FOR WORLD\u2019S SERIES SCORES\u201d: *The New York Times*, 8 October 1929, 1.\n\n27 \u201cYOU HUNCH LIKE A PIANIST\u201d: Anthony Lane, \u201cByte Verse,\u201d *The New Yorker*, 20 February 1995, 108.\n\n28 \u201cTHE OBVIOUS COUNTERHYPOTHESIS ARISES\u201d: Daniel C. Dennett, \u201cMemes and the Exploitation of Imagination,\u201d *Journal of Aesthetics and Art Criticism* 48 (1990): 132.\n\n29 \u201cTAKE THE LIBRARY OF THE BRITISH MUSEUM\u201d: Augustus De Morgan, *Arithmetical Books: From the Invention of Printing to the Present Time* (London: Taylor & Walton, 1847), ix.\n\n30 \u201cTHE MULTITUDE OF BOOKS, THE SHORTNESS OF TIME\u201d: Vincent of Beauvais, Prologue, *Speculum Maius*, quoted in Ann Blair, \u201cReading Strategies for Coping with Information Overload ca. 1550\u20131700,\u201d *Journal of the History of Ideas* 64, no. 1 (2003): 12.\n\n31 \u201cTHE PERCEPTION OF AN OVERABUNDANCE\u201d: Ibid.\n\n32 \u201cDRIVEN BY THE NEED TO MASTER THE INFORMATION OVERLOAD\u201d: Brian W. Ogilvie, \u201cThe Many Books of Nature: Renaissance Naturalists and Information Overload,\u201d *Journal of the History of Ideas* 64, no. 1 (2003): 40.\n\n33 \u201cA MAN WHO HAS SOMETHING TO SAY\u201d: Bertolt Brecht, *Radio Theory* (1927), quoted in Kathleen Woodward, *The Myths of Information: Technology and Postindustrial Culture* (Madison, Wisc.: Coda Press, 1980).\n\nEPILOGUE\n\n1 \u201cIT WAS INEVITABLE THAT MEANING\u201d: Jean-Pierre Dupuy, *The Mechanization of the Mind: On the Origins of Cognitive Science*, trans. M. B. DeBevoise (Princeton, N.J.: Princeton University Press, 2000), 119.\n\n2 \u201cWE ARE TODAY AS FAR INTO THE ELECTRIC AGE\u201d: Marshall McLuhan, *The Gutenberg Galaxy* (Toronto: University of Toronto Press, 1962), 1.\n\n3 \u201cTODAY \u2026 WE HAVE EXTENDED OUR CENTRAL NERVOUS SYSTEMS\u201d: Marshall McLuhan, *Understanding Media: The Extensions of Man* (New York: McGraw-Hill, 1965), 3.\n\n4 \u201cWHAT WHISPERS ARE THESE\u201d: Walt Whitman, \u201cYears of the Modern,\u201d *Leaves of Grass* (Garden City, N.Y.: Doubleday, 1919), 272.\n\n5 THEOLOGIANS BEGAN SPEAKING OF A SHARED MIND: For example, \u201cTwo beings, or two millions\u2014any number thus placed \u2018in communication\u2019\u2014all possess one mind.\u201d Parley Parker Pratt, *Key to the Science of Theology* (1855), quoted in John Durham Peters, *Speaking Into the Air*:\nThe Information\n\nA History of the Idea of Communication (Chicago: University of Chicago Press, 1999), 275.\n\n6 \u201cIT BECOMES ABSOLUTELY NECESSARY\u201d: \u201c\u2026 this amounts to imagining, above the animal biosphere and continuing it, a human sphere, the sphere of reflection, of conscious and free invention, of thought strictly speaking, in short, the sphere of mind or noosphere.\u201d \u00c9douard Le Roy, Les Origines humaines et l\u2019\u00e9volution de l\u2019intelligence (Paris: Boivin et Cie, 1928), quoted and translated by M. J. Aronson, Journal of Philosophy 27, no. 18 (28 August 1930): 499.\n\n7 \u201cDOES IT NOT SEEM AS THOUGH A GREAT BODY\u201d: Pierre Teilhard de Chardin, The Human Phenomenon, trans. Sarah Appleton-Weber (Brighton, U.K.: Sussex Academic Press, 1999), 174.\n\n8 \u201cNONSENSE, TRICKED OUT\u201d: Mind 70, no. 277 (1961): 99. Medawar did not much like Teilhard\u2019s prose, either: \u201cthat tipsy, euphoric prose-poetry which is one of the more tiresome manifestations of the French spirit.\u201d\n\n9 WRITERS OF SCIENCE FICTION: Perhaps first and most notably Olaf Stapledon, Last and First Men (London: Methuen, 1930).\n\n10 \u201cOUR MULTITUDE OF UNCO-ORDINATED GANGLIA\u201d: H. G. Wells, World Brain (London: Methuen, 1938), xiv.\n\n11 \u201cIN A FEW SCORE YEARS\u201d: Ibid., 56.\n\n12 \u201cSORT OF CEREBRUM FOR HUMANITY\u201d: Ibid., 63.\n\n13 \u201cA NETWORK OF MARVELLOUSLY GNARLED AND TWISTED STEMS\u201d: H. G. Wells, The Passionate Friends (London: Harper, 1913), 332; H. G. Wells, The War in the Air (New York: Macmillan, 1922), 14.\n\n14 \u201cIT\u2019S NOT IN THE BEEPS\u201d: Quoted in Flo Conway and Jim Siegelman, Dark Hero of the Information Age: In Search of Norbert Wiener, the Father of Cybernetics (New York: Basic Books, 2005), 189.\n\n15 \u201cI KNOW AN UNCOUTH REGION\u201d: Jorge Luis Borges, \u201cThe Library of Babel,\u201d Labyrinths: Selected Stories and Other Writings (New York: New Directions, 1962), 54.\n\n16 \u201cBEAUTY IS IN THE EYE OF THE BEHOLDER\u201d: Fred I. Dretske, Knowledge and the Flow of Information (Cambridge, Mass.: MIT Press, 1981), vii.\n\n17 \u201cI TAKE \u2018HELL\u2019 IN ITS THEOLOGICAL SENSE\u201d: Jean-Pierre Dupuy, \u201cMyths of the Informational Society,\u201d in Kathleen Woodward, The Myths of Information: Technology and Postindustrial Culture (Madison, Wisc.: Coda Press, 1980), 3.\n\n18 \u201cI IMAGINE \u2026 THAT THE ENTRIES OF THE DICTIONARY\u201d: Dexter Palmer, The Dream of Perpetual Motion (New York: St. Martin\u2019s Press, 2010), 220.\n\n19 \u201cALL HUMAN THOUGHTS MIGHT BE ENTIRELY RESOLVABLE\u201d: Gottfried Wilhelm Leibniz, De scientia universali seu calculo philosophico, 1875; cf. Umberto Eco, The Search for the Perfect Language, trans. James Fentress (Malden, Mass.: Blackwell, 1995), 281.\n\n20 \u201cIS IT SIGNALING, LIKE TELEGRAPHS?\u201d: Margaret Atwood, \u201cAtwood in the\nThe Information\n\nTwittersphere,\u201d The New York Review of Books blog, http://www.nybooks.com/blogs/nyrblog/2010/mar/29/atwood-in-the-twittersphere/, 29 March 2010.\n\n21 \u201cGO MAD IN HERDS\u201d: Charles Mackay, Memoirs of Extraordinary Popular Delusions (Philadelphia: Lindsay & Blakiston, 1850), 14.\n\n22 BROWSE SU[BJECT] CENSORSHIP: Nicholson Baker, \u201cDiscards\u201d (1994), in The Size of Thoughts: Essays and Other Lumber (New York: Random House, 1996), 168.\n\n23 \u201cWE HAVE A LEXICON OF THE CURRENT LANGUAGE\u201d: Interview, Allan Jennings, February 1996; James Gleick, \u201cHere Comes the Spider,\u201d in What Just Happened: A Chronicle from the Information Frontier (New York: Pantheon, 2002), 128\u201332.\n\n24 \u201cI READ SOMEWHERE THAT EVERYBODY ON THIS PLANET\u201d: John Guare, Six Degrees of Separation (New York: Dramatists Play Service, 1990), 45.\n\n25 THE IDEA CAN BE TRACED BACK: Albert-L\u00e1szl\u00f3 Barab\u00e1si, Linked (New York: Plume, 2003), 26 ff.\n\n26 WHAT WATTS AND STROGATZ DISCOVERED: Duncan J. Watts and Steven H. Strogatz, \u201cCollective Dynamics of \u2018Small-World\u2019 Networks,\u201d Nature 393 (1998): 440\u201342; also Duncan J. Watts, Six Degrees: The Science of a Connected Age (New York: Norton, 2003); Albert-L\u00e1szl\u00f3 Barab\u00e1si, Linked.\n\n27 \u201cINFECTIOUS DISEASES ARE PREDICTED\u201d: Duncan J. Watts and Steven H. Strogatz, \u201cCollective Dynamics of \u2018Small-World\u2019 Networks,\u201d 442.\n\n28 \u201cWE WANT THE DEMON, YOU SEE\u201d: Stanislaw Lem, The Cyberiad, trans. Michael Kandel (London: Secker & Warburg, 1975), 155.\n\n29 \u201cWHEN IT WAS PROCLAIMED\u201d: Jorge Luis Borges, \u201cThe Library of Babel,\u201d Labyrinths, 54.\n\n30 \u201cHE THAT DESIRES TO PRINT A BOOK\u201d: John Donne, \u201cFrom a Sermon Preached before King Charles I\u201d (April 1627).\nBibliography\n\nAaboe, Asger. *Episodes from the Early History of Mathematics*. New York: L. W. Singer, 1963.\n\nAdams, Frederick. \u201cThe Informational Turn in Philosophy.\u201d *Minds and Machines* 13 (2003): 471\u2013501.\n\nAllen, William, and Thomas R. H. Thompson. *A Narrative of the Expedition to the River Niger in 1841*. London: Richard Bentley, 1848.\n\nArcher, Charles Maybury, ed. *The London Anecdotes: The Electric Telegraph*, vol. 1. London: David Bogue, 1848.\n\nArchibald, Raymond Clare. \u201cSeventeenth Century Calculating Machines.\u201d *Mathematical Tables and Other Aids to Computation* 1:1 (1943): 27\u201328.\n\nAspray, William. \u201cFrom Mathematical Constructivity to Computer Science: Alan Turing, John Von Neumann, and the Origins of Computer Science in Mathematical Logic.\u201d PhD thesis, University of Wisconsin-Madison, 1980.\n\n\u2014\u2014\u2014. \u201cThe Scientific Conceptualization of Information: A Survey.\u201d *Annals of the History of Computing* 7, no. 2 (1985): 117\u201340.\n\nAunger, Robert, ed. *Darwinizing Culture: The Status of Memetics as a Science*. Oxford: Oxford University Press, 2000.\n\nAvery, John. *Information Theory and Evolution*. Singapore: World Scientific, 2003.\n\nBaars, Bernard J. *The Cognitive Revolution in Psychology*. New York: Guilford Press, 1986.\n\nBabbage, Charles. \u201cOn a Method of Expressing by Signs the Action of Machinery.\u201d *Philosophical Transactions of the Royal Society of London* 116, no. 3(1826): 250\u201365.\n\n\u2014\u2014\u2014. *Reflections on the Decline of Science in England and on Some of Its Causes*. London: B. Fellowes, 1830.\n\n\u2014\u2014\u2014. *Table of the Logarithms of the Natural Numbers, From 1 to 108,000*. London: B. Fellowes, 1831.\n\n\u2014\u2014\u2014. *On the Economy of Machinery and Manufactures*. 4th ed. London: Charles Knight, 1835.\n\n\u2014\u2014\u2014. *The Ninth Bridgewater Treatise. A Fragment*. 2nd ed. London: John Murray, 1838.\n\n\u2014\u2014\u2014. *Passages from the Life of a Philosopher*. London: Longman, Green, Longman, Roberts, & Green, 1864.\nThe Information\n\n\u2014\u2014\u2014. *Charles Babbage and His Calculating Engines: Selected Writings*. Edited by Philip Morrison and Emily Morrison. New York: Dover Publications, 1961.\n\n\u2014\u2014\u2014. *The Analytical Engine and Mechanical Notation*. New York: New York University Press, 1989.\n\n\u2014\u2014\u2014. *The Difference Engine and Table Making*. New York: New York University Press, 1989.\n\n\u2014\u2014\u2014. *The Works of Charles Babbage*. Edited by Martin Campbell-Kelly. New York: New York University Press, 1989.\n\nBabbage, Henry Prevost, ed. *Babbage\u2019s Calculating Engines: Being a Collection of Papers Relating to Them; Their History and Construction*. London: E. & F. N. Spon, 1889.\n\nBairstow, Jeff. \u201cThe Father of the Information Age.\u201d *Laser Focus World* (2002): 114.\n\nBaker, Nicholson. *The Size of Thoughts: Essays and Other Lumber*. New York: Random House, 1996.\n\nBall, W. W. Rouse. *A History of the Study of Mathematics at Cambridge*. Cambridge: Cambridge University Press, 1889.\n\nBar-Hillel, Yehoshua. \u201cAn Examination of Information Theory.\u201d *Philosophy of Science* 22, no. 2 (1955): 86\u2013105.\n\nBarab\u00e1si, Albert-L\u00e1szl\u00f3. *Linked: How Everything Is Connected to Everything Else and What It Means for Business, Science, and Everyday Life*. New York: Plume, 2003.\n\nBarnard, G. A. \u201cThe Theory of Information.\u201d *Journal of the Royal Statistical Society, Series B* 13, no. 1 (1951): 46\u201364.\n\nBaron, Sabrina Alcorn, Eric N. Lindquist, and Eleanor F. Shevlin. *Agent of Change: Print Culture Studies After Elizabeth L. Eisenstein*. Amherst: University of Massachusetts Press, 2007.\n\nBartlett, C. J., and Calvin G. Green. \u201cClinical Prediction: Does One Sometimes Know Too Much.\u201d *Journal of Counseling Psychology* 13, no. 3 (1966): 267\u201370.\n\nBarwise, Jon. \u201cInformation and Circumstance.\u201d *Notre Dame Journal of Formal Logic* 27, no. 3 (1986): 324\u201338.\n\nBattelle, John. *The Search: How Google and Its Rivals Rewrote the Rules of Business and Transformed Our Culture*. New York: Portfolio, 2005.\n\nBaugh, Albert C. *A History of the English Language*. 2nd ed. New York: Appleton-Century-Crofts, 1957.\n\nBaum, Joan. *The Calculating Passion of Ada Byron*. Hamden, Conn.: Shoe String Press, 1986.\n\nBelot, Gordon, John Earman, and Laura Ruetsche. \u201cThe Hawking Information Loss Paradox: The Anatomy of a Controversy.\u201d *British Journal for the Philosophy of Science* 50 (1999): 189\u2013229.\nThe Information\n\nBenjamin, Park. *A History of Electricity (the Intellectual Rise in Electricity) from Antiquity to the Days of Benjamin Franklin*. New York: Wiley and Sons, 1898.\n\nBennett, Charles H. \u201cOn Random and Hard-to-Describe Numbers.\u201d IBM Watson Research Center Report RC 7483 (1979).\n\n\u2014\u2014\u2014. \u201cThe Thermodynamics of Computation\u2014A Review.\u201d *International Journal of Theoretical Physics* 21, no. 12 (1982): 906\u201340.\n\n\u2014\u2014\u2014. \u201cDissipation, Information, Computational Complexity and the Definition of Organization.\u201d In *Emerging Syntheses in Science*, edited by D. Pines, 297\u2013313. Santa Fe: Santa Fe Institute, 1985.\n\n\u2014\u2014\u2014. \u201cDemons, Engines, and the Second Law.\u201d *Scientific American* 257, no. 5 (1987): 108\u201316.\n\n\u2014\u2014\u2014. \u201cLogical Depth and Physical Complexity.\u201d In *The Universal Turing Machine: A Half-Century Survey*, edited by Rolf Herken. Oxford: Oxford University Press, 1988.\n\n\u2014\u2014\u2014. \u201cHow to Define Complexity in Physics, and Why.\u201d In *Complexity, Entropy, and the Physics of Information*, edited by W. H. Zurek. Reading, Mass.: Addison-Wesley, 1990.\n\n\u2014\u2014\u2014. \u201cNotes on the History of Reversible Computation.\u201d *IBM Journal of Research and Development* 44 (2000): 270\u201377.\n\n\u2014\u2014\u2014. \u201cNotes on Landauer\u2019s Principle, Reversible Computation, and Maxwell\u2019s Demon.\u201d *arXiv:physics* 0210005 v2 (2003).\n\n\u2014\u2014\u2014. \u201cPublicity, Privacy, and Permanence of Information.\u201d In *Quantum Computing: Back Action 2006, AIP Conference Proceedings* 864, edited by Debabrata Goswami. Melville, N.Y.: American Institute of Physics, 2006.\n\nBennett, Charles H., and Gilles Brassard. \u201cQuantum Cryptography: Public Key Distribution and Coin Tossing.\u201d In *Proceedings of IEEE International Conference on Computers, Systems and Signal Processing*, 175\u201379. Bangalore, India: 1984.\n\nBennett, Charles H., Gilles Brassard, Claude Cr\u00e9peau, Richard Jozsa, Asher Peres, and William K. Wootters. \u201cTeleporting an Unknown Quantum State Via Dual Classical and Einstein-Podolsky-Rosen Channels.\u201d *Physical Review Letters* 70 (1993): 1895.\n\nBennett, Charles H., and Rolf Landauer. \u201cFundamental Physical Limits of Computation.\u201d *Scientific American* 253, no. 1 (1985): 48\u201356.\n\nBennett, Charles H., Ming Li, and Bin Ma. \u201cChain Letters and Evolutionary Histories.\u201d *Scientific American* 288, no. 6 (June 2003): 76\u201381.\n\nBenzer, Seymour. \u201cThe Elementary Units of Heredity.\u201d In *The Chemical Basis of Heredity*, edited by W. D. McElroy and B. Glass, 70\u201393. Baltimore: Johns Hopkins University Press, 1957.\n\nBerlinski, David. *The Advent of the Algorithm: The Idea That Rules the World*. New York:\nThe Information\n\nHarcourt, 2000.\n\nBernstein, Jeremy. *The Analytical Engine: Computers\u2014Past, Present and Future*. New York: Random House, 1963.\n\nBikhchandani, Sushil, David Hirshleifer, and Ivo Welch. \u201cA Theory of Fads, Fashion, Custom, and Cultural Change as Informational Cascades.\u201d *Journal of Political Economy* 100, no. 5 (1992): 992\u20131026.\n\nBlackmore, Susan. *The Meme Machine*. Oxford: Oxford University Press, 1999.\n\nBlair, Ann. \u201cReading Strategies for Coping with Information Overload ca. 1550\u20131700.\u201d *Journal of the History of Ideas* 64, no. 1 (2003): 11\u201328.\n\nBlohm, Hans, Stafford Beer, and David Suzuki. *Pebbles to Computers: The Thread*. Toronto: Oxford University Press, 1986.\n\nBoden, Margaret A. *Mind as Machine: A History of Cognitive Science*. Oxford: Oxford University Press, 2006.\n\nBollob\u00e1s, B\u00e9la, and Oliver Riordan. *Percolation*. Cambridge: Cambridge University Press, 2006.\n\nBolter, J. David. *Turing\u2019s Man: Western Culture in the Computer Age*. Chapel Hill: University of North Carolina Press, 1984.\n\nBoole, George. \u201cThe Calculus of Logic.\u201d *Cambridge and Dublin Mathematical Journal* 3 (1848): 183\u201398.\n\n\u2014\u2014\u2014. *An Investigation of the Laws of Thought, on Which Are Founded the Mathematical Theories of Logic and Probabilities*. London: Walton & Maberly, 1854.\n\n\u2014\u2014\u2014. *Studies in Logic and Probability*, vol. 1. La Salle, Ill.: Open Court, 1952.\n\nBorges, Jorge Luis. *Labyrinths: Selected Stories and Other Writings*. New York: New Directions, 1962.\n\nBouwmeester, Dik, Jian-Wei Pan, Klaus Mattle, Manfred Eibl, Harald Weinfurter, and Anton Zeilinger. \u201cExperimental Quantum Teleportation.\u201d *Nature* 390 (11 December 1997): 575\u201379.\n\nBowden, B. V., ed. *Faster Than Thought: A Symposium on Digital Computing Machines*. New York: Pitman, 1953.\n\nBraitenberg, Valentino. *Vehicles: Experiments in Synthetic Psychology*. Cambridge, Mass.: MIT Press, 1984.\n\nBrewer, Charlotte. \u201cAuthority and Personality in the *Oxford English Dictionary*.\u201d *Transactions of the Philological Society* 103, no. 3 (2005): 261\u2013301.\n\nBrewster, David. *Letters on Natural Magic*. New York: Harper & Brothers, 1843.\n\nBrewster, Edwin Tenney. *A Guide to Living Things*. Garden City, N.Y.: Doubleday, 1913.\n\nBridenbaugh, Carl. \u201cThe Great Mutation.\u201d *American Historical Review* 68, no. 2 (1963):\nBriggs, Henry. *Logarithmicall Arithmetike: Or Tables of Logarithmes for Absolute Numbers from an Unite to 100000.* London: George Miller, 1631.\n\nBrillouin, L\u00e9on. *Science and Information Theory.* New York: Academic Press, 1956.\n\nBroadbent, Donald E. *Perception and Communication.* Oxford: Pergamon Press, 1958.\n\nBromley, Allan G. \u201cThe Evolution of Babbage\u2019s Computers.\u201d *Annals of the History of Computing* 9 (1987): 113\u201336.\n\nBrown, John Seely, and Paul Duguid. *The Social Life of Information.* Boston: Harvard Business School Press, 2002.\n\nBrowne, Thomas. *Pseudoxia Epidemica: Or, Enquiries into Very Many Received Tenents, and Commonly Presumed Truths.* 3rd ed. London: Nath. Ekins, 1658.\n\nBruce, Robert V. *Bell: Alexander Graham Bell and the Conquest of Solitude.* Boston: Little, Brown, 1973.\n\nBuckland, Michael K. \u201cInformation as Thing.\u201d *Journal of the American Society for Information Science* 42 (1991): 351\u201360.\n\nBurchfield, R. W., and Hans Aarsleff. *Oxford English Dictionary and the State of the Language.* Washington, D.C.: Library of Congress, 1988.\n\nBurgess, Anthony. *But Do Blondes Prefer Gentlemen? Homage to Qwert Yuiop and Other Writings.* New York: McGraw-Hill, 1986.\n\nBush, Vannevar. \u201cAs We May Think.\u201d *The Atlantic,* July 1945.\n\nButler, Samuel. *Life and Habit.* London: Tr\u00fcbner & Co, 1878.\n\n\u2014\u2014\u2014. *Essays on Life, Art, and Science.* Edited by R. A Streatfeild. Port Washington, N.Y.: Kennikat Press, 1970.\n\nBuxton, H. W., and Anthony Hyman. *Memoir of the Life and Labours of the Late Charles Babbage Esq., F.R.S.* Vol. 13 of the Charles Babbage Institute Reprint Series for the History of Computing. Cambridge, Mass.: MIT Press, 1988.\n\nCalude, Cristian S. *Information and Randomness: An Algorithmic Perspective.* Berlin: Springer, 2002.\n\nCalude, Cristian S., and Gregory J. Chaitin. *Randomness and Complexity: From Leibniz to Chaitin.* Singapore, Hackensack, N.J.: World Scientific, 2007.\n\nCampbell-Kelly, Martin. \u201cCharles Babbage\u2019s Table of Logarithms (1827).\u201d *Annals of the History of Computing* 10 (1988): 159\u201369.\n\nCampbell-Kelly, Martin, and William Aspray. *Computer: A History of the Information Machine.* New York: Basic Books, 1996.\n\nCampbell-Kelly, Martin, Mary Croarken, Raymond Flood, and Eleanor Robson, eds. *The History of Mathematical Tables: From Sumer to Spreadsheets.* Oxford: Oxford\nThe Information\n\nUniversity Press, 2003.\n\nCampbell, Jeremy. *Grammatical Man: Information, Entropy, Language, and Life*. New York: Simon & Schuster, 1982.\n\nCampbell, Robert V. D. \u201cEvolution of Automatic Computation.\u201d In *Proceedings of the 1952 ACM National Meeting (Pittsburgh)*, 29\u201332. New York: ACM, 1952.\n\nCarr, Nicholas. *The Big Switch: Rewiring the World, from Edison to Google*. New York: Norton, 2008.\n\n\u2014\u2014\u2014. *The Shallows: What the Internet Is Doing to Our Brains*. New York: Norton, 2010.\n\nCarrington, John F. *A Comparative Study of Some Central African Gong-Languages*. Brussels: Falk, G. van Campenhout, 1949.\n\n\u2014\u2014\u2014. *The Talking Drums of Africa*. London: Carey Kingsgate, 1949.\n\n\u2014\u2014\u2014. *La Voix des tambours: comment comprendre le langage tambourin\u00e9 d\u2019Afrique*. Kinshasa: Centre Protestant d\u2019\u00c9ditions et de Diffusion, 1974.\n\nCasson, Herbert N. *The History of the Telephone*. Chicago: A. C. McClurg, 1910.\n\nCawdrey, Robert. *A Table Alphabetical of Hard Usual English Words (1604); the First English Dictionary*. Gainesville, Fla.: Scholars\u2019 Facsimiles & Reprints, 1966.\n\nCeruzzi, Paul. *A History of Modern Computing*. Cambridge, Mass.: MIT Press, 2003.\n\nChaitin, Gregory J. \u201cOn the Length of Programs for Computing Finite Binary Sequences.\u201d *Journal of the Association for Computing Machinery* 13 (1966): 547\u201369.\n\n\u2014\u2014\u2014. \u201cInformation-Theoretic Computational Complexity.\u201d *IEEE Transactions on Information Theory* 20 (1974): 10\u201315.\n\n\u2014\u2014\u2014. *Information, Randomness & Incompleteness: Papers on Algorithmic Information Theory*. Singapore: World Scientific, 1987.\n\n\u2014\u2014\u2014. *Algorithmic Information Theory*. Cambridge: Cambridge University Press, 1990.\n\n\u2014\u2014\u2014. *At Home in the Universe*. Woodbury, N.Y.: American Institute of Physics, 1994.\n\n\u2014\u2014\u2014. *Conversations with a Mathematician*. London: Springer, 2002.\n\n\u2014\u2014\u2014. *Meta Math: The Quest for Omega*. New York: Pantheon, 2005.\n\n\u2014\u2014\u2014. \u201cThe Limits of Reason.\u201d *Scientific American* 294, no. 3 (March 2006): 74.\n\n\u2014\u2014\u2014. *Thinking About G\u00f6del and Turing: Essays on Complexity, 1970\u20132007*. Singapore: World Scientific, 2007.\n\nChandler, Alfred D., and Cortada, James W., eds. \u201cA Nation Transformed By Information: How Information Has Shaped the United States from Colonial Times to the Present.\u201d (2000).\n\nChentsov, Nicolai N. \u201cThe Unfathomable Influence of Kolmogorov.\u201d *The Annals of Statistics* 18, no. 3 (1990): 987\u201398.\nCherry, E. Colin. \u201cA History of the Theory of Information.\u201d *Transactions of the IRE Professional Group on Information Theory* 1, no. 1 (1953): 22\u201343.\n\n\u2014\u2014\u2014. *On Human Communication*. Cambridge, Mass.: MIT Press, 1957.\n\nChomsky, Noam. \u201cThree Models for the Description of Language.\u201d *IRE Transactions on Information Theory* 2, no. 3 (1956): 113\u201324.\n\n\u2014\u2014\u2014. *Reflections on Language*. New York: Pantheon, 1975.\n\nChrisley, Ronald, ed. *Artificial Intelligence: Critical Concepts*. London: Routledge, 2000.\n\nChurch, Alonzo. \u201cOn the Concept of a Random Sequence.\u201d *Bulletin of the American Mathematical Society* 46, no. 2 (1940): 130\u201335.\n\nChurchland, Patricia S., and Terrence J. Sejnowski. *The Computational Brain*. Cambridge, Mass.: MIT Press, 1992.\n\nCilibrasi, Rudi, and Paul Vitanyi. \u201cAutomatic Meaning Discovery Using Google.\u201d *arXiv:cs.CL/0412098 v2*, 2005.\n\nClanchy, M. T. *From Memory to Written Record, England, 1066\u20131307*. Cambridge, Mass.: Harvard University Press, 1979.\n\nClarke, Roger T. \u201cThe Drum Language of the Tumba People.\u201d *American Journal of Sociology* 40, no. 1 (1934): 34\u201348.\n\nClayton, Jay. *Charles Dickens in Cyberspace: The Afterlife of the Nineteenth Century in Postmodern Culture*. Oxford: Oxford University Press, 2003.\n\nClerke, Agnes M. *The Herschels and Modern Astronomy*. New York: Macmillan, 1895.\n\nCoe, Lewis. *The Telegraph: A History of Morse\u2019s Invention and Its Predecessors in the United States*. Jefferson, N.C.: McFarland, 1993.\n\nColton, F. Barrows. \u201cThe Miracle of Talking by Telephone.\u201d *National Geographic* 72 (1937): 395\u2013433.\n\nConway, Flo, and Jim Siegelman. *Dark Hero of the Information Age: In Search of Norbert Wiener, the Father of Cybernetics*. New York: Basic Books, 2005.\n\nCooke, William Fothergill. *The Electric Telegraph: Was It Invented by Professor Wheatstone?* London: W. H. Smith & Son, 1857.\n\nCoote, Edmund. *The English Schoole-maister*. London: Ralph Jackson & Robert Dexter, 1596.\n\nCordeschi, Roberto. *The Discovery of the Artificial: Behavior, Mind, and Machines Before and Beyond Cybernetics*. Dordrecht, Netherlands: Springer, 2002.\n\nCortada, James W. *Before the Computer*. Princeton, N.J.: Princeton University Press, 1993.\n\nCover, Thomas M., Peter Gacs, and Robert M. Gray. \u201cKolmogorov\u2019s Contributions to Information Theory and Algorithmic Complexity.\u201d *The Annals of Probability* 17, no. 3 (1989): 840\u201365.\nCraven, Kenneth. *Jonathan Swift and the Millennium of Madness: The Information Age in Swift\u2019s Tale of a Tub*. Leiden, Netherlands: E. J. Brill, 1992.\n\nCrick, Francis. \u201cOn Protein Synthesis.\u201d *Symposium of the Society for Experimental Biology* 12 (1958): 138\u201363.\n\n\u2014\u2014\u2014. \u201cCentral Dogma of Molecular Biology.\u201d *Nature* 227 (1970): 561\u201363.\n\n\u2014\u2014\u2014. *What Mad Pursuit*. New York: Basic Books, 1988.\n\nCroarken, Mary. \u201cTabulating the Heavens: Computing the Nautical Almanac in 18th-Century England.\u201d *IEEE Annals of the History of Computing* 25, no. 3 (2003): 48\u201361.\n\n\u2014\u2014\u2014. \u201cMary Edwards: Computing for a Living in 18th-Century England.\u201d *IEEE Annals of the History of Computing* 25, no 4 (2003): 9\u201315.\n\nCrowley, David, and Paul Heyer, eds. *Communication in History: Technology, Culture, Society*. Boston: Allyn and Bacon, 2003.\n\nCrowley, David, and David Mitchell, eds. *Communication Theory Today*. Stanford, Calif.: Stanford University Press, 1994.\n\nDaly, Lloyd W. *Contributions to a History of Alphabeticization in Antiquity and the Middle Ages*. Brussels: Latomus, 1967.\n\nDanielsson, Ulf H., and Marcelo Schiffer. \u201cQuantum Mechanics, Common Sense, and the Black Hole Information Paradox.\u201d *Physical Review D* 48, no. 10 (1993): 4779\u201384.\n\nDarrow, Karl K. \u201cEntropy.\u201d *Proceedings of the American Philosophical Society* 87, no. 5 (1944): 365\u201367.\n\nDavis, Martin. *The Universal Computer: The Road from Leibniz to Turing*. New York: Norton, 2000.\n\nDawkins, Richard. \u201cIn Defence of Selfish Genes.\u201d *Philosophy* 56, no. 218 (1981): 556\u201373.\n\n\u2014\u2014\u2014. *The Blind Watchmaker*. New York: Norton, 1986.\n\n\u2014\u2014\u2014. *The Extended Phenotype*. Rev. ed. Oxford: Oxford University Press, 1999.\n\n\u2014\u2014\u2014. *The Selfish Gene*. 30th anniversary edition. Oxford: Oxford University Press, 2006.\n\nDe Chadarevian, Soraya. \u201cThe Selfish Gene at 30: The Origin and Career of a Book and Its Title.\u201d *Notes and Records of the Royal Society* 61 (2007): 31\u201338.\n\nDe Morgan, Augustus. *Arithmetical Books: From the Invention of Printing to the Present Time*. London: Taylor & Walton, 1847.\n\nDe Morgan, Sophia Elizabeth. *Memoir of Augustus De Morgan*. London: Longmans, Green, 1882.\n\nDelbr\u00fcck, Max. \u201cA Physicist Looks at Biology.\u201d *Transactions of the Connecticut Academy of Arts and Sciences* 38 (1949): 173\u201390.\n\nDelius, Juan D. \u201cOf Mind Memes and Brain Bugs, a Natural History of Culture.\u201d In *The Nature of Culture*, edited by Walter A. Koch. Bochum, Germany: Bochum, 1989.\nDenbigh, K. G., and J. S. Denbigh. *Entropy in Relation to Incomplete Knowledge*. Cambridge: Cambridge University Press, 1984.\n\nDennett, Daniel C. \u201cMemes and the Exploitation of Imagination.\u201d *Journal of Aesthetics and Art Criticism* 48 (1990): 127\u201335.\n\n\u2014\u2014\u2014. *Consciousness Explained*. Boston: Little, Brown, 1991.\n\n\u2014\u2014\u2014. *Darwin\u2019s Dangerous Idea: Evolution and the Meanings of Life*. New York: Simon & Schuster, 1995.\n\n\u2014\u2014\u2014. *Brainchildren: Essays on Designing Minds*. Cambridge, Mass.: MIT Press, 1998.\n\nDesmond, Adrian, and James Moore. *Darwin*. London: Michael Joseph, 1991.\n\nDiaz Vera, Javier E. *A Changing World of Words: Studies in English Historical Lexicography, Lexicology and Semantics*. Amsterdam: Rodopi, 2002.\n\nDilts, Marion May. *The Telephone in a Changing World*. New York: Longmans, Green, 1941.\n\nDiringer, David, and Reinhold Regensburger. *The Alphabet: A Key to the History of Mankind*. 3d ed. New York: Funk & Wagnalls, 1968.\n\nDretske, Fred I. *Knowledge and the Flow of Information*. Cambridge, Mass.: MIT Press, 1981.\n\nDuane, Alexander. \u201cSight and Signalling in the Navy.\u201d *Proceedings of the American Philosophical Society* 55, no. 5 (1916): 400\u201314.\n\nDubbey, J. M. *The Mathematical Work of Charles Babbage*. Cambridge: Cambridge University Press, 1978.\n\nDupuy, Jean-Pierre. *The Mechanization of the Mind: On the Origins of Cognitive Science*. Translated by M. B. DeBevoise. Princeton, N.J.: Princeton University Press, 2000.\n\nDyson, George B. *Darwin Among the Machines: The Evolution of Global Intelligence*. Cambridge, Mass.: Perseus, 1997.\n\nEco, Umberto. *The Search for the Perfect Language*. Translated by James Fentress. Malden, Mass.: Blackwell, 1995.\n\nEdwards, P. N. *The Closed World: Computers and the Politics of Discourse in Cold War America*. Cambridge, Mass.: MIT Press, 1996.\n\nEisenstein, Elizabeth L. \u201cClio and Chronos: An Essay on the Making and Breaking of History-Book Times.\u201d In *History and Theory* suppl. 6: History and the Concept of Time (1966): 36\u201364.\n\n\u2014\u2014\u2014. *The Printing Press as an Agent of Change: Communications and Cultural Transformations in Early-Modern Europe*. Cambridge: Cambridge University Press, 1979.\n\nEkert, Artur. \u201cShannon\u2019s Theorem Revisited.\u201d *Nature* 367 (1994): 513\u201314.\n\u2014\u2014\u2014. \u201cFrom Quantum Code-Making to Quantum Code-Breaking.\u201d arXiv:quant-ph/9703035 v1, 1997.\n\nElias, Peter. \u201cTwo Famous Papers.\u201d IRE Transactions on Information Theory 4, no. 3 (1958): 99.\n\nEmerson, Ralph Waldo. Society and Solitude. Boston: Fields, Osgood, 1870.\n\nEverett, Edward. \u201cThe Uses of Astronomy.\u201d In Orations and Speeches on Various Occasions, 422\u201365. Boston: Little, Brown, 1870.\n\nFahie, J. J. A History of Electric Telegraphy to the Year 1837. London: E. & F. N. Spon, 1884.\n\nFauvel, John, and Jeremy Gray. The History of Mathematics: A Reader. Mathematical Association of America, 1997.\n\nFeferman, Solomon, ed. Kurt G\u00f6del: Collected Works. New York: Oxford University Press, 1986.\n\nFeynman, Richard P. The Character of Physical Law. New York: Modern Library, 1994.\n\n\u2014\u2014\u2014. Feynman Lectures on Computation. Edited by Anthony J. G. Hey and Robin W. Allen. Boulder, Colo.: Westview Press, 1996.\n\nFinnegan, Ruth. Oral Literature in Africa. Oxford: Oxford University Press, 1970.\n\nFischer, Claude S. America Calling: A Social History of the Telephone to 1940. Berkeley: University of California Press, 1992.\n\nFord, Joseph. \u201cDirections in Classical Chaos.\u201d In Directions in Chaos, edited by Hao Bai-lin. Singapore: World Scientific, 1987.\n\nFranksen, Ole I. \u201cIntroducing \u2018Mr. Babbage\u2019s Secret.\u2019 \u201d APL Quote Quad 15, no. 1 (1984): 14\u201317.\n\nFriedman, William F. \u201cEdgar Allan Poe, Cryptographer.\u201d American Literature 8, no. 3 (1936): 266\u201380.\n\nFuchs, Christopher A. \u201cNotes on a Paulian Idea: Foundational, Historical, Anecdotal and Forward-Looking Thoughts on the Quantum.\u201d arXiv:quant-ph/0105039, 2001.\n\n\u2014\u2014\u2014. \u201cQuantum Mechanics as Quantum Information (and Only a Little More),\u201d 2002. arXiv:quant-ph/0205039 v1, 8 May 2001.\n\n\u2014\u2014\u2014. \u201cQBism, the Perimeter of Quantum Bayesianism,\u201d arXiv:quant-ph/1003.5209 vi, 2010.\n\n\u2014\u2014\u2014. Coming of Age with Quantum Information: Notes on a Paulian Idea. Cambridge, Mass.: Cambridge University Press, 2010.\n\nGalison, Peter. Image and Logic: A Material Culture of Microphysics. Chicago: University of Chicago Press, 1997.\n\nGallager, Robert G. \u201cClaude E. Shannon: A Retrospective on His Life, Work, and Impact.\u201d\nGamow, George. \u201cPossible Relation Between Deoxyribonucleic Acid and Protein Structures.\u201d *Nature* 173 (1954): 318.\n\n\u2014\u2014\u2014. \u201cInformation Transfer in the Living Cell.\u201d *Scientific American* 193, no. 10 (October 1955): 70.\n\nGardner, Martin. *Hexaflexagons and Other Mathematical Diversions*. Chicago: University of Chicago Press, 1959.\n\n\u2014\u2014\u2014. *Martin Gardner\u2019s Sixth Book of Mathematical Games from Scientific American*. San Francisco: W. H. Freeman, 1963.\n\nGasser, James, ed. *A Boole Anthology: Recent and Classical Studies in the Logic of George Boole*. Dordrecht, Netherlands: Kluwer, 2000.\n\nGell-Mann, Murray, and Seth Lloyd. \u201cInformation Measures, Effective Complexity, and Total Information.\u201d *Complexity* 2, no. 1 (1996): 44\u201352.\n\nGenosko, Gary. *Marshall McLuhan: Critical Evaluations in Cultural Theory*. Abingdon, U.K.: Routledge, 2005.\n\nGeoghegan, Bernard Dionysius. \u201cThe Historiographic Conceptualization of Information: A Critical Survey.\u201d *Annals of the History of Computing* (2008): 66\u201381.\n\nGerovitch, Slava. *From Newspeak to Cyberspeak: A History of Soviet Cybernetics*. Cambridge, Mass.: MIT Press, 2002.\n\nGilbert, E. N. \u201cInformation Theory After 18 Years.\u201d *Science* 152, no. 3720 (1966): 320\u201326.\n\nGilder, Louisa. *The Age of Entanglement: When Quantum Physics Was Reborn*. New York: Knopf, 2008.\n\nGilliver, Peter, Jeremy Marshall, and Edmund Weiner. *The Ring of Words: Tolkien and the Oxford English Dictionary*. Oxford: Oxford University Press, 2006.\n\nGitelman, Lisa, and Geoffrey B. Pingree, eds. *New Media 1740\u20131915*. Cambridge, Mass.: MIT Press, 2003.\n\nGlassner, Jean-Jacques. *The Invention of Cuneiform*. Translated and edited by Zainab Bahrani and Marc Van De Mieroop. Baltimore: Johns Hopkins University Press, 2003.\n\nGleick, James. *Chaos: Making a New Science*. New York: Viking, 1987.\n\n\u2014\u2014\u2014. \u201cThe Lives They Lived: Claude Shannon, B. 1916; Bit Player.\u201d *New York Times Magazine*, 30 December 2001, 48.\n\n\u2014\u2014\u2014. *What Just Happened: A Chronicle from the Information Frontier*. New York: Pantheon, 2002.\n\nG\u00f6del, Kurt. \u201cRussell\u2019s Mathematical Logic\u201d (1944). In *Kurt G\u00f6del: Collected Works*, edited by Solomon Feferman, vol. 2, 119. New York: Oxford University Press, 1986.\n\nGoldsmid, Frederic John. *Telegraph and Travel: A Narrative of the Formation and\nThe Information\n\nDevelopment of Telegraphic Communication Between England and India, Under the Orders of Her Majesty\u2019s Government, With Incidental Notices of the Countries Traversed By the Lines. London: Macmillan, 1874.\n\nGoldstein, Rebecca. Incompleteness: The Proof and Paradox of Kurt G\u00f6del. New York: Atlas, 2005.\n\nGoldstine, Herman H. \u201cInformation Theory.\u201d Science 133, no. 3462 (1961): 1395\u201399.\n\n\u2014\u2014\u2014. The Computer: From Pascal to Von Neumann. Princeton, N.J.: Princeton University Press, 1973.\n\nGoodwin, Astley J. H. Communication Has Been Established. London: Methuen, 1937.\n\nGoody, Jack. The Domestication of the Savage Mind. Cambridge: Cambridge University Press, 1977.\n\n\u2014\u2014\u2014. The Interface Between the Written and the Oral. Cambridge: Cambridge University Press, 1987.\n\nGoody, Jack, and Ian Watt. \u201cThe Consequences of Literacy.\u201d Comparative Studies in Society and History 5, no. 3 (1963): 304\u201345.\n\nGoonatilake, Susantha. The Evolution of Information: Lineages in Gene, Culture and Artefact. London: Pinter, 1991.\n\nGorman, Michael E. Transforming Nature: Ethics, Invention and Discovery. Boston: Kluwer Academic, 1998.\n\nGould, Stephen Jay. The Panda\u2019s Thumb. New York: Norton, 1980.\n\n\u2014\u2014\u2014. \u201cHumbled by the Genome\u2019s Mysteries.\u201d The New York Times, 19 February 2001.\n\nGrafen, Alan, and Mark Ridley, eds. Richard Dawkins: How a Scientist Changed the Way We Think. Oxford: Oxford University Press, 2006.\n\nGraham, A. C. Studies in Chinese Philosophy and Philosophical Literature. Vol. SUNY Series in Chinese Philosophy and Culture. Albany: State University of New York Press, 1990.\n\nGreen, Jonathon. Chasing the Sun: Dictionary Makers and the Dictionaries They Made. New York: Holt, 1996.\n\nGregersen, Niels Henrik, ed. From Complexity to Life: On the Emergence of Life and Meaning. Oxford: Oxford University Press, 2003.\n\nGriffiths, Robert B. \u201cNature and Location of Quantum Information.\u201d Physical Review A 66 (2002): 012311\u20131.\n\nGr\u00fcnwald, Peter, and Paul Vit\u00e1nyi. \u201cShannon Information and Kolmogorov Complexity.\u201d arXiv:cs.IT/0410002 v1, 8 August 2005.\n\nGuizzo, Erico Mariu. \u201cThe Essential Message: Claude Shannon and the Making of Information Theory.\u201d Master\u2019s thesis, Massachusetts Institute of Technology,\nThe Information\n\nSeptember 2003.\n\nGutfreund, H., and G. Toulouse. *Biology and Computation: A Physicist\u2019s Choice*. Singapore: World Scientific, 1994.\n\nHailperin, Theodore. \u201cBoole\u2019s Algebra Isn\u2019t Boolean Algebra.\u201d *Mathematics Magazine* 54, no. 4 (1981): 172\u201384.\n\nHalstead, Frank G. \u201cThe Genesis and Speed of the Telegraph Codes.\u201d *Proceedings of the American Philosophical Society* 93, no. 5 (1949): 448\u201358.\n\nHalverson, John. \u201cGoody and the Implosion of the Literacy Thesis.\u201d *Man* 27, no. 2 (1992): 301\u201317.\n\nHarlow, Alvin F. *Old Wires and New Waves*. New York: D. Appleton-Century, 1936.\n\nHarms, William F. \u201cThe Use of Information Theory in Epistemology.\u201d *Philosophy of Science* 65, no. 3 (1998): 472\u2013501.\n\nHarris, Roy. *Rethinking Writing*. Bloomington: Indiana University Press, 2000.\n\nHartley, Ralph V. L. \u201cTransmission of Information.\u201d *Bell System Technical Journal* 7 (1928): 535\u201363.\n\nHavelock, Eric A. *Preface to Plato*. Cambridge, Mass.: Harvard University Press, 1963.\n\n\u2014\u2014\u2014. *The Muse Learns to Write: Reflections on Orality and Literacy from Antiquity to the Present*. New Haven, Conn.: Yale University Press, 1986.\n\nHavelock, Eric Alfred, and Jackson P. Hershbell. *Communication Arts in the Ancient World*. New York: Hastings House, 1978.\n\nHawking, Stephen. *God Created the Integers: The Mathematical Breakthroughs That Changed History*. Philadelphia: Running Press, 2005.\n\n\u2014\u2014\u2014. \u201cInformation Loss in Black Holes.\u201d *Physical Review D* 72, arXiv:hep-th/0507171v2, 2005.\n\nHayles, N. Katherine. *How We Became Posthuman: Virtual Bodies in Cybernetics, Literature, and Informatics*. Chicago: University of Chicago Press, 1999.\n\nHeadrick, Daniel R. *When Information Came of Age: Technologies of Knowledge in the Age of Reason and Revolution, 1700\u20131850*. Oxford: Oxford University Press, 2000.\n\nHeims, Steve J. *John Von Neumann and Norbert Wiener*. Cambridge, Mass.: MIT Press, 1980.\n\n\u2014\u2014\u2014. *The Cybernetics Group*. Cambridge, Mass.: MIT Press, 1991.\n\nHerken, Rolf, ed. *The Universal Turing Machine: A Half-Century Survey*. Vienna: Springer-Verlag, 1995.\n\nHey, Anthony J. G., ed. *Feynman and Computation*. Boulder, Colo.: Westview Press, 2002.\n\nHobbes, Thomas. *Leviathan, or, the Matter, Forme, and Power of a Commonwealth, Eclesiasticall and Civill*. London: Andrew Crooke, 1660.\nHodges, Andrew. *Alan Turing: The Enigma*. London: Vintage, 1992.\n\nHofstadter, Douglas R. *G\u00f6del, Escher, Bach: An Eternal Golden Braid*. New York: Basic Books, 1979.\n\n\u2014\u2014\u2014. *Metamagical Themas: Questing for the Essence of Mind and Pattern*. New York: Basic Books, 1985.\n\n\u2014\u2014\u2014. *I Am a Strange Loop*. New York: Basic Books, 2007.\n\nHolland, Owen. \u201cThe First Biologically Inspired Robots.\u201d *Robotica* 21 (2003): 351\u201363.\n\nHolmes, Oliver Wendell. *The Autocrat of the Breakfast-Table*. New York: Houghton Mifflin, 1893.\n\nHolzmann, Gerard J., and Bj\u00f6rn Pehrson. *The Early History of Data Networks*. Washington D.C.: IEEE Computer Society, 1995.\n\nHopper, Robert. *Telephone Conversation*. Bloomington: Indiana University Press, 1992.\n\nHorgan, John. \u201cClaude E. Shannon.\u201d *IEEE Spectrum* (April 1992): 72\u201375.\n\nHorsley, Victor. \u201cDescription of the Brain of Mr. Charles Babbage, F.R.S.\u201d *Philosophical Transactions of the Royal Society of London, Series B* 200 (1909): 117\u201331.\n\nHuberman, Bernardo A. *The Laws of the Web: Patterns in the Ecology of Information*. Cambridge, Mass.: MIT Press, 2001.\n\nHughes, Geoffrey. *A History of English Words*. Oxford: Blackwell, 2000.\n\nH\u00fcllen, Werner. *English Dictionaries 800\u20131700: The Topical Tradition*. Oxford: Clarendon Press, 1999.\n\nHume, Alexander. *Of the Orthographie and Congruitie of the Britan Tongue* (1620). Edited from the original ms. in the British Museum by Henry B. Wheatley. London: Early English Text Society, 1865.\n\nHusbands, Philip, and Owen Holland. \u201cThe Ratio Club: A Hub of British Cybernetics.\u201d In *The Mechanical Mind in History*, 91\u2013148. Cambridge, Mass.: MIT Press, 2008.\n\nHusbands, Philip, Owen Holland, and Michael Wheeler, eds. *The Mechanical Mind in History*. Cambridge, Mass.: MIT Press, 2008.\n\nHuskey, Harry D., and Velma R. Huskey. \u201cLady Lovelace and Charles Babbage.\u201d *Annals of the History of Computing* 2, no. 4 (1980): 299\u2013329.\n\nHyatt, Harry Middleton. *Folk-Lore from Adams County, Illinois*. 2nd and rev. ed. Hannibal, Mo.: Alma Egan Hyatt Foundation, 1965.\n\nHyman, Anthony. *Charles Babbage: Pioneer of the Computer*. Princeton, N.J.: Princeton University Press, 1982.\n\nHyman, Anthony, ed. *Science and Reform: Selected Works of Charles Babbage*. Cambridge: Cambridge University Press, 1989.\n\nIfrah, Georges. *The Universal History of Computing: From the Abacus to the Quantum*\nThe Information\n\nComputer. New York: Wiley and Sons, 2001.\n\nIvanhoe, P. J., and Bryan W. Van Norden. Readings in Classical Chinese Philosophy. 2nd ed. Indianapolis: Hackett Publishing, 2005.\n\nJackson, Willis, ed. Communication Theory. New York: Academic Press, 1953.\n\nJames, William. Principles of Psychology. Chicago: Encyclop\u00e6dia Britannica, 1952.\n\nJaynes, Edwin T. \u201cInformation Theory and Statistical Mechanics.\u201d Physical Review 106, no. 4 (1957): 620\u201330.\n\n\u2014\u2014\u2014. \u201cWhere Do We Stand on Maximum Entropy.\u201d In The Maximum Entropy Formalism, edited by R. D. Levine and Myron Tribus. Cambridge, Mass.: MIT Press, 1979.\n\nJaynes, Edwin T., Walter T. Grandy, and Peter W. Milonni. Physics and Probability: Essays in Honor of Edwin T. Jaynes. Cambridge: Cambridge University Press, 1993.\n\nJaynes, Julian. The Origin of Consciousness in the Breakdown of the Bicameral Mind. Boston: Houghton Mifflin, 1977.\n\nJennings, Humphrey. Pandaemonium: The Coming of the Machine as Seen by Contemporary Observers, 1660\u20131886. Edited by Mary-Lou Jennings and Charles Madge. New York: Free Press, 1985.\n\nJohannsen, Wilhelm. \u201cThe Genotype Conception of Heredity.\u201d American Naturalist 45, no. 531 (1911): 129\u201359.\n\nJohns, Adrian. The Nature of the Book: Print and Knowledge in the Making. Chicago: University of Chicago Press, 1998.\n\nJohnson, George. Fire in the Mind: Science, Faith, and the Search for Order. New York: Knopf, 1995.\n\n\u2014\u2014\u2014. \u201cClaude Shannon, Mathematician, Dies at 84.\u201d The New York Times, 27 February 2001, B7.\n\nJohnson, Horton A. \u201cThermal Noise and Biological Information.\u201d Quarterly Review of Biology 62, no. 2 (1987): 141\u201352.\n\nJoncourt, \u00c9lie de. De Natura et Praeclaro Usu Simplicissimae Speciei Numerorum Trigonalium. Edited by \u00c9. de Joncourt Auctore. Hagae Comitum: Husson, 1762.\n\nJones, Alexander. Historical Sketch of the Electric Telegraph: Including Its Rise and Progress in the United States. New York: Putnam, 1852.\n\nJones, Jonathan. \u201cQuantum Computers Get Real.\u201d Physics World 15, no. 4 (2002): 21\u201322.\n\n\u2014\u2014\u2014. \u201cQuantum Computing: Putting It into Practice.\u201d Nature 421 (2003): 28\u201329.\n\nJudson, Horace Freeland. The Eighth Day of Creation: Makers of the Revolution in Biology. New York: Simon & Schuster, 1979.\n\nKahn, David. The Codebreakers: The Story of Secret Writing. London: Weidenfeld &\nNicolson, 1968.\n\n\u2014\u2014\u2014. *Seizing the Enigma: The Race to Break the German U-Boat Codes, 1939\u20131943*. New York: Barnes & Noble, 1998.\n\nKahn, Robert E. \u201cA Tribute to Claude E. Shannon.\u201d *IEEE Communications Magazine* (2001): 18\u201322.\n\nKalin, Theodore A. \u201cFormal Logic and Switching Circuits.\u201d In *Proceedings of the 1952 ACM National Meeting (Pittsburgh)*, 251\u201357. New York: ACM, 1952.\n\nKauffman, Stuart. *Investigations*. Oxford: Oxford University Press, 2002.\n\nKay, Lily E. *Who Wrote the Book of Life: A History of the Genetic Code*. Stanford, Calif.: Stanford University Press, 2000.\n\nKelly, Kevin. *Out of Control: The Rise of Neo-Biological Civilization*. Reading, Mass.: Addison-Wesley, 1994.\n\nKendall, David G. \u201cAndrei Nikolaevich Kolmogorov. 25 April 1903\u201320 October 1987.\u201d *Biographical Memoirs of Fellows of the Royal Society* 37 (1991): 301\u201319.\n\nKeynes, John Maynard. *A Treatise on Probability*. London: Macmillan, 1921.\n\nKneale, William. \u201cBoole and the Revival of Logic.\u201d *Mind* 57, no. 226 (1948): 149\u201375.\n\nKnuth, Donald E. \u201cAncient Babylonian Algorithms.\u201d *Communications of the Association for Computing Machinery* 15, no. 7 (1972): 671\u201377.\n\nKolmogorov, A. N. \u201cCombinatorial Foundations of Information Theory and the Calculus of Probabilities.\u201d *Russian Mathematical Surveys* 38, no. 4 (1983): 29\u201343.\n\n\u2014\u2014\u2014. *Selected Works of A. N. Kolmogorov. Vol. 3, Information Theory and the Theory of Algorithms*. Translated by A. B. Sossinsky. Dordrecht, Netherlands: Kluwer Academic Publishers, 1993.\n\nKolmogorov, A. N., I. M. Gelfand, and A. M. Yaglom. \u201cOn the General Definition of the Quantity of Information\u201d (1956). In *Selected Works of A. N. Kolmogorov, vol. 3, Information Theory and the Theory of Algorithms*, 2\u20135. Dordrecht, Netherlands: Kluwer Academic Publishers, 1993.\n\nKolmogorov, A. N., and A. N. Shiryaev. *Kolmogorov in Perspective. History of Mathematics*, vol. 20. Translated by Harold H. McFaden. N.p.: American Mathematical Society, London Mathematical Society, 2000.\n\nKrutch, Joseph Wood. *Edgar Allan Poe: A Study in Genius*. New York: Knopf, 1926.\n\nKub\u00e1t, Libor, and Jiri Zeman. *Entropy and Information in Science and Philosophy*. Amsterdam: Elsevier, 1975.\n\nLangville, Amy N., and Carl D. Meyer. *Google\u2019s Page Rank and Beyond: The Science of Search Engine Rankings*. Princeton, N.J.: Princeton University Press, 2006.\n\nLanier, Jaron. *You Are Not a Gadget*. New York: Knopf, 2010.\nLanouette, William. *Genius in the Shadows*. New York: Scribner\u2019s, 1992.\n\nLardner, Dionysius. \u201cBabbage\u2019s Calculating Engines.\u201d *Edinburgh Review* 59, no. 120 (1834): 263\u2013327.\n\n\u2014\u2014\u2014. *The Electric Telegraph*. Revised and rewritten by Edward B. Bright. London: James Walton, 1867.\n\nLasker, Edward. *The Adventure of Chess*. 2nd ed. New York: Dover, 1959.\n\nLeavitt, Harold J., and Thomas L. Whisler. \u201cManagement in the 1980s.\u201d *Harvard Business Review* (1958): 41\u201348.\n\nLeff, Harvey S., and Andrew F. Rex, eds. *Maxwell\u2019s Demon: Entropy, Information, Computing*. Princeton, N.J.: Princeton University Press, 1990.\n\n\u2014\u2014\u2014. *Maxwell\u2019s Demon 2: Entropy, Classical and Quantum Information, Computing*. Bristol U.K.: Institute of Physics, 2003.\n\nLenoir, Timothy, ed. *Inscribing Science: Scientific Texts and the Materiality of Communication*. Stanford, Calif.: Stanford University Press, 1998.\n\nLicklider, J. C. R. \u201cInterview Conducted by William Aspray and Arthur Norberg.\u201d (1988).\n\nLieberman, Phillip. \u201cVoice in the Wilderness: How Humans Acquired the Power of Speech.\u201d *Sciences* (1988): 23\u201329.\n\nLloyd, Seth. \u201cComputational Capacity of the Universe.\u201d *Physical Review Letters* 88, no. 23 (2002). arXiv:quant-ph/0110141v1.\n\n\u2014\u2014\u2014. *Programming the Universe*. New York: Knopf, 2006.\n\nLoewenstein, Werner R. *The Touchstone of Life: Molecular Information, Cell Communication, and the Foundations of Life*. New York: Oxford University Press, 1999.\n\nLucky, Robert W. *Silicon Dreams: Information, Man, and Machine*. New York: St. Martin\u2019s Press, 1989.\n\nLundheim, Lars. \u201cOn Shannon and \u2018Shannon\u2019s Formula.\u2019 \u201d *Telektronikk* 98, no. 1 (2002): 20\u201329.\n\nLuria, A. R. *Cognitive Development: Its Cultural and Social Foundations*. Cambridge, Mass.: Harvard University Press, 1976.\n\nLynch, Aaron. *Thought Contagion: How Belief Spreads Through Society*. New York: Basic Books, 1996.\n\nMabee, Carleton. *The American Leonardo: A Life of Samuel F. B. Morse*. New York: Knopf, 1943.\n\nMacFarlane, Alistair G. J. \u201cInformation, Knowledge, and the Future of Machines.\u201d *Philosophical Transactions: Mathematical, Physical and Engineering Sciences* 361, no. 1809 (2003): 1581\u2013616.\nMachlup, Fritz, and Una Mansfield, eds. *The Study of Information: Interdisciplinary Messages*. New York: Wiley and Sons, 1983.\n\nMachta, J. \u201cEntropy, Information, and Computation.\u201d *American Journal of Physics* 67, no. 12 (1999): 1074\u201377.\n\nMackay, Charles. *Memoirs of Extraordinary Popular Delusions*. Philadelphia: Lindsay & Blakiston, 1850.\n\nMacKay, David J. C. *Information Theory, Inference, and Learning Algorithms*. Cambridge: Cambridge University Press, 2002.\n\nMacKay, Donald M. *Information, Mechanism, and Meaning*. Cambridge, Mass.: MIT Press, 1969.\n\nMacrae, Norman. *John Von Neumann: The Scientific Genius Who Pioneered the Modern Computer, Game Theory, Nuclear Deterrence, and Much More*. New York: Pantheon, 1992.\n\nMacray, William Dunn. *Annals of the Bodleian Library, Oxford, 1598\u20131867*. London: Rivingtons, 1868.\n\nMancosu, Paolo. *From Brouwer to Hilbert: The Debate on the Foundations of Mathematics in the 1920s*. New York: Oxford University Press, 1998.\n\nMarland, E. A. *Early Electrical Communication*. London: Abelard-Schuman, 1964.\n\nMartin, Mich\u00e8le. \u201c\u2018Hello, Central?\u2019\u201d: *Gender, Technology, and Culture in the Formation of Telephone Systems*. Montreal: McGill\u2013Queen\u2019s University Press, 1991.\n\nMarvin, Carolyn. *When Old Technologies Were New: Thinking About Electric Communication in the Late Nineteenth Century*. New York: Oxford University Press, 1988.\n\nMaxwell, James Clerk. *Theory of Heat*. 8th ed. London: Longmans, Green, 1885.\n\nMayr, Otto. \u201cMaxwell and the Origins of Cybernetics.\u201d *Isis* 62, no. 4 (1971): 424\u201344.\n\nMcCulloch, Warren S. \u201cBrain and Behavior.\u201d *Comparative Psychology Monograph* 20 1, Series 103 (1950).\n\n\u2014\u2014\u2014. \u201cThrough the Den of the Metaphysician.\u201d *British Journal for the Philosophy of Science* 5, no. 17 (1954): 18\u201331.\n\n\u2014\u2014\u2014. *Embodiments of Mind*. Cambridge, Mass.: MIT Press, 1965.\n\n\u2014\u2014\u2014. \u201cRecollections of the Many Sources of Cybernetics.\u201d *ASC Forum* 6, no. 2 (1974): 5\u201316.\n\nMcCulloch, Warren S., and John Pfieffer. \u201cOf Digital Computers Called Brains.\u201d *Scientific Monthly* 69, no. 6 (1949): 368\u201376.\n\nMcLuhan, Marshall. *The Mechanical Bride: Folklore of Industrial Man*. New York: Vanguard Press, 1951.\nThe Information\n\n\u2014\u2014\u2014. *The Gutenberg Galaxy*. Toronto: University of Toronto Press, 1962.\n\n\u2014\u2014\u2014. *Understanding Media: The Extensions of Man*. New York: McGraw-Hill, 1965.\n\n\u2014\u2014\u2014. *Essential McLuhan*. Edited by Eric McLuhan and Frank Zingrone. New York: Basic Books, 1996.\n\nMcLuhan, Marshall, and Quentin Fiore. *The Medium Is the Massage*. New York: Random House, 1967.\n\nMcNeely, Ian F., with Lisa Wolverton. *Reinventing Knowledge: From Alexandria to the Internet*. New York: Norton, 2008.\n\nMenabrea, L. F. \u201cSketch of the Analytical Engine Invented by Charles Babbage. With notes upon the Memoir by the Translator, Ada Augusta, Countess of Lovelace.\u201d *Biblioth\u00e8que Universelle de Gen\u00e8ve* 82 (October 1842). Also available online at http://www.fournilab.ch/babbage/sketch.html.\n\nMenninger, Karl, and Paul Broneer. *Number Words and Number Symbols: A Cultural History of Numbers*. Dover Publications, 1992.\n\nMermin, N. David. \u201cCopenhagen Computation: How I Learned to Stop Worrying and Love Bohr.\u201d *IBM Journal of Research and Development* 48 (2004): 53\u201361.\n\n\u2014\u2014\u2014. *Quantum Computer Science: An Introduction*. Cambridge: Cambridge University Press, 2007.\n\nMiller, George A. \u201cThe Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information.\u201d *Psychological Review* 63 (1956): 81\u201397.\n\nMiller, Jonathan. *Marshall McLuhan*. New York: Viking, 1971.\n\n\u2014\u2014\u2014. *States of Mind*. New York: Pantheon, 1983.\n\nMillman, S., ed. *A History of Engineering and Science in the Bell System: Communications Sciences (1925\u20131980)*. Bell Telephone Laboratories, 1984.\n\nMindell, David A. *Between Human and Machine: Feedback, Control, and Computing Before Cybernetics*. Baltimore: Johns Hopkins University Press, 2002.\n\nMindell, David A., J\u00e9r\u00f4me Segal, and Slava Gerovitch. \u201cCybernetics and Information Theory in the United States, France, and the Soviet Union.\u201d In *Science and Ideology: A Comparative History*, edited by Mark Walker, 66\u201395. London: Routledge, 2003.\n\nMonod, Jacques. *Chance and Necessity: An Essay on the Natural Philosophy of Modern Biology*. Translated by Austryn Wainhouse. New York: Knopf, 1971.\n\nMoore, Francis. *Travels Into the Inland Parts of Africa*. London: J. Knox, 1767.\n\nMoore, Gordon E. \u201cCramming More Components onto Integrated Circuits.\u201d *Electronics* 38, no. 8 (1965): 114\u201317.\n\nMorowitz, Harold J. *The Emergence of Everything: How the World Became Complex*. New York: Oxford University Press, 2002.\nMorse, Samuel F. B. *Samuel F. B. Morse: His Letters and Journals*. Edited by Edward Lind Morse. Boston: Houghton Mifflin, 1914.\n\nMorus, Iwan Rhys. \u201c\u2018The Nervous System of Britain\u2019: Space, Time and the Electric Telegraph in the Victorian Age.\u201d *British Journal of the History of Science* 33 (2000): 455\u201375.\n\nMoseley, Maboth. *Irascible Genius: A Life of Charles Babbage, Inventor*. London: Hutchinson, 1964.\n\nMugglestone, Lynda. \u201cLabels Reconsidered: Objectivity and the *OED*.\u201d *Dictionaries* 21 (2000): 22\u201337.\n\n\u2014\u2014\u2014. *Lost for Words: The Hidden History of the Oxford English Dictionary*. New Haven, Conn.: Yale University Press, 2005.\n\nMulcaster, Richard. *The First Part of the Elementarie Which Entreateth Chefelie of the Right Writing of Our English Tung*. London: Thomas Vautroullier, 1582.\n\nMullett, Charles F. \u201cCharles Babbage: A Scientific Gadfly.\u201d *Scientific Monthly* 67, no. 5 (1948): 361\u201371.\n\nMumford, Lewis. *The Myth of the Machine*. Vol. 2, *The Pentagon of Power*. New York: Harcourt, Brace, 1970.\n\nMurray, K. M. E. *Caught in the Web of Words*. New Haven, Conn.: Yale University Press, 1978.\n\nMushengyezi, Aaron. \u201cRethinking Indigenous Media: Rituals, \u2018Talking\u2019 Drums and Orality as Forms of Public Communication in Uganda.\u201d *Journal of African Cultural Studies* 16, no. 1 (2003): 107\u201317.\n\nNagel, Ernest, and James R. Newman. *G\u00f6del\u2019s Proof*. New York: New York University Press, 1958.\n\nNapier, John. *A Description of the Admirable Table of Logarithmes*. Translated by Edward Wright. London: Nicholas Okes, 1616.\n\nNemes, Tiham\u00e9r. *Cybernetic Machines*. Translated by I. F\u00f6ldes. New York: Gordon & Breach, 1970.\n\nNeugebauer, Otto. *The Exact Sciences in Antiquity*. 2nd ed. Providence, R.I.: Brown University Press, 1957.\n\n\u2014\u2014\u2014. *A History of Ancient Mathematical Astronomy*. Studies in the History of Mathematics and Physical Sciences, vol. 1. New York: Springer-Verlag, 1975.\n\nNeugebauer, Otto, Abraham Joseph Sachs, and Albrecht G\u00f6tze. *Mathematical Cuneiform Texts*. American Oriental Series, vol. 29. New Haven, Conn.: American Oriental Society and the American Schools of Oriental Research, 1945.\n\nNewman, M. E. J. \u201cThe Structure and Function of Complex Networks.\u201d *SIAM Review* 45, no. 2 (2003): 167\u2013256.\nNiven, W. D., ed. *The Scientific Papers of James Clerk Maxwell*. Cambridge: Cambridge University Press, 1890; repr. New York: Dover, 1965.\n\nNorman, Donald A. *Things That Make Us Smart: Defending Human Attributes in the Age of the Machine*. Reading, Mass.: Addison-Wesley, 1993.\n\nN\u00f8rretranders, Tor. *The User Illusion: Cutting Consciousness Down to Size*. Translated by Jonathan Sydenham. New York: Penguin, 1998.\n\nNoyes, Gertrude E. \u201cThe First English Dictionary, Cawdrey\u2019s Table Alphabeticall.\u201d *Modern Language Notes* 58, no. 8 (1943): 600\u2013605.\n\nOgilvie, Brian W. \u201cThe Many Books of Nature: Renaissance Naturalists and Information Overload.\u201d *Journal of the History of Ideas* 64, no. 1 (2003): 29\u201340.\n\n\u2014\u2014\u2014. *The Science of Describing: Natural History in Renaissance Europe*. Chicago: University of Chicago Press, 2006.\n\nOlson, David R. \u201cFrom Utterance to Text: The Bias of Language in Speech and Writing.\u201d *Harvard Educational Review* 47 (1977): 257\u201381.\n\n\u2014\u2014\u2014. \u201cThe Cognitive Consequences of Literacy.\u201d *Canadian Psychology* 27, no. 2 (1986): 109\u201321.\n\nOng, Walter J. \u201cThis Side of Oral Culture and of Print.\u201d *Lincoln Lecture* (1973).\n\n\u2014\u2014\u2014. \u201cAfrican Talking Drums and Oral Noetics.\u201d *New Literary History* 8, no. 3 (1977): 411\u201329.\n\n\u2014\u2014\u2014. *Interfaces of the Word*. Ithaca, N.Y.: Cornell University Press, 1977.\n\n\u2014\u2014\u2014. *Orality and Literacy: The Technologizing of the Word*. London: Methuen, 1982.\n\nOslin, George P. *The Story of Telecommunications*. Macon, Ga.: Mercer University Press, 1992.\n\nPage, Lawrence, Sergey Brin, Rajeev Motwani, and Terry Winograd. \u201cThe Pagerank Citation Ranking: Bringing Order to the Web.\u201d Technical Report SIDL-WP-1999-0120, Stanford University InfoLab (1998). Available online at http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf.\n\nPain, Stephanie. \u201cMr. Babbage and the Buskers.\u201d *New Scientist* 179, no. 2408 (2003): 42.\n\nPaine, Albert Bigelow. *In One Man\u2019s Life: Being Chapters from the Personal & Business Career of Theodore N. Vail*. New York: Harper & Brothers, 1921.\n\nPalme, Jacob. \u201cYou Have 134 Unread Mail! Do You Want to Read Them Now?\u201d In *Computer-Based Message Services*, edited by Hugh T. Smith. North Holland: Elsevier, 1984.\n\nPeckhaus, Volker. \u201c19th Century Logic Between Philosophy and Mathematics.\u201d *Bulletin of Symbolic Logic* 5, no. 4 (1999): 433\u201350.\n\nPeres, Asher. \u201cEinstein, Podolsky, Rosen, and Shannon.\u201d arXiv:quant-ph/0310010 v1, 2003.\n\u2014\u2014\u2014. \u201cWhat Is Actually Teleported?\u201d *IBM Journal of Research and Development* 48, no. 1 (2004): 63\u201369.\n\nP\u00e9rez-Montoro, Mario. *The Phenomenon of Information: A Conceptual Approach to Information Flow*. Translated by Dick Edelstein. Lanham, Md.: Scarecrow, 2007.\n\nPeters, John Durham. *Speaking Into the Air: A History of the Idea of Communication*. Chicago: University of Chicago Press, 1999.\n\nPhilological Society. *Proposal for a Publication of a New English Dictionary by the Philological Society*. London: Tr\u00fcbner & Co., 1859.\n\nPickering, John. *A Lecture on Telegraphic Language*. Boston: Hilliard, Gray, 1833.\n\nPierce, John R. *Symbols, Signals and Noise: The Nature and Process of Communication*. New York: Harper & Brothers, 1961.\n\n\u2014\u2014\u2014. \u201cThe Early Days of Information Theory.\u201d *IEEE Transactions on Information Theory* 19, no. 1 (1973): 3\u20138.\n\n\u2014\u2014\u2014. *An Introduction to Information Theory: Symbols, Signals and Noise*. 2nd ed. New York: Dover, 1980.\n\n\u2014\u2014\u2014. \u201cLooking Back: Claude Elwood Shannon.\u201d *IEEE Potentials* 12, no. 4 (December 1993): 38\u201340.\n\nPinker, Steven. *The Language Instinct: How the Mind Creates Language*. New York: William Morrow, 1994.\n\n\u2014\u2014\u2014. *The Stuff of Thought: Language as a Window into Human Nature*. New York: Viking, 2007.\n\nPlatt, John R., ed. *New Views of the Nature of Man*. Chicago: University of Chicago Press, 1983.\n\nPlenio, Martin B., and Vincenzo Vitelli. \u201cThe Physics of Forgetting: Landauer\u2019s Erasure Principle and Information Theory.\u201d *Contemporary Physics* 42, no. 1 (2001): 25\u201360.\n\nPoe, Edgar Allan. *Essays and Reviews*. New York: Library of America, 1984.\n\n\u2014\u2014\u2014. *Poetry and Tales*. New York: Library of America, 1984.\n\nPool, Ithiel de Sola, ed. *The Social Impact of the Telephone*. Cambridge, Mass.: MIT Press, 1977.\n\nPoundstone, William. *The Recursive Universe: Cosmic Complexity and the Limits of Scientific Knowledge*. Chicago: Contemporary Books, 1985.\n\nPrager, John. *On Turing*. Belmont, Calif.: Wadsworth, 2001.\n\nPrice, Robert. \u201cA Conversation with Claude Shannon: One Man\u2019s Approach to Problem Solving.\u201d *IEEE Communications Magazine* 22 (1984): 123\u201326.\n\nPulgram, Ernst. *Theory of Names*. Berkeley, Calif.: American Name Society, 1954.\n\nPurbrick, Louise. \u201cThe Dream Machine: Charles Babbage and His Imaginary Computers.\u201d\nThe Information\n\nJournal of Design History 6:1 (1993): 9\u201323.\n\nQuastler, Henry, ed. Essays on the Use of Information Theory in Biology. Urbana: University of Illinois Press, 1953.\n\n\u2014\u2014\u2014. Information Theory in Psychology: Problems and Methods. Glencoe, Ill.: Free Press, 1955.\n\nRadford, Gary P. \u201cOvercoming Dewey\u2019s \u2018False Psychology\u2019: Reclaiming Communication for Communication Studies.\u201d Paper presented at the 80th Annual Meeting of the Speech Communication Association, New Orleans, November 1994. Available online at http://www.theprofessors.net/dewey.html.\n\nRattray, Robert Sutherland. \u201cThe Drum Language of West Africa: Part I.\u201d Journal of the Royal African Society 22, no. 87 (1923): 226\u201336.\n\n\u2014\u2014\u2014. \u201cThe Drum Language of West Africa: Part II.\u201d Journal of the Royal African Society 22, no. 88 (1923): 302\u201316.\n\nRedfield, Robert. The Primitive World and Its Transformations. Ithaca, N.Y.: Cornell University Press, 1953.\n\nR\u00e9nyi, Alfr\u00e9d. A Diary on Information Theory. Chichester, N.Y.: Wiley and Sons, 1984.\n\nRheingold, Howard. Tools for Thought: The History and Future of Mind-Expanding Technology. Cambridge, Mass.: MIT Press, 2000.\n\nRhodes, Frederick Leland. Beginnings of Telephony. New York: Harper & Brothers, 1929.\n\nRhodes, Neil, and Jonathan Sawday, eds. The Renaissance Computer: Knowledge Technology in the First Age of Print. London: Routledge, 2000.\n\nRichardson, Robert D. William James: In the Maelstrom of American Modernism. New York: Houghton Mifflin, 2006.\n\nRobertson, Douglas S. The New Renaissance: Computers and the Next Level of Civilization. Oxford: Oxford University Press, 1998.\n\n\u2014\u2014\u2014. Phase Change: The Computer Revolution in Science and Mathematics. Oxford: Oxford University Press, 2003.\n\nRochberg, Francesca. The Heavenly Writing: Divination, Horoscopy, and Astronomy in Mesopotamian Culture. Cambridge: Cambridge University Press, 2004.\n\nRoederer, Juan G. Information and Its Role in Nature. Berlin: Springer, 2005.\n\nRogers, Everett M. \u201cClaude Shannon\u2019s Cryptography Research during World War II and the Mathematical Theory of Communication.\u201d In Proceedings, IEEE 28th International Carnaham Conference on Security Technology, October 1994: 1\u20135.\n\nRomans, James. ABC of the Telephone. New York: Audel & Co., 1901.\n\nRonell, Avital. The Telephone Book: Technology, Schizophrenia, Electric Speech. Lincoln: University of Nebraska Press, 1991.\nRosenblueth, Arturo, Norbert Wiener, and Julian Bigelow. \u201cBehavior, Purpose and Teleology.\u201d *Philosophy of Science* 10 (1943): 18\u201324.\n\nRosenheim, Shawn James. *The Cryptographic Imagination: Secret Writing from Edgar Poe to the Internet*. Baltimore: Johns Hopkins University Press, 1997.\n\nRussell, Bertrand. *Logic and Knowledge: Essays, 1901\u20131950*. London: Routledge, 1956.\n\nSagan, Carl. *Murmurs of Earth: The Voyager Interstellar Record*. New York: Random House, 1978.\n\nSapir, Edward. *Language: An Introduction to the Study of Speech*. New York: Harcourt, Brace, 1921.\n\nSarkar, Sahotra. *Molecular Models of Life*. Cambridge, Mass.: MIT Press, 2005.\n\nSchaffer, Simon. \u201cBabbage\u2019s Intelligence: Calculating Engines and the Factory System.\u201d *Critical Inquiry* 21, no. 1 (1994): 203\u201327.\n\n\u2014\u2014\u2014. \u201cPaper and Brass: The Lucasian Professorship 1820\u201339.\u201d In *From Newton to Hawking: A History of Cambridge University\u2019s Lucasian Professors of Mathematics*, edited by Kevin C. Knox and Richard Noakes, 241\u201394. Cambridge: Cambridge University Press, 2003.\n\nSchindler, G. E., Jr., ed. *A History of Engineering and Science in the Bell System: Switching Technology (1925\u20131975)*. Bell Telephone Laboratories, 1982.\n\nSchr\u00f6dinger, Erwin. *What Is Life?* Reprint ed. Cambridge: Cambridge University Press, 1967.\n\nSeife, Charles. *Decoding the Universe*. New York: Viking, 2006.\n\nShaffner, Taliaferro P. *The Telegraph Manual: A Complete History and Description of the Semaphoric, Electric and Magnetic Telegraphs of Europe, Asia, Africa, and America, Ancient and Modern*. New York: Pudney & Russell, 1859.\n\nShannon, Claude Elwood. *Collected Papers*. Edited by N. J. A. Sloane and Aaron D. Wyner. New York: IEEE Press, 1993.\n\n\u2014\u2014\u2014. *Miscellaneous Writings*. Edited by N. J. A. Sloane and Aaron D. Wyner. Murray Hill, N.J.: Mathematical Sciences Research Center, AT&T Bell Laboratories, 1993.\n\nShannon, Claude Elwood, and Warren Weaver. *The Mathematical Theory of Communication*. Urbana: University of Illinois Press, 1949.\n\nShenk, David. *Data Smog: Surviving the Information Glut*. New York: HarperCollins, 1997.\n\nSchieber, Stuart M., ed. *The Turing Test: Verbal Behavior as the Hallmark of Intelligence*. Cambridge, Mass.: MIT Press, 2004.\n\nShiryaev, A. N. \u201cKolmogorov: Life and Creative Activities.\u201d *Annals of Probability* 17, no. 3 (1989): 866\u2013944.\n\nSiegfried, Tom. *The Bit and the Pendulum: From Quantum Computing to M Theory\u2014The*\nThe Information\n\nNew Physics of Information. New York: Wiley and Sons, 2000.\n\nSilverman, Kenneth. Lightning Man: The Accursed Life of Samuel F. B. Morse. New York: Knopf, 2003.\n\nSimpson, John. \u201cPreface to the Third Edition of the Oxford English Dictionary.\u201d Oxford University Press, http://oed.com/about/oed3-preface/#general (accessed 13 June 2010).\n\nSimpson, John, ed. The First English Dictionary, 1604: Robert Cawdrey\u2019s A Table Alphabeticall. Oxford: Bodleian Library, 2007.\n\nSingh, Jagjit. Great Ideas in Information Theory, Language and Cybernetics. New York: Dover, 1966.\n\nSingh, Simon. The Code Book: The Secret History of Codes and Codebreaking. London: Fourth Estate, 1999.\n\nSlater, Robert. Portraits in Silicon. Cambridge, Mass.: MIT Press, 1987.\n\nSlepian, David. \u201cInformation Theory in the Fifties.\u201d IEEE Transactions on Information Theory 19, no. 2 (1973): 145\u201348.\n\nSloman, Aaron. The Computer Revolution in Philosophy. Hassocks, Sussex: Harrester Press, 1978.\n\nSmith, D. E. A Source Book in Mathematics. New York: McGraw-Hill, 1929.\n\nSmith, Francis O. J. The Secret Corresponding Vocabulary; Adapted for Use to Morse\u2019s Electro-Magnetic Telegraph: And Also in Conducting Written Correspondence, Transmitted by the Mails, or Otherwise. Portland, Maine: Thurston, Ilsley, 1845.\n\nSmith, G. C. The Boole\u2013De Morgan Correspondence 1842\u20131864. Oxford: Clarendon Press, 1982.\n\nSmith, John Maynard. \u201cThe Concept of Information in Biology.\u201d Philosophy of Science 67 (2000): 177\u201394.\n\nSmolin, J. A. \u201cThe Early Days of Experimental Quantum Cryptography.\u201d IBM Journal of Research and Development 48 (2004): 47\u201352.\n\nSolana-Ortega, Alberto. \u201cThe Information Revolution Is Yet to Come: An Homage to Claude E. Shannon.\u201d In Bayesian Inference and Maximum Entropy Methods in Science and Engineering, AIP Conference Proceedings 617, edited by Robert L. Fry. Melville, N.Y.: American Institute of Physics, 2002.\n\nSolomonoff, Ray J. \u201cA Formal Theory of Inductive Inference.\u201d Information and Control 7, no. 1 (1964): 1\u201322.\n\n\u2014\u2014\u2014. \u201cThe Discovery of Algorithmic Probability.\u201d Journal of Computer and System Sciences 55, no. 1 (1997): 73\u201388.\n\nSolymar, Laszlo. Getting the Message: A History of Communications. Oxford: Oxford University Press, 1999.\nSpellerberg, Ian F., and Peter J. Fedor. \u201cA Tribute to Claude Shannon (1916\u20132001) and a Plea for More Rigorous Use of Species Richness, Species Diversity and the \u2018Shannon-Wiener\u2019 Index,\u201d *Global Ecology and Biogeography* 12 (2003): 177\u201379.\n\nSperry, Roger. \u201cMind, Brain, and Humanist Values.\u201d In *New Views of the Nature of Man*, edited by John R. Platt, 71\u201392. Chicago: University of Chicago Press, 1983.\n\nSprat, Thomas. *The History of the Royal Society of London, for the Improving of Natural Knowledge*. 3rd ed. London: 1722.\n\nSpufford, Francis, and Jenny Uglow, eds. *Cultural Babbage: Technology, Time and Invention*. London: Faber and Faber, 1996.\n\nStandage, Tom. *The Victorian Internet: The Remarkable Story of the Telegraph and the Nineteenth Century\u2019s On-Line Pioneers*. New York: Berkley, 1998.\n\nStarnes, De Witt T., and Gertrude E. Noyes. *The English Dictionary from Cawdrey to Johnson 1604\u20131755*. Chapel Hill: University of North Carolina Press, 1946.\n\nSteane, Andrew M., and Eleanor G. Rieffel. \u201cBeyond Bits: The Future of Quantum Information Processing.\u201d *Computer* 33 (2000): 38\u201345.\n\nStein, Gabriele. *The English Dictionary Before Cawdrey*. T\u00fcbingen, Germany: Max Neimeyer, 1985.\n\nSteiner, George. \u201cOn Reading Marshall McLuhan.\u201d In *Language and Silence: Essays on Language, Literature, and the Inhuman*, 251\u201368. New York: Atheneum, 1967.\n\nStent, Gunther S. \u201cThat Was the Molecular Biology That Was.\u201d *Science* 160, no. 3826 (1968): 390\u201395.\n\n\u2014\u2014\u2014. \u201cDNA.\u201d *Daedalus* 99 (1970): 909\u201337.\n\n\u2014\u2014\u2014. \u201cYou Can Take the Ethics Out of Altruism But You Can\u2019t Take the Altruism Out of Ethics.\u201d *Hastings Center Report* 7, no. 6 (1977): 33\u201336.\n\nStephens, Mitchell. *The Rise of the Image, the Fall of the Word*. Oxford: Oxford University Press, 1998.\n\nStern, Theodore. \u201cDrum and Whistle \u2018Languages\u2019: An Analysis of Speech Surrogates.\u201d *American Anthropologist* 59 (1957): 487\u2013506.\n\nStix, Gary. \u201cRiding the Back of Electrons.\u201d *Scientific American* (September 1998): 32\u201333.\n\nStonier, Tom. *Beyond Information: The Natural History of Intelligence*. London: Springer-Verlag, 1992.\n\n\u2014\u2014\u2014. *Information and Meaning: An Evolutionary Perspective*. Berlin: Springer-Verlag, 1997.\n\nStreuert, Siegfried, Peter Suedfeld, and Michael J. Driver. \u201cConceptual Structure, Information Search, and Information Utilization.\u201d *Journal of Personality and Social Psychology* 2, no. 5 (1965): 736\u201340.\nSunstein, Cass R. *Infotopia: How Many Minds Produce Knowledge*. Oxford: Oxford University Press, 2006.\n\nSurowiecki, James. *The Wisdom of Crowds*. New York: Doubleday, 2004.\n\nSwade, Doron. \u201cThe World Reduced to Number.\u201d *Isis* 82, no. 3 (1991): 532\u201336.\n\n\u2014\u2014\u2014. *The Cogwheel Brain: Charles Babbage and the Quest to Build the First Computer*. London: Little, Brown, 2000.\n\n\u2014\u2014\u2014. *The Difference Engine: Charles Babbage and the Quest to Build the First Computer*. New York: Viking, 2001.\n\nSwift, Jonathan. *A Tale of a Tub: Written for the Universal Improvement of Mankind*. 1692.\n\nSzil\u00e1rd, Le\u00f3. \u201cOn the Decrease of Entropy in a Thermodynamic System by the Intervention of Intelligent Beings.\u201d Translated by Anatol Rapoport and Mechtilde Knoller from \u201c\u00dcber Die Entropieverminderung in Einem Thermodynamischen System Bei Eingriffen Intelligenter Wesen,\u201d *Zeitschrift F\u00fcr Physik* 53 (1929). *Behavioral Science* 9, no. 4 (1964): 301\u201310.\n\n Teilhard de Chardin, Pierre. *The Human Phenomenon*. Translated by Sarah Appleton-Weber. Brighton, U.K.: Sussex Academic Press, 1999.\n\nTerhal, Barbara M. \u201cIs Entanglement Monogamous?\u201d *IBM Journal of Research and Development* 48, no. 1 (2004): 71\u201378.\n\nThompson, A. J., and Karl Pearson. \u201cHenry Briggs and His Work on Logarithms.\u201d *American Mathematical Monthly* 32, no. 3 (1925): 129\u201331.\n\nThomsen, Samuel W. \u201cSome Evidence Concerning the Genesis of Shannon\u2019s Information Theory.\u201d *Studies in History and Philosophy of Science* 40 (2009): 81\u201391.\n\nThorp, Edward O. \u201cThe Invention of the First Wearable Computer.\u201d In *Proceedings of the 2nd IEEE International Symposium on Wearable Computers*. Washington, D.C.: IEEE Computer Society, 1998.\n\nToole, Betty Alexandra. \u201cAda Byron, Lady Lovelace, an Analyst and Metaphysician.\u201d *IEEE Annals of the History of Computing* 18, no. 3 (1996): 4\u201312.\n\n\u2014\u2014\u2014. *Ada, the Enchantress of Numbers: Prophet of the Computer Age*. Mill Valley, Calif.: Strawberry Press, 1998.\n\nTufte, Edward R. \u201cThe Cognitive Style of PowerPoint.\u201d Cheshire, Conn.: Graphics Press, 2003.\n\nTuring, Alan M. \u201cOn Computable Numbers, with an Application to the Entscheidungsproblem.\u201d *Proceedings of the London Mathematical Society* 42 (1936): 230\u201365.\n\n\u2014\u2014\u2014. \u201cComputing Machinery and Intelligence.\u201d *Minds and Machines* 59, no. 236 (1950): 433\u201360.\n\n\u2014\u2014\u2014. \u201cThe Chemical Basis of Morphogenesis.\u201d *Philosophical Transactions of the Royal\nThe Information\n\nSociety of London, Series B 237, no. 641 (1952): 37\u201372.\n\nTurnbull, Laurence. *The Electro-Magnetic Telegraph, With an Historical Account of Its Rise, Progress, and Present Condition*. Philadelphia: A. Hart, 1853.\n\nVail, Alfred. *The American Electro Magnetic Telegraph: With the Reports of Congress, and a Description of All Telegraphs Known, Employing Electricity Or Galvanism*. Philadelphia: Lea & Blanchard, 1847.\n\nVerd\u00fa, Sergio. \u201cFifty Years of Shannon Theory.\u201d *IEEE Transactions on Information Theory* 44, no. 6 (1998): 2057\u201378.\n\nVincent, David. *Literacy and Popular Culture: England 1750\u20131914*. Cambridge: Cambridge University Press, 1989.\n\nVirilio, Paul. *The Information Bomb*. Translated by Chris Turner. London: Verso, 2000.\n\nvon Baeyer, Hans Christian. *Maxwell\u2019s Demon: Why Warmth Disperses and Time Passes*. New York: Random House, 1998.\n\n\u2014\u2014\u2014. *Information: The New Language of Science*. Cambridge, Mass.: Harvard University Press, 2004.\n\nvon Foerster, Heinz. *Cybernetics: Circular Causal and Feedback Mechanisms in Biological and Social Systems: Transactions of the Seventh Conference, March 23\u201324, 1950*. New York: Josiah Macy, Jr. Foundation, 1951.\n\n\u2014\u2014\u2014. *Cybernetics: Circular Causal and Feedback Mechanisms in Biological and Social Systems: Transactions of the Eighth Conference, March 15\u201316, 1951*. New York: Josiah Macy, Jr. Foundation, 1952.\n\n\u2014\u2014\u2014. \u201cInterview with Stefano Franchi, G\u00fcven G\u00fczeldere, and Eric Minch.\u201d *Stanford Humanities Review* 4, no. 2 (1995). Available online at http://www.stanford.edu/group/SHR/4-2/text/interviewvonf.html.\n\nvon Neumann, John. *The Computer and the Brain*. New Haven, Conn.: Yale University Press, 1958.\n\n\u2014\u2014\u2014. *Collected Works*. Vols. 1\u20136. Oxford: Pergamon Press, 1961.\n\nVulpiani, A., and Roberto Livi. *The Kolmogorov Legacy in Physics: A Century of Turbulence and Complexity*. Lecture Notes in Physics, no. 642. Berlin: Springer, 2003.\n\nWaldrop, M. Mitchell. \u201cReluctant Father of the Digital Age.\u201d *Technology Review* (July\u2013August 2001): 64\u201371.\n\nWang, Hao. \u201cSome Facts About Kurt G\u00f6del.\u201d *Journal of Symbolic Logic* 46 (1981): 653\u201359.\n\nWatson, David L. \u201cBiological Organization.\u201d *Quarterly Review of Biology* 6, no. 2 (1931): 143\u201366.\n\nWatson, James D. *The Double Helix*. New York: Atheneum, 1968.\n\n\u2014\u2014\u2014. *Genes, Girls, and Gamow: After the Double Helix*. New York: Knopf, 2002.\nThe Information\n\n\u2014\u2014\u2014. *Molecular Models of Life*. Oxford: Oxford University Press, 2003.\n\nWatson, James D., and Francis Crick. \u201cA Structure for Deoxyribose Nucleic Acid.\u201d *Nature* 171 (1953): 737.\n\n\u2014\u2014\u2014. \u201cGenetical Implications of the Structure of Deoxyribonucleic Acid.\u201d *Nature* 171 (1953): 964\u201366.\n\nWatts, Duncan J. \u201cNetworks, Dynamics, and the Small-World Phenomenon.\u201d *American Journal of Sociology* 105, no. 2 (1999): 493\u2013527.\n\n\u2014\u2014\u2014. *Small Worlds: The Dynamics of Networks Between Order and Randomness*. Princeton, N.J.: Princeton University Press, 1999.\n\n\u2014\u2014\u2014. *Six Degrees: The Science of a Connected Age*. New York: Norton, 2003.\n\nWatts, Duncan J., and Steven H. Strogatz. \u201cCollective Dynamics of \u2018Small-World\u2019 Networks.\u201d *Nature* 393 (1998): 440\u201342.\n\nWeaver, Warren. \u201cThe Mathematics of Communication.\u201d *Scientific American* 181, no. 1 (1949): 11\u201315.\n\nWells, H. G. *World Brain*. London: Methuen, 1938.\n\n\u2014\u2014\u2014. *A Short History of the World*. San Diego: Book Tree, 2000.\n\nWheeler, John Archibald. \u201cInformation, Physics, Quantum: The Search for Links.\u201d *Proceedings of the Third International Symposium on the Foundations of Quantum Mechanics* (1989): 354\u201368.\n\n\u2014\u2014\u2014. *At Home in the Universe. Masters of Modern Physics*, vol. 9. New York: American Institute of Physics, 1994.\n\nWheeler, John Archibald, with Kenneth Ford. *Geons, Black Holes, and Quantum Foam: A Life in Physics*. New York: Norton, 1998.\n\nWhitehead, Alfred North, and Bertrand Russell. *Principia Mathematica*. Cambridge: Cambridge University Press, 1910.\n\nWiener, Norbert. *Cybernetics: Or Control and Communication in the Animal and the Machine*. 2nd ed. Cambridge, Mass.: MIT Press, 1961.\n\n\u2014\u2014\u2014. *I Am a Mathematician: The Later Life of a Prodigy*. Cambridge, Mass.: MIT Press, 1964.\n\nWiener, Philip P., ed. *Leibniz Selections*. New York: Scribner\u2019s, 1951.\n\nWilkins, John. *Mercury: Or the Secret and Swift Messenger. Shewing, How a Man May With Privacy and Speed Communicate His Thoughts to a Friend At Any Distance*. 3rd ed. London: John Nicholson, 1708.\n\nWilliams, Michael. *A History of Computing Technology*. Washington, D.C.: IEEE Computer Society, 1997.\n\nWilson, Geoffrey. *The Old Telegraphs*. London: Phillimore, 1976.\nWinchester, Simon. *The Meaning of Everything: The Story of the Oxford English Dictionary*. Oxford: Oxford University Press, 2003.\n\nWisdom, J. O. \u201cThe Hypothesis of Cybernetics.\u201d *British Journal for the Philosophy of Science* 2, no. 5 (1951): 1\u201324.\n\nWittgenstein, Ludwig. *Philosophical Investigation*. Translated by G. E. M. Anscombe. New York: Macmillan, 1953.\n\n\u2014\u2014\u2014. *Remarks on the Foundations of Mathematics*. Cambridge, Mass.: MIT Press, 1967.\n\nWoodward, Kathleen. *The Myths of Information: Technology and Postindustrial Culture*. Madison, Wisc.: Coda Press, 1980.\n\nWoolley, Benjamin. *The Bride of Science: Romance, Reason, and Byron\u2019s Daughter*. New York: McGraw-Hill, 1999.\n\nWynter, Andrew. \u201cThe Electric Telegraph.\u201d *Quarterly Review* 95 (1854): 118\u201364.\n\n\u2014\u2014\u2014. *Subtle Brains and Lissom Fingers: Being Some of the Chisel-Marks of Our Industrial and Scientific Progress*. London: Robert Hardwicke, 1863.\n\nYeo, Richard. \u201cReading Encyclopedias: Science and the Organization of Knowledge in British Dictionaries of Arts and Sciences, 1730\u20131850.\u201d *Isis* 82:1 (1991): 24\u201349.\n\n\u2014\u2014\u2014. *Encyclopaedic Visions: Scientific Dictionaries and Enlightenment Culture*. Cambridge: Cambridge University Press, 2001.\n\nYockey, Hubert P. *Information Theory, Evolution, and the Origin of Life*. Cambridge: Cambridge University Press, 2005.\n\nYoung, Peter. *Person to Person: The International Impact of the Telephone*. Cambridge: Granta, 1991.\n\nYourgrau, Palle. *A World Without Time: The Forgotten Legacy of G\u00f6del and Einstein*. New York: Basic Books, 2005.\n\nYovits, Marshall C., George T. Jacobi, and Gordon D. Goldstein, eds. *Self-Organizing Systems*. Washington D.C.: Spartan, 1962.\nIndex\n\nIt is much easier to talk about information than it is to say what it is you are talking about. A surprising number of books, and this includes textbooks, have the word information in their title without bothering to include it in the index.\n\n\u2014Fred I. Dretske (1979)\n\nPage numbers in italics refer to illustrations.\n\nAaboe, Asger, 2.1, 2.2\nabacus, 4.1, 8.1\n* A B C Universal Commercial Electric Telegraphic Code, The* (Clauson-Thue), 5.1, 5.2\nabstraction\n  logic and, 2.1, 2.2\n  in mathematical computation\n  origins of thinking and\n  words representing, 2.1, 3.1\nAdams, Brooks\nAdams, Frederick\nAdams, Henry\nAeschylus\nAfrican languages; see also talking drums\nAharonov, Dorit\nAiry, George Biddell\n\u201cAlgebra for Theoretical Genetics, An\u201d (Shannon), 6.1, 6.2, 6.3\nalgebra of logic, prl.1, 8.1; see also symbolic logic\nalgorithmic information theory, 12.1, 12.2, 12.3, 12.4, 12.5\nalgorithm(s)\n  to calculate complexity, 12.1, 12.2\n  to control accuracy and speed of communication, 7.1, 7.2\n  data compression\n  to describe biological processes, 10.1, 10.2\n  to generate uninteresting number, 12.1, 12.2\n  historical evolution of, 2.1, 2.2, 4.1, 7.1\n  Lovelace\u2019s operations for Analytical Engine as\n  for measurement of computability\nThe Information\n\nfor measurement of information, 12.1, 12.2, 12.3, 12.4\nnumber tables based on, 4.1, 4.2, 4.3\nfor proof of number\u2019s randomness, 12.1, 12.2\nto reconstruct phylogeny\nscientific method as, 12.1, 12.2\nShor\u2019s factoring, 13.1, 13.2\nTuring machine, 7.1, 7.2\n\nAlice in Wonderland (Carroll)\n\nAllen, William\nalphabet(s)\nas code\nevolution of, 2.1, 2.2, 3.1\nevolution of telegraph coding systems and, 5.1, 5.2, 5.3, 5.4\ninformation transmission capacity of, 6.1, 7.1\nletter frequency in, 1.1, 7.1\nMorse code representation of\norder of letters in, 3.1, 3.2, 3.3\norganization of information based on, 3.1, 3.2\n\nAltaVista, epl.1, epl.2\n\naltruism, 10.1, 10.2, 10.3\n\nAmerican Telephone & Telegraph, prl.1, 6.1, 7.1\n\namino acids, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6\n\nAmp\u00e8re, Andr\u00e9-Marie, 5.1, 5.2\n\namplitude modulation, 6.1, 6.2, 6.3\n\nanalog technology, 8.1, 8.2\n\nAnalytical Engine, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 6.1, 7.1, 8.1\n\nAnalytical Society, 4.1, 4.2\n\nAnatomy of Melancholy, The (Burton)\n\nAnglo-American Cyclopedia, The (Borges)\n\nAnglo-Saxon speech, 3.1, 3.2\n\nanthropocentrism\n\nantiaircraft guns and artillery, prl.1, 6.1, 6.2, 7.1, 8.1, 8.2, 8.3, 12.1, 12.2\n\naperiodic crystals, 9.1, 10.1\n\nArabic numerals\n\nArcadia (Stoppard), 9.1, 9.2, 14.1\n\nAristotle and Aristotelian philosophy, prl.1, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 14.1, 14.2\n\nArmani, Giorgio, 14.1, 14.2\n\nArte of Rhetorique, The (Wilson)\n\nartificial intelligence, prl.1, 12.1; see also machines, attribution of thinking to\n\nAshby, W. Ross\n\nastronomy\n\natomic science, prl.1, 7.1, 8.1, 9.1, 9.2, 12.1\nAtwood, Margaret, 11.1, epl.1, epl.2\nAuden, W. H.\nautomata, 4.1, 8.1, 8.2, 8.3\nchess automata\naviation radio\n\nBabbage, Charles, 4.1, 4.2, 4.3, 5.1, 6.1, 6.2, 7.1, 7.2, 7.3, 8.1, 8.2\nAnalytical Engine of, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 6.1, 7.1, 8.1\nat Cambridge, 4.1, 4.2, 4.3, 4.4, 4.5\ncryptographic work of, 5.1, 5.2, 7.1\nDifference Engine of, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 4.13, 4.14,\n4.15, 4.16, 4.17, 4.18, 6.1\nearly life, 4.1, 4.2\ninformation transmission studies of, 4.1, 4.2\nlanguage work of, 4.1, 4.2\nLovelace and, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9\nmechanical notation system of, 4.1, 4.2, 5.1, 6.1\non persistence of thought and information, 14.1, 14.2, 14.3\npersonal qualities, 4.1, 4.2\nrailroad studies of, 4.1, 4.2\nrange of interests and expertise, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6\nvision of future of, 4.1, 4.2\n\nBabbage, Georgiana Whitmore\nBabel, 14.1, 14.2, 14.3, epl.1, epl.2\nBabylonian culture, 2.1, 2.2, 2.3, 2.4, 2.5\nBach, Johann Sebastian, 12.1, 12.2, 12.3, 12.4\nBacon, Francis\nbacteria, 10.1, 10.2, 10.3\nBaker, Nicholson, 14.1, 14.2, epl.1, epl.2\nBalbus, Johannes\nBalzac, Honor\u00e9 de\nbandwidth, 6.1, 6.2, 6.3, 8.1, 8.2, 12.1\nban unit of probability\nBanville, John\nBarber paradox\nBaruch, Bernard M.\nBarwise, Jon\nBates, John\nBateson, Gregory, 8.1, 8.2\nBaudot code\nBavelas, Alex\nBeethoven, Ludwig von, 11.1, 15.1, epl.1\nBell, Alexander Graham, 6.1, 6.2\nBell, Gordon\nBell Laboratories, prl.1, prl.2, prl.3, prl.4, 1.1, 3.1, 6.1, 6.2, 6.3, 6.4, 6.5, 7.1, 7.2, 7.3, 8.1, 8.2\nBell System Technical Journal, prl.1, 6.1, 7.1\nBell Telephone Company\nBennett, Charles H., 11.1, 11.2, 12.1, 12.2, 13.1, 13.2, 13.3, 13.4, 13.5, 13.6, 13.7, 13.8, 13.9,\n13.10, 13.11, 15.1\nBenton, Billy\nBenzer, Seymour, 10.1, 10.2\nBernoulli numbers, 4.1, 4.2, 4.3\nBerry, G. G., 6.1, 6.2\nBerry\u2019s paradox, 6.1, 6.2, 12.1, 12.2, 12.3\nBible\nBierce, Ambrose\nBigelow, Julian\nbinary operations\ncoding systems for, 5.1, 5.2\nrepresentation of relay circuits as\nin telegraphy, 7.1, 8.1\nin use of alphabetical ordering systems\nsee also bit(s)\nbiology\nentropy and, 9.1, 9.2, 9.3, 9.4\nevolutionary, 10.1, 11.1\nfundamental particles of\nof human ecosystem, 10.1, 10.2\ninformation processing in, prl.1, prl.2, 10.1, 10.2, 10.3, 10.4\nmolecular, 9.1, 10.1, 10.2, 10.3\npurposeful action in processes of, 9.1, 9.2\nsee also genetics; neurophysiology\nbiosphere, 11.1, 11.2, 11.3\nbit(s)\nas basis of physics, prl.1, prl.2, 13.1, 13.2\nbiological measurements\ncost of information processing\ndata compression strategies, 12.1, 12.2\ndecision-making requirements\ndefinition of, prl.1, 7.1\nfirst usage\ngrowth of measuring units, 14.1, 14.2\nmeaning and\nmeasurement of cosmos in, prl.1, 14.1\npurpose\ntransmission by fire beacon, 1.1, 1.2\nblack holes, prl.1, 13.1, 13.2, 13.3, 13.4\nBlair, Ann\nBlair, Earl\nBletchley Park, 7.1, 7.2, 8.1\nBlount, Thomas, 3.1, 3.2\nBodleian Library, 3.1, 3.2, 6.1\nBohr, Niels, prl.1, 6.1, 13.1\nBoltzmann, Ludwig, 9.1, 9.2\nBombe machine\nbook burning\nBoole, George, prl.1, 5.1, 5.2, 5.3, 5.4, 5.5, 6.1, 6.2, 8.1, 8.2, 12.1\nBorges, Jorge Luis, 14.1, 14.2, epl.1, epl.2\nbotanical dictionaries, 14.1, 14.2, 15.1\nBradley, Henry, 3.1, 3.2\nBrahe, Tycho, 4.1, 15.1\nbrain; see neurophysiology\nBrassard, Gilles, 13.1, 13.2\n\u201cBreakdown of Physics in Gravitational Collapse, The\u201d (Hawking)\nBrecht, Bertolt\nBreguet, Abraham-Louis, 5.1, 5.2\nBrenner, Sydney, 10.1, 10.2, 10.3\nBrewster, David, 4.1, 8.1\nBridenbaugh, Carl, 15.1, 15.2, 15.3\nBriggs, Henry, 4.1, 4.2, 4.3, 4.4, 4.5\nBrillouin, L\u00e9on, 9.1, 9.2, 9.3\nBrin, Sergey, 14.1, epl.1\nBroadbent, Donald, 8.1, 8.2\nBrosin, Henry\nBrown, Robert\nBrowne, Thomas, 1.1, 1.2, 5.1\nBrownian motion, 6.1, 6.2, 8.1\nBrunel, Isambard Kingdom\nBuchanan, James\nBullokar, John\nBurgess, Anthony\nBurney, Venetia\nBurton, Robert, 15.1, 15.2, 15.3\nBush, Vannevar, prl.1, prl.2, 5.1n, 6.1, 6.2, 6.3, 6.4, 7.1\nButler, Samuel, 2.1, 10.1, 10.2\nbutterfly effect\nByron, Augusta Ada; see Lovelace, Ada\nByron, George Gordon, Lord, 4.1, 4.2\nbytes\n\nCage, John, 12.1, 12.2\nCairns-Smith, Alexander, 10.1, 10.2\ncalculators, calculating machines\n  analog and digital\n    Babbage\u2019s Analytical Engine, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 6.1, 7.1, 8.1\n    Babbage\u2019s Difference Engine, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 4.13, 4.14, 4.15, 4.16, 4.17, 4.18, 6.1\n  definition of \u201ccalculation,\u201d 7.1\n  Differential Analyzer, 6.1, 6.2, 6.3, 6.4\n  in evolution of information technology, prl.1, 4.1\n  use of relay circuits in\n    see also computation; computer(s); machines\ncalculus, 4.1, 4.2, 4.3, 4.4, epl.1\nCampbell, George, prl.1, prl.2\n\u201cCan Quantum-Mechanical Description of Physical Reality Be Considered Complete?\u201d (Einstein, Podolsky, Rosen)\nCarnot, Nicolas Sadi\nCarpenter, Margaret\nCarreras, Jos\u00e9\nCarrington, John F., 1.1, 1.2, 1.3, 1.4, 1.5\nCarroll, Lewis, 5.1, 5.2, 14.1\nCarty, John J.\ncatalogues of information, 5.1, 14.1, 15.1\n  botanical, 14.1, 14.2\n  of cryptographic techniques\n  genes as, 10.1, 10.2\n  for libraries, 3.1, 3.2\n  search techniques for, 15.1, epl.1, epl.2, epl.3\n  of telegraph messages\n    see also dictionaries\nCatholicon (Balbus)\nCawdrey, Robert, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 3.10, 3.11, 3.12, 3.13, 3.14\nCawdrey, Thomas\ncellular processes, prl.1, prl.2, 9.1, 9.2\nCelts\nCentral Dogma\n\u201cCertain Factors Affecting Telegraph Speed\u201d (Nyquist)\nChadwyck-Healey, Charles\nchain letters, as examples of memes, 11.1, 11.2, 11.3\nChains (Karinthy)\nChaitin, Gregory, 12.1, 12.2, 12.3, 12.4, 12.5, 12.6, 12.7, 12.8, 12.9, 12.10, 12.11, 12.12, 12.13,\nThe Information\n\n12.14, 12.15\nChampernowne, David\nChandler, Raymond\nChandrasekhar, Subrahmanyan\nchannels\n  applications of information theory\n  definition of\n  multiplexed\n  psychological formulation\n  quantum, 13.1, 13.2\n  transmission capacity of, 6.1, 6.2, 6.3, 6.4, 6.5, 7.1, 7.2, 7.3, 8.1, 8.2\n  writing as, 2.1, 2.2\n  see also bandwidth\nchaos theory, 8.1, 10.1, 12.1, 12.2, 12.3, 12.4, 14.1, 14.2\nChappe, Claude, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7\nChappe, Ignace, 5.1, 5.2, 5.3\nChappe, Pierre\nChappe, Ren\u00e9\nCharles Albert, King of Sardinia, 4.1, 4.2\nCherry, Colin\nchess-playing machines, 8.1, 8.2\nChina, 1.1, 2.1, 2.2, 2.3, 3.1\nChomsky, Noam\nchromosomes, 6.1, 7.1, 9.1, 9.2, 10.1, 10.2\nChurchill, Winston, prl.1, prl.2, 7.1\ncircularity\n  in defining words, 3.1, 3.2\n  G\u00f6del\u2019s critique of Principia Mathematica, 6.1\n  in paradoxes\nClark, Josiah Latimer\nClarke, Roger T.\nclassification, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 3.1, 3.2\nClausius, Rudolf, 9.1, 9.2, 9.3\nClauson-Thue, William, 5.1, 5.2, 5.3\nClement, Joseph, 4.1, 4.2\nclocks, synchronization of, 1.1, 5.1, 5.2, 5.3, 5.4\ncloud, information, 14.1, 14.2\nclustering\nClytemnestra\ncode\n  attempts to reduce cost of telegraphy, 5.1, 5.2\n  Babbage\u2019s interest in\ncipher and compression systems for telegraphy, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6\nEnigma, 7.1, 7.2, 7.3\ngenetic, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7, 10.8, 10.9, 10.10\nin Jacquard loom operations\nMorse, prl.1, 1.1, 1.2, 1.3, 1.4, 5.1, 5.2, 5.3, 5.4, 6.1, 11.1\nas noise\nfor printing telegraph\nShannon\u2019s interest in, prl.1, 6.1, 7.1\ntelegraphy before Morse code, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7\nsee also cryptography\ncoding theory, 8.1, 8.2, 10.1, 12.1\ncognitive science, 8.1, 8.2, 8.3, 8.4\nColebrooke, Henry\ncollective consciousness, epl.1, epl.2, epl.3, epl.4, epl.5\nColossus computing machine\nColumbus, Christopher\ncombinatorial analysis, 6.1, 10.1, 10.2\ncommunication\nby algorithm\nwith alien life-form, 12.1, 12.2, 12.3, 12.4, 12.5\nBabbage\u2019s mechanical notation for describing, 4.1, 4.2, 5.1\nconstrained channels of, 2.1, 2.2\ndisruptive effects of new technologies in, 15.1, 15.2\nemergence of global consciousness, epl.1, ep1.2, epl.3\nevolution of electrical technologies for, 5.1, 5.2, 6.1, 6.2\nfundamental problem of, prl.1, 7.1, 7.2, 8.1\nhuman evolution and, prl.1, prl.2\nimplications of technological evolution of, 15.1, 15.2\ninformation overload and, epl.1, epl.2\nknowledge needs for, 12.1, 12.2, 12.3\nin origins of governance\nShannon\u2019s diagram of, 7.1, 7.2, 7.3\nas stochastic process\nsymbolic logic to describe systems of\nsystem elements, 7.1, 7.2\nin Twitter, epl.1, epl.2\nsee also talking drums; telegraphy; telephony; transmission of information\ncompact disc, prl.1, 8.1, epl.1\ncomplexity, 12.1, 12.2, 12.3, 12.4, 12.5, 12.6, 12.7, 12.8, 12.9\ncompression of information; see data compression\n\u201cComputable Numbers, On\u201d (Turing), 7.1, 7.2, 12.1\ncomputation\nThe Information\n\nin Babylonian mathematics, 2.1, 2.2\ncomputable and uncomputable numbers, 7.1, 7.2, 7.3, 7.4, 12.1, 12.2, 12.3\nof differential equations, 4.1, 4.2\nin evolution of complex structures\nhuman computers, 4.1, 4.2, 4.3\nthermodynamics of, 13.1, 13.2, 13.3, 13.4\nTuring machine for, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6\nsee also calculators; computers\n\ncomputer(s)\nanalog and digital, 8.1, 8.2\nchess-playing, 8.1, 8.2\ncomparison to humans, 8.1, 8.2\ncost of memory storage\ncost of work of, 13.1, 13.2\nearly mechanical, prl.1, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 8.1\ngrowth of memory and processing speed of, 14.1, 14.2, 14.3, 14.4\ninductive learning in\nperception of thinking by, 8.1, 8.2, 8.3, 8.4\npublic awareness of\nquantum-based, 13.1, 13.2, 13.3, 13.4\nShannon\u2019s information theory in, prl.1, 6.1, 7.1, 7.2, 8.1, 8.2\nsignificance of information theory in development of\nspread of memes through\nTuring\u2019s conceptualization of, 8.1, 8.2, 8.3\nuniverse as, 14.1, 14.2\nsee also calculators; computation; programming\n\nConference on Cybernetics, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 8.10, 8.11, 8.12\n\nConnolly, Sean J.\n\nconsciousness, 2.1, 2.2, 8.1, 8.2, epl.1, epl.2, epl.3\n\ncontinuous signal systems, 6.1, 7.1\n\nCooke, William, 5.1, 5.2\n\nCooper, Pat\n\nCoote, Edmund\n\nCoy, George W.\n\nCrick, Francis, 10.1, 10.2, 10.3, 10.4, 10.5\n\nCrow, James F. n\n\ncryptography\nassessment of system security\nBabbage\u2019s work in, 5.1, 5.2\nearly strategies, 5.1, 5.2\nEnigma system of, 7.1, 7.2\ninformation theory and\nThe Information\n\nmathematics of, 5.1, 5.2, 5.3, 7.1, 7.2\nmental skill for\npattern recognition in, 7.1, 7.2\nperfect cipher system\npopular interest in, 5.1, 5.2\nquantum, 13.1, 13.2, 13.3, 13.4\nRSA encryption\nShannon\u2019s work on, prl.1, prl.2, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6\nTuring\u2019s work on, 7.1, 7.2, 7.3, 7.4\nvoice encryption, 7.1, 7.2\nwriting and, 5.1, 5.2\nsee also code\n\ncrystals, 9.1, 9.2, 10.1\nculture\ncommunication technology and, 15.1, 15.2, 15.3\ncommunicative capacity of drums, 1.1, 1.2\nfunction of meme\nperceptions changed by telegraphy, 5.1, 5.2\nreplication and transmission of\nthought processes biased by, 2.1, 2.2\nsee also oral culture\n\nCummings, E. E., 6.1, 8.1\ncuneiform, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7\nCunningham, Michael\ncybernetics, prl.1, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 12.1, 12.2\nCybernetics (Wiener), 8.1, 8.2, 8.3, 8.4, 9.1\ncyberspace, 13.1, epl.1\ncapacity for transmitting information, 3.1, 3.2\nconcepts of literacy and orality in\nconnectivity in, epl.1, epl.2\nnaming issues, 14.1, 14.2, 14.3\nonline version of Oxford English Dictionary, 3.1, 3.2, 3.3\nparadox of distance in\nsee also Internet\n\nDaguerre, Louis\nDancoff, Sidney\nDarwin, Charles, 4.1, 10.1\ndata compression, prl.1, prl.2, prl.3, 5.1, 5.2, 8.1, 12.1, 12.2, 12.3, 12.4\nDavy, Edward, 4.1, 5.1, 5.2\nDawkins, Richard, prl.1, prl.2, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 11.1, 11.2, 11.3, 11.4, 11.5, 11.6, 11.7\nde Back, James\nThe Information\n\ndecision problem, 7.1, 7.2, 7.3, 7.4\ndefinitions of words\n  interlocking and circular nature of, 3.1, 3.2\n  in perfect language\n  scientific progress and, prl.1, prl.2, 3.1, 3.2\n  see also dictionaries\nDelbr\u00fcck, Max, 10.1, 10.2\nDeletionpedia, 14.1, 14.2\nDemocritus\nDe Morgan, Augustus, 4.1, 5.1, 15.1\nDennett, Daniel, 10.1, 11.1, 11.2, 11.3, 15.1, 15.2\ndeoxyribonucleic acid (DNA), prl.1, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7\ndiamond code, 10.1, 10.2\nDibdin, Charles\nDickens, Charles, 4.1n, 14.1\ndictionaries, 1.1, 1.2, 2.1, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 3.10, 3.11, 3.12, 3.13; see also Oxford English Dictionary\nDictionarium (Thomas)\nDiderot, Denis, 14.1, epl.1\nDifference Engine, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 4.13, 4.14, 4.15, 6.1\nDifferential Analyzer, prl.1, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 8.1\nDifferential and Integral Calculus (Lacroix)\ndifferential equations, 6.1, 6.2, 6.3\n\u201cDigital Computers Called Brains, Of\u201d (McCulloch)\ndigital technology, 6.1, 8.1, 8.2, 8.3, 12.1\nDiringer, David\ndiscrete information, 6.1, 7.1, 7.2, 12.1\nD\u2019Israeli, Isaac\nDisreali, Benjamin\ndistortion of signal; see noise\nDNA; see deoxyribonucleic acid\n\u201cDoes One Sometimes Know Too Much?,\u201d 15.1\ndomain names, 14.1, 14.2\nDonne, John\nDoob, Joseph L.\nDowd, Maureen\nDoyle, Arthur Conan\nDretske, Fred, 11.1, epl.1, ind.1\ndrums; see talking drums\nDupuy, Jean-Pierre, epl.1, epl.2, epl.3\nDyer, Harrison Gray\necho\nThe Information\n\nEckart, Carl\nEckert, W. H.\neconomics\n  Babbage\u2019s research on, 4.1, 4.2\n  business of telegraphy, 5.1, 5.2, 5.3, 5.4, 5.5\n  commercial interest in telegraphy, 5.1, 5.2\n  commercial interest in telephony, 6.1, 6.2\n  cost of computation, 13.1, 13.2\n  costs of computer memory\n    in information cloud\n    as information science\n    of number table production, 4.1, 4.2, 4.3, 4.4\n  origins of mathematics and\nEdison, Thomas A., 5.1, 12.1\nEdwards, Mary\nEgypt, 3.1, 3.2\nEinstein, Albert, 6.1, 6.2, 6.3, 9.1, 13.1, 13.2, 13.3, 13.4\nEisenstein, Elizabeth, 15.1, 15.2, 15.3\nelectrical circuits\n  development of telegraphy, 1.1, 1.2\n  noise in, 6.1, 7.1\n  symbolic logic and, prl.1, 6.1, 6.2, 6.3, 6.4, 6.5\n  transmission capacity of, 6.1, 6.2\nelectricity\n  amplitude modulation, 6.1, 6.2, 6.3\n  biological analogies for\n  evolution of scientific understanding of, 5.1, 5.2\n  in measurement of communication\n  public response to new technologies of\n  recognition of communication potential of, 5.1, 5.2\n  source of noise in\n  technical demands of telephony, 6.1, 6.2\n  see also electrical circuits; telegraphy\nElectric Telegraph Company, 5.1, 5.2\nElements of Electro-Biology (Smee)\nElias, Peter, 8.1, 8.2\nEliot, T. S., 3.1, 15.1\nElyot, Thomas\ne-mail, 2.1, 11.1, 11.2, 14.1, 15.1, 15.2, 15.3\nEmerson, Ralph Waldo\nEncyclopaedia Britannica, 7.1, 14.1, 14.2, 14.3, 14.4, epl.1\nencyclopedias, prl.1, epl.1, epl.2; see also specific encyclopedia\nThe Information\n\nEncyclop\u00e9die, 14.1\nEnderton, Herbert\nenergy\nin concept of entropy, 9.1, 9.2, 9.3\ncost of information processing, 13.1, 13.2\ninformation and, prl.1, 9.1, 9.2, 9.3, 9.5, 9.6, 9.7, 9.8, 9.9, 10.1, 13.1, 13.2, 15.1, epl.1\nperpetual motion machine, 9.1, 9.2, 9.3\nin physics of black holes\nsee also thermodynamics\nEngland, 5.1, 5.2, 5.3, 5.4, 5.5, 8.1, 8.2; see also English language\nEnglish Expositour, An (Bullokar)\nEnglish language\nearliest dictionaries, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 3.10, 3.11\nevolution of, 3.1, 3.2, 3.3\ngrowth of, 3.1, 3.2, 3.3\nnumber of speakers of, 3.1, 3.2, 3.3\nOxford English Dictionary of, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 3.10, 3.11\nphonemes of, 1.1, 1.2\nredundancy in, 1.1, 7.1, 7.2, 8.1, 8.2\nspelling of words in, 3.1, 3.2\nstatistical analysis, 7.1, 7.2, 7.3\nuse of tonality in\nvocabulary size\nEnglish Schoolemaister, The (Coote)\nENIAC\nEnigma code, 7.1, 7.2, 7.3, 7.4\nentanglement, prl.1, 1.1, 13.1, 13.2, 13.3, 13.4, 13.5\nentelechy\nentropy, prl.1, 8.1\nconcept of mind and\ndefinition of, 9.1, 9.2, 9.3\nas disorder\ndissipation of energy in, 9.1, 9.2\ninformation as, 7.1, 7.2, 8.1, 9.1, 12.1, 12.2\ninformation to reduce, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7\nof language\nmathematical complexity and\nMaxwell\u2019s demon, 8.1, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9, 10.1, 13.1, 13.2, 15.1, epl.1\nmeasurement of\nas measure of uncertainty, 9.1, 9.2\nmovement of universe toward, 9.1, 9.2, 9.3, 9.4\nThe Information\n\norderliness of biological life and, 9.1, 9.2, 9.3, 9.4\nrandomness and\nin thermodynamics of computation\nEntscheidungsproblem, 7.1, 7.2, 7.3, 7.4\nenzymes, 9.1, 10.1, 10.2\nEphrussi, Boris\nEpimenides\u2019 paradox\nepistemology\nerasure of information, 13.1, 13.2, 13.3, 14.1\nerror correction\napplications of Shannon\u2019s theories\nin artillery targeting\nin early telegraphic code systems, 5.1, 5.2\nin genetic code\nto overcome noise, 7.1, 7.2, 8.1\nredundancy for, 7.1, 7.2\nin talking drum language\nin telegraphy\nerrors, in logarithmic tables, 4.1, 4.2\nErya, 3.1\nevolution\nas computational process\nemergence of global consciousness as\ngene interactions and, 10.1, 10.2\nof genes, 10.1, 10.2\nof ideas\ninformation processing in\nrole of altruistic behavior in, 10.1, 10.2\nevolutionary biology, 10.1, 11.1\nEx-Prodigy (Wiener)\nExtrapolation, Interpolation, and Smoothing of Stationary Time Series (Wiener, Bigelow)\nfactoring algorithm, 13.1, 13.2\nFano, Robert, 7.1, 7.2, 12.1\nFaraday, Michael, 4.1, 5.1, 5.2\nfeedback, 5.1, 6.1, 8.1, 8.2, 10.1\nFeynman, Richard, 9.1, 10.1, 13.1, 13.2, 13.3, 13.4\nfile storage technology\nfire beacons\nfire-control; see antiaircraft guns and artillery\nFitzRoy, Robert, 5.1, 5.2\nFord, Joseph, 12.1, 12.2\nFormal Logic (De Morgan)\nThe Information\n\nFoundations of the Theory of Probability (Kolmogorov)\nFour Great Books of Song, ep1.1\nFrance, 3.1, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8\nFrank, Lawrence K., 8.1, 8.2\nFranklin, Benjamin\nFreeman, Thomas, 15.1, 15.2\nFreud, Sigmund, 8.1, 9.1\nFrost, Robert\nFry, Thornton C., 6.1, 6.2\nFuchs, Christopher, 13.1, 13.2, 13.3\nFuchs, Ulrich\nGabor, Dennis\nGalileo, 1.1, 1.2, 3.1\ngalvanometer, 5.1, 5.2\ngames, 4.1, 4.2, 4.3, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6\ngame theory\nGamow, George, 10.1, 10.2, 10.3, 10.4, 10.5\nGauss, Carl Friedrich\nGeneral Electric\ngenetics\naltruistic behavior and, 10.1, 10.2\naperiodic crystal model of, 9.1, 10.1\ncoding system, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7, 10.8, 10.9, 10.10\ndevelopment of scientific concepts of, 10.1, 10.2, 10.3, 10.4, 10.5\ndiscovery of DNA, 10.1, 10.2\ngene structure and function, 9.1, 9.2, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7, 10.8, 10.9,\n10.10, 10.11, 10.12, 10.13, 10.14\ngenome mapping\nas information science, prl.1, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7\ninformation storage in, 7.1, 7.2\nmemetics and\nSchr\u00f6dinger\u2019s formulation of, 9.1, 9.2, 9.3\nselfish gene concept, 10.1, 10.2, 10.3, 10.4, 11.1\nsymbolic logic to describe, 6.1, 6.2, 6.3\nGerard, Ralph, 8.1, 8.2, 8.3, 8.4\nGibbs, Willard\nGibson, William\nGilgamesh\nGilliver, Peter, 3.1, 3.2, 3.3\nGlossographia: or a Dictionary (Blount), 3.1, 3.2\nG\u00f6del, Kurt, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 7.1, 7.2, 7.3, 10.1, 12.1, 12.2, 12.3, ep1.1\nG\u00f6del\u2019s Proof (Nagel, Newman)\nThe Information\n\nGodfather (film)\n\u201cGold Bug, The\u201d (Poe)\nGongsun Long\nGoogle, 11.1, 14.1, 14.2, 15.1, ep1.1, ep1.2\nGould, Glenn, 12.1, 12.2\nGould, Stephen Jay\ngravity, 13.1, 13.2, 14.1\nGray, Elisha\nGreat Exhibition of 1851 (London)\nGreat Soviet Encyclopedia, 12.1\nGreece, 1.1, 1.2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6\nGrover, Lov\nGuare, John, ep1.1, ep1.2\nGutenberg Galaxy (McLuhan)\nGuyot, Jules\n\nHamilton, W. D., 11.1, 11.2\nHammurabi\nHardy, G. H.\nHardy-Ramanujan number\nHart, Sarah\nHartley, Ralph, 1.1, 1.2, 6.1, 6.2, 6.3, 7.1\nHarvard University, 8.1, 8.2, 9.1\nHatto, Joyce\nHavelock, Eric, 2.1, 2.2, 2.3\nHawking, Stephen, 13.1, 13.2, 13.3\nHawthorne, Nathaniel\nheat, 8.1, 13.1, 13.2; see also thermodynamics\nHein, Jon\nHeisenberg, Werner, 7.1, 12.1, 13.1\nHennig, Richard\nHenry, Joseph\nHerschel, John, 4.1, 4.2, 4.3\nhieroglyphics, 2.1, 8.1\nHilbert, David, 7.1, 7.2, 7.3\nHobbes, Thomas, prl.1, 2.1\nHofstadter, Douglas R., 6.1, 6.2, 6.3, 7.1, 10.1, 10.2, 11.1, 11.2, 11.3, 11.4\nHolland, Owen\nHolmes, Oliver Wendell\nholography\nHomeric epics, 1.1, 2.1, 2.2, 2.3, 2.4, 2.5, 11.1\nHuffman, David\nHuffman coding\nHumphrey, Nicholas\nHusbands, Philip\nHusson, M.\n\n*I Am a Mathematician* (Wiener)\niatroepidemics\nIBM, 8.1, 9.1, 12.1, 12.2, 12.3, 12.4, 13.1, 13.2, 13.3, 13.4, 14.1, 14.2\nideas, compared to biosphere, 11.1, 11.2; *see also* memes\nidiographic writing\n*Iliad* (Homer)\nimages\n  compressibility of\n    memes as\n      recording of, 14.1, 14.2\nimagination, 2.1n, 4.1, 4.2, 7.1\n*Imitation Game* (Turing), 8.1, 8.2, 8.3, 8.4\nincompleteness theorem\n  algorithmic proof of randomness and, 12.1, 12.2\n  chaos theory and, 12.1, 12.2\n  decision problem and, 7.1, 7.2\n  proof of, 6.1, 6.2, 6.3\n  significance of, 6.1, 6.2\n    Turing machine and\nindexes, 15.1, 15.2, epl.1, epl.2, epl.3\ninductive reasoning\n*Infinities, The* (Banville)\n\u201cInformation Is Inevitably Physical\u201d (Landauer)\n\u201cInformation Is Physical\u201d (Landauer)\ninformation overload\n  in Borges\u2019s \u201cLibrary of Babel,\u201d 14.1\n  e-mail and, 15.1, 15.2\n  filter and search strategies to prevent, 15.1, 15.2\n  historical fears of, 15.1, 15.2, 15.3\n  human\u2013computer comparison of effects of\n    knowledge and, 15.1, 15.2\n    manifestations of, 15.1, 15.2, 15.3\n    meaning and, epl.1, epl.2, epl.3, epl.4\n    psychological studies of, 15.1, 15.2\n    technological progress and, prl.1, 15.1, 15.2, 15.3, 15.4\ninformation theory\n  attempts to add semantic counterpart to\n  on control of redundancy in messages, 7.1, 7.2\nThe Information\n\ncryptography and\ndevelopment in England, 8.1, 8.2\ndiagram of communication in, 7.1, 7.2, 7.3\ngenetic science and, prl.1, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7\nlanguage as possibility in, epl.1, epl.2\nmeasurement of information in, 7.1, 7.2\nmessage value in, 12.1-3.1\nnoise source in, 7.1, 7.2\norigins of, prl.1, prl.2, prl.3, prl.4, 7.1; see also Mathematical Theory of Communication,\nThe (Shannon, Weaver)\nphysics and, prl.1, prl.2, prl.3\nplace of meaning in, 7.1, 7.2, 8.1, 8.2, 8.3, epl.1, epl.2\nresponse of wider scientific community to, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9\nresponse to Shannon\u2019s initial publication, 8.1, 8.2\nsignificance of, prl.1, prl.2, 8.1, 8.2, 8.3\nin Soviet Union, 12.1, 12.2\nsystem states in\ntheories of psychology and, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7\nsee also quantum information science\nInternet, 11.1, 11.2, epl.1, epl.2, epl.3\nIt from Bit (Wheeler), prl.1, 13.1\n\nJacobson, Homer\nJacquard, Joseph-Marie\nJacquard loom, 4.1, 4.2, 4.3, 4.4, 12.1\nJames, William, 8.1, 8.2\nJ\u00e1nos, Neumann; see John von Neumann\nJaynes, Julian, 2.1, 2.2\nJennings, Allan\nJohannsen, Wilhelm\nJohn of Salisbury\nJohnson, John B.\nJohnson, Samuel, 3.1, 3.2, 3.3, 3.4\nJohnstone, James\nJoncourt, \u00c9lie de, 4.1, 4.2, 4.3\nJones, Alexander\nJonsson, Lars\nJowett, Benjamin\nJudson, Horace Freeland\nJust, Ward\nKahn, David\nKarinthy, Frigyes\nThe Information\n\nKele language, 1.1, 1.2, 1.3\nKelvin, William Thomson, Lord\nKepler, Johannes\nKermode, Frank, 2.1, 2.2\nKeynes, John Maynard\nKhwarizmi, Abu Abdullah Mohammad Ibn Musa al-\nKierkegaard, Soren\nKing, August Ada; see Lovelace, Ada\nKing, William\nKl\u00fcver, Heinrich\nknowledge\n  curse of omniscience, epl.1, epl.2\n  emergence of global consciousness, epl.1, epl.2, epl.3\n  epistemological theory of information\n  information overload and, 15.1, 15.2, 15.3\n  limits to scientific investigation, 12.1, 12.2\n  in literate cultures, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6\n  power of\n    as product of logic\n  requirements for communication, 12.1, 12.2, 12.3\n  transmission of, through human history, prl.1, prl.2\nKnuth, Donald, 2.1, 2.2\nKolmogorov, Andrei Nikolaevich, 12.1, 12.2, 12.3, 12.4, 12.5, 12.6, 12.7, 12.8\nKolmogorov-Chaitin complexity, 12.1, 12.2, 12.3, 12.4\nKonversations-Lexikon, epl.1\nLacroix, Sylvestre Fran\u00e7ois\nLagrange, Joseph Louis\nLandauer, Rolf, 13.1, 13.2\nLandowska, Wanda\nLandsberg, Peter\nLane, Anthony, 15.1, 15.2\nlanguage\n  adaptations for telegraphy, 5.1, 5.2\n  Babbage\u2019s work on, 4.1, 4.2\n  compressibility of\n  concept of mind and\n  for discussing language, 3.1, 3.2, 4.1\n  functions of, 5.1, 5.2\n  as infinite possibility, epl.1, epl.2\n  limitations of\n  measuring redundancy in, 1.1, 1.2, 8.1, 8.2, 8.3\n  paradoxes of, 2.1, 2.2, 6.1, 6.2, 6.3\npattern analysis\n\nperfect\n\nredundancy in, 1.1, 1.2, 1.3, 5.1, 7.1, 7.2, 7.3, 7.4, 8.1, 8.2, 8.3, 12.1\n\nas shared experience\n\nstatistical structure of, 7.1, 7.2, 7.3, 7.4\n\nsymbolic expression of, 5.1, 5.2\n\ntechnical, 3.1, 3.2\n\ntransmission capacity of Internet and, 3.1, 3.2\n\nuniversal, 4.1, 6.1\n\nsee also oral culture; writing; specific language\n\nLanguage Instinct, The (Pinker), 3.1, 3.2\n\nLanier, Jaron\n\nLaplace, Pierre-Simon, 14.1, 14.2\n\nLardner, Dionysius, 4.1, 4.2, 4.3, 5.1, 5.2\n\nLasker, Edward\n\nLatin language, 3.1, 3.2, 3.3, 3.4\n\nLawrence Livermore Laboratory\n\nLaws of Thought, The (Boole), 5.1, 5.2\n\nLeibniz, Gottfried Wilhelm, 3.1, 4.1, 4.2, 4.3, 6.1, 6.2, 7.1, 15.1, epl.1\n\nLem, Stanislaw\n\nLe Roy, \u00c9douard\n\nLe Sage, Georges-Louis\n\nLever, Ralph\n\nLevor, Norma, 6.1, 6.2, 6.3\n\nLeyland numbers\n\nLi, Ming, 11.1, 11.2\n\nliar\u2019s paradox\n\nlibraries, organization of materials in, 3.1, 3.2, 15.1\n\nLibrary of Alexandria, 14.1, 14.2\n\n\u201cLibrary of Babel, The\u201d (Borges), 14.1, 14.2, 15.1, epl.1, epl.2\n\nLibrary of Congress, 7.1, 14.1, 14.2, epl.1\n\nLicklider, J. C. R., 8.1, 8.2\n\nlife\n\ndefinition of, 9.1, 9.2\n\nentropy and, 9.1, 9.2, 9.3, 9.4\n\norigins of, 10.1, 10.2, 10.3, 11.1\n\nas vehicle for propagating memes\n\nsee also biology\n\nlighthouses\n\nLinnaeus, Carl\n\nLittlewood, J. E.\n\nLloyd, Seth, prl.1, 13.1, 14.1\nThe Information\n\nLocke, John\nLoewenstein, Werner, prl.1, 10.1\nLogarithmicall Arithmetike (Briggs)\nlogarithms, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 4.13, 4.14, 4.15, 4.16, 4.17,\n4.18, 4.19, 4.20, 4.21, 7.1, 7.2\nLogarithms (Taylor)\nlogic\ncircularity problem of words, 3.1, 3.2\nconcept of machines using, 7.1, 7.2\nform of thinking for, 2.1, 2.2\nfunction of, 2.1, 2.2\norigins and early development of, 2.1, 2.2\nparadoxes of, 2.1, 2.2, 6.1, 6.2, 6.3\nthought and, 5.1, 5.2\nwriting and, 2.1, 2.2\nsee also symbolic logic\nlogical depth, 12.1, 12.2\nlogographic writing\nLokele tribe\nlongitude, 4.1, 5.1, 5.2\nLovelace, Ada, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 4.13, 4.14, 4.15, 5.1, 6.1,\n7.1, 7.2, 7.3\nbackground of, 4.1, 4.2, 4.3\nexposition on Menabrea\u2019s essay, 4.1, 4.2, 4.3, 4.4, 4.5\nillnesses and death of, 4.1, 4.2\nmathematics studied by, 4.1, 4.2, 4.3, 4.4\nLuria, Aleksandr Romanovich, 2.1, 2.2\nLyell, Charles\nLysenko, Trofim\nMa, Bin, 11.1, 11.2\nmachines\nAnalytical Engine, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 6.1, 7.1, 8.1\nattribution of thinking to, 6.1, 7.1, 7.2, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8\nDifference Engine, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 4.13, 4.14, 4.15,\n4.16, 4.17, 4.18, 6.1\nDifferential Analyzer, prl.1, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 8.1\nEnigma, 7.1, 7.2\nImitation Game to identify humans from, 8.1, 8.2, 8.3, 8.4\nJacquard loom, 4.1, 4.2\nmaze-navigating robot, 8.1, 8.2, 8.3, 8.4\nmemory function in\nto prove computability of numbers, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6\npurposeful behavior of\nThe Information\n\nself-replicating, 8.1, 8.2\nstandardization of manufacturing\nsee also calculators; computer(s); Turing machine(s)\n\nMackay, Charles\nmacrostates, 9.1, 9.2\n\u201cMagical Number Seven, Plus or Minus Two, The\u201d (Miller)\nmagnetism, 1.1, 1.2, 5.1, 5.2, 6.1, 6.2\nMani, Anand Ramnath, 14.1, 14.2\nMantel, Hillary\nmaps and mapping, 4.1, 7.1, 14.1\nMark I computer\nMassachusetts Institute of Technology, prl.1, prl.2, prl.3, 6.1, 6.2, 6.3, 6.4, 8.1, 8.2, 12.1, 14.1, epl.1\nMathematical Analysis of Logic (Boole)\nMathematical Theory of Communication, The (Shannon, Weaver), prl.1, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 7.10, 7.11, 8.1, 8.2, 8.3, 8.4, 12.1, 12.2, 12.3, epl.1\n\u201cMathematical Theory of Cryptography, A\u201d (Shannon)\nmathematics\nBabbage\u2019s Cambridge studies in, 4.1, 4.2, 4.3, 4.4, 4.5\nBabylonian, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6\nballistics modeling, 6.1, 6.2\ncode analysis\nof cryptography, 5.1, 5.2, 5.3, 7.1, 7.2\ndesire for certainty in\ndifferential equations, 6.1, 6.2, 6.3\nengineering and, 6.1, 6.2\nexpression of logic through\nincompleteness theorem, 6.1, 6.2, 6.3, 6.4, 7.1, 7.2, 7.3, 12.1, 12.2, 12.3\nto purge logic of paradox\nsearch for perfect expression in\nin signal research at Bell Labs, prl.1, prl.2\nin telephone switching technology, 6.1, 6.2\nuses of random numbers in\nsee also logarithms; numbers\n\nMaxwell, James Clerk, 6.1, 6.2, 6.3, 6.4, 8.1, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7\nMaxwell\u2019s demon, 8.1, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9, 10.1, 13.1, 13.2, 15.1, epl.1\nMaynard Smith, John\nMcCarthy, John\nMcCulloch, Warren, 8.1, 8.2, 8.3, 8.4, 8.5\nMcLuhan, Marshall, prl.1, 2.1, 2.2, 2.3, 2.4, 2.5, 8.1, 15.1, epl.1\nMead, Margaret\nmeaning\nin agenda for quantum information science\nThe Information\n\nattempts to incorporate, into information theory\nexpressed through differences\nfuture of science and\ninformation overload and, ep1.1, ep1.2, ep1.3, ep1.4\nlanguage and, ep1.1, ep1.2\nmeasurement of communication and\nof numbers\nin perfect language\nShannon\u2019s information theory and, prl.1, 7.1, 7.2, 8.1, 8.2, 8.3, ep1.1, ep1.2\nsymbolic logic and, 5.1, 5.2, 6.1\ntalking drum method of conveying, 1.1, 1.2, 1.3\nuse of alphabetical ordering systems and\nuse of tonality to convey\nsee also definitions of words\n\nmeasurement of information\nalgorithmic, 12.1, 12.2, 12.3, 12.4\ncombinatorial approach to\nconceptual evolution of, prl.1, prl.2, prl.3, prl.4, prl.5, prl.6, prl.7, 1.1, 6.1, 6.2\ncosmic calculations, prl.1, prl.2, 14.1\nexpanding scale of, 14.1, 14.2, 14.3, 14.4\nmeasurement of message value and, 12.1, 12.2\nmeasurement of randomness and\nas measure of uncertainty, 7.1, 9.1, 9.2\nin music, 12.1, 12.2, 12.3\nprobabilistic approach to, 7.1, 7.2, 7.3, 8.1, 12.1\nin psychology research\nquantifying redundancy for, 1.1, 1.2, 7.1, 7.2\nquantizing speech for\nsymbols as unit for, 6.1, 6.2, 6.3\nin telephony, prl.1, 6.1, 6.2, 6.3, 6.4, 6.5\nTuring\u2019s approach to, 7.1, 7.2\nsee also bit(s)\n\nMedawar, Peter\nmeme(s); memetics\ncatchphrases as, 11.1, 11.2\nchain letters as, 11.1-1.1\nconceptual origins of, 11.1, 11.2, 11.3, 11.4\ndefinition of; prl.1, 11.1, 11.2\ndisease analogy for, 11.1, 11.2\neffects\nforms of, 11.1, 11.2, 11.3\ngenetic model of\nhumans as vehicles for\nideas as\nimages as\nas living structures\nmission of\nmusic as\nreplication through imitation\nscholarly research on, 11.1, 11.2\ntransmission of, 11.1, 11.2, 11.3\n\nmemory\naids in oral literature\ncomputer, cost of\nevolution of information technology and, 15.1, 15.2, 15.3\nin machine functions\nin maze-navigating machine, 8.1, 8.2, 8.3, 8.4\nmeme strategies\npsychology research on, 8.1, 8.2, 8.3, 8.4\nquantum erasure of\nwriting and, 2.1, 2.2\n\nMenabrea, Luigi\nMencken, H. L., 3.1, 11.1\nMendel, Gregor\nMercury: or the Secret and Swift Messenger (Wilkins)\nMerlin, John\nMermin, David, 13.1n, 13.2\nMerrill, James\nmessenger RNA, 11.1, 13.1\nmeta-language\nMetalogicon\nmetamathematics, 6.1, 6.2, 6.3, 10.1, 12.1\nmetaphor\n\u201cMethod of Expressing by Signs the Action of Machinery, On a\u201d (Babbage), 4.1, 4.2\nMetropolis, Nicholas\nmicrofilm\nmicrostates, 9.1, 9.2\nMiddleton, Thomas\nMilbanke, Anna Isabella\nMilgram, Stanley\nMiller, George, 8.1, 8.2, 8.3\nMiller, Jonathan, 2.1, 2.2\nMillion Random Digits, A, 12.1, 12.2\nMilton, John, 3.1, 11.1\nMingjia (School of Names)\nMinsky, Marvin\nMiot de Melito, Count n\nMitchell, David\nmonodegreens, 3.1, 3.2\nMonod, Jacques\nMonte Carlo simulations, 11.1, 12.1\nMoore, Francis\nMoore, Gordon\nMorse, Samuel F. B., 1.1, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6\nMorse code, prl.1, 1.1, 1.2, 1.3, 1.4, 5.1, 6.1, 11.1, 12.1\nmortality tables, 4.1, 4.2, 4.3\nMulcaster, Richard\nmultiplexed signals\nMumford, Lewis\nMunch, Edvard\nMurray, James, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6\nmusic, 10.1, 12.1, 12.2, 12.3, 12.4\nNagel, Ernest\nnaming, 2.1, 14.1, 14.2, 14.3, 14.4, 14.5, 14.6\nNapier, John, 4.1, 4.2\nNapoleon Bonaparte, 5.1, 5.2\nNational Defense Research Committee\nnatural history, 14.1, 14.2\nnatural philosophy, prl.1, prl.2, 3.1\nnatural selection, 5.1, 10.1, 10.2, 10.3, 11.1; see also evolution\nNature, 10.1, 10.2, 10.3, epl.1\nNautical Almanac, 4.1, 4.2\nnavigation, number tables for, 4.1, 4.2, 4.3\nneedle telegraphy, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6\nnetworks\napplications of Shannon\u2019s theories, 8.1, 8.2\nbarbed-wire telephone\nbiological analogies for electrical\ncloud processing\nclustering in\ncollective judgment and behavior enabled by, epl.1, epl.2\ne-mail\nemergence of global consciousness, epl.1, epl.2, epl.3\nEnglish poetry\nglobal information in, epl.1, epl.2\nscience of\nThe Information\n\nsmall-world, epl.1, epl.2\nspread of memes through\ntelegraphic, 5.1, 5.2, 5.3, 5.1\ntelephone, 6.1, 6.2, 6.3, 6.4\nsee also cyberspace; Internet\n\nNeugebauer, Otto\nneurophysiology\nanalog versus digital descriptions of, 8.1, 8.2\nconcept of human global organism, epl.1, epl.2, epl.3\nfeedback systems in, 8.1, 8.2\nhuman\u2013computer comparison, 8.1, 8.2, 8.3\nmetaphors for electrical systems\n\nneurosis\nNew Logic, 6.1, 6.2\n\nNewman, James R.\n\nNewton, Isaac, prl.1, 3.1, 3.2, 3.3, 4.1, 6.1, 9.1, 11.1, 12.1, 14.1, 14.2, 14.3\n\nnoise\nin biological systems\ncoded messages as, 7.1, 7.2\nerror correction to overcome, 7.1, 7.2, 8.1\nlimits of information transmission, 8.1, 8.2\nin modeling of communication systems, 6.1, 7.1\nnoisy coding theorem\npredictability\nproblems of telephony, prl.1, prl.2, 6.1, 6.2, 7.1\nquantification of\nscientific study of, 6.1, 6.2\nsource of, 6.1, 7.1\nas subject of psychology research, 8.1, 8.2\nWiener\u2019s studies of, 8.1, 8.2\n\nNollet, Abb\u00e9 Jean-Antoine\n\nnoosphere\nNotions sur la machine analytique (Menabrea)\nnucleic acid, 10.1, 10.2; see also deoxyribonucleic acid, 10.1\nnucleotides, 10.1, 10.2, 10.3, 10.4\n\nnumbers\ncomputability question, 7.1, 7.2, 7.3, 7.4, 7.5, 12.1, 12.2, 12.3, 12.4, 12.5\nconcept of normality in, 12.1, 12.2\nearliest written, 2.1, 2.2, 2.3\ninformation in, 12.1, 12.2\ninteresting, 12.1, 12.2, 12.3, 12.4\nmeaning of\nThe Information\n\nprinted tables of, 4.1, 4.2, 4.3, 4.4\nproducts of Babbage\u2019s work with, 4.1, 4.2, 4.3\ntable of differences, 4.1, 4.2\nas universal language, 6.1, 6.2\nsee also mathematics\n\nNyquist, Harry, 6.1, 6.2, 6.3, 6.4, 7.1\n\nobserver effects on subject of observation, 7.1, 13.1, 13.2, 13.3, 13.4, 13.5\nOccam\u2019s razor\n\nOdyssey (Homer), 2.1, 11.1\n\nOgilvie, Brian, 14.1, 15.1\n\nOhm, Georg\n\nOng, Walter J., 2.1, 2.2, 2.3, 2.4, 2.5\n\noral culture(s), 1.1, 1.2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9\n\nOxford English Dictionary, 3.1, 9.1, 14.1, 15.1, 15.2\nadditions and revisions to, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6\neditions of\ngoals of, 3.1, 3.2\ngrowth of language and, 3.1, 3.2, 3.3\nonline, 3.1, 3.2, 3.3\nsources of words and definitions for\nspelling of words in, 3.1, 3.2\n\nPage, Larry, 14.1, ep1.1\n\nPalme, Jacob, 15.1, 15.2\n\nPalmer, Dexter, ep1.1, ep1.2\n\npaper, 2.1, 4.1, 4.2, 7.1, 9.1, 13.1, 14.1, 14.2, 14.3, 15.1, 15.2\n\nparadox(es)\nBarber\nBerry\u2019s, 6.1, 6.2, 12.1\nchallenges for symbolic logic, 6.1, 6.2, 6.3\nof distance in cyberspace\nEpimenides\u2019\nG\u00f6del\u2019s insight into, 6.1, 6.2, 6.3, 6.4\nof language and logic, 2.1, 2.2, 4.1\nliar\u2019s\nmathematics as solution to\nof perpetual motion, 9.1, 9.2, 9.3\nRussell\u2019s, 6.1, 6.2\nself-referencing as basis of, 6.1, 6.2\nof smallest uninteresting number, 12.1, 12.2\n\nparallel processing, 4.1, 4.2\n\nParker, Moses Greeley\nParry, Milman\nPascal, Blaise\npatterns\n  distinguished from randomness, 12.1, 12.2, 12.3, 12.4\n  recognition of, in cryptography, 7.1, 7.2\n  in valuation of messages, 12.1, 12.2\n  in *Voyager* spacecraft messages, 12.1, 12.2, 12.3\nPauli, Wolfgang\nPavlov, Ivan Petrovich\nPeacock, George\nPeel, Robert, 4.1, 4.2\nPeres, Asher, 13.1, 13.2\nPerks, William George\nperpetual motion machines, 9.1, 9.2, 9.3\nperturbation studies\npetroglyphs\npharmaceutical industry, 14.1, 14.2\n*Philosophiae Naturalis Principia Mathematica* (Newton), 4.1, 6.1, 14.1\n*Philosophy of Decyphering, The* (Babbage)\nphonemes, 1.1, 1.2, 8.1\nphotographic images, 12.1, 14.1, 14.2\nphysics, prl.1, prl.2, prl.3, prl.4, prl.5, 6.1, 6.2, 13.1, 13.2; see also quantum physics; thermodynamics\npi, 12.1, 12.2, 12.3\nPickering, John\npictographs\nPierce, John Robinson, prl.1, 8.1\nPinker, Steven, 3.1, 3.2\nplanimeter\nPlato, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6\nPliny, 2.1, 6.1\nPluto, 3.1, 3.2\nPM (formal system), 6.1, 6.2, 6.3\n*Pocket Telegraphic Code*, 5.1\nPodolsky, Boris\nPoe, Edgar Allan, prl.1, 4.1, 5.1, 6.1, 7.1, 14.1\npoetry, 2.1, 2.2, 2.3, 12.1, 12.2, 15.1, 15.2, 15.3\nPoincar\u00e9, Henri, 9.1, 12.1\npolarization states, 13.1, 13.2\nPope, Alexander\nPorsche\nPreece, William\nPreskill, John, 13.1, 13.2\nPrime Computer\nprime numbers, 12.1, 12.2, 13.1\nPrimrose, Frank\nPrince\nPrinceton University, 6.1, 6.2, 6.3\n*Principia Mathematica* (Russell, Whitehead), 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7\n*Principles of Psychology* (James)\n*Printing Press as an Agent of Change, The* (Einstein)\nprinting technology, prl.1, 3.1, 4.1, 4.2, 15.1, 15.2, 15.3\nprobability\ncalculations for control of redundancy in messages, 7.1, 7.2\nin measurement of information, 7.1, 7.2, 7.3, 8.1, 12.1\nas problem for quantum computing, 13.1, 13.2\nqualities of randomness and\nstatistical analysis of language, 7.1, 7.2, 7.3, 7.4\nin stochastic processes\nin thermodynamics, 9.1, 9.2, 9.3, 9.4\nTuring\u2019s ban unit of, 7.1, 7.2\n*Problems of Information Transmission*, 12.1, 12.2\nprogramming\nto generate random numbers, 12.1, 12.2\nLovelace\u2019s operations for Analytical Engine as, 4.1, 4.2\nof Turing machine states, 7.1, 7.2, 7.3, 8.1, 12.1, 12.2\nproteins, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7\npseudorandom numbers\npsyche\nPsycho-Acoustic Laboratory\npsychology, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9\nPulgram, Ernst\nquadratic equations\nquantum information science\ncomputing based on, 13.1, 13.2, 13.3, 13.4\nconceptual basis, 13.1, 13.2, 13.3, 13.4\nentanglement in, prl.1, 13.1, 13.2, 13.3, 13.4\nfirst encoded message based on, 13.1, 13.2, 13.3\nfuture applications of\nmeasurement units in, 13.1, 13.2\nproblem of black holes in, 13.1, 13.2, 13.3\nscope of, prl.1, prl.2\nShannon\u2019s contribution to, 13.1, 13.2\nsuperposition principle in\nquantum physics\nThe Information\n\nof black holes\ncomplementarity concept in\nconflicting theories in, 13.1, 13.2\nentanglement\nincompleteness theorem and, 12.1, 12.2\nsee also quantum information science\n\nQuastler, Henry\nqubits, prl.1, 13.1, 13.2, 13.3, 13.4, 13.5\nqueuing theory\nQuittner, Joshua\n\nRamanaujan, Srinivasa\n\nrandomness\nChaitin\u2019s insight\ncoded data disguised by\ncomplexity perceived as, 12.1, 12.2\ncomputability and, 12.1, 12.2, 12.3\ncomputer programs to generate, 12.1, 12.2\ndata compression and, 12.1, 12.2\ndefinition of\nfrequency of, among numbers\ninformation-carrying capacity of\ninteresting numbers and, 12.1, 12.2\nmathematical proof of, 12.1, 12.2\nin quantum cryptography\nrecognition of, 12.1, 12.2, 12.3\nstatistical normality in\ntables of random numbers, 7.1, 12.1, 12.2\n\nRatio Club, 8.1, 8.2\n\nRattray, Robert Sutherland, 1.1, 1.2\n\nRatzberger, Caspar, 14.1, 14.2\n\nRayleigh, Lord\n\n\u201crecoding\u201d of information, 8.1, 8.2\n\nrecordings, 2.1, 5.1, 5.2, 12.1, 12.2, 12.3, 14.1, 14.2\n\nrecursive procedures\nin algorithmic proof of randomness, 12.1, 12.2\nin Lovelace\u2019s operations for Analytical Engine\nparadoxes based on, 6.1, 6.2\nin Turing machine operations, 7.1, 7.2\nin use of alphabetical ordering systems\n\nredundancy\ncontrol of, for communication, 7.1, 7.2\nin English language, 1.1, 1.2, 7.1, 7.2, 8.1, 8.2, 8.3\nThe Information\n\nin genetic code\ninformation content and\nin language of talking drums, 1.1, 1.2\nmathematical modeling of\nin oral literature\npredictability and, 7.1, 7.2, 8.1, 12.1\nto prevent telegraph errors\nquantifying, in measurement of information, 7.1, 7.2\nin quantifying message value\nrole of, in language, 1.1, 1.2, 7.1\nsignificance of, in cryptanalysis\n\nRegiomontanus\nrelays, electrical, 5.1, 6.1, 6.2, 6.3, 6.4, 6.5, 7.1, 8.1, 8.2, 8.3\n\u201cReliable Circuits Using Less Reliable Relays\u201d (Shannon)\nReuss, Christoph\nRevere, Paul, 1.1, 7.1\nrhyme\nrhythm\nribosomes\nRNA, 10.1, 10.2, 10.3, 11.1, 13.1, 13.2\nRNA Tie Club, 10.1, 10.2\nRoget, Peter\nRomme, Gilbert\nRoosevelt, Franklin D., prl.1, prl.2, 7.1\nRosen, Nathan\nRoss, Alex\nRSA encryption\nRussell, Bertrand, 5.1, 5.2, 6.1, 6.2, 6.3, 6.4, 6.5, 7.1, 8.1, 8.2, 12.1\nRussell\u2019s paradox, 6.1, 6.2, 12.1\n\nSafire, William, 3.1, 11.1\nSagan, Carl\nsampling, 6.1, 6.2, 7.1, 7.2, 12.1\nSapir, Edward\nSavage, Leonard, 8.1, 8.2\nSchilling, Pavel\nSchr\u00f6dinger, Erwin, 9.1, 10.1, 10.2, 13.1\n\nscience\nas algorithmic process, 12.1, 12.2\ndata compression in laws of\nevolution of language for development of, 3.1, 3.2, 3.3\nlimits to knowledge in, 12.1, 12.2\nin Soviet Union\nsee also specific discipline\n\nscience fiction, epl.1, epl.2\n\n*Scientific American*, 5.1, 6.1, 7.1, 8.1, 8.2, 11.1, 12.1\n\nScott, E. Erskine\n\nsearch engines, 15.1, epl.1, epl.2, epl.3\n\nsecond law of thermodynamics, 8.1, 9.1, 9.2, 9.3, 9.4, 9.5\n\n*Secret Corresponding Vocabulary, The* (Smith)\n\nself-awareness, prl.1, 2.1, 2.2, 2.3, 2.4\n\n*Selfish Gene, The* (Dawkins), 10.1, 11.1, 11.2\n\nselfish genes, 10.1, 10.2, 10.3, 10.4, 11.1\n\nself-organizing systems\n\nself-referencing, 6.1, 6.2, 6.3, 7.1, 7.2\n\nself-replication\n\nas ability of living organisms\n\nof chain letters, 11.1, 11.2, 11.3\n\ncrystal capacity for\n\ndisease analogy, 11.1, 11.2\n\nDNA\n\nmachine, 8.1, 8.2\n\nas mission of genes, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7\n\nthrough imitation\n\nsee also meme(s)\n\nsemiconductor\n\nsensory processing\n\nserver farms, 11.1, 14.1\n\nset theory, 6.1, 6.2\n\nShaffner, Taliaferro\n\nShakespeare, William, 3.1, 3.2\n\nShannon, Betty Moore, 7.1, 7.2\n\nShannon, Catherine Wolf\n\nShannon, Claude, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 13.1\n\nballistics research of, 6.1, 6.2\n\nat Bell Labs, prl.1, prl.2, 6.1, 7.1, 7.2, 7.3, 7.4, 7.5\n\nin Conference on Cybernetics, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8\n\ncryptography work of, prl.1, prl.2, 6.1, 6.2, 6.3, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7\n\ndata compression studies of, prl.1, prl.2, 12.1, 12.2, 12.3\n\nearly life and education, 6.1, 6.2, 6.3, 6.4\n\nearly studies in symbolic logic, 6.1, 6.2, 6.3, 6.4, 6.5\n\ninformation storage studies of, 7.1, 7.2\n\nKolmogorov and, 12.1, 12.2\n\nmaster\u2019s thesis of, 6.1, 6.2, 6.3\n\nmaze-navigating machine of, 8.1, 8.2, 8.3, 8.4, 8.5\nThe Information\n\non meaning in messages, prl.1, 7.1\nmeasurement of information by, prl.1, 6.1, 6.2, 9.1, 9.2, 14.1\nat MIT, prl.1, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 8.1, 12.1\nat Princeton, 6.1, 6.2\nquantum information science and, 13.1, 13.2\nstatistical analysis of language by, 7.1, 7.2, 7.3, 7.4\nstudy of redundancy in language by, 1.1, 1.2, 7.1, 7.2\ntheory of information, prl.1, prl.2, prl.3, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 7.10, 7.11, 7.12, 7.13, 8.1, 8.2, 8.3\non thinking machines, 8.1, 8.2\nTuring machine analysis by\nWiener and, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 9.1, 9.2\nwork with Differential Analyzer, 6.1, 6.2, 6.3\n\nShannon, Mabel Catherine Wolf\nShannon, Norma Levor, 6.1, 6.2, 6.3\nShannon entropy, 7.1, 7.2, 10.1, 10.2\nShannon-Fano coding\nShannon limit\nShaw, George Bernard\nShockley, William\nShor, Peter, 13.1, 13.2\nsignal distortion; see noise\nsignals and signaling\nBabbage\u2019s occulting light for\nbrain function as\nfire beacons\nhistorical evolution of, 1.1, 1.2\nlighthouses\nnature of telephone communication, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6\nin neurological disorders\npower of writing, 2.1, 2.2\nin telegraphy before electricity, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6\nin telegraphy before Morse code, 5.1, 5.2, 5.3, 5.4, 5.5\nfor telephone switching, 6.1, 6.2\nsee also Morse code\nsignal-to-noise ratio, 8.1, 8.2, 15.1\nSimpson, John, 3.1, 3.2, 3.3, 3.4, 3.5\nsimultaneity\nSix Degrees of Separation (Guare), epl.1, epl.2\nSkinner, B. F.\nSmalley, Sondra\nsmall-world networks, epl.1, epl.2\nSmee, Alfred\nThe Information\n\nSmith, Francis O. J., 5.1, 5.2\nSmolin, John\nsocial sciences, 8.1, 8.2, 8.3\nSolomonoff, Ray, 12.1, 12.2, 12.3, 12.4\nS\u00f6mmerring, Samuel Thomas von\nSophocles, 14.1, 15.1\nSouthwell, Robert\nSoviet Union, 12.1, 12.2, 12.3\nspace exploration\nSpeculum Maius (Vincent of Beauvais)\nspelling, 3.1, 3.2, 3.3, 3.4\nSpender, Stephen\nSperry, Roger\n\u201cspooky action at a distance,\u201d (Einstein), 13.1, 13.2\nSprat, Thomas, 2.1, 3.1\nstatistical analysis, 7.1, 7.2, 7.3, 7.4, 9.1, 9.2, 12.1\nsteam power, 4.1, 4.2, 4.3, 9.1, 9.2\nStent, Gunther, 10.1, 10.2, 10.3\nStevin, Simon\nstochastic processes, 7.1, 7.2\nStoppard, Tom, 9.1, 9.2, 14.1\nstorage of information\nShannon\u2019s early calculations on, 7.1, 7.2\nsources of confusion in, 14.1, 14.2\ntrends in, 14.1, 14.2\nStreufert, Siegfried, 15.1, 15.2\nStrogatz, Steven, epl.1, epl.2\nStuart, Gilbert\nSuetonius\nsuperposition of states, 13.1, 13.2\nSurowiecki, James\nsurprise, as feature of information, 7.1, 9.1\nSusskind, Leonard\nsyllabary\nsymbolic logic\napplication to genetics, 6.1, 6.2, 6.3\nto avoid paradox\nconceptual basis, 5.1, 5.2, 5.3\nconceptual origins of computers in, 6.1, 6.2\nto describe communication systems\nto describe relay circuits, prl.1, 6.1, 6.2\ngoals of Principia Mathematica, 6.1, 6.2, 6.3\nThe Information\n\nincompleteness of formal systems of, 6.1, 6.2, 6.3, 6.4, 7.1\nas mechanical operation, 6.1, 6.2, 7.1, 7.2\npromise of, 6.1, 6.2\nsearch for perfect system of\nsymbols and symbol sets\nin Babbage\u2019s mechanical notation, 4.1, 4.2, 5.1, 6.1\nfor cryptography\nfo universal language\nin Lovelace\u2019s game solution formula\nfor measurement of information, 6.1, 6.2, 6.3\nfor perfect language\nredundancy of communication determined by, 1.1, 1.2\nin structure of language\nfor Turing machine\nsee also alphabet(s); code; symbolic logic; writing\n\nSzil\u00e1rd, Le\u00f3, 9.1, 9.2, 9.3, 9.4, 13.1\n\n\u201cTable Alphabeticall, A\u201d (Cawdrey), 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 3.10, 3.11, 3.12, 3.13,\n3.14, 3.15, 3.16, 3.17, 3.18, 3.19\nTable of Constants of the Class Mammalia (Babbage)\nTable of the Relative Frequency of the Causes of Breaking of Plate Glass Windows (Babbage)\nTable of Triangular Numbers, (Babbage)\nTables for the Improvement of Navigation (Briggs)\nTable to find the Height of the Pole (Briggs)\nTafelen van Interest (Stevin)\n\nTalbot, William Fox\ntalking drums, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 1.10, 1.11, 1.12\nTalking Drums of Africa, The (Carrington)\n\nTawell, John\n\n Teilhard de Chardin, Pierre\ntelegraphy, prl.1, 1.1, 4.1\naddress codes, 14.1, 14.2\nBaudot code for\nbubble\ncipher and compression systems for, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6\nas commercial business, 5.1, 5.2\ncommercial interest in, 5.1, 5.2\nconceptual understanding of, 5.1, 5.2\nearly systems for, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 5.10, 5.11, 5.12\nelectrical relays in\nbefore electricity, 5.1, 5.2, 5.3, 5.4\nin England, 5.1, 5.2, 5.3\nerrors in\nThe Information\n\nin France, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8\ngrowth of, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9\ninfrastructure of\ninvention of, 5.1, 5.2, 5.3, 5.4\nas medium, 5.1, 5.2\noperator\u2019s key\nperception of time and, 5.1, 5.2\npreservation of messages sent by, 5.1, 5.2\nprivate ciphers to reduce cost of, 5.1, 5.2\npublic interest in codes and, 5.1, 5.2\nin Soviet Union\nstatistical structure of language in, 7.1, 7.2\ntelephony and, 6.1, 6.2, 6.3\ntrans-Atlantic, 5.1, 5.2\nwaveform analysis in\nweather reporting and, 5.1, 5.2\n\nsee also Morse code\n\ntelephony\narchitecture and\nbarbed-wire networks\nbiological metaphors for\ncommercial applications of, 6.1, 6.2\nconcern about social effects of\ndemand for information and, 15.1, 15.2\nelectrical engineering requirements of, 6.1, 6.2\nevolution of switching technology for, 6.1, 6.2, 6.3, 6.4\nfarmer cooperative networks of\ngrowth of, 6.1, 6.2, 6.3\nmeasurement of information carried by, prl.1, 6.1, 6.2, 6.3, 6.4, 6.5\nprinted directories, 6.1, 6.2\nrelays in\nsignal distortion in, prl.1, prl.2\nin Soviet Union\ntelephotography, 6.1, 6.2\nteleportation, 13.1, 13.2, 13.3, 13.4\ntelevision, prl.1, prl.2, 7.1, 11.1, 11.2\n\nTeller, Edward\nTennyson, Alfred, Lord, 4.1, 4.2\nTerhal, Barbara\nTh\u00e9orie des fonctions analytiques (Lagrange)\nTheory of Heat (Maxwell)\n\nthermodynamics\nThe Information\n\nof computation, 13.1, 13.2, 13.3, 13.4\nconcept of entropy in, 9.1, 9.2, 9.3\nconceptual evolution of, 9.1, 9.2\nfirst law of\nof life\nmolecular fluctuations in, 9.1, 9.2\nprobability in, 9.1, 9.2, 9.3, 9.4\nsecond law of, 8.1, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6\n\nThesaurus (Roget)\n\nthinking\ncryptographic skills\nas digital operation, 8.1, 8.2\ndiscovery of\nhuman\u2013computer comparison, 8.1, 8.2\nlanguage and, 2.1, 2.2\nin literate cultures, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8\nlogic and, 2.1, 2.2, 5.1, 5.2\nmachine and computer operations as, 6.1, 7.1, 7.2, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 8.10\n\u201crecoding\u201d of information in, 8.1, 8.2\ntelegraph effects on, 5.1, 5.2, 5.3, 5.4\nsee also logic\n\nThomas, Thomas\nThomson, James\nThomson, William, Lord Kelvin, 9.1, 9.2, 9.3\n\n\u201cThree Approaches to the Definition of the Concept \u2018Amount of Information\u2019\u201d (Kolmogorov)\nThree Letter Code for Condensed Telegraphic and Inscrutably Secret Messages and Correspondence (Scott)\n\u201cThree Models for the Description of Language\u201d (Chomsky)\nTHROBAC\n\ntime\neffects of information technology in perception of\nmovement toward entropy in, 9.1, 9.2\nin physics of black holes\nspeed of early mechanical calculators, 4.1, 4.2\nstandardization of clocks, 1.1, 5.1, 5.2, 5.3, 5.4\ntelegraph effects on understanding of, 5.1, 5.2\nwritten language and\n\nTime Machine, The (Wells)\nTobias, Andrew\ntonality, in communication, 1.1, 1.2, 1.3\nTorres y Quevedo, Leonardo\nTotal Baseball: The Ultimate Baseball Encyclopedia, 13.1\nThe Information\n\ntrademark names, 14.1, 14.2, 14.3\ntransistor, prl.1, prl.2, prl.3, 3.1, 7.1, 14.1\ntranslation, language, 3.1, 3.2\ntransmission of information\n  Babbage\u2019s work on, 4.1, 4.2\n  bandwidth requirements, 6.1, 6.2\n  in biological evolution, 10.1, 10.2\n  in cuneiform, 2.1, 2.2\ndata compression for\ndisruptive effects of new technologies for, prl.1, prl.2\nentanglement as\nevolution of electrical technologies for, 5.1, 5.2\ngenetic, 10.1, 10.2\nhistorical evolution, 1.1, 1.2, 1.3, 1.4\nhuman history and, prl.1, prl.2\nin telephotography, 6.1, 6.2\ninterconnectedness of cyberspace for, 3.1, 3.2\nlimits of speed and capacity, 7.1, 8.1, 8.2\nnews reports, 5.1, 5.2\noverload effects, 15.1, 15.2, 15.3, 15.4, 15.5\nby quantum teleportation, 13.1, 13.2\nfor replication of culture\nsensory involvement as indicator of quality of, 2.1, 2.2\nsource of noise in\ntransmission of electricity as, 5.1, 5.2\nunits of measurement\nsee also communication; meme(s); specific mode of transmission\n\nTreatise on Electro-Magnetism (Roget)\n\ntree rings\ntriangular numbers, 4.1, 4.2, 4.3, 4.4\nTrudeau, Garry\ntruth, 2.1, 5.1, 6.1, 6.2, 6.3, 6.4, 6.5\nTuring, Alan, prl.1, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 8.1, 8.2, 8.3, 8.4, 8.5, 9.1, 14.1\nTuring machine(s)\n  capabilities\n    as code generator\n  proof of incompleteness theorem by, 7.1, 7.2, 7.3, 7.4, 12.1\n  significance of, in computer science, 12.1, 12.2\n  states\n    symbols\n    tape, 7.1, 7.2\n  thermodynamics of, 13.1, 13.2\ntwo-state model\n\n$U$ machine, 7.1, 7.2, 7.3, 12.1\n\nTuring Test, 8.1, 8.2, 8.3, 8.4\n\nTwitter, 11.1, ep1.1, ep1.2\n\nUglow, Jenny\n\nuncertainty\n\nentropy as measure of, 7.1, 9.1, 9.2\n\nincompleteness theorem and, 7.1, 12.1\n\ninformation and\n\nlimits to science, 12.1, 12.2\n\nin measurement of quantum properties, 13.1, 13.2, 13.3\n\nuncomputability, 7.1, 7.2, 7.3, 7.4, 7.5, 12.1, 12.2, 12.3, 12.4, 12.5\n\nundecidability; see decision problem\n\nuninteresting numbers, 12.1, 12.2\n\nUniversity of Vienna\n\nUpdike, John\n\nUruk, 2.1, 2.2, 2.3\n\nVail, Alfred, 1.1, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 7.1\n\nVail, Theodore N., 6.1, 6.2\n\nVanArsdale, Daniel W.\n\nvan Leeuwenhoek, Antony, 6.1, 6.2, 8.1\n\nVautroullier, Thomas\n\nVerne, Jules\n\nVictoria, Queen, 5.1, 6.1\n\nVienna Circle, 6.1, 6.2\n\nVigen\u00e8re cipher, 5.1, 7.1, 7.2\n\nVincent of Beauvais\n\nviruses, prl.1, 11.1, 11.2\n\nvocabulary size, 2.1, 2.2, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9\n\ngrowth of language, 3.1, 3.2, 3.3, 3.4\n\nShakespeare\u2019s\n\nVolta, Alessandro\n\nvon Foerster, Heinz, 8.1, ep1.1\n\nvon Neumann, John, 6.1, 6.2, 8.1, 8.2, 8.3, 8.4, 9.1, 10.1, 12.1, 12.2, 12.3, 13.1\n\nVoyager spacecraft\n\nWales, Jimmy, 14.1, 14.2, 14.3, 14.4, 14.5\n\nWallace, David Foster\n\nWalton, Stephen, 11.1, 11.2\n\nWashington, George\n\nWassall, Irma\n\nWatson, David L.\nThe Information\n\nWatson, James D., 7.1, 7.2, 10.1, 10.2, 10.3, 13.1\nWatson, John B.\nWatts, Duncan, epl.1, epl.2\nWeaver, Edmund\nWeaver, Warren, 7.1, 7.2, 8.1, 8.2, 8.3\nWeber, Wilhelm\nWebster, Noah\nWells, H. G., 6.1, 9.1, 14.1, epl.1, epl.2\nWell-Tempered Clavier (Bach), 12.1, 12.2, 12.3, 12.4\nWestern Union Telegraph Company\nWeyl, Hermann, prl.1, 6.1\nWhat Is Life? (Schr\u00f6dinger)\nWheatstone, Charles, 5.1, 5.2, 5.3\nWheeler, John Archibald, prl.1, prl.2, 12.1, 12.2, 13.1, 13.2, 13.3\nWhitehead, Alfred North, 6.1, 6.2, 6.3, 7.1\nWhitman, Walt, epl.1, epl.2\nWhitmore, Georgiana\nWiener, Norbert, prl.1, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 8.10, 8.11, 8.12, 8.13, 8.14, 8.15, 8.16, 8.17, 8.18, 9.1, 9.2, 9.3, 12.1\nWikipedia, 12.1, 12.2, 14.1, 14.2, 14.3, 14.4, 14.5, 14.6, 14.7, 14.8, 14.9, 14.10, 14.11, 14.12, 15.1, epl.1\nWilkes, Charles\nWilkins, John, 5.1, 5.2\nWilson, Edward O.\nWilson, Thomas\nwire fences, 6.1, 6.2\nWisdom of Crowds (Surowiecki)\nWittgenstein, Ludwig, 3.1, 6.1, 6.2, 8.1\nWorld Brain (Wells)\nWorld Congress of Universal Documentation\nWorld War II, prl.1, prl.2, 6.1, 6.2, 6.3, 7.1, 7.2, 7.3\nWright, Sylvia\nwriting\nabstract thinking and\nalphabet-based, 2.1, 2.2\ncriticism of communicative capacity of, 2.1, 2.2\ncryptography and, 5.1, 5.2\ncuneiform, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7\nin development of mathematics, 2.1, 2.2, 2.3, 2.4, 2.5\nextension of time and space in\nhistorical development of, 2.1, 2.2, 2.3, 2.4, 2.5\nlevels of representation in\nmemory and, 2.1, 2.2\nThe Information\n\nmodes and uses of information arising from, 2.1, 2.2, 2.3, 2.4\norigins of logic in, 2.1, 2.2\nsecond age of orality and, 2.1, 2.2\nself-awareness in, 2.1, 2.2, 2.3\nas technology\nthinking and, 2.1, 2.2, 2.3, 2.4, 2.5\nWyman, Bill, 14.1, 14.2\nWynter, Andrew, 5.1, 5.2, 5.3, 5.4\nX System, prl.1, prl.2, 7.1\nYahoo!\nYaunde language\nYouTube\nILLUSTRATION CREDITS\n\n4.1 Photograph courtesy of the Charles Babbage Institute, University of Minnesota, Minneapolis\n\n6.1 The New York Times Archive/Redux\n\n7.1 Copyright Robert Lord\n\n7.2 Reprinted with permission from *Journal Franklin Institute*, vol. 262, E. F. Moore and C. E. Shannon, \u201cReliable Circuits Using Less Reliable Rays,\u201d pp. 191\u2013208, \u00a9 1956, with permission from Elsevier.\n\n7.3 Taken from *Claude Elwood Shannon Collected Papers*, ed. NJA Sloane & Aaron Wyner \u00a9 1993 IEEE\n\n7.4 Taken from *Claude Elwood Shannon Collected Papers*, ed. NJA Sloane & Aaron Wyner, \u00a9 1993 IEEE\n\n7.5 \u00a9 Mary E. Shannon\n\n8.1 Alfred Eisenstaedt/Time & Life Pictures/Getty Images\n\n8.2 Keystone/Stringer/Hulton Archive/Getty Images\n\n8.3 Alfred Eisenstaedt/Time & Life Pictures/Getty Images\n\n9.1 Taken from *Entropy and Energy Levels* by Gasser & Richards (1974) Figs. 9.7, 9.8 pp. 117\u2013118. By permission of Oxford University Press.\n\n9.2 From *Symbols, Signals & Noise* by J. R. Pierce (Harper & Brothers, NY, 1961), p. 199.\n\n9.3 Copyright \u00a9 2010 Stanley Angrist, reprinted by permission of Basic Books, a member of the Perseus Books Group.\n\n9.4 Reproduced from *Fundamentals of Cybernetics*, Lerner AY (Plenum Publishing Corp., NY 1975), p. 257.\n\n9.5 Copyright \u00a9 2010 Stanley Angrist, reprinted by permission of Basic Books, a member of the Perseus Books Group\n\n12.1 Courtesy NASA/JPL-Caltech\n\n13.1 Christopher Fuchs\nA NOTE ABOUT THE AUTHOR\n\nJames Gleick was born in New York City in 1954. His previous books include *Chaos* and *Genius*, both Pulitzer Prize finalists and National Book Award nominees. His last book, *Isaac Newton*, was also a Pulitzer Prize finalist. They have been translated into more than twenty languages. His Web site is at www.around.com.\nThe Information", "source": "olmocr", "added": "2025-08-12", "created": "2025-08-12", "metadata": {"Source-File": "gleick2011.pdf", "olmocr-version": "0.2.3", "pdf-total-pages": 448, "total-input-tokens": 743680, "total-output-tokens": 285431, "total-fallback-pages": 0}, "attributes": {"pdf_page_numbers": [[0, 1085, 1], [1085, 1202, 2], [1202, 1425, 3], [1425, 1441, 4], [1441, 1525, 5], [1525, 2202, 6], [2202, 2214, 7], [2214, 2230, 8], [2230, 2609, 9], [2609, 2625, 10], [2625, 3252, 11], [3252, 3268, 12], [3268, 3284, 13], [3284, 3344, 14], [3344, 5975, 15], [5975, 9049, 16], [9049, 12019, 17], [12019, 15024, 18], [15024, 18021, 19], [18021, 21028, 20], [21028, 23891, 21], [23891, 25952, 22], [25952, 28906, 23], [28906, 32034, 24], [32034, 35098, 25], [35098, 38027, 26], [38027, 41129, 27], [41129, 44230, 28], [44230, 47165, 29], [47165, 50132, 30], [50132, 53070, 31], [53070, 54712, 32], [54712, 56938, 33], [56938, 60021, 34], [60021, 63154, 35], [63154, 66070, 36], [66070, 69073, 37], [69073, 72183, 38], [72183, 75169, 39], [75169, 78284, 40], [78284, 80802, 41], [80802, 83750, 42], [83750, 85870, 43], [85870, 87418, 44], [87418, 90234, 45], [90234, 92994, 46], [92994, 95969, 47], [95969, 98989, 48], [98989, 99922, 49], [99922, 101241, 50], [101241, 104337, 51], [104337, 107202, 52], [107202, 110278, 53], [110278, 113187, 54], [113187, 116187, 55], [116187, 118652, 56], [118652, 121322, 57], [121322, 124341, 58], [124341, 127203, 59], [127203, 130285, 60], [130285, 133339, 61], [133339, 136426, 62], [136426, 139483, 63], [139483, 142530, 64], [142530, 145765, 65], [145765, 148671, 66], [148671, 151466, 67], [151466, 153505, 68], [153505, 155854, 69], [155854, 158885, 70], [158885, 161897, 71], [161897, 164955, 72], [164955, 167787, 73], [167787, 170414, 74], [170414, 173455, 75], [173455, 175000, 76], [175000, 176159, 77], [176159, 179112, 78], [179112, 182108, 79], [182108, 184654, 80], [184654, 187652, 81], [187652, 190331, 82], [190331, 192446, 83], [192446, 193996, 84], [193996, 197039, 85], [197039, 199543, 86], [199543, 201093, 87], [201093, 204219, 88], [204219, 207281, 89], [207281, 208812, 90], [208812, 211788, 91], [211788, 213214, 92], [213214, 216132, 93], [216132, 219065, 94], [219065, 221314, 95], [221314, 224238, 96], [224238, 227004, 97], [227004, 229940, 98], [229940, 231971, 99], [231971, 234074, 100], [234074, 237078, 101], [237078, 239930, 102], [239930, 242992, 103], [242992, 245919, 104], [245919, 247881, 105], [247881, 250093, 106], [250093, 253115, 107], [253115, 255989, 108], [255989, 258995, 109], [258995, 262067, 110], [262067, 264242, 111], [264242, 265255, 112], [265255, 267755, 113], [267755, 269577, 114], [269577, 272503, 115], [272503, 274946, 116], [274946, 277972, 117], [277972, 281119, 118], [281119, 282925, 119], [282925, 285876, 120], [285876, 288976, 121], [288976, 292018, 122], [292018, 294994, 123], [294994, 298061, 124], [298061, 300881, 125], [300881, 303857, 126], [303857, 306424, 127], [306424, 309254, 128], [309254, 311462, 129], [311462, 314254, 130], [314254, 317020, 131], [317020, 319431, 132], [319431, 322502, 133], [322502, 325504, 134], [325504, 328270, 135], [328270, 330417, 136], [330417, 332944, 137], [332944, 335975, 138], [335975, 338786, 139], [338786, 340913, 140], [340913, 343911, 141], [343911, 346779, 142], [346779, 349640, 143], [349640, 352610, 144], [352610, 355706, 145], [355706, 358561, 146], [358561, 361571, 147], [361571, 364284, 148], [364284, 367160, 149], [367160, 370163, 150], [370163, 373073, 151], [373073, 376090, 152], [376090, 379268, 153], [379268, 382393, 154], [382393, 385489, 155], [385489, 388531, 156], [388531, 391501, 157], [391501, 394509, 158], [394509, 397569, 159], [397569, 400543, 160], [400543, 403349, 161], [403349, 404310, 162], [404310, 406730, 163], [406730, 409672, 164], [409672, 412369, 165], [412369, 415342, 166], [415342, 418190, 167], [418190, 421058, 168], [421058, 424024, 169], [424024, 425810, 170], [425810, 428683, 171], [428683, 431766, 172], [431766, 433597, 173], [433597, 436266, 174], [436266, 438574, 175], [438574, 439981, 176], [439981, 442053, 177], [442053, 444119, 178], [444119, 447272, 179], [447272, 449241, 180], [449241, 451967, 181], [451967, 454981, 182], [454981, 457954, 183], [457954, 458955, 184], [458955, 461109, 185], [461109, 463934, 186], [463934, 465989, 187], [465989, 469103, 188], [469103, 472095, 189], [472095, 475101, 190], [475101, 478065, 191], [478065, 481166, 192], [481166, 484125, 193], [484125, 486698, 194], [486698, 489613, 195], [489613, 492404, 196], [492404, 494429, 197], [494429, 497194, 198], [497194, 500134, 199], [500134, 503130, 200], [503130, 506074, 201], [506074, 509142, 202], [509142, 512188, 203], [512188, 515364, 204], [515364, 518412, 205], [518412, 521276, 206], [521276, 522766, 207], [522766, 525711, 208], [525711, 528684, 209], [528684, 529861, 210], [529861, 532120, 211], [532120, 534859, 212], [534859, 537818, 213], [537818, 540857, 214], [540857, 542566, 215], [542566, 545371, 216], [545371, 546839, 217], [546839, 549918, 218], [549918, 552737, 219], [552737, 555699, 220], [555699, 558632, 221], [558632, 561713, 222], [561713, 564121, 223], [564121, 566425, 224], [566425, 569461, 225], [569461, 572210, 226], [572210, 575173, 227], [575173, 577981, 228], [577981, 580952, 229], [580952, 583950, 230], [583950, 586876, 231], [586876, 589923, 232], [589923, 592718, 233], [592718, 595736, 234], [595736, 598931, 235], [598931, 602036, 236], [602036, 605108, 237], [605108, 608592, 238], [608592, 611246, 239], [611246, 611528, 240], [611528, 613870, 241], [613870, 616167, 242], [616167, 619130, 243], [619130, 622095, 244], [622095, 625179, 245], [625179, 628077, 246], [628077, 631034, 247], [631034, 633677, 248], [633677, 636671, 249], [636671, 638637, 250], [638637, 641029, 251], [641029, 643857, 252], [643857, 646412, 253], [646412, 649239, 254], [649239, 652196, 255], [652196, 655006, 256], [655006, 657816, 257], [657816, 660822, 258], [660822, 663844, 259], [663844, 666930, 260], [666930, 669826, 261], [669826, 672685, 262], [672685, 675694, 263], [675694, 678433, 264], [678433, 681241, 265], [681241, 684103, 266], [684103, 686721, 267], [686721, 689545, 268], [689545, 691937, 269], [691937, 693890, 270], [693890, 695954, 271], [695954, 698841, 272], [698841, 700080, 273], [700080, 702472, 274], [702472, 704239, 275], [704239, 707259, 276], [707259, 710180, 277], [710180, 713170, 278], [713170, 716027, 279], [716027, 719073, 280], [719073, 722087, 281], [722087, 724023, 282], [724023, 727065, 283], [727065, 729941, 284], [729941, 732761, 285], [732761, 735588, 286], [735588, 737532, 287], [737532, 739909, 288], [739909, 742937, 289], [742937, 745976, 290], [745976, 748910, 291], [748910, 751861, 292], [751861, 754855, 293], [754855, 757843, 294], [757843, 760888, 295], [760888, 763974, 296], [763974, 767046, 297], [767046, 770024, 298], [770024, 773001, 299], [773001, 775953, 300], [775953, 778783, 301], [778783, 781615, 302], [781615, 784630, 303], [784630, 787605, 304], [787605, 790577, 305], [790577, 792974, 306], [792974, 796017, 307], [796017, 799354, 308], [799354, 802069, 309], [802069, 805158, 310], [805158, 807973, 311], [807973, 810890, 312], [810890, 813930, 313], [813930, 816895, 314], [816895, 819679, 315], [819679, 822018, 316], [822018, 824995, 317], [824995, 827908, 318], [827908, 830828, 319], [830828, 833886, 320], [833886, 836908, 321], [836908, 839505, 322], [839505, 842541, 323], [842541, 845392, 324], [845392, 846290, 325], [846290, 846814, 326], [846814, 848885, 327], [848885, 851117, 328], [851117, 853636, 329], [853636, 855927, 330], [855927, 858478, 331], [858478, 860712, 332], [860712, 863253, 333], [863253, 866307, 334], [866307, 869012, 335], [869012, 871509, 336], [871509, 874011, 337], [874011, 876494, 338], [876494, 878838, 339], [878838, 881011, 340], [881011, 882947, 341], [882947, 885565, 342], [885565, 887984, 343], [887984, 890263, 344], [890263, 892834, 345], [892834, 895182, 346], [895182, 897522, 347], [897522, 900114, 348], [900114, 902573, 349], [902573, 904904, 350], [904904, 907806, 351], [907806, 910111, 352], [910111, 912435, 353], [912435, 914651, 354], [914651, 917248, 355], [917248, 919656, 356], [919656, 922499, 357], [922499, 925048, 358], [925048, 927748, 359], [927748, 930457, 360], [930457, 932757, 361], [932757, 935097, 362], [935097, 937281, 363], [937281, 939962, 364], [939962, 942408, 365], [942408, 944792, 366], [944792, 947411, 367], [947411, 949817, 368], [949817, 952329, 369], [952329, 954357, 370], [954357, 956829, 371], [956829, 959266, 372], [959266, 961916, 373], [961916, 963568, 374], [963568, 965473, 375], [965473, 967807, 376], [967807, 970341, 377], [970341, 972626, 378], [972626, 974960, 379], [974960, 977321, 380], [977321, 979694, 381], [979694, 982119, 382], [982119, 984361, 383], [984361, 986496, 384], [986496, 988772, 385], [988772, 990982, 386], [990982, 993277, 387], [993277, 995627, 388], [995627, 997916, 389], [997916, 1000324, 390], [1000324, 1002472, 391], [1002472, 1004631, 392], [1004631, 1007074, 393], [1007074, 1009302, 394], [1009302, 1011695, 395], [1011695, 1013971, 396], [1013971, 1016337, 397], [1016337, 1018760, 398], [1018760, 1020993, 399], [1020993, 1023372, 400], [1023372, 1025741, 401], [1025741, 1028100, 402], [1028100, 1030301, 403], [1030301, 1031975, 404], [1031975, 1033211, 405], [1033211, 1034807, 406], [1034807, 1036246, 407], [1036246, 1037570, 408], [1037570, 1038799, 409], [1038799, 1040384, 410], [1040384, 1041593, 411], [1041593, 1043258, 412], [1043258, 1044750, 413], [1044750, 1046157, 414], [1046157, 1047613, 415], [1047613, 1049060, 416], [1049060, 1050519, 417], [1050519, 1051772, 418], [1051772, 1053252, 419], [1053252, 1054331, 420], [1054331, 1055698, 421], [1055698, 1057058, 422], [1057058, 1058420, 423], [1058420, 1059724, 424], [1059724, 1061338, 425], [1061338, 1063047, 426], [1063047, 1064494, 427], [1064494, 1065533, 428], [1065533, 1066772, 429], [1066772, 1068134, 430], [1068134, 1069488, 431], [1069488, 1070733, 432], [1070733, 1072242, 433], [1072242, 1073545, 434], [1073545, 1074745, 435], [1074745, 1076319, 436], [1076319, 1077828, 437], [1077828, 1079069, 438], [1079069, 1080703, 439], [1080703, 1082024, 440], [1082024, 1083522, 441], [1083522, 1084975, 442], [1084975, 1086249, 443], [1086249, 1087737, 444], [1087737, 1088086, 445], [1088086, 1089489, 446], [1089489, 1089836, 447], [1089836, 1089851, 448]], "primary_language": ["en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en"], "is_rotation_valid": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "rotation_correction": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "is_table": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "is_diagram": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false]}}
