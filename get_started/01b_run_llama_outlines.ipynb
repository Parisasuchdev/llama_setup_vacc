{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53557750",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'outlines'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moutlines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Generator, from_transformers, Template\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'outlines'"
     ]
    }
   ],
   "source": [
    "from outlines import Generator, from_transformers, Template\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from rich import print as rprint \n",
    "from rich.json import JSON  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6779e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.98s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support\n"
     ]
    }
   ],
   "source": [
    "# Define our multiple choice output type\n",
    "class Stance(Enum):\n",
    "    support = \"Support\"\n",
    "    oppose = \"Oppose\"\n",
    "    neutral = \"Neutral\"\n",
    "\n",
    "model_path = \"/gpfs1/llm/llama-3.2-hf/Meta-Llama-3.2-3B-Instruct\"\n",
    "\n",
    "model = from_transformers(\n",
    "    AutoModelForCausalLM.from_pretrained(model_path, device_map=\"cuda\"),\n",
    "    AutoTokenizer.from_pretrained(model_path)\n",
    ")\n",
    "\n",
    "# Generate text corresponding to either of the choices defined above\n",
    "result = model(\n",
    "    \"I used to strongly support breastfeeding, but now I am not so sure. I think it is a personal choice and should be respected either way. So, fed is best.\",\n",
    "    Stance,\n",
    ")\n",
    "rprint(JSON(result)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd2313",
   "metadata": {},
   "source": [
    "### Fancier way to accomplish the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3affc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Support\"</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"justification\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"The text starts by expressing a strong support for breastfeeding, but then shifts to a more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">nuanced view, acknowledging that it is a personal choice. The phrase 'So, fed is best' is a common slogan used to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">support breastfeeding, indicating that the author is still leaning towards breastfeeding as the best option.\"</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"topic\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"Breastfeeding\"</span>\n",
       "  <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"label\"\u001b[0m: \u001b[32m\"Support\"\u001b[0m,\n",
       "  \u001b[1;34m\"justification\"\u001b[0m: \u001b[32m\"The text starts by expressing a strong support for breastfeeding, but then shifts to a more \u001b[0m\n",
       "\u001b[32mnuanced view, acknowledging that it is a personal choice. The phrase 'So, fed is best' is a common slogan used to \u001b[0m\n",
       "\u001b[32msupport breastfeeding, indicating that the author is still leaning towards breastfeeding as the best option.\"\u001b[0m,\n",
       "  \u001b[1;34m\"topic\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "    \u001b[32m\"Breastfeeding\"\u001b[0m\n",
       "  \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using this approach, we can build more complex queries.\n",
    "class Topic(str, Enum):\n",
    "   BREASTFEEDING = \"Breastfeeding\"\n",
    "   VACCINES = \"Vaccines\"\n",
    "   SLEEP_TRAINING = \"Sleep_Training\"\n",
    "\n",
    "class Classification(BaseModel):\n",
    "   label: Stance \n",
    "   justification: str = Field(description=\"Why this stance?\")\n",
    "   topic: list[Topic]\n",
    "\n",
    "# See https://dottxt-ai.github.io/outlines/latest/guide/getting_started/#generators\n",
    "generator = Generator(model, Classification)\n",
    "\n",
    "# We use outlines.Template b/c they can live in a separate .txt file, \n",
    "# which is nice for benchmarking.\n",
    "text=\"I used to strongly support breastfeeding, but now I am not so sure. I think it is a personal choice and should be respected either way. So, fed is best.\"\n",
    "\n",
    "stance_template = Template.from_string(\"\"\"\n",
    "### Instruction:\n",
    "Classify the stance of the following text as Support, Oppose, or Neutral.\n",
    "\n",
    "### Input:\n",
    "{{ text }}\n",
    "\n",
    "### Response\n",
    "\"\"\")\n",
    "\n",
    "prompt = stance_template(text=text)\n",
    "\n",
    "result = generator(prompt, max_new_tokens=400, temperature=0.0, do_sample=False)\n",
    "rprint(JSON(result)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-setup-vacc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
