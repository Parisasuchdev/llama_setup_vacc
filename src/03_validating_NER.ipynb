{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12803792",
   "metadata": {},
   "source": [
    "Extra Spacy dependencies:\n",
    "- `uv pip install pip`\n",
    "- `python -m spacy download en_core_web_trf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27f983d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/j/s/jstonge1/llama_setup_vacc/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from outlines import Generator, from_transformers, Template\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from rich import print as rprint \n",
    "from textwrap import wrap\n",
    "from rich.json import JSON  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e367978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6f2ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14de169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This text is longer, and requires some handling.\n",
    "# It contains boilerplate text too.\n",
    "text = \"\"\"2 | THE PERSISTENCE OF THE WORD\n",
    "(There Is No Dictionary in the Mind)\n",
    "Odysseus wept when he heard the poet sing of his great deeds abroad because, once sung, they were no longer his alone. They belonged to anyone who heard the song.\n",
    "—Ward Just (2004)\n",
    "“TRY TO IMAGINE,” proposed Walter J. Ong, Jesuit priest, philosopher, and cultural historian, “a culture where no one has ever ‘looked up’ anything.” To subtract the technologies of information internalized over two millennia requires a leap of imagination backward into a forgotten past. The hardest technology to erase from our minds is the first of all: writing. This arises at the very dawn of history, as it must, because the history begins with the writing. The pastness of the past depends on it.\n",
    "It takes a few thousand years for this mapping of language onto a system of signs to become second nature, and then there is no return to naïveté. Forgotten is the time when our very awareness of words came from seeing them. “In a primary oral culture,” as Ong noted,\n",
    "the expression “to look up something” is an empty phrase: it would have no conceivable meaning. Without writing, words as such have no visual presence, even when the objects they represent are visual. They are sounds. You might “call” them back—“recall” them. But there is nowhere to “look” for them. They have no focus and no trace.\n",
    "In the 1960s and ’70s, Ong declared the electronic age to be a new age of orality—but of “secondary orality,” the spoken word amplified and extended as never before, but always in the context of literacy: voices heard against a background of ubiquitous print. The first age of orality had lasted quite a bit longer. It covered almost the entire lifetime of the species, writing being a late development, general literacy being almost an afterthought. Like Marshall McLuhan, with whom he was often compared (“the other eminent Catholic-electronic prophet,” said a scornful Frank Kermode), Ong had the misfortune to make his visionary assessments of a new age just before it actually arrived. The new media seemed to be radio, telephone, and television. But these were just the faint glimmerings in the night sky, signaling the light that still lay just beyond the horizon. Whether Ong would have seen cyberspace as fundamentally oral or literary, he would surely have recognized it as transformative: not just a revitalization of older forms, not just an amplification, but something wholly new. He might have sensed a coming discontinuity akin to the emergence of literacy itself. Few understood better than Ong just how profound a discontinuity that had been.\n",
    "When he began his studies, “oral literature” was a common phrase. It is an oxymoron laced with anachronism; the words imply an all-too-unconscious approach to the past by way of the present. Oral literature was generally treated as a variant of writing; this, Ong said, was “rather like thinking of horses as automobiles without wheels.”\n",
    "You can, of course, undertake to do this. Imagine writing a treatise on horses (for people who have never seen a horse) which starts with the concept not of “horse” but of “automobile,” built on the readers’ direct experience of automobiles. It proceeds to discourse on horses by always referring to them as “wheelless automobiles,” explaining to highly automobilized readers all the points of difference…. Instead of wheels, the wheelless automobiles have enlarged toenails called hooves; instead of headlights, eyes; instead of a coat of lacquer, something called hair; instead of gasoline for fuel, hay, and so on. In the end, horses are only what they are not.\n",
    "When it comes to understanding the preliterate past, we modern folk are hopelessly automobilized. The written word is the mechanism by which we know what we know. It organizes our thought. We may wish to understand the rise of literacy both historically and logically, but history and logic are themselves the products of literate thought.\n",
    "Writing, as a technology, requires premeditation and special art. Language is not a technology, no matter how well developed and efficacious. It is not best seen as something separate from the mind; it is what the mind does. “Language in fact bears the same relationship to the concept of mind that legislation bears to the concept of parliament,” says Jonathan Miller: “it is a competence forever bodying itself in a series of concrete performances.” Much the same might be said of writing—it is concrete performance—but when the word is instantiated in paper or stone, it takes on a separate existence as artifice. It is a product of tools, and it is a tool. And like many technologies that followed, it thereby inspired immediate detractors.\n",
    "One unlikely Luddite was also one of the first long-term beneficiaries. Plato (channeling the nonwriter Socrates) warned that this technology meant impoverishment:\n",
    "For this invention will produce forgetfulness in the minds of those who learn to use it, because they will not practice their memory. Their trust in writing, produced by external characters which are no part of themselves, will discourage the use of their own memory within them. You have invented an elixir not of memory, but of reminding; and you offer your pupils the appearance of wisdom, not true wisdom.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bcc387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd8cfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token persons (14): ['Odysseus', 'Ward Just', 'Walter J. Ong', 'Ong', 'Ong', 'Marshall McLuhan', 'Frank Kermode', 'Ong', 'Ong', 'Ong', 'Ong', 'Jonathan Miller', 'Plato', 'Socrates']\n",
      "Types persons (9): {'Ward Just', 'Frank Kermode', 'Marshall McLuhan', 'Odysseus', 'Socrates', 'Jonathan Miller', 'Ong', 'Walter J. Ong', 'Plato'}\n"
     ]
    }
   ],
   "source": [
    "persons_spacy = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"] \n",
    "print(f\"Token persons ({len(persons_spacy)}): {persons_spacy}\")\n",
    "print(f\"Types persons ({len(set(persons_spacy))}): {set(persons_spacy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3e4320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://dottxt-ai.github.io/outlines/main/examples/extraction/\n",
    "template_ner = Template.from_string(\n",
    "    \"\"\"You are an experienced history of science professor.\n",
    "\n",
    "Given some text, you need to extract:\n",
    "\n",
    "1. The canonical name of characters in the book\n",
    "2. The alternative display names of characters \n",
    "\n",
    "# Examples\n",
    "\n",
    "TEXT: It fell to John F. Carrington to explain. An English missionary, born in 1914 in\n",
    "Northamptonshire, Carrington left for Africa at the age of twenty-four and Africa\n",
    "became his lifetime home.\n",
    "RESULT: {\"display_name\": \"John F. Carrington\", alternative_display_names: [\"Carrington\"]}\n",
    "\n",
    "# OUTPUT INSTRUCTIONS\n",
    "\n",
    "Answer in valid JSON. Here are the different objects relevant for the output:\n",
    "\n",
    "Person:\n",
    "        display_name (str): canonical name of character\n",
    "        alternative_display_names (list[str]): alternative display names of the character\n",
    "\n",
    "Return a valid JSON of type \"Person\"\n",
    "        \n",
    "# OUTPUT\n",
    "\n",
    "PERSON: {{ text }}\n",
    "RESULT: \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb1db4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person(BaseModel):\n",
    "    display_name: str = Field(description=\"The name of the author as a single string.\")\n",
    "    display_name_alternatives: list[str] = Field(description=\"Other ways that we've found this author's name displayed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70057a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.34s/it]\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/gpfs1/llm/llama-3.2-hf/Meta-Llama-3.2-3B-Instruct\"\n",
    "\n",
    "model = from_transformers(\n",
    "    AutoModelForCausalLM.from_pretrained(model_path, device_map=\"cuda\"),\n",
    "    AutoTokenizer.from_pretrained(model_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d8356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template_ner(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a9e9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(model, Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "120d47c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/j/s/jstonge1/llama_setup_vacc/.venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/users/j/s/jstonge1/llama_setup_vacc/.venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"display_name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Walter J. Ong\"</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"display_name_alternatives\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"Ong, Walter J.\"</span>\n",
       "  <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"display_name\"\u001b[0m: \u001b[32m\"Walter J. Ong\"\u001b[0m,\n",
       "  \u001b[1;34m\"display_name_alternatives\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "    \u001b[32m\"Ong, Walter J.\"\u001b[0m\n",
       "  \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = generator(prompt, max_new_tokens=400, temperature=0.0, do_sample=False)\n",
    "rprint(JSON(result)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
